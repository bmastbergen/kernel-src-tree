bpf: Support attaching tracing BPF program to other BPF programs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Alexei Starovoitov <ast@kernel.org>
commit 5b92a28aae4dd0f88778d540ecfdcdaec5a41723
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/5b92a28a.failed

Allow FENTRY/FEXIT BPF programs to attach to other BPF programs of any type
including their subprograms. This feature allows snooping on input and output
packets in XDP, TC programs including their return values. In order to do that
the verifier needs to track types not only of vmlinux, but types of other BPF
programs as well. The verifier also needs to translate uapi/linux/bpf.h types
used by networking programs into kernel internal BTF types used by FENTRY/FEXIT
BPF programs. In some cases LLVM optimizations can remove arguments from BPF
subprograms without adjusting BTF info that LLVM backend knows. When BTF info
disagrees with actual types that the verifiers sees the BPF trampoline has to
fallback to conservative and treat all arguments as u64. The FENTRY/FEXIT
program can still attach to such subprograms, but it won't be able to recognize
pointer types like 'struct sk_buff *' and it won't be able to pass them to
bpf_skb_output() for dumping packets to user space. The FENTRY/FEXIT program
would need to use bpf_probe_read_kernel() instead.

The BPF_PROG_LOAD command is extended with attach_prog_fd field. When it's set
to zero the attach_btf_id is one vmlinux BTF type ids. When attach_prog_fd
points to previously loaded BPF program the attach_btf_id is BTF type id of
main function or one of its subprograms.

	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Acked-by: Song Liu <songliubraving@fb.com>
Link: https://lore.kernel.org/bpf/20191114185720.1641606-18-ast@kernel.org
(cherry picked from commit 5b92a28aae4dd0f88778d540ecfdcdaec5a41723)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	include/uapi/linux/bpf.h
#	kernel/bpf/btf.c
#	kernel/bpf/syscall.c
#	kernel/bpf/verifier.c
diff --cc include/linux/bpf.h
index a5585413dfbe,5b81cde47314..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -399,9 -493,20 +399,16 @@@ struct bpf_prog_aux 
  	u32 stack_depth;
  	u32 id;
  	u32 func_cnt; /* used by non-func prog as the number of func progs */
++<<<<<<< HEAD
 +	RH_KABI_BROKEN_INSERT(u32 func_idx) /* 0 for non-func prog, the index in func array for func prog */
 +	RH_KABI_BROKEN_INSERT(bool verifier_zext) /* Zero extensions has been inserted by verifier. */
++=======
+ 	u32 func_idx; /* 0 for non-func prog, the index in func array for func prog */
+ 	u32 attach_btf_id; /* in-kernel BTF type id to attach to */
+ 	struct bpf_prog *linked_prog;
+ 	bool verifier_zext; /* Zero extensions has been inserted by verifier. */
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  	bool offload_requested;
 -	bool attach_btf_trace; /* true if attaching to BTF-enabled raw tp */
 -	bool func_proto_unreliable;
 -	enum bpf_tramp_prog_type trampoline_prog_type;
 -	struct bpf_trampoline *trampoline;
 -	struct hlist_node tramp_hlist;
 -	/* BTF_KIND_FUNC_PROTO for valid attach_btf_id */
 -	const struct btf_type *attach_func_proto;
 -	/* function name for valid attach_btf_id */
 -	const char *attach_func_name;
  	struct bpf_prog **func;
  	void *jit_data; /* JIT specific data. arch dependent */
  	struct latch_tree_node ksym_tnode;
diff --cc include/uapi/linux/bpf.h
index f26f93a554f1,4842a134b202..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -426,7 -424,8 +426,12 @@@ union bpf_attr 
  		__u32		line_info_rec_size;	/* userspace bpf_line_info size */
  		__aligned_u64	line_info;	/* line info */
  		__u32		line_info_cnt;	/* number of bpf_line_info records */
++<<<<<<< HEAD
 +#endif /* __GENKSYMS__ */
++=======
+ 		__u32		attach_btf_id;	/* in-kernel BTF type id to attach to */
+ 		__u32		attach_prog_fd; /* 0 to attach to vmlinux */
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  	};
  
  	struct { /* anonymous struct used by BPF_OBJ_* commands */
diff --cc kernel/bpf/btf.c
index dc1f2324f36a,40efde5eedcb..000000000000
--- a/kernel/bpf/btf.c
+++ b/kernel/bpf/btf.c
@@@ -3459,7 -3444,106 +3459,21 @@@ errout
  
  extern char __weak _binary__btf_vmlinux_bin_start[];
  extern char __weak _binary__btf_vmlinux_bin_end[];
 -extern struct btf *btf_vmlinux;
 -
 -#define BPF_MAP_TYPE(_id, _ops)
 -static union {
 -	struct bpf_ctx_convert {
 -#define BPF_PROG_TYPE(_id, _name, prog_ctx_type, kern_ctx_type) \
 -	prog_ctx_type _id##_prog; \
 -	kern_ctx_type _id##_kern;
 -#include <linux/bpf_types.h>
 -#undef BPF_PROG_TYPE
 -	} *__t;
 -	/* 't' is written once under lock. Read many times. */
 -	const struct btf_type *t;
 -} bpf_ctx_convert;
 -enum {
 -#define BPF_PROG_TYPE(_id, _name, prog_ctx_type, kern_ctx_type) \
 -	__ctx_convert##_id,
 -#include <linux/bpf_types.h>
 -#undef BPF_PROG_TYPE
 -};
 -static u8 bpf_ctx_convert_map[] = {
 -#define BPF_PROG_TYPE(_id, _name, prog_ctx_type, kern_ctx_type) \
 -	[_id] = __ctx_convert##_id,
 -#include <linux/bpf_types.h>
 -#undef BPF_PROG_TYPE
 -};
 -#undef BPF_MAP_TYPE
 -
 -static const struct btf_member *
 -btf_get_prog_ctx_type(struct bpf_verifier_log *log, struct btf *btf,
 -		      const struct btf_type *t, enum bpf_prog_type prog_type)
 -{
 -	const struct btf_type *conv_struct;
 -	const struct btf_type *ctx_struct;
 -	const struct btf_member *ctx_type;
 -	const char *tname, *ctx_tname;
 -
 -	conv_struct = bpf_ctx_convert.t;
 -	if (!conv_struct) {
 -		bpf_log(log, "btf_vmlinux is malformed\n");
 -		return NULL;
 -	}
 -	t = btf_type_by_id(btf, t->type);
 -	while (btf_type_is_modifier(t))
 -		t = btf_type_by_id(btf, t->type);
 -	if (!btf_type_is_struct(t)) {
 -		/* Only pointer to struct is supported for now.
 -		 * That means that BPF_PROG_TYPE_TRACEPOINT with BTF
 -		 * is not supported yet.
 -		 * BPF_PROG_TYPE_RAW_TRACEPOINT is fine.
 -		 */
 -		bpf_log(log, "BPF program ctx type is not a struct\n");
 -		return NULL;
 -	}
 -	tname = btf_name_by_offset(btf, t->name_off);
 -	if (!tname) {
 -		bpf_log(log, "BPF program ctx struct doesn't have a name\n");
 -		return NULL;
 -	}
 -	/* prog_type is valid bpf program type. No need for bounds check. */
 -	ctx_type = btf_type_member(conv_struct) + bpf_ctx_convert_map[prog_type] * 2;
 -	/* ctx_struct is a pointer to prog_ctx_type in vmlinux.
 -	 * Like 'struct __sk_buff'
 -	 */
 -	ctx_struct = btf_type_by_id(btf_vmlinux, ctx_type->type);
 -	if (!ctx_struct)
 -		/* should not happen */
 -		return NULL;
 -	ctx_tname = btf_name_by_offset(btf_vmlinux, ctx_struct->name_off);
 -	if (!ctx_tname) {
 -		/* should not happen */
 -		bpf_log(log, "Please fix kernel include/linux/bpf_types.h\n");
 -		return NULL;
 -	}
 -	/* only compare that prog's ctx type name is the same as
 -	 * kernel expects. No need to compare field by field.
 -	 * It's ok for bpf prog to do:
 -	 * struct __sk_buff {};
 -	 * int socket_filter_bpf_prog(struct __sk_buff *skb)
 -	 * { // no fields of skb are ever used }
 -	 */
 -	if (strcmp(ctx_tname, tname))
 -		return NULL;
 -	return ctx_type;
 -}
  
+ static int btf_translate_to_vmlinux(struct bpf_verifier_log *log,
+ 				     struct btf *btf,
+ 				     const struct btf_type *t,
+ 				     enum bpf_prog_type prog_type)
+ {
+ 	const struct btf_member *prog_ctx_type, *kern_ctx_type;
+ 
+ 	prog_ctx_type = btf_get_prog_ctx_type(log, btf, t, prog_type);
+ 	if (!prog_ctx_type)
+ 		return -ENOENT;
+ 	kern_ctx_type = prog_ctx_type + 1;
+ 	return kern_ctx_type->type;
+ }
+ 
  struct btf *btf_parse_vmlinux(void)
  {
  	struct btf_verifier_env *env = NULL;
@@@ -3512,76 -3616,73 +3526,125 @@@ errout
  	return ERR_PTR(err);
  }
  
++<<<<<<< HEAD
 +extern struct btf *btf_vmlinux;
++=======
+ struct btf *bpf_prog_get_target_btf(const struct bpf_prog *prog)
+ {
+ 	struct bpf_prog *tgt_prog = prog->aux->linked_prog;
+ 
+ 	if (tgt_prog) {
+ 		return tgt_prog->aux->btf;
+ 	} else {
+ 		return btf_vmlinux;
+ 	}
+ }
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  
  bool btf_ctx_access(int off, int size, enum bpf_access_type type,
  		    const struct bpf_prog *prog,
  		    struct bpf_insn_access_aux *info)
  {
++<<<<<<< HEAD
++=======
+ 	const struct btf_type *t = prog->aux->attach_func_proto;
+ 	struct bpf_prog *tgt_prog = prog->aux->linked_prog;
+ 	struct btf *btf = bpf_prog_get_target_btf(prog);
+ 	const char *tname = prog->aux->attach_func_name;
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  	struct bpf_verifier_log *log = info->log;
 +	u32 btf_id = prog->aux->attach_btf_id;
  	const struct btf_param *args;
 +	const struct btf_type *t;
 +	const char prefix[] = "btf_trace_";
 +	const char *tname;
  	u32 nr_args, arg;
+ 	int ret;
  
 +	if (!btf_id)
 +		return true;
 +
 +	if (IS_ERR(btf_vmlinux)) {
 +		bpf_log(log, "btf_vmlinux is malformed\n");
 +		return false;
 +	}
 +
 +	t = btf_type_by_id(btf_vmlinux, btf_id);
 +	if (!t || BTF_INFO_KIND(t->info) != BTF_KIND_TYPEDEF) {
 +		bpf_log(log, "btf_id is invalid\n");
 +		return false;
 +	}
 +
 +	tname = __btf_name_by_offset(btf_vmlinux, t->name_off);
 +	if (strncmp(prefix, tname, sizeof(prefix) - 1)) {
 +		bpf_log(log, "btf_id points to wrong type name %s\n", tname);
 +		return false;
 +	}
 +	tname += sizeof(prefix) - 1;
 +
 +	t = btf_type_by_id(btf_vmlinux, t->type);
 +	if (!btf_type_is_ptr(t))
 +		return false;
 +	t = btf_type_by_id(btf_vmlinux, t->type);
 +	if (!btf_type_is_func_proto(t))
 +		return false;
 +
  	if (off % 8) {
 -		bpf_log(log, "func '%s' offset %d is not multiple of 8\n",
 +		bpf_log(log, "raw_tp '%s' offset %d is not multiple of 8\n",
  			tname, off);
  		return false;
  	}
  	arg = off / 8;
  	args = (const struct btf_param *)(t + 1);
++<<<<<<< HEAD
 +	/* skip first 'void *__data' argument in btf_trace_##name typedef */
 +	args++;
 +	nr_args = btf_type_vlen(t) - 1;
 +	if (arg >= nr_args) {
 +		bpf_log(log, "raw_tp '%s' doesn't have %d-th argument\n",
 +			tname, arg);
 +		return false;
 +	}
 +
 +	t = btf_type_by_id(btf_vmlinux, args[arg].type);
++=======
+ 	/* if (t == NULL) Fall back to default BPF prog with 5 u64 arguments */
+ 	nr_args = t ? btf_type_vlen(t) : 5;
+ 	if (prog->aux->attach_btf_trace) {
+ 		/* skip first 'void *__data' argument in btf_trace_##name typedef */
+ 		args++;
+ 		nr_args--;
+ 	}
+ 
+ 	if (prog->expected_attach_type == BPF_TRACE_FEXIT &&
+ 	    arg == nr_args) {
+ 		if (!t)
+ 			/* Default prog with 5 args. 6th arg is retval. */
+ 			return true;
+ 		/* function return type */
+ 		t = btf_type_by_id(btf, t->type);
+ 	} else if (arg >= nr_args) {
+ 		bpf_log(log, "func '%s' doesn't have %d-th argument\n",
+ 			tname, arg + 1);
+ 		return false;
+ 	} else {
+ 		if (!t)
+ 			/* Default prog with 5 args */
+ 			return true;
+ 		t = btf_type_by_id(btf, args[arg].type);
+ 	}
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  	/* skip modifiers */
  	while (btf_type_is_modifier(t))
- 		t = btf_type_by_id(btf_vmlinux, t->type);
+ 		t = btf_type_by_id(btf, t->type);
  	if (btf_type_is_int(t))
  		/* accessing a scalar */
  		return true;
  	if (!btf_type_is_ptr(t)) {
  		bpf_log(log,
 -			"func '%s' arg%d '%s' has type %s. Only pointer access is allowed\n",
 +			"raw_tp '%s' arg%d '%s' has type %s. Only pointer access is allowed\n",
  			tname, arg,
- 			__btf_name_by_offset(btf_vmlinux, t->name_off),
+ 			__btf_name_by_offset(btf, t->name_off),
  			btf_kind_str[BTF_INFO_KIND(t->info)]);
  		return false;
  	}
@@@ -3596,19 -3697,28 +3659,28 @@@
  	info->reg_type = PTR_TO_BTF_ID;
  	info->btf_id = t->type;
  
- 	t = btf_type_by_id(btf_vmlinux, t->type);
+ 	if (tgt_prog) {
+ 		ret = btf_translate_to_vmlinux(log, btf, t, tgt_prog->type);
+ 		if (ret > 0) {
+ 			info->btf_id = ret;
+ 			return true;
+ 		} else {
+ 			return false;
+ 		}
+ 	}
+ 	t = btf_type_by_id(btf, t->type);
  	/* skip modifiers */
  	while (btf_type_is_modifier(t))
- 		t = btf_type_by_id(btf_vmlinux, t->type);
+ 		t = btf_type_by_id(btf, t->type);
  	if (!btf_type_is_struct(t)) {
  		bpf_log(log,
 -			"func '%s' arg%d type %s is not a struct\n",
 +			"raw_tp '%s' arg%d type %s is not a struct\n",
  			tname, arg, btf_kind_str[BTF_INFO_KIND(t->info)]);
  		return false;
  	}
 -	bpf_log(log, "func '%s' arg%d has btf_id %d type %s '%s'\n",
 +	bpf_log(log, "raw_tp '%s' arg%d has btf_id %d type %s '%s'\n",
  		tname, arg, info->btf_id, btf_kind_str[BTF_INFO_KIND(t->info)],
- 		__btf_name_by_offset(btf_vmlinux, t->name_off));
+ 		__btf_name_by_offset(btf, t->name_off));
  	return true;
  }
  
@@@ -3763,6 -3873,254 +3835,257 @@@ again
  	return -EINVAL;
  }
  
++<<<<<<< HEAD
++=======
+ static int __btf_resolve_helper_id(struct bpf_verifier_log *log, void *fn,
+ 				   int arg)
+ {
+ 	char fnname[KSYM_SYMBOL_LEN + 4] = "btf_";
+ 	const struct btf_param *args;
+ 	const struct btf_type *t;
+ 	const char *tname, *sym;
+ 	u32 btf_id, i;
+ 
+ 	if (IS_ERR(btf_vmlinux)) {
+ 		bpf_log(log, "btf_vmlinux is malformed\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	sym = kallsyms_lookup((long)fn, NULL, NULL, NULL, fnname + 4);
+ 	if (!sym) {
+ 		bpf_log(log, "kernel doesn't have kallsyms\n");
+ 		return -EFAULT;
+ 	}
+ 
+ 	for (i = 1; i <= btf_vmlinux->nr_types; i++) {
+ 		t = btf_type_by_id(btf_vmlinux, i);
+ 		if (BTF_INFO_KIND(t->info) != BTF_KIND_TYPEDEF)
+ 			continue;
+ 		tname = __btf_name_by_offset(btf_vmlinux, t->name_off);
+ 		if (!strcmp(tname, fnname))
+ 			break;
+ 	}
+ 	if (i > btf_vmlinux->nr_types) {
+ 		bpf_log(log, "helper %s type is not found\n", fnname);
+ 		return -ENOENT;
+ 	}
+ 
+ 	t = btf_type_by_id(btf_vmlinux, t->type);
+ 	if (!btf_type_is_ptr(t))
+ 		return -EFAULT;
+ 	t = btf_type_by_id(btf_vmlinux, t->type);
+ 	if (!btf_type_is_func_proto(t))
+ 		return -EFAULT;
+ 
+ 	args = (const struct btf_param *)(t + 1);
+ 	if (arg >= btf_type_vlen(t)) {
+ 		bpf_log(log, "bpf helper %s doesn't have %d-th argument\n",
+ 			fnname, arg);
+ 		return -EINVAL;
+ 	}
+ 
+ 	t = btf_type_by_id(btf_vmlinux, args[arg].type);
+ 	if (!btf_type_is_ptr(t) || !t->type) {
+ 		/* anything but the pointer to struct is a helper config bug */
+ 		bpf_log(log, "ARG_PTR_TO_BTF is misconfigured\n");
+ 		return -EFAULT;
+ 	}
+ 	btf_id = t->type;
+ 	t = btf_type_by_id(btf_vmlinux, t->type);
+ 	/* skip modifiers */
+ 	while (btf_type_is_modifier(t)) {
+ 		btf_id = t->type;
+ 		t = btf_type_by_id(btf_vmlinux, t->type);
+ 	}
+ 	if (!btf_type_is_struct(t)) {
+ 		bpf_log(log, "ARG_PTR_TO_BTF is not a struct\n");
+ 		return -EFAULT;
+ 	}
+ 	bpf_log(log, "helper %s arg%d has btf_id %d struct %s\n", fnname + 4,
+ 		arg, btf_id, __btf_name_by_offset(btf_vmlinux, t->name_off));
+ 	return btf_id;
+ }
+ 
+ int btf_resolve_helper_id(struct bpf_verifier_log *log,
+ 			  const struct bpf_func_proto *fn, int arg)
+ {
+ 	int *btf_id = &fn->btf_id[arg];
+ 	int ret;
+ 
+ 	if (fn->arg_type[arg] != ARG_PTR_TO_BTF_ID)
+ 		return -EINVAL;
+ 
+ 	ret = READ_ONCE(*btf_id);
+ 	if (ret)
+ 		return ret;
+ 	/* ok to race the search. The result is the same */
+ 	ret = __btf_resolve_helper_id(log, fn->func, arg);
+ 	if (!ret) {
+ 		/* Function argument cannot be type 'void' */
+ 		bpf_log(log, "BTF resolution bug\n");
+ 		return -EFAULT;
+ 	}
+ 	WRITE_ONCE(*btf_id, ret);
+ 	return ret;
+ }
+ 
+ static int __get_type_size(struct btf *btf, u32 btf_id,
+ 			   const struct btf_type **bad_type)
+ {
+ 	const struct btf_type *t;
+ 
+ 	if (!btf_id)
+ 		/* void */
+ 		return 0;
+ 	t = btf_type_by_id(btf, btf_id);
+ 	while (t && btf_type_is_modifier(t))
+ 		t = btf_type_by_id(btf, t->type);
+ 	if (!t)
+ 		return -EINVAL;
+ 	if (btf_type_is_ptr(t))
+ 		/* kernel size of pointer. Not BPF's size of pointer*/
+ 		return sizeof(void *);
+ 	if (btf_type_is_int(t) || btf_type_is_enum(t))
+ 		return t->size;
+ 	*bad_type = t;
+ 	return -EINVAL;
+ }
+ 
+ int btf_distill_func_proto(struct bpf_verifier_log *log,
+ 			   struct btf *btf,
+ 			   const struct btf_type *func,
+ 			   const char *tname,
+ 			   struct btf_func_model *m)
+ {
+ 	const struct btf_param *args;
+ 	const struct btf_type *t;
+ 	u32 i, nargs;
+ 	int ret;
+ 
+ 	if (!func) {
+ 		/* BTF function prototype doesn't match the verifier types.
+ 		 * Fall back to 5 u64 args.
+ 		 */
+ 		for (i = 0; i < 5; i++)
+ 			m->arg_size[i] = 8;
+ 		m->ret_size = 8;
+ 		m->nr_args = 5;
+ 		return 0;
+ 	}
+ 	args = (const struct btf_param *)(func + 1);
+ 	nargs = btf_type_vlen(func);
+ 	if (nargs >= MAX_BPF_FUNC_ARGS) {
+ 		bpf_log(log,
+ 			"The function %s has %d arguments. Too many.\n",
+ 			tname, nargs);
+ 		return -EINVAL;
+ 	}
+ 	ret = __get_type_size(btf, func->type, &t);
+ 	if (ret < 0) {
+ 		bpf_log(log,
+ 			"The function %s return type %s is unsupported.\n",
+ 			tname, btf_kind_str[BTF_INFO_KIND(t->info)]);
+ 		return -EINVAL;
+ 	}
+ 	m->ret_size = ret;
+ 
+ 	for (i = 0; i < nargs; i++) {
+ 		ret = __get_type_size(btf, args[i].type, &t);
+ 		if (ret < 0) {
+ 			bpf_log(log,
+ 				"The function %s arg%d type %s is unsupported.\n",
+ 				tname, i, btf_kind_str[BTF_INFO_KIND(t->info)]);
+ 			return -EINVAL;
+ 		}
+ 		m->arg_size[i] = ret;
+ 	}
+ 	m->nr_args = nargs;
+ 	return 0;
+ }
+ 
+ int btf_check_func_arg_match(struct bpf_verifier_env *env, int subprog)
+ {
+ 	struct bpf_verifier_state *st = env->cur_state;
+ 	struct bpf_func_state *func = st->frame[st->curframe];
+ 	struct bpf_reg_state *reg = func->regs;
+ 	struct bpf_verifier_log *log = &env->log;
+ 	struct bpf_prog *prog = env->prog;
+ 	struct btf *btf = prog->aux->btf;
+ 	const struct btf_param *args;
+ 	const struct btf_type *t;
+ 	u32 i, nargs, btf_id;
+ 	const char *tname;
+ 
+ 	if (!prog->aux->func_info)
+ 		return 0;
+ 
+ 	btf_id = prog->aux->func_info[subprog].type_id;
+ 	if (!btf_id)
+ 		return 0;
+ 
+ 	if (prog->aux->func_info_aux[subprog].unreliable)
+ 		return 0;
+ 
+ 	t = btf_type_by_id(btf, btf_id);
+ 	if (!t || !btf_type_is_func(t)) {
+ 		bpf_log(log, "BTF of subprog %d doesn't point to KIND_FUNC\n",
+ 			subprog);
+ 		return -EINVAL;
+ 	}
+ 	tname = btf_name_by_offset(btf, t->name_off);
+ 
+ 	t = btf_type_by_id(btf, t->type);
+ 	if (!t || !btf_type_is_func_proto(t)) {
+ 		bpf_log(log, "Invalid type of func %s\n", tname);
+ 		return -EINVAL;
+ 	}
+ 	args = (const struct btf_param *)(t + 1);
+ 	nargs = btf_type_vlen(t);
+ 	if (nargs > 5) {
+ 		bpf_log(log, "Function %s has %d > 5 args\n", tname, nargs);
+ 		goto out;
+ 	}
+ 	/* check that BTF function arguments match actual types that the
+ 	 * verifier sees.
+ 	 */
+ 	for (i = 0; i < nargs; i++) {
+ 		t = btf_type_by_id(btf, args[i].type);
+ 		while (btf_type_is_modifier(t))
+ 			t = btf_type_by_id(btf, t->type);
+ 		if (btf_type_is_int(t) || btf_type_is_enum(t)) {
+ 			if (reg[i + 1].type == SCALAR_VALUE)
+ 				continue;
+ 			bpf_log(log, "R%d is not a scalar\n", i + 1);
+ 			goto out;
+ 		}
+ 		if (btf_type_is_ptr(t)) {
+ 			if (reg[i + 1].type == SCALAR_VALUE) {
+ 				bpf_log(log, "R%d is not a pointer\n", i + 1);
+ 				goto out;
+ 			}
+ 			/* If program is passing PTR_TO_CTX into subprogram
+ 			 * check that BTF type matches.
+ 			 */
+ 			if (reg[i + 1].type == PTR_TO_CTX &&
+ 			    !btf_get_prog_ctx_type(log, btf, t, prog->type))
+ 				goto out;
+ 			/* All other pointers are ok */
+ 			continue;
+ 		}
+ 		bpf_log(log, "Unrecognized argument type %s\n",
+ 			btf_kind_str[BTF_INFO_KIND(t->info)]);
+ 		goto out;
+ 	}
+ 	return 0;
+ out:
+ 	/* LLVM optimizations can remove arguments from static functions. */
+ 	bpf_log(log,
+ 		"Type info disagrees with actual arguments due to compiler optimizations\n");
+ 	prog->aux->func_info_aux[subprog].unreliable = true;
+ 	return 0;
+ }
+ 
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  void btf_type_seq_show(const struct btf *btf, u32 type_id, void *obj,
  		       struct seq_file *m)
  {
diff --cc kernel/bpf/syscall.c
index dd68cbc967e7,c88c815c2154..000000000000
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@@ -1636,11 -1575,12 +1636,17 @@@ static void bpf_prog_load_fixup_attach_
  }
  
  static int
++<<<<<<< HEAD
 +bpf_prog_load_check_attach_type(enum bpf_prog_type prog_type,
 +				enum bpf_attach_type expected_attach_type)
++=======
+ bpf_prog_load_check_attach(enum bpf_prog_type prog_type,
+ 			   enum bpf_attach_type expected_attach_type,
+ 			   u32 btf_id, u32 prog_fd)
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  {
  	switch (prog_type) {
 -	case BPF_PROG_TYPE_TRACING:
 +	case BPF_PROG_TYPE_RAW_TRACEPOINT:
  		if (btf_id > BTF_MAX_TYPE)
  			return -EINVAL;
  		break;
@@@ -1696,7 -1636,7 +1702,11 @@@
  }
  
  /* last field in 'union bpf_attr' used by this command */
++<<<<<<< HEAD
 +#define	BPF_PROG_LOAD_LAST_FIELD line_info_cnt
++=======
+ #define	BPF_PROG_LOAD_LAST_FIELD attach_prog_fd
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  
  static int bpf_prog_load(union bpf_attr *attr, union bpf_attr __user *uattr)
  {
@@@ -1738,7 -1678,9 +1748,13 @@@
  		return -EPERM;
  
  	bpf_prog_load_fixup_attach_type(attr);
++<<<<<<< HEAD
 +	if (bpf_prog_load_check_attach_type(type, attr->expected_attach_type))
++=======
+ 	if (bpf_prog_load_check_attach(type, attr->expected_attach_type,
+ 				       attr->attach_btf_id,
+ 				       attr->attach_prog_fd))
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  		return -EINVAL;
  
  	/* plain bpf_prog allocation */
@@@ -1747,6 -1689,17 +1763,20 @@@
  		return -ENOMEM;
  
  	prog->expected_attach_type = attr->expected_attach_type;
++<<<<<<< HEAD
++=======
+ 	prog->aux->attach_btf_id = attr->attach_btf_id;
+ 	if (attr->attach_prog_fd) {
+ 		struct bpf_prog *tgt_prog;
+ 
+ 		tgt_prog = bpf_prog_get(attr->attach_prog_fd);
+ 		if (IS_ERR(tgt_prog)) {
+ 			err = PTR_ERR(tgt_prog);
+ 			goto free_prog_nouncharge;
+ 		}
+ 		prog->aux->linked_prog = tgt_prog;
+ 	}
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  
  	prog->aux->offload_requested = !!attr->prog_ifindex;
  
diff --cc kernel/bpf/verifier.c
index ba15160eab20,e9dc95a18d44..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -9382,6 -9387,161 +9382,164 @@@ static void print_verification_stats(st
  		env->peak_states, env->longest_mark_read_walk);
  }
  
++<<<<<<< HEAD
++=======
+ static int check_attach_btf_id(struct bpf_verifier_env *env)
+ {
+ 	struct bpf_prog *prog = env->prog;
+ 	struct bpf_prog *tgt_prog = prog->aux->linked_prog;
+ 	u32 btf_id = prog->aux->attach_btf_id;
+ 	const char prefix[] = "btf_trace_";
+ 	int ret = 0, subprog = -1, i;
+ 	struct bpf_trampoline *tr;
+ 	const struct btf_type *t;
+ 	bool conservative = true;
+ 	const char *tname;
+ 	struct btf *btf;
+ 	long addr;
+ 	u64 key;
+ 
+ 	if (prog->type != BPF_PROG_TYPE_TRACING)
+ 		return 0;
+ 
+ 	if (!btf_id) {
+ 		verbose(env, "Tracing programs must provide btf_id\n");
+ 		return -EINVAL;
+ 	}
+ 	btf = bpf_prog_get_target_btf(prog);
+ 	if (!btf) {
+ 		verbose(env,
+ 			"FENTRY/FEXIT program can only be attached to another program annotated with BTF\n");
+ 		return -EINVAL;
+ 	}
+ 	t = btf_type_by_id(btf, btf_id);
+ 	if (!t) {
+ 		verbose(env, "attach_btf_id %u is invalid\n", btf_id);
+ 		return -EINVAL;
+ 	}
+ 	tname = btf_name_by_offset(btf, t->name_off);
+ 	if (!tname) {
+ 		verbose(env, "attach_btf_id %u doesn't have a name\n", btf_id);
+ 		return -EINVAL;
+ 	}
+ 	if (tgt_prog) {
+ 		struct bpf_prog_aux *aux = tgt_prog->aux;
+ 
+ 		for (i = 0; i < aux->func_info_cnt; i++)
+ 			if (aux->func_info[i].type_id == btf_id) {
+ 				subprog = i;
+ 				break;
+ 			}
+ 		if (subprog == -1) {
+ 			verbose(env, "Subprog %s doesn't exist\n", tname);
+ 			return -EINVAL;
+ 		}
+ 		conservative = aux->func_info_aux[subprog].unreliable;
+ 		key = ((u64)aux->id) << 32 | btf_id;
+ 	} else {
+ 		key = btf_id;
+ 	}
+ 
+ 	switch (prog->expected_attach_type) {
+ 	case BPF_TRACE_RAW_TP:
+ 		if (tgt_prog) {
+ 			verbose(env,
+ 				"Only FENTRY/FEXIT progs are attachable to another BPF prog\n");
+ 			return -EINVAL;
+ 		}
+ 		if (!btf_type_is_typedef(t)) {
+ 			verbose(env, "attach_btf_id %u is not a typedef\n",
+ 				btf_id);
+ 			return -EINVAL;
+ 		}
+ 		if (strncmp(prefix, tname, sizeof(prefix) - 1)) {
+ 			verbose(env, "attach_btf_id %u points to wrong type name %s\n",
+ 				btf_id, tname);
+ 			return -EINVAL;
+ 		}
+ 		tname += sizeof(prefix) - 1;
+ 		t = btf_type_by_id(btf, t->type);
+ 		if (!btf_type_is_ptr(t))
+ 			/* should never happen in valid vmlinux build */
+ 			return -EINVAL;
+ 		t = btf_type_by_id(btf, t->type);
+ 		if (!btf_type_is_func_proto(t))
+ 			/* should never happen in valid vmlinux build */
+ 			return -EINVAL;
+ 
+ 		/* remember two read only pointers that are valid for
+ 		 * the life time of the kernel
+ 		 */
+ 		prog->aux->attach_func_name = tname;
+ 		prog->aux->attach_func_proto = t;
+ 		prog->aux->attach_btf_trace = true;
+ 		return 0;
+ 	case BPF_TRACE_FENTRY:
+ 	case BPF_TRACE_FEXIT:
+ 		if (!btf_type_is_func(t)) {
+ 			verbose(env, "attach_btf_id %u is not a function\n",
+ 				btf_id);
+ 			return -EINVAL;
+ 		}
+ 		t = btf_type_by_id(btf, t->type);
+ 		if (!btf_type_is_func_proto(t))
+ 			return -EINVAL;
+ 		tr = bpf_trampoline_lookup(key);
+ 		if (!tr)
+ 			return -ENOMEM;
+ 		prog->aux->attach_func_name = tname;
+ 		/* t is either vmlinux type or another program's type */
+ 		prog->aux->attach_func_proto = t;
+ 		mutex_lock(&tr->mutex);
+ 		if (tr->func.addr) {
+ 			prog->aux->trampoline = tr;
+ 			goto out;
+ 		}
+ 		if (tgt_prog && conservative) {
+ 			prog->aux->attach_func_proto = NULL;
+ 			t = NULL;
+ 		}
+ 		ret = btf_distill_func_proto(&env->log, btf, t,
+ 					     tname, &tr->func.model);
+ 		if (ret < 0)
+ 			goto out;
+ 		if (tgt_prog) {
+ 			if (!tgt_prog->jited) {
+ 				/* for now */
+ 				verbose(env, "Can trace only JITed BPF progs\n");
+ 				ret = -EINVAL;
+ 				goto out;
+ 			}
+ 			if (tgt_prog->type == BPF_PROG_TYPE_TRACING) {
+ 				/* prevent cycles */
+ 				verbose(env, "Cannot recursively attach\n");
+ 				ret = -EINVAL;
+ 				goto out;
+ 			}
+ 			addr = (long) tgt_prog->aux->func[subprog]->bpf_func;
+ 		} else {
+ 			addr = kallsyms_lookup_name(tname);
+ 			if (!addr) {
+ 				verbose(env,
+ 					"The address of function %s cannot be found\n",
+ 					tname);
+ 				ret = -ENOENT;
+ 				goto out;
+ 			}
+ 		}
+ 		tr->func.addr = (void *)addr;
+ 		prog->aux->trampoline = tr;
+ out:
+ 		mutex_unlock(&tr->mutex);
+ 		if (ret)
+ 			bpf_trampoline_put(tr);
+ 		return ret;
+ 	default:
+ 		return -EINVAL;
+ 	}
+ }
+ 
++>>>>>>> 5b92a28aae4d (bpf: Support attaching tracing BPF program to other BPF programs)
  int bpf_check(struct bpf_prog **prog, union bpf_attr *attr,
  	      union bpf_attr __user *uattr)
  {
diff --git a/arch/x86/net/bpf_jit_comp.c b/arch/x86/net/bpf_jit_comp.c
index 490d8e35c7c9..c9cb79931eff 100644
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@ -505,7 +505,8 @@ int bpf_arch_text_poke(void *ip, enum bpf_text_poke_type t,
 	u8 *prog;
 	int ret;
 
-	if (!is_kernel_text((long)ip))
+	if (!is_kernel_text((long)ip) &&
+	    !is_bpf_text_address((long)ip))
 		/* BPF trampoline in modules is not supported */
 		return -EINVAL;
 
* Unmerged path include/linux/bpf.h
diff --git a/include/linux/btf.h b/include/linux/btf.h
index 55d43bc856be..c8a9377a650d 100644
--- a/include/linux/btf.h
+++ b/include/linux/btf.h
@@ -57,6 +57,7 @@ bool btf_type_is_void(const struct btf_type *t);
 const struct btf_type *btf_type_by_id(const struct btf *btf, u32 type_id);
 const char *btf_name_by_offset(const struct btf *btf, u32 offset);
 struct btf *btf_parse_vmlinux(void);
+struct btf *bpf_prog_get_target_btf(const struct bpf_prog *prog);
 #else
 static inline const struct btf_type *btf_type_by_id(const struct btf *btf,
 						    u32 type_id)
* Unmerged path include/uapi/linux/bpf.h
* Unmerged path kernel/bpf/btf.c
diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c
index bb9fdedbeefb..624f5b55fc10 100644
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@ -2036,6 +2036,8 @@ void bpf_prog_free(struct bpf_prog *fp)
 {
 	struct bpf_prog_aux *aux = fp->aux;
 
+	if (aux->linked_prog)
+		bpf_prog_put(aux->linked_prog);
 	INIT_WORK(&aux->work, bpf_prog_free_deferred);
 	schedule_work(&aux->work);
 }
* Unmerged path kernel/bpf/syscall.c
* Unmerged path kernel/bpf/verifier.c
