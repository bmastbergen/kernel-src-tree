KVM: Unexport kvm_vcpu_cache and kvm_vcpu_{un}init()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit aaba298c6bca8d8625880a8016e5b80adc8a11af
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/aaba298c.failed

Unexport kvm_vcpu_cache and kvm_vcpu_{un}init() and make them static
now that they are referenced only in kvm_main.c.

	Acked-by: Christoffer Dall <christoffer.dall@arm.com>
	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
	Reviewed-by: Cornelia Huck <cohuck@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit aaba298c6bca8d8625880a8016e5b80adc8a11af)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/kvm_host.h
diff --cc include/linux/kvm_host.h
index 76c481d92694,521f17cd2b26..000000000000
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@@ -582,8 -577,7 +580,12 @@@ static inline int kvm_vcpu_get_idx(stru
  	      memslot < slots->memslots + KVM_MEM_SLOTS_NUM && memslot->npages;\
  		memslot++)
  
++<<<<<<< HEAD
 +int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id);
 +void kvm_vcpu_uninit(struct kvm_vcpu *vcpu);
++=======
+ void kvm_vcpu_destroy(struct kvm_vcpu *vcpu);
++>>>>>>> aaba298c6bca (KVM: Unexport kvm_vcpu_cache and kvm_vcpu_{un}init())
  
  void vcpu_load(struct kvm_vcpu *vcpu);
  void vcpu_put(struct kvm_vcpu *vcpu);
* Unmerged path include/linux/kvm_host.h
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index c6256c9afce6..ef26c6ad048b 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -107,8 +107,7 @@ static cpumask_var_t cpus_hardware_enabled;
 static int kvm_usage_count;
 static atomic_t hardware_enable_failed;
 
-struct kmem_cache *kvm_vcpu_cache;
-EXPORT_SYMBOL_GPL(kvm_vcpu_cache);
+static struct kmem_cache *kvm_vcpu_cache;
 
 static __read_mostly struct preempt_ops kvm_preempt_ops;
 
@@ -324,7 +323,7 @@ void kvm_reload_remote_mmus(struct kvm *kvm)
 	kvm_make_all_cpus_request(kvm, KVM_REQ_MMU_RELOAD);
 }
 
-int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
+static int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 {
 	struct page *page;
 	int r;
@@ -362,9 +361,8 @@ int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 fail:
 	return r;
 }
-EXPORT_SYMBOL_GPL(kvm_vcpu_init);
 
-void kvm_vcpu_uninit(struct kvm_vcpu *vcpu)
+static void kvm_vcpu_uninit(struct kvm_vcpu *vcpu)
 {
 	/*
 	 * no need for rcu_read_lock as VCPU_RUN is the only place that
@@ -375,7 +373,6 @@ void kvm_vcpu_uninit(struct kvm_vcpu *vcpu)
 	kvm_arch_vcpu_uninit(vcpu);
 	free_page((unsigned long)vcpu->run);
 }
-EXPORT_SYMBOL_GPL(kvm_vcpu_uninit);
 
 #if defined(CONFIG_MMU_NOTIFIER) && defined(KVM_ARCH_WANT_MMU_NOTIFIER)
 static inline struct kvm *mmu_notifier_to_kvm(struct mmu_notifier *mn)
