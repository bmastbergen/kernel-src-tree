netfilter: conntrack: split resolve_clash function

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Florian Westphal <fw@strlen.de>
commit bb89abe52bf426f1f40850c441efc77426cc31e1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/bb89abe5.failed

Followup patch will need a helper function with the 'clashing entries
refer to the identical tuple in both directions' resolution logic.

This patch will add another resolve_clash helper where loser_ct must
not be added to the dying list because it will be inserted into the
table.

Therefore this also moves the stat counters and dying-list insertion
of the losing ct.

	Signed-off-by: Florian Westphal <fw@strlen.de>
	Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
(cherry picked from commit bb89abe52bf426f1f40850c441efc77426cc31e1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/netfilter/nf_conntrack_core.c
diff --cc net/netfilter/nf_conntrack_core.c
index fc498c249518,3f069eb0f0fc..000000000000
--- a/net/netfilter/nf_conntrack_core.c
+++ b/net/netfilter/nf_conntrack_core.c
@@@ -734,32 -894,103 +734,128 @@@ static void nf_ct_acct_merge(struct nf_
  	}
  }
  
++<<<<<<< HEAD
 +/* Resolve race on insertion if this protocol allows this. */
++=======
+ static void __nf_conntrack_insert_prepare(struct nf_conn *ct)
+ {
+ 	struct nf_conn_tstamp *tstamp;
+ 
+ 	atomic_inc(&ct->ct_general.use);
+ 	ct->status |= IPS_CONFIRMED;
+ 
+ 	/* set conntrack timestamp, if enabled. */
+ 	tstamp = nf_conn_tstamp_find(ct);
+ 	if (tstamp)
+ 		tstamp->start = ktime_get_real_ns();
+ }
+ 
+ static int __nf_ct_resolve_clash(struct sk_buff *skb,
+ 				 struct nf_conntrack_tuple_hash *h)
+ {
+ 	/* This is the conntrack entry already in hashes that won race. */
+ 	struct nf_conn *ct = nf_ct_tuplehash_to_ctrack(h);
+ 	enum ip_conntrack_info ctinfo;
+ 	struct nf_conn *loser_ct;
+ 
+ 	loser_ct = nf_ct_get(skb, &ctinfo);
+ 
+ 	if (nf_ct_is_dying(ct))
+ 		return NF_DROP;
+ 
+ 	if (!atomic_inc_not_zero(&ct->ct_general.use))
+ 		return NF_DROP;
+ 
+ 	if (((ct->status & IPS_NAT_DONE_MASK) == 0) ||
+ 	    nf_ct_match(ct, loser_ct)) {
+ 		struct net *net = nf_ct_net(ct);
+ 
+ 		nf_ct_acct_merge(ct, ctinfo, loser_ct);
+ 		nf_ct_add_to_dying_list(loser_ct);
+ 		nf_conntrack_put(&loser_ct->ct_general);
+ 		nf_ct_set(skb, ct, ctinfo);
+ 
+ 		NF_CT_STAT_INC(net, insert_failed);
+ 		return NF_ACCEPT;
+ 	}
+ 
+ 	nf_ct_put(ct);
+ 	return NF_DROP;
+ }
+ 
+ /**
+  * nf_ct_resolve_clash - attempt to handle clash without packet drop
+  *
+  * @skb: skb that causes the clash
+  * @h: tuplehash of the clashing entry already in table
+  *
+  * A conntrack entry can be inserted to the connection tracking table
+  * if there is no existing entry with an identical tuple.
+  *
+  * If there is one, @skb (and the assocated, unconfirmed conntrack) has
+  * to be dropped.  In case @skb is retransmitted, next conntrack lookup
+  * will find the already-existing entry.
+  *
+  * The major problem with such packet drop is the extra delay added by
+  * the packet loss -- it will take some time for a retransmit to occur
+  * (or the sender to time out when waiting for a reply).
+  *
+  * This function attempts to handle the situation without packet drop.
+  *
+  * If @skb has no NAT transformation or if the colliding entries are
+  * exactly the same, only the to-be-confirmed conntrack entry is discarded
+  * and @skb is associated with the conntrack entry already in the table.
+  *
+  * Returns NF_DROP if the clash could not be resolved.
+  */
++>>>>>>> bb89abe52bf4 (netfilter: conntrack: split resolve_clash function)
  static __cold noinline int
 -nf_ct_resolve_clash(struct sk_buff *skb, struct nf_conntrack_tuple_hash *h)
 +nf_ct_resolve_clash(struct net *net, struct sk_buff *skb,
 +		    enum ip_conntrack_info ctinfo,
 +		    struct nf_conntrack_tuple_hash *h)
  {
  	/* This is the conntrack entry already in hashes that won race. */
  	struct nf_conn *ct = nf_ct_tuplehash_to_ctrack(h);
  	const struct nf_conntrack_l4proto *l4proto;
++<<<<<<< HEAD
 +	enum ip_conntrack_info oldinfo;
 +	struct nf_conn *loser_ct = nf_ct_get(skb, &oldinfo);
 +
 +	l4proto = __nf_ct_l4proto_find(nf_ct_l3num(ct), nf_ct_protonum(ct));
 +	if (l4proto->allow_clash &&
 +	    !nf_ct_is_dying(ct) &&
 +	    atomic_inc_not_zero(&ct->ct_general.use)) {
 +		if (((ct->status & IPS_NAT_DONE_MASK) == 0) ||
 +		    nf_ct_match(ct, loser_ct)) {
 +			nf_ct_acct_merge(ct, ctinfo, loser_ct);
 +			nf_conntrack_put(&loser_ct->ct_general);
 +			nf_ct_set(skb, ct, oldinfo);
 +			return NF_ACCEPT;
 +		}
 +		nf_ct_put(ct);
 +	}
++=======
+ 	enum ip_conntrack_info ctinfo;
+ 	struct nf_conn *loser_ct;
+ 	struct net *net;
+ 	int ret;
+ 
+ 	loser_ct = nf_ct_get(skb, &ctinfo);
+ 	net = nf_ct_net(loser_ct);
+ 
+ 	l4proto = nf_ct_l4proto_find(nf_ct_protonum(ct));
+ 	if (!l4proto->allow_clash)
+ 		goto drop;
+ 
+ 	ret = __nf_ct_resolve_clash(skb, h);
+ 	if (ret == NF_ACCEPT)
+ 		return ret;
+ 
+ drop:
+ 	nf_ct_add_to_dying_list(loser_ct);
++>>>>>>> bb89abe52bf4 (netfilter: conntrack: split resolve_clash function)
  	NF_CT_STAT_INC(net, drop);
+ 	NF_CT_STAT_INC(net, insert_failed);
  	return NF_DROP;
  }
  
@@@ -867,11 -1101,9 +964,14 @@@ __nf_conntrack_confirm(struct sk_buff *
  	return NF_ACCEPT;
  
  out:
++<<<<<<< HEAD
 +	nf_ct_add_to_dying_list(ct);
 +	ret = nf_ct_resolve_clash(net, skb, ctinfo, h);
++=======
+ 	ret = nf_ct_resolve_clash(skb, h);
++>>>>>>> bb89abe52bf4 (netfilter: conntrack: split resolve_clash function)
  dying:
  	nf_conntrack_double_unlock(hash, reply_hash);
- 	NF_CT_STAT_INC(net, insert_failed);
  	local_bh_enable();
  	return ret;
  }
* Unmerged path net/netfilter/nf_conntrack_core.c
