esp4: improve xfrm4_beet_gso_segment() to be more readable

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Xin Long <lucien.xin@gmail.com>
commit 3ffb93ba326f40b47b17a4e8b3399c0fa2e8cee6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/3ffb93ba.failed

This patch is to improve the code to make xfrm4_beet_gso_segment()
more readable, and keep consistent with xfrm6_beet_gso_segment().

	Signed-off-by: Xin Long <lucien.xin@gmail.com>
	Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
(cherry picked from commit 3ffb93ba326f40b47b17a4e8b3399c0fa2e8cee6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/esp4_offload.c
diff --cc net/ipv4/esp4_offload.c
index 3a37786789f5,d14133eac476..000000000000
--- a/net/ipv4/esp4_offload.c
+++ b/net/ipv4/esp4_offload.c
@@@ -108,6 -106,84 +108,87 @@@ static void esp4_gso_encap(struct xfrm_
  	xo->proto = proto;
  }
  
++<<<<<<< HEAD
++=======
+ static struct sk_buff *xfrm4_tunnel_gso_segment(struct xfrm_state *x,
+ 						struct sk_buff *skb,
+ 						netdev_features_t features)
+ {
+ 	__skb_push(skb, skb->mac_len);
+ 	return skb_mac_gso_segment(skb, features);
+ }
+ 
+ static struct sk_buff *xfrm4_transport_gso_segment(struct xfrm_state *x,
+ 						   struct sk_buff *skb,
+ 						   netdev_features_t features)
+ {
+ 	const struct net_offload *ops;
+ 	struct sk_buff *segs = ERR_PTR(-EINVAL);
+ 	struct xfrm_offload *xo = xfrm_offload(skb);
+ 
+ 	skb->transport_header += x->props.header_len;
+ 	ops = rcu_dereference(inet_offloads[xo->proto]);
+ 	if (likely(ops && ops->callbacks.gso_segment))
+ 		segs = ops->callbacks.gso_segment(skb, features);
+ 
+ 	return segs;
+ }
+ 
+ static struct sk_buff *xfrm4_beet_gso_segment(struct xfrm_state *x,
+ 					      struct sk_buff *skb,
+ 					      netdev_features_t features)
+ {
+ 	struct xfrm_offload *xo = xfrm_offload(skb);
+ 	struct sk_buff *segs = ERR_PTR(-EINVAL);
+ 	const struct net_offload *ops;
+ 	u8 proto = xo->proto;
+ 
+ 	skb->transport_header += x->props.header_len;
+ 
+ 	if (x->sel.family != AF_INET6) {
+ 		if (proto == IPPROTO_BEETPH) {
+ 			struct ip_beet_phdr *ph =
+ 				(struct ip_beet_phdr *)skb->data;
+ 
+ 			skb->transport_header += ph->hdrlen * 8;
+ 			proto = ph->nexthdr;
+ 		} else {
+ 			skb->transport_header -= IPV4_BEET_PHMAXLEN;
+ 		}
+ 	} else {
+ 		__be16 frag;
+ 
+ 		skb->transport_header +=
+ 			ipv6_skip_exthdr(skb, 0, &proto, &frag);
+ 		if (proto == IPPROTO_TCP)
+ 			skb_shinfo(skb)->gso_type |= SKB_GSO_TCPV4;
+ 	}
+ 
+ 	__skb_pull(skb, skb_transport_offset(skb));
+ 	ops = rcu_dereference(inet_offloads[proto]);
+ 	if (likely(ops && ops->callbacks.gso_segment))
+ 		segs = ops->callbacks.gso_segment(skb, features);
+ 
+ 	return segs;
+ }
+ 
+ static struct sk_buff *xfrm4_outer_mode_gso_segment(struct xfrm_state *x,
+ 						    struct sk_buff *skb,
+ 						    netdev_features_t features)
+ {
+ 	switch (x->outer_mode.encap) {
+ 	case XFRM_MODE_TUNNEL:
+ 		return xfrm4_tunnel_gso_segment(x, skb, features);
+ 	case XFRM_MODE_TRANSPORT:
+ 		return xfrm4_transport_gso_segment(x, skb, features);
+ 	case XFRM_MODE_BEET:
+ 		return xfrm4_beet_gso_segment(x, skb, features);
+ 	}
+ 
+ 	return ERR_PTR(-EOPNOTSUPP);
+ }
+ 
++>>>>>>> 3ffb93ba326f (esp4: improve xfrm4_beet_gso_segment() to be more readable)
  static struct sk_buff *esp4_gso_segment(struct sk_buff *skb,
  				        netdev_features_t features)
  {
* Unmerged path net/ipv4/esp4_offload.c
