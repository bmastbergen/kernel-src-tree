net/smc: log important pnetid and state change events

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Karsten Graul <kgraul@linux.ibm.com>
commit 0a99be434d145079d0509473b19e840629d851c2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/0a99be43.failed

Print to system log when SMC links are available or go down, link group
state changes or pnetids are applied to and removed from devices.
The log entries are triggered by either user configuration actions or
adapter activation/deactivation events and are not expected to happen
often. The entries help SMC users to keep track of the SMC link group
status and to detect when actions are needed (like to add replacements
for failed adapters).

	Signed-off-by: Karsten Graul <kgraul@linux.ibm.com>
	Reviewed-by: Ursula Braun <ubraun@linux.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 0a99be434d145079d0509473b19e840629d851c2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/smc/af_smc.c
#	net/smc/smc_core.c
#	net/smc/smc_core.h
#	net/smc/smc_llc.c
#	net/smc/smc_llc.h
diff --cc net/smc/af_smc.c
index 61adbee56cf2,903321543838..000000000000
--- a/net/smc/af_smc.c
+++ b/net/smc/af_smc.c
@@@ -413,10 -411,13 +413,20 @@@ static int smcr_clnt_conf_first_link(st
  	if (rc < 0)
  		return SMC_CLC_DECL_TIMEOUT_CL;
  
++<<<<<<< HEAD
 +	/* receive ADD LINK request from server over RoCE fabric */
 +	rest = wait_for_completion_interruptible_timeout(&link->llc_add,
 +							 SMC_LLC_WAIT_TIME);
 +	if (rest <= 0) {
++=======
+ 	smc_llc_link_active(link);
+ 	smcr_lgr_set_type(link->lgr, SMC_LGR_SINGLE);
+ 
+ 	/* optional 2nd link, receive ADD LINK request from server */
+ 	qentry = smc_llc_wait(link->lgr, NULL, SMC_LLC_WAIT_TIME,
+ 			      SMC_LLC_ADD_LINK);
+ 	if (!qentry) {
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  		struct smc_clc_msg_decline dclc;
  
  		rc = smc_clc_wait_msg(smc, &dclc, sizeof(dclc),
@@@ -1017,12 -1032,11 +1027,16 @@@ void smc_close_non_accepted(struct soc
  
  static int smcr_serv_conf_first_link(struct smc_sock *smc)
  {
 +	struct net *net = sock_net(smc->clcsock->sk);
  	struct smc_link *link = smc->conn.lnk;
 -	struct smc_llc_qentry *qentry;
 +	int rest;
  	int rc;
  
++<<<<<<< HEAD
 +	if (smcr_link_reg_rmb(link, smc->conn.rmb_desc, false))
++=======
+ 	if (smcr_link_reg_rmb(link, smc->conn.rmb_desc))
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  		return SMC_CLC_DECL_ERR_REGRMB;
  
  	/* send CONFIRM LINK request to client over the RoCE fabric */
@@@ -1041,30 -1054,20 +1055,35 @@@
  				      SMC_CLC_DECLINE, CLC_WAIT_TIME_SHORT);
  		return rc == -EAGAIN ? SMC_CLC_DECL_TIMEOUT_CL : rc;
  	}
 -	smc_llc_save_peer_uid(qentry);
 -	rc = smc_llc_eval_conf_link(qentry, SMC_LLC_RESP);
 -	smc_llc_flow_qentry_del(&link->lgr->llc_flow_lcl);
 -	if (rc)
 +
 +	if (link->llc_confirm_resp_rc)
  		return SMC_CLC_DECL_RMBE_EC;
  
 -	/* confirm_rkey is implicit on 1st contact */
 -	smc->conn.rmb_desc->is_conf_rkey = true;
 +	/* send ADD LINK request to client over the RoCE fabric */
 +	rc = smc_llc_send_add_link(link,
 +				   link->smcibdev->mac[link->ibport - 1],
 +				   link->gid, SMC_LLC_REQ);
 +	if (rc < 0)
 +		return SMC_CLC_DECL_TIMEOUT_AL;
 +
++<<<<<<< HEAD
 +	/* receive ADD LINK response from client over the RoCE fabric */
 +	rest = wait_for_completion_interruptible_timeout(&link->llc_add_resp,
 +							 SMC_LLC_WAIT_TIME);
 +	if (rest <= 0) {
 +		struct smc_clc_msg_decline dclc;
 +
 +		rc = smc_clc_wait_msg(smc, &dclc, sizeof(dclc),
 +				      SMC_CLC_DECLINE, CLC_WAIT_TIME_SHORT);
 +		return rc == -EAGAIN ? SMC_CLC_DECL_TIMEOUT_AL : rc;
 +	}
  
 +	smc_llc_link_active(link, net->ipv4.sysctl_tcp_keepalive_time);
++=======
+ 	smc_llc_link_active(link);
+ 	smcr_lgr_set_type(link->lgr, SMC_LGR_SINGLE);
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  
 -	/* initial contact - try to establish second link */
 -	smc_llc_srv_add_link(link);
  	return 0;
  }
  
diff --cc net/smc/smc_core.c
index 399bc3ffb64e,65de700e1f17..000000000000
--- a/net/smc/smc_core.c
+++ b/net/smc/smc_core.c
@@@ -534,12 -664,70 +534,75 @@@ void smc_conn_free(struct smc_connectio
  		smc_lgr_schedule_free_work(lgr);
  }
  
 -/* unregister a link from a buf_desc */
 -static void smcr_buf_unmap_link(struct smc_buf_desc *buf_desc, bool is_rmb,
 -				struct smc_link *lnk)
 +static void smcr_link_clear(struct smc_link *lnk)
  {
++<<<<<<< HEAD
 +	if (lnk->peer_qpn == 0)
 +		return;
 +	lnk->peer_qpn = 0;
 +	smc_llc_link_clear(lnk);
++=======
+ 	if (is_rmb)
+ 		buf_desc->is_reg_mr[lnk->link_idx] = false;
+ 	if (!buf_desc->is_map_ib[lnk->link_idx])
+ 		return;
+ 	if (is_rmb) {
+ 		if (buf_desc->mr_rx[lnk->link_idx]) {
+ 			smc_ib_put_memory_region(
+ 					buf_desc->mr_rx[lnk->link_idx]);
+ 			buf_desc->mr_rx[lnk->link_idx] = NULL;
+ 		}
+ 		smc_ib_buf_unmap_sg(lnk, buf_desc, DMA_FROM_DEVICE);
+ 	} else {
+ 		smc_ib_buf_unmap_sg(lnk, buf_desc, DMA_TO_DEVICE);
+ 	}
+ 	sg_free_table(&buf_desc->sgt[lnk->link_idx]);
+ 	buf_desc->is_map_ib[lnk->link_idx] = false;
+ }
+ 
+ /* unmap all buffers of lgr for a deleted link */
+ static void smcr_buf_unmap_lgr(struct smc_link *lnk)
+ {
+ 	struct smc_link_group *lgr = lnk->lgr;
+ 	struct smc_buf_desc *buf_desc, *bf;
+ 	int i;
+ 
+ 	for (i = 0; i < SMC_RMBE_SIZES; i++) {
+ 		mutex_lock(&lgr->rmbs_lock);
+ 		list_for_each_entry_safe(buf_desc, bf, &lgr->rmbs[i], list)
+ 			smcr_buf_unmap_link(buf_desc, true, lnk);
+ 		mutex_unlock(&lgr->rmbs_lock);
+ 		mutex_lock(&lgr->sndbufs_lock);
+ 		list_for_each_entry_safe(buf_desc, bf, &lgr->sndbufs[i],
+ 					 list)
+ 			smcr_buf_unmap_link(buf_desc, false, lnk);
+ 		mutex_unlock(&lgr->sndbufs_lock);
+ 	}
+ }
+ 
+ static void smcr_rtoken_clear_link(struct smc_link *lnk)
+ {
+ 	struct smc_link_group *lgr = lnk->lgr;
+ 	int i;
+ 
+ 	for (i = 0; i < SMC_RMBS_PER_LGR_MAX; i++) {
+ 		lgr->rtokens[i][lnk->link_idx].rkey = 0;
+ 		lgr->rtokens[i][lnk->link_idx].dma_addr = 0;
+ 	}
+ }
+ 
+ /* must be called under lgr->llc_conf_mutex lock */
+ void smcr_link_clear(struct smc_link *lnk, bool log)
+ {
+ 	struct smc_ib_device *smcibdev;
+ 
+ 	if (!lnk->lgr || lnk->state == SMC_LNK_UNUSED)
+ 		return;
+ 	lnk->peer_qpn = 0;
+ 	smc_llc_link_clear(lnk, log);
+ 	smcr_buf_unmap_lgr(lnk);
+ 	smcr_rtoken_clear_link(lnk);
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  	smc_ib_modify_qp_reset(lnk);
  	smc_wr_free_link(lnk);
  	smc_ib_destroy_queue_pair(lnk);
@@@ -630,6 -808,16 +693,19 @@@ static void smc_lgr_free(struct smc_lin
  {
  	int i;
  
++<<<<<<< HEAD
++=======
+ 	if (!lgr->is_smcd) {
+ 		mutex_lock(&lgr->llc_conf_mutex);
+ 		for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 			if (lgr->lnk[i].state != SMC_LNK_UNUSED)
+ 				smcr_link_clear(&lgr->lnk[i], false);
+ 		}
+ 		mutex_unlock(&lgr->llc_conf_mutex);
+ 		smc_llc_lgr_clear(lgr);
+ 	}
+ 
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  	smc_lgr_free_bufs(lgr);
  	if (lgr->is_smcd) {
  		if (!lgr->terminating) {
@@@ -909,6 -1037,49 +985,52 @@@ void smc_smcr_terminate_all(struct smc_
  	}
  }
  
++<<<<<<< HEAD
++=======
+ /* set new lgr type and clear all asymmetric link tagging */
+ void smcr_lgr_set_type(struct smc_link_group *lgr, enum smc_lgr_type new_type)
+ {
+ 	char *lgr_type = "";
+ 	int i;
+ 
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++)
+ 		if (smc_link_usable(&lgr->lnk[i]))
+ 			lgr->lnk[i].link_is_asym = false;
+ 	if (lgr->type == new_type)
+ 		return;
+ 	lgr->type = new_type;
+ 
+ 	switch (lgr->type) {
+ 	case SMC_LGR_NONE:
+ 		lgr_type = "NONE";
+ 		break;
+ 	case SMC_LGR_SINGLE:
+ 		lgr_type = "SINGLE";
+ 		break;
+ 	case SMC_LGR_SYMMETRIC:
+ 		lgr_type = "SYMMETRIC";
+ 		break;
+ 	case SMC_LGR_ASYMMETRIC_PEER:
+ 		lgr_type = "ASYMMETRIC_PEER";
+ 		break;
+ 	case SMC_LGR_ASYMMETRIC_LOCAL:
+ 		lgr_type = "ASYMMETRIC_LOCAL";
+ 		break;
+ 	}
+ 	pr_warn_ratelimited("smc: SMC-R lg %*phN state changed: "
+ 			    "%s, pnetid %.16s\n", SMC_LGR_ID_SIZE, &lgr->id,
+ 			    lgr_type, lgr->pnet_id);
+ }
+ 
+ /* set new lgr type and tag a link as asymmetric */
+ void smcr_lgr_set_type_asym(struct smc_link_group *lgr,
+ 			    enum smc_lgr_type new_type, int asym_lnk_idx)
+ {
+ 	smcr_lgr_set_type(lgr, new_type);
+ 	lgr->lnk[asym_lnk_idx].link_is_asym = true;
+ }
+ 
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  /* abort connection, abort_work scheduled from tasklet context */
  static void smc_conn_abort_work(struct work_struct *work)
  {
@@@ -984,6 -1155,79 +1106,82 @@@ void smcr_port_add(struct smc_ib_devic
  	}
  }
  
++<<<<<<< HEAD
++=======
+ /* link is down - switch connections to alternate link,
+  * must be called under lgr->llc_conf_mutex lock
+  */
+ static void smcr_link_down(struct smc_link *lnk)
+ {
+ 	struct smc_link_group *lgr = lnk->lgr;
+ 	struct smc_link *to_lnk;
+ 	int del_link_id;
+ 
+ 	if (!lgr || lnk->state == SMC_LNK_UNUSED || list_empty(&lgr->list))
+ 		return;
+ 
+ 	smc_ib_modify_qp_reset(lnk);
+ 	to_lnk = smc_switch_conns(lgr, lnk, true);
+ 	if (!to_lnk) { /* no backup link available */
+ 		smcr_link_clear(lnk, true);
+ 		return;
+ 	}
+ 	smcr_lgr_set_type(lgr, SMC_LGR_SINGLE);
+ 	del_link_id = lnk->link_id;
+ 
+ 	if (lgr->role == SMC_SERV) {
+ 		/* trigger local delete link processing */
+ 		smc_llc_srv_delete_link_local(to_lnk, del_link_id);
+ 	} else {
+ 		if (lgr->llc_flow_lcl.type != SMC_LLC_FLOW_NONE) {
+ 			/* another llc task is ongoing */
+ 			mutex_unlock(&lgr->llc_conf_mutex);
+ 			wait_event_interruptible_timeout(lgr->llc_waiter,
+ 				(lgr->llc_flow_lcl.type == SMC_LLC_FLOW_NONE),
+ 				SMC_LLC_WAIT_TIME);
+ 			mutex_lock(&lgr->llc_conf_mutex);
+ 		}
+ 		smc_llc_send_delete_link(to_lnk, del_link_id, SMC_LLC_REQ, true,
+ 					 SMC_LLC_DEL_LOST_PATH);
+ 	}
+ }
+ 
+ /* must be called under lgr->llc_conf_mutex lock */
+ void smcr_link_down_cond(struct smc_link *lnk)
+ {
+ 	if (smc_link_downing(&lnk->state))
+ 		smcr_link_down(lnk);
+ }
+ 
+ /* will get the lgr->llc_conf_mutex lock */
+ void smcr_link_down_cond_sched(struct smc_link *lnk)
+ {
+ 	if (smc_link_downing(&lnk->state))
+ 		schedule_work(&lnk->link_down_wrk);
+ }
+ 
+ void smcr_port_err(struct smc_ib_device *smcibdev, u8 ibport)
+ {
+ 	struct smc_link_group *lgr, *n;
+ 	int i;
+ 
+ 	list_for_each_entry_safe(lgr, n, &smc_lgr_list.list, list) {
+ 		if (strncmp(smcibdev->pnetid[ibport - 1], lgr->pnet_id,
+ 			    SMC_MAX_PNETID_LEN))
+ 			continue; /* lgr is not affected */
+ 		if (list_empty(&lgr->list))
+ 			continue;
+ 		for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 			struct smc_link *lnk = &lgr->lnk[i];
+ 
+ 			if (smc_link_usable(lnk) &&
+ 			    lnk->smcibdev == smcibdev && lnk->ibport == ibport)
+ 				smcr_link_down_cond_sched(lnk);
+ 		}
+ 	}
+ }
+ 
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  static void smc_link_up_work(struct work_struct *work)
  {
  	struct smc_ib_up_work *ib_work = container_of(work,
diff --cc net/smc/smc_core.h
index dc42fae85777,86d160f0d187..000000000000
--- a/net/smc/smc_core.h
+++ b/net/smc/smc_core.h
@@@ -337,6 -381,20 +337,23 @@@ void smc_lgr_schedule_free_work_fast(st
  int smc_core_init(void);
  void smc_core_exit(void);
  
++<<<<<<< HEAD
++=======
+ int smcr_link_init(struct smc_link_group *lgr, struct smc_link *lnk,
+ 		   u8 link_idx, struct smc_init_info *ini);
+ void smcr_link_clear(struct smc_link *lnk, bool log);
+ int smcr_buf_map_lgr(struct smc_link *lnk);
+ int smcr_buf_reg_lgr(struct smc_link *lnk);
+ void smcr_lgr_set_type(struct smc_link_group *lgr, enum smc_lgr_type new_type);
+ void smcr_lgr_set_type_asym(struct smc_link_group *lgr,
+ 			    enum smc_lgr_type new_type, int asym_lnk_idx);
+ int smcr_link_reg_rmb(struct smc_link *link, struct smc_buf_desc *rmb_desc);
+ struct smc_link *smc_switch_conns(struct smc_link_group *lgr,
+ 				  struct smc_link *from_lnk, bool is_dev_err);
+ void smcr_link_down_cond(struct smc_link *lnk);
+ void smcr_link_down_cond_sched(struct smc_link *lnk);
+ 
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  static inline struct smc_link_group *smc_get_lgr(struct smc_link *link)
  {
  	return link->lgr;
diff --cc net/smc/smc_llc.c
index 4119cdb6b6bf,4cc583678ac7..000000000000
--- a/net/smc/smc_llc.c
+++ b/net/smc/smc_llc.c
@@@ -398,137 -804,603 +398,570 @@@ static int smc_llc_send_message(struct 
  	return 0;
  }
  
 -static void smc_llc_save_add_link_info(struct smc_link *link,
 -				       struct smc_llc_msg_add_link *add_llc)
 -{
 -	link->peer_qpn = ntoh24(add_llc->sender_qp_num);
 -	memcpy(link->peer_gid, add_llc->sender_gid, SMC_GID_SIZE);
 -	memcpy(link->peer_mac, add_llc->sender_mac, ETH_ALEN);
 -	link->peer_psn = ntoh24(add_llc->initial_psn);
 -	link->peer_mtu = add_llc->qp_mtu;
 -}
 +/********************************* receive ***********************************/
  
 -/* as an SMC client, process an add link request */
 -int smc_llc_cli_add_link(struct smc_link *link, struct smc_llc_qentry *qentry)
 +static void smc_llc_rx_confirm_link(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_link *llc)
  {
 -	struct smc_llc_msg_add_link *llc = &qentry->msg.add_link;
 -	enum smc_lgr_type lgr_new_t = SMC_LGR_SYMMETRIC;
  	struct smc_link_group *lgr = smc_get_lgr(link);
 -	struct smc_link *lnk_new = NULL;
 -	struct smc_init_info ini;
 -	int lnk_idx, rc = 0;
 -
 -	ini.vlan_id = lgr->vlan_id;
 -	smc_pnet_find_alt_roce(lgr, &ini, link->smcibdev);
 -	if (!memcmp(llc->sender_gid, link->peer_gid, SMC_GID_SIZE) &&
 -	    !memcmp(llc->sender_mac, link->peer_mac, ETH_ALEN)) {
 -		if (!ini.ib_dev)
 -			goto out_reject;
 -		lgr_new_t = SMC_LGR_ASYMMETRIC_PEER;
 -	}
 -	if (!ini.ib_dev) {
 -		lgr_new_t = SMC_LGR_ASYMMETRIC_LOCAL;
 -		ini.ib_dev = link->smcibdev;
 -		ini.ib_port = link->ibport;
 -	}
 -	lnk_idx = smc_llc_alloc_alt_link(lgr, lgr_new_t);
 -	if (lnk_idx < 0)
 -		goto out_reject;
 -	lnk_new = &lgr->lnk[lnk_idx];
 -	rc = smcr_link_init(lgr, lnk_new, lnk_idx, &ini);
 -	if (rc)
 -		goto out_reject;
 -	smc_llc_save_add_link_info(lnk_new, llc);
 -	lnk_new->link_id = llc->link_num;	/* SMC server assigns link id */
 -	smc_llc_link_set_uid(lnk_new);
 +	int conf_rc;
  
 +	/* RMBE eyecatchers are not supported */
 +	if (llc->hd.flags & SMC_LLC_FLAG_NO_RMBE_EYEC)
 +		conf_rc = 0;
 +	else
 +		conf_rc = ENOTSUPP;
 +
++<<<<<<< HEAD
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_resp_rc = conf_rc;
 +			complete(&link->llc_confirm_resp);
++=======
+ 	rc = smc_ib_ready_link(lnk_new);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 
+ 	rc = smcr_buf_map_lgr(lnk_new);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 
+ 	rc = smc_llc_send_add_link(link,
+ 				   lnk_new->smcibdev->mac[ini.ib_port - 1],
+ 				   lnk_new->gid, lnk_new, SMC_LLC_RESP);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 	rc = smc_llc_cli_rkey_exchange(link, lnk_new);
+ 	if (rc) {
+ 		rc = 0;
+ 		goto out_clear_lnk;
+ 	}
+ 	rc = smc_llc_cli_conf_link(link, &ini, lnk_new, lgr_new_t);
+ 	if (!rc)
+ 		goto out;
+ out_clear_lnk:
+ 	smcr_link_clear(lnk_new, false);
+ out_reject:
+ 	smc_llc_cli_add_link_reject(qentry);
+ out:
+ 	kfree(qentry);
+ 	return rc;
+ }
+ 
+ static void smc_llc_process_cli_add_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_llc_qentry *qentry;
+ 
+ 	qentry = smc_llc_flow_qentry_clr(&lgr->llc_flow_lcl);
+ 
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	smc_llc_cli_add_link(qentry->link, qentry);
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ }
+ 
+ static int smc_llc_active_link_count(struct smc_link_group *lgr)
+ {
+ 	int i, link_count = 0;
+ 
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		if (!smc_link_usable(&lgr->lnk[i]))
+ 			continue;
+ 		link_count++;
+ 	}
+ 	return link_count;
+ }
+ 
+ /* find the asymmetric link when 3 links are established  */
+ static struct smc_link *smc_llc_find_asym_link(struct smc_link_group *lgr)
+ {
+ 	int asym_idx = -ENOENT;
+ 	int i, j, k;
+ 	bool found;
+ 
+ 	/* determine asymmetric link */
+ 	found = false;
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		for (j = i + 1; j < SMC_LINKS_PER_LGR_MAX; j++) {
+ 			if (!smc_link_usable(&lgr->lnk[i]) ||
+ 			    !smc_link_usable(&lgr->lnk[j]))
+ 				continue;
+ 			if (!memcmp(lgr->lnk[i].gid, lgr->lnk[j].gid,
+ 				    SMC_GID_SIZE)) {
+ 				found = true;	/* asym_lnk is i or j */
+ 				break;
+ 			}
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
 +		}
 +	} else {
 +		if (lgr->role == SMC_CLNT &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_rc = conf_rc;
 +			link->link_id = llc->link_num;
 +			complete(&link->llc_confirm);
  		}
 -		if (found)
 -			break;
  	}
 -	if (!found)
 -		goto out; /* no asymmetric link */
 -	for (k = 0; k < SMC_LINKS_PER_LGR_MAX; k++) {
 -		if (!smc_link_usable(&lgr->lnk[k]))
 -			continue;
 -		if (k != i &&
 -		    !memcmp(lgr->lnk[i].peer_gid, lgr->lnk[k].peer_gid,
 -			    SMC_GID_SIZE)) {
 -			asym_idx = i;
 -			break;
 +}
 +
 +static void smc_llc_rx_add_link(struct smc_link *link,
 +				struct smc_llc_msg_add_link *llc)
 +{
 +	struct smc_link_group *lgr = smc_get_lgr(link);
 +
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVATING)
 +			complete(&link->llc_add_resp);
 +	} else {
 +		if (link->state == SMC_LNK_ACTIVATING) {
 +			complete(&link->llc_add);
 +			return;
  		}
 -		if (k != j &&
 -		    !memcmp(lgr->lnk[j].peer_gid, lgr->lnk[k].peer_gid,
 -			    SMC_GID_SIZE)) {
 -			asym_idx = j;
 -			break;
 +
 +		if (lgr->role == SMC_SERV) {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_REQ);
 +
 +		} else {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_RESP);
  		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -out:
 -	return (asym_idx < 0) ? NULL : &lgr->lnk[asym_idx];
  }
  
 -static void smc_llc_delete_asym_link(struct smc_link_group *lgr)
 +static void smc_llc_rx_delete_link(struct smc_link *link,
 +				   struct smc_llc_msg_del_link *llc)
 +{
 +	struct smc_link_group *lgr = smc_get_lgr(link);
 +
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV)
 +			smc_lgr_schedule_free_work_fast(lgr);
 +	} else {
 +		smc_lgr_forget(lgr);
 +		smc_llc_link_deleting(link);
 +		if (lgr->role == SMC_SERV) {
 +			/* client asks to delete this link, send request */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_REQ, true);
 +		} else {
 +			/* server requests to delete this link, send response */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_RESP, true);
 +		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +		smc_lgr_terminate_sched(lgr);
 +	}
 +}
 +
 +static void smc_llc_rx_test_link(struct smc_link *link,
 +				 struct smc_llc_msg_test_link *llc)
 +{
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVE)
 +			complete(&link->llc_testlink_resp);
 +	} else {
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
 +}
 +
 +static void smc_llc_rx_confirm_rkey(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_rkey *llc)
  {
 -	struct smc_link *lnk_new = NULL, *lnk_asym;
 -	struct smc_llc_qentry *qentry;
  	int rc;
  
++<<<<<<< HEAD
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		link->llc_confirm_rkey_rc = llc->hd.flags &
 +					    SMC_LLC_FLAG_RKEY_NEG;
 +		complete(&link->llc_confirm_rkey);
 +	} else {
 +		rc = smc_rtoken_add(link,
 +				    llc->rtoken[0].rmb_vaddr,
 +				    llc->rtoken[0].rmb_key);
++=======
+ 	lnk_asym = smc_llc_find_asym_link(lgr);
+ 	if (!lnk_asym)
+ 		return; /* no asymmetric link */
+ 	if (!smc_link_downing(&lnk_asym->state))
+ 		return;
+ 	lnk_new = smc_switch_conns(lgr, lnk_asym, false);
+ 	smc_wr_tx_wait_no_pending_sends(lnk_asym);
+ 	if (!lnk_new)
+ 		goto out_free;
+ 	/* change flow type from ADD_LINK into DEL_LINK */
+ 	lgr->llc_flow_lcl.type = SMC_LLC_FLOW_DEL_LINK;
+ 	rc = smc_llc_send_delete_link(lnk_new, lnk_asym->link_id, SMC_LLC_REQ,
+ 				      true, SMC_LLC_DEL_NO_ASYM_NEEDED);
+ 	if (rc) {
+ 		smcr_link_down_cond(lnk_new);
+ 		goto out_free;
+ 	}
+ 	qentry = smc_llc_wait(lgr, lnk_new, SMC_LLC_WAIT_TIME,
+ 			      SMC_LLC_DELETE_LINK);
+ 	if (!qentry) {
+ 		smcr_link_down_cond(lnk_new);
+ 		goto out_free;
+ 	}
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ out_free:
+ 	smcr_link_clear(lnk_asym, true);
+ }
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  
 -static int smc_llc_srv_rkey_exchange(struct smc_link *link,
 -				     struct smc_link *link_new)
 -{
 -	struct smc_llc_msg_add_link_cont *addc_llc;
 -	struct smc_link_group *lgr = link->lgr;
 -	u8 max, num_rkeys_send, num_rkeys_recv;
 -	struct smc_llc_qentry *qentry = NULL;
 -	struct smc_buf_desc *buf_pos;
 -	int buf_lst;
 -	int rc = 0;
 -	int i;
 +		/* ignore rtokens for other links, we have only one link */
  
++<<<<<<< HEAD
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		if (rc < 0)
 +			llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
++=======
+ 	mutex_lock(&lgr->rmbs_lock);
+ 	num_rkeys_send = lgr->conns_num;
+ 	buf_pos = smc_llc_get_first_rmb(lgr, &buf_lst);
+ 	do {
+ 		smc_llc_add_link_cont(link, link_new, &num_rkeys_send,
+ 				      &buf_lst, &buf_pos);
+ 		qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_TIME,
+ 				      SMC_LLC_ADD_LINK_CONT);
+ 		if (!qentry) {
+ 			rc = -ETIMEDOUT;
+ 			goto out;
+ 		}
+ 		addc_llc = &qentry->msg.add_link_cont;
+ 		num_rkeys_recv = addc_llc->num_rkeys;
+ 		max = min_t(u8, num_rkeys_recv, SMC_LLC_RKEYS_PER_CONT_MSG);
+ 		for (i = 0; i < max; i++) {
+ 			smc_rtoken_set(lgr, link->link_idx, link_new->link_idx,
+ 				       addc_llc->rt[i].rmb_key,
+ 				       addc_llc->rt[i].rmb_vaddr_new,
+ 				       addc_llc->rt[i].rmb_key_new);
+ 			num_rkeys_recv--;
+ 		}
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 	} while (num_rkeys_send || num_rkeys_recv);
+ out:
+ 	mutex_unlock(&lgr->rmbs_lock);
+ 	return rc;
+ }
+ 
+ static int smc_llc_srv_conf_link(struct smc_link *link,
+ 				 struct smc_link *link_new,
+ 				 enum smc_lgr_type lgr_new_t)
+ {
+ 	struct smc_link_group *lgr = link->lgr;
+ 	struct smc_llc_qentry *qentry = NULL;
+ 	int rc;
+ 
+ 	/* send CONFIRM LINK request over the RoCE fabric */
+ 	rc = smc_llc_send_confirm_link(link_new, SMC_LLC_REQ);
+ 	if (rc)
+ 		return -ENOLINK;
+ 	/* receive CONFIRM LINK response over the RoCE fabric */
+ 	qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_FIRST_TIME,
+ 			      SMC_LLC_CONFIRM_LINK);
+ 	if (!qentry) {
+ 		/* send DELETE LINK */
+ 		smc_llc_send_delete_link(link, link_new->link_id, SMC_LLC_REQ,
+ 					 false, SMC_LLC_DEL_LOST_PATH);
+ 		return -ENOLINK;
+ 	}
+ 	smc_llc_save_peer_uid(qentry);
+ 	smc_llc_link_active(link_new);
+ 	if (lgr_new_t == SMC_LGR_ASYMMETRIC_LOCAL ||
+ 	    lgr_new_t == SMC_LGR_ASYMMETRIC_PEER)
+ 		smcr_lgr_set_type_asym(lgr, lgr_new_t, link_new->link_idx);
+ 	else
+ 		smcr_lgr_set_type(lgr, lgr_new_t);
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 	return 0;
+ }
+ 
+ int smc_llc_srv_add_link(struct smc_link *link)
+ {
+ 	enum smc_lgr_type lgr_new_t = SMC_LGR_SYMMETRIC;
+ 	struct smc_link_group *lgr = link->lgr;
+ 	struct smc_llc_msg_add_link *add_llc;
+ 	struct smc_llc_qentry *qentry = NULL;
+ 	struct smc_link *link_new;
+ 	struct smc_init_info ini;
+ 	int lnk_idx, rc = 0;
+ 
+ 	/* ignore client add link recommendation, start new flow */
+ 	ini.vlan_id = lgr->vlan_id;
+ 	smc_pnet_find_alt_roce(lgr, &ini, link->smcibdev);
+ 	if (!ini.ib_dev) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_LOCAL;
+ 		ini.ib_dev = link->smcibdev;
+ 		ini.ib_port = link->ibport;
+ 	}
+ 	lnk_idx = smc_llc_alloc_alt_link(lgr, lgr_new_t);
+ 	if (lnk_idx < 0)
+ 		return 0;
+ 
+ 	rc = smcr_link_init(lgr, &lgr->lnk[lnk_idx], lnk_idx, &ini);
+ 	if (rc)
+ 		return rc;
+ 	link_new = &lgr->lnk[lnk_idx];
+ 	rc = smc_llc_send_add_link(link,
+ 				   link_new->smcibdev->mac[ini.ib_port - 1],
+ 				   link_new->gid, link_new, SMC_LLC_REQ);
+ 	if (rc)
+ 		goto out_err;
+ 	/* receive ADD LINK response over the RoCE fabric */
+ 	qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_TIME, SMC_LLC_ADD_LINK);
+ 	if (!qentry) {
+ 		rc = -ETIMEDOUT;
+ 		goto out_err;
+ 	}
+ 	add_llc = &qentry->msg.add_link;
+ 	if (add_llc->hd.flags & SMC_LLC_FLAG_ADD_LNK_REJ) {
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 		rc = -ENOLINK;
+ 		goto out_err;
+ 	}
+ 	if (lgr->type == SMC_LGR_SINGLE &&
+ 	    (!memcmp(add_llc->sender_gid, link->peer_gid, SMC_GID_SIZE) &&
+ 	     !memcmp(add_llc->sender_mac, link->peer_mac, ETH_ALEN))) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_PEER;
+ 	}
+ 	smc_llc_save_add_link_info(link_new, add_llc);
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 
+ 	rc = smc_ib_ready_link(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smcr_buf_map_lgr(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smcr_buf_reg_lgr(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smc_llc_srv_rkey_exchange(link, link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smc_llc_srv_conf_link(link, link_new, lgr_new_t);
+ 	if (rc)
+ 		goto out_err;
+ 	return 0;
+ out_err:
+ 	smcr_link_clear(link_new, false);
+ 	return rc;
+ }
+ 
+ static void smc_llc_process_srv_add_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_link *link = lgr->llc_flow_lcl.qentry->link;
+ 	int rc;
+ 
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	rc = smc_llc_srv_add_link(link);
+ 	if (!rc && lgr->type == SMC_LGR_SYMMETRIC) {
+ 		/* delete any asymmetric link */
+ 		smc_llc_delete_asym_link(lgr);
+ 	}
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ }
+ 
+ /* enqueue a local add_link req to trigger a new add_link flow, only as SERV */
+ void smc_llc_srv_add_link_local(struct smc_link *link)
+ {
+ 	struct smc_llc_msg_add_link add_llc = {0};
+ 
+ 	add_llc.hd.length = sizeof(add_llc);
+ 	add_llc.hd.common.type = SMC_LLC_ADD_LINK;
+ 	/* no dev and port needed, we as server ignore client data anyway */
+ 	smc_llc_enqueue(link, (union smc_llc_msg *)&add_llc);
+ }
+ 
+ /* worker to process an add link message */
+ static void smc_llc_add_link_work(struct work_struct *work)
+ {
+ 	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
+ 						  llc_add_link_work);
+ 
+ 	if (list_empty(&lgr->list)) {
+ 		/* link group is terminating */
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 		goto out;
+ 	}
+ 
+ 	if (lgr->role == SMC_CLNT)
+ 		smc_llc_process_cli_add_link(lgr);
+ 	else
+ 		smc_llc_process_srv_add_link(lgr);
+ out:
+ 	smc_llc_flow_stop(lgr, &lgr->llc_flow_lcl);
+ }
+ 
+ /* enqueue a local del_link msg to trigger a new del_link flow,
+  * called only for role SMC_SERV
+  */
+ void smc_llc_srv_delete_link_local(struct smc_link *link, u8 del_link_id)
+ {
+ 	struct smc_llc_msg_del_link del_llc = {0};
+ 
+ 	del_llc.hd.length = sizeof(del_llc);
+ 	del_llc.hd.common.type = SMC_LLC_DELETE_LINK;
+ 	del_llc.link_num = del_link_id;
+ 	del_llc.reason = htonl(SMC_LLC_DEL_LOST_PATH);
+ 	del_llc.hd.flags |= SMC_LLC_FLAG_DEL_LINK_ORDERLY;
+ 	smc_llc_enqueue(link, (union smc_llc_msg *)&del_llc);
+ }
+ 
+ static void smc_llc_process_cli_delete_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_link *lnk_del = NULL, *lnk_asym, *lnk;
+ 	struct smc_llc_msg_del_link *del_llc;
+ 	struct smc_llc_qentry *qentry;
+ 	int active_links;
+ 	int lnk_idx;
+ 
+ 	qentry = smc_llc_flow_qentry_clr(&lgr->llc_flow_lcl);
+ 	lnk = qentry->link;
+ 	del_llc = &qentry->msg.delete_link;
+ 
+ 	if (del_llc->hd.flags & SMC_LLC_FLAG_DEL_LINK_ALL) {
+ 		smc_lgr_terminate_sched(lgr);
+ 		goto out;
+ 	}
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	/* delete single link */
+ 	for (lnk_idx = 0; lnk_idx < SMC_LINKS_PER_LGR_MAX; lnk_idx++) {
+ 		if (lgr->lnk[lnk_idx].link_id != del_llc->link_num)
+ 			continue;
+ 		lnk_del = &lgr->lnk[lnk_idx];
+ 		break;
+ 	}
+ 	del_llc->hd.flags |= SMC_LLC_FLAG_RESP;
+ 	if (!lnk_del) {
+ 		/* link was not found */
+ 		del_llc->reason = htonl(SMC_LLC_DEL_NOLNK);
+ 		smc_llc_send_message(lnk, &qentry->msg);
+ 		goto out_unlock;
+ 	}
+ 	lnk_asym = smc_llc_find_asym_link(lgr);
+ 
+ 	del_llc->reason = 0;
+ 	smc_llc_send_message(lnk, &qentry->msg); /* response */
+ 
+ 	if (smc_link_downing(&lnk_del->state)) {
+ 		smc_switch_conns(lgr, lnk_del, false);
+ 		smc_wr_tx_wait_no_pending_sends(lnk_del);
+ 	}
+ 	smcr_link_clear(lnk_del, true);
+ 
+ 	active_links = smc_llc_active_link_count(lgr);
+ 	if (lnk_del == lnk_asym) {
+ 		/* expected deletion of asym link, don't change lgr state */
+ 	} else if (active_links == 1) {
+ 		smcr_lgr_set_type(lgr, SMC_LGR_SINGLE);
+ 	} else if (!active_links) {
+ 		smcr_lgr_set_type(lgr, SMC_LGR_NONE);
+ 		smc_lgr_terminate_sched(lgr);
+ 	}
+ out_unlock:
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ out:
+ 	kfree(qentry);
+ }
+ 
+ /* try to send a DELETE LINK ALL request on any active link,
+  * waiting for send completion
+  */
+ void smc_llc_send_link_delete_all(struct smc_link_group *lgr, bool ord, u32 rsn)
+ {
+ 	struct smc_llc_msg_del_link delllc = {0};
+ 	int i;
+ 
+ 	delllc.hd.common.type = SMC_LLC_DELETE_LINK;
+ 	delllc.hd.length = sizeof(delllc);
+ 	if (ord)
+ 		delllc.hd.flags |= SMC_LLC_FLAG_DEL_LINK_ORDERLY;
+ 	delllc.hd.flags |= SMC_LLC_FLAG_DEL_LINK_ALL;
+ 	delllc.reason = htonl(rsn);
+ 
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		if (!smc_link_usable(&lgr->lnk[i]))
+ 			continue;
+ 		if (!smc_llc_send_message_wait(&lgr->lnk[i], &delllc))
+ 			break;
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  	}
  }
  
 -static void smc_llc_process_srv_delete_link(struct smc_link_group *lgr)
 +static void smc_llc_rx_confirm_rkey_cont(struct smc_link *link,
 +				      struct smc_llc_msg_confirm_rkey_cont *llc)
  {
 -	struct smc_llc_msg_del_link *del_llc;
 -	struct smc_link *lnk, *lnk_del;
 -	struct smc_llc_qentry *qentry;
 -	int active_links;
 -	int i;
 -
 -	mutex_lock(&lgr->llc_conf_mutex);
 -	qentry = smc_llc_flow_qentry_clr(&lgr->llc_flow_lcl);
 -	lnk = qentry->link;
 -	del_llc = &qentry->msg.delete_link;
 -
 -	if (qentry->msg.delete_link.hd.flags & SMC_LLC_FLAG_DEL_LINK_ALL) {
 -		/* delete entire lgr */
 -		smc_llc_send_link_delete_all(lgr, true, ntohl(
 -					      qentry->msg.delete_link.reason));
 -		smc_lgr_terminate_sched(lgr);
 -		goto out;
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		/* unused as long as we don't send this type of msg */
 +	} else {
 +		/* ignore rtokens for other links, we have only one link */
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
++<<<<<<< HEAD
++=======
+ 	/* delete single link */
+ 	lnk_del = NULL;
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		if (lgr->lnk[i].link_id == del_llc->link_num) {
+ 			lnk_del = &lgr->lnk[i];
+ 			break;
+ 		}
+ 	}
+ 	if (!lnk_del)
+ 		goto out; /* asymmetric link already deleted */
+ 
+ 	if (smc_link_downing(&lnk_del->state)) {
+ 		smc_switch_conns(lgr, lnk_del, false);
+ 		smc_wr_tx_wait_no_pending_sends(lnk_del);
+ 	}
+ 	if (!list_empty(&lgr->list)) {
+ 		/* qentry is either a request from peer (send it back to
+ 		 * initiate the DELETE_LINK processing), or a locally
+ 		 * enqueued DELETE_LINK request (forward it)
+ 		 */
+ 		if (!smc_llc_send_message(lnk, &qentry->msg)) {
+ 			struct smc_llc_msg_del_link *del_llc_resp;
+ 			struct smc_llc_qentry *qentry2;
+ 
+ 			qentry2 = smc_llc_wait(lgr, lnk, SMC_LLC_WAIT_TIME,
+ 					       SMC_LLC_DELETE_LINK);
+ 			if (!qentry2) {
+ 			} else {
+ 				del_llc_resp = &qentry2->msg.delete_link;
+ 				smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 			}
+ 		}
+ 	}
+ 	smcr_link_clear(lnk_del, true);
+ 
+ 	active_links = smc_llc_active_link_count(lgr);
+ 	if (active_links == 1) {
+ 		smcr_lgr_set_type(lgr, SMC_LGR_SINGLE);
+ 	} else if (!active_links) {
+ 		smcr_lgr_set_type(lgr, SMC_LGR_NONE);
+ 		smc_lgr_terminate_sched(lgr);
+ 	}
+ 
+ 	if (lgr->type == SMC_LGR_SINGLE && !list_empty(&lgr->list)) {
+ 		/* trigger setup of asymm alt link */
+ 		smc_llc_srv_add_link_local(lnk);
+ 	}
+ out:
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ 	kfree(qentry);
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  }
  
 -static void smc_llc_delete_link_work(struct work_struct *work)
 -{
 -	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
 -						  llc_del_link_work);
 -
 -	if (list_empty(&lgr->list)) {
 -		/* link group is terminating */
 -		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
 -		goto out;
 -	}
 -
 -	if (lgr->role == SMC_CLNT)
 -		smc_llc_process_cli_delete_link(lgr);
 -	else
 -		smc_llc_process_srv_delete_link(lgr);
 -out:
 -	smc_llc_flow_stop(lgr, &lgr->llc_flow_lcl);
 -}
 -
 -/* process a confirm_rkey request from peer, remote flow */
 -static void smc_llc_rmt_conf_rkey(struct smc_link_group *lgr)
 +static void smc_llc_rx_delete_rkey(struct smc_link *link,
 +				   struct smc_llc_msg_delete_rkey *llc)
  {
 -	struct smc_llc_msg_confirm_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
 -	int num_entries;
 -	int rk_idx;
 -	int i;
 -
 -	qentry = lgr->llc_flow_rmt.qentry;
 -	llc = &qentry->msg.confirm_rkey;
 -	link = qentry->link;
 -
 -	num_entries = llc->rtoken[0].num_rkeys;
 -	/* first rkey entry is for receiving link */
 -	rk_idx = smc_rtoken_add(link,
 -				llc->rtoken[0].rmb_vaddr,
 -				llc->rtoken[0].rmb_key);
 -	if (rk_idx < 0)
 -		goto out_err;
 -
 -	for (i = 1; i <= min_t(u8, num_entries, SMC_LLC_RKEYS_PER_MSG - 1); i++)
 -		smc_rtoken_set2(lgr, rk_idx, llc->rtoken[i].link_id,
 -				llc->rtoken[i].rmb_vaddr,
 -				llc->rtoken[i].rmb_key);
 -	/* max links is 3 so there is no need to support conf_rkey_cont msgs */
 -	goto out;
 -out_err:
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_RETRY;
 -out:
 -	llc->hd.flags |= SMC_LLC_FLAG_RESP;
 -	smc_llc_send_message(link, &qentry->msg);
 -	smc_llc_flow_qentry_del(&lgr->llc_flow_rmt);
 -}
 -
 -/* process a delete_rkey request from peer, remote flow */
 -static void smc_llc_rmt_delete_rkey(struct smc_link_group *lgr)
 -{
 -	struct smc_llc_msg_delete_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
  	u8 err_mask = 0;
  	int i, max;
  
@@@ -644,28 -1709,33 +1077,48 @@@ int smc_llc_link_init(struct smc_link *
  	return 0;
  }
  
 -void smc_llc_link_active(struct smc_link *link)
 +void smc_llc_link_active(struct smc_link *link, int testlink_time)
  {
+ 	pr_warn_ratelimited("smc: SMC-R lg %*phN link added: id %*phN, "
+ 			    "peerid %*phN, ibdev %s, ibport %d\n",
+ 			    SMC_LGR_ID_SIZE, &link->lgr->id,
+ 			    SMC_LGR_ID_SIZE, &link->link_uid,
+ 			    SMC_LGR_ID_SIZE, &link->peer_link_uid,
+ 			    link->smcibdev->ibdev->name, link->ibport);
  	link->state = SMC_LNK_ACTIVE;
 -	if (link->lgr->llc_testlink_time) {
 -		link->llc_testlink_time = link->lgr->llc_testlink_time * HZ;
 +	if (testlink_time) {
 +		link->llc_testlink_time = testlink_time * HZ;
  		schedule_delayed_work(&link->llc_testlink_wrk,
  				      link->llc_testlink_time);
  	}
  }
  
++<<<<<<< HEAD
 +void smc_llc_link_deleting(struct smc_link *link)
 +{
 +	link->state = SMC_LNK_DELETING;
 +	smc_wr_wakeup_tx_wait(link);
 +}
 +
 +/* called in tasklet context */
 +void smc_llc_link_inactive(struct smc_link *link)
 +{
 +	if (link->state == SMC_LNK_INACTIVE)
 +		return;
 +	link->state = SMC_LNK_INACTIVE;
++=======
+ /* called in worker context */
+ void smc_llc_link_clear(struct smc_link *link, bool log)
+ {
+ 	if (log)
+ 		pr_warn_ratelimited("smc: SMC-R lg %*phN link removed: id %*phN"
+ 				    ", peerid %*phN, ibdev %s, ibport %d\n",
+ 				    SMC_LGR_ID_SIZE, &link->lgr->id,
+ 				    SMC_LGR_ID_SIZE, &link->link_uid,
+ 				    SMC_LGR_ID_SIZE, &link->peer_link_uid,
+ 				    link->smcibdev->ibdev->name, link->ibport);
+ 	complete(&link->llc_testlink_resp);
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  	cancel_delayed_work_sync(&link->llc_testlink_wrk);
  	smc_wr_wakeup_reg_wait(link);
  	smc_wr_wakeup_tx_wait(link);
diff --cc net/smc/smc_llc.h
index 461c0c3ef76e,a5d2fe3eea61..000000000000
--- a/net/smc/smc_llc.h
+++ b/net/smc/smc_llc.h
@@@ -39,18 -72,38 +39,24 @@@ enum smc_llc_msg_type 
  int smc_llc_send_confirm_link(struct smc_link *lnk,
  			      enum smc_llc_reqresp reqresp);
  int smc_llc_send_add_link(struct smc_link *link, u8 mac[], u8 gid[],
 -			  struct smc_link *link_new,
  			  enum smc_llc_reqresp reqresp);
 -int smc_llc_send_delete_link(struct smc_link *link, u8 link_del_id,
 -			     enum smc_llc_reqresp reqresp, bool orderly,
 -			     u32 reason);
 -void smc_llc_srv_delete_link_local(struct smc_link *link, u8 del_link_id);
 -void smc_llc_lgr_init(struct smc_link_group *lgr, struct smc_sock *smc);
 -void smc_llc_lgr_clear(struct smc_link_group *lgr);
 +int smc_llc_send_delete_link(struct smc_link *link,
 +			     enum smc_llc_reqresp reqresp, bool orderly);
  int smc_llc_link_init(struct smc_link *link);
++<<<<<<< HEAD
 +void smc_llc_link_active(struct smc_link *link, int testlink_time);
 +void smc_llc_link_deleting(struct smc_link *link);
 +void smc_llc_link_inactive(struct smc_link *link);
 +void smc_llc_link_clear(struct smc_link *link);
 +int smc_llc_do_confirm_rkey(struct smc_link *link,
++=======
+ void smc_llc_link_active(struct smc_link *link);
+ void smc_llc_link_clear(struct smc_link *link, bool log);
+ int smc_llc_do_confirm_rkey(struct smc_link *send_link,
++>>>>>>> 0a99be434d14 (net/smc: log important pnetid and state change events)
  			    struct smc_buf_desc *rmb_desc);
 -int smc_llc_do_delete_rkey(struct smc_link_group *lgr,
 +int smc_llc_do_delete_rkey(struct smc_link *link,
  			   struct smc_buf_desc *rmb_desc);
 -int smc_llc_flow_initiate(struct smc_link_group *lgr,
 -			  enum smc_llc_flowtype type);
 -void smc_llc_flow_stop(struct smc_link_group *lgr, struct smc_llc_flow *flow);
 -int smc_llc_eval_conf_link(struct smc_llc_qentry *qentry,
 -			   enum smc_llc_reqresp type);
 -void smc_llc_link_set_uid(struct smc_link *link);
 -void smc_llc_save_peer_uid(struct smc_llc_qentry *qentry);
 -struct smc_llc_qentry *smc_llc_wait(struct smc_link_group *lgr,
 -				    struct smc_link *lnk,
 -				    int time_out, u8 exp_msg);
 -struct smc_llc_qentry *smc_llc_flow_qentry_clr(struct smc_llc_flow *flow);
 -void smc_llc_flow_qentry_del(struct smc_llc_flow *flow);
 -void smc_llc_send_link_delete_all(struct smc_link_group *lgr, bool ord,
 -				  u32 rsn);
 -int smc_llc_cli_add_link(struct smc_link *link, struct smc_llc_qentry *qentry);
 -int smc_llc_srv_add_link(struct smc_link *link);
 -void smc_llc_srv_add_link_local(struct smc_link *link);
  int smc_llc_init(void) __init;
  
  #endif /* SMC_LLC_H */
* Unmerged path net/smc/af_smc.c
* Unmerged path net/smc/smc_core.c
* Unmerged path net/smc/smc_core.h
diff --git a/net/smc/smc_ib.c b/net/smc/smc_ib.c
index 3d87e3a22e90..0ee784d29a1a 100644
--- a/net/smc/smc_ib.c
+++ b/net/smc/smc_ib.c
@@ -575,6 +575,8 @@ static void smc_ib_add_dev(struct ib_device *ibdev)
 
 	/* trigger reading of the port attributes */
 	port_cnt = smcibdev->ibdev->phys_port_cnt;
+	pr_warn_ratelimited("smc: adding ib device %s with port count %d\n",
+			    smcibdev->ibdev->name, port_cnt);
 	for (i = 0;
 	     i < min_t(size_t, port_cnt, SMC_MAX_PORTS);
 	     i++) {
@@ -583,6 +585,13 @@ static void smc_ib_add_dev(struct ib_device *ibdev)
 		if (smc_pnetid_by_dev_port(ibdev->dev.parent, i,
 					   smcibdev->pnetid[i]))
 			smc_pnetid_by_table_ib(smcibdev, i + 1);
+		pr_warn_ratelimited("smc:    ib device %s port %d has pnetid "
+				    "%.16s%s\n",
+				    smcibdev->ibdev->name, i + 1,
+				    smcibdev->pnetid[i],
+				    smcibdev->pnetid_by_user[i] ?
+				     " (user defined)" :
+				     "");
 	}
 	schedule_work(&smcibdev->port_event_work);
 }
@@ -599,6 +608,8 @@ static void smc_ib_remove_dev(struct ib_device *ibdev, void *client_data)
 	spin_lock(&smc_ib_devices.lock);
 	list_del_init(&smcibdev->list); /* remove from smc_ib_devices */
 	spin_unlock(&smc_ib_devices.lock);
+	pr_warn_ratelimited("smc: removing ib device %s\n",
+			    smcibdev->ibdev->name);
 	smc_smcr_terminate_all(smcibdev);
 	smc_ib_cleanup_per_ibdev(smcibdev);
 	ib_unregister_event_handler(&smcibdev->event_handler);
diff --git a/net/smc/smc_ism.c b/net/smc/smc_ism.c
index 32be2da2cb85..91f85fc09fb8 100644
--- a/net/smc/smc_ism.c
+++ b/net/smc/smc_ism.c
@@ -321,12 +321,18 @@ int smcd_register_dev(struct smcd_dev *smcd)
 	list_add_tail(&smcd->list, &smcd_dev_list.list);
 	spin_unlock(&smcd_dev_list.lock);
 
+	pr_warn_ratelimited("smc: adding smcd device %s with pnetid %.16s%s\n",
+			    dev_name(&smcd->dev), smcd->pnetid,
+			    smcd->pnetid_by_user ? " (user defined)" : "");
+
 	return device_add(&smcd->dev);
 }
 EXPORT_SYMBOL_GPL(smcd_register_dev);
 
 void smcd_unregister_dev(struct smcd_dev *smcd)
 {
+	pr_warn_ratelimited("smc: removing smcd device %s\n",
+			    dev_name(&smcd->dev));
 	spin_lock(&smcd_dev_list.lock);
 	list_del_init(&smcd->list);
 	spin_unlock(&smcd_dev_list.lock);
* Unmerged path net/smc/smc_llc.c
* Unmerged path net/smc/smc_llc.h
diff --git a/net/smc/smc_pnet.c b/net/smc/smc_pnet.c
index ae595dc27284..5e9c0c2e6ee5 100644
--- a/net/smc/smc_pnet.c
+++ b/net/smc/smc_pnet.c
@@ -110,8 +110,14 @@ static int smc_pnet_remove_by_pnetid(struct net *net, char *pnet_name)
 		if (!pnet_name ||
 		    smc_pnet_match(pnetelem->pnet_name, pnet_name)) {
 			list_del(&pnetelem->list);
-			if (pnetelem->type == SMC_PNET_ETH && pnetelem->ndev)
+			if (pnetelem->type == SMC_PNET_ETH && pnetelem->ndev) {
 				dev_put(pnetelem->ndev);
+				pr_warn_ratelimited("smc: net device %s "
+						    "erased user defined "
+						    "pnetid %.16s\n",
+						    pnetelem->eth_name,
+						    pnetelem->pnet_name);
+			}
 			kfree(pnetelem);
 			rc = 0;
 		}
@@ -130,6 +136,12 @@ static int smc_pnet_remove_by_pnetid(struct net *net, char *pnet_name)
 			    (!pnet_name ||
 			     smc_pnet_match(pnet_name,
 					    ibdev->pnetid[ibport]))) {
+				pr_warn_ratelimited("smc: ib device %s ibport "
+						    "%d erased user defined "
+						    "pnetid %.16s\n",
+						    ibdev->ibdev->name,
+						    ibport + 1,
+						    ibdev->pnetid[ibport]);
 				memset(ibdev->pnetid[ibport], 0,
 				       SMC_MAX_PNETID_LEN);
 				ibdev->pnetid_by_user[ibport] = false;
@@ -144,6 +156,10 @@ static int smc_pnet_remove_by_pnetid(struct net *net, char *pnet_name)
 		if (smcd_dev->pnetid_by_user &&
 		    (!pnet_name ||
 		     smc_pnet_match(pnet_name, smcd_dev->pnetid))) {
+			pr_warn_ratelimited("smc: smcd device %s "
+					    "erased user defined pnetid "
+					    "%.16s\n", dev_name(&smcd_dev->dev),
+					    smcd_dev->pnetid);
 			memset(smcd_dev->pnetid, 0, SMC_MAX_PNETID_LEN);
 			smcd_dev->pnetid_by_user = false;
 			rc = 0;
@@ -174,6 +190,10 @@ static int smc_pnet_add_by_ndev(struct net_device *ndev)
 			dev_hold(ndev);
 			pnetelem->ndev = ndev;
 			rc = 0;
+			pr_warn_ratelimited("smc: adding net device %s with "
+					    "user defined pnetid %.16s\n",
+					    pnetelem->eth_name,
+					    pnetelem->pnet_name);
 			break;
 		}
 	}
@@ -201,6 +221,10 @@ static int smc_pnet_remove_by_ndev(struct net_device *ndev)
 			dev_put(pnetelem->ndev);
 			pnetelem->ndev = NULL;
 			rc = 0;
+			pr_warn_ratelimited("smc: removing net device %s with "
+					    "user defined pnetid %.16s\n",
+					    pnetelem->eth_name,
+					    pnetelem->pnet_name);
 			break;
 		}
 	}
@@ -357,6 +381,10 @@ static int smc_pnet_add_eth(struct smc_pnettable *pnettable, struct net *net,
 		kfree(new_pe);
 		goto out_put;
 	}
+	if (ndev)
+		pr_warn_ratelimited("smc: net device %s "
+				    "applied user defined pnetid %.16s\n",
+				    new_pe->eth_name, new_pe->pnet_name);
 	return 0;
 
 out_put:
@@ -377,11 +405,24 @@ static int smc_pnet_add_ib(struct smc_pnettable *pnettable, char *ib_name,
 
 	/* try to apply the pnetid to active devices */
 	ib_dev = smc_pnet_find_ib(ib_name);
-	if (ib_dev)
+	if (ib_dev) {
 		ibdev_applied = smc_pnet_apply_ib(ib_dev, ib_port, pnet_name);
+		if (ibdev_applied)
+			pr_warn_ratelimited("smc: ib device %s ibport %d "
+					    "applied user defined pnetid "
+					    "%.16s\n", ib_dev->ibdev->name,
+					    ib_port,
+					    ib_dev->pnetid[ib_port - 1]);
+	}
 	smcd_dev = smc_pnet_find_smcd(ib_name);
-	if (smcd_dev)
+	if (smcd_dev) {
 		smcddev_applied = smc_pnet_apply_smcd(smcd_dev, pnet_name);
+		if (smcddev_applied)
+			pr_warn_ratelimited("smc: smcd device %s "
+					    "applied user defined pnetid "
+					    "%.16s\n", dev_name(&smcd_dev->dev),
+					    smcd_dev->pnetid);
+	}
 	/* Apply fails when a device has a hardware-defined pnetid set, do not
 	 * add a pnet table entry in that case.
 	 */
