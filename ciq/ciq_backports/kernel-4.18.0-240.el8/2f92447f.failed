powerpc/book3s64/hash: Use the pte_t address from the caller

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
Rebuild_CHGLOG: - [powerpc] book3s64/hash: Use the pte_t address from the caller (Greg Kurz) [1748772]
Rebuild_FUZZ: 92.86%
commit-author Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
commit 2f92447f9f96583112420aa3cfb400ded55f667e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/2f92447f.failed

Don't fetch the pte value using lockless page table walk. Instead use the value from the
caller. hash_preload is called with ptl lock held. So it is safe to use the
pte_t address directly.

	Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://lore.kernel.org/r/20200505071729.54912-6-aneesh.kumar@linux.ibm.com
(cherry picked from commit 2f92447f9f96583112420aa3cfb400ded55f667e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/mm/book3s64/hash_utils.c
diff --cc arch/powerpc/mm/book3s64/hash_utils.c
index a638a0fa8666,3d727f73a8db..000000000000
--- a/arch/powerpc/mm/book3s64/hash_utils.c
+++ b/arch/powerpc/mm/book3s64/hash_utils.c
@@@ -1507,14 -1546,11 +1507,16 @@@ static bool should_hash_preload(struct 
  }
  #endif
  
++<<<<<<< HEAD
 +void hash_preload(struct mm_struct *mm, unsigned long ea,
 +		  bool is_exec, unsigned long trap)
++=======
+ static void hash_preload(struct mm_struct *mm, pte_t *ptep, unsigned long ea,
+ 			 bool is_exec, unsigned long trap)
++>>>>>>> 2f92447f9f96 (powerpc/book3s64/hash: Use the pte_t address from the caller)
  {
- 	int hugepage_shift;
  	unsigned long vsid;
  	pgd_t *pgdir;
- 	pte_t *ptep;
- 	unsigned long flags;
  	int rc, ssize, update_flags = 0;
  	unsigned long access = _PAGE_PRESENT | _PAGE_READ | (is_exec ? _PAGE_EXEC : 0);
  
@@@ -1581,36 -1605,61 +1571,59 @@@
  	 */
  	if (rc == -1)
  		hash_failure_debug(ea, access, vsid, trap, ssize,
 -				   mm_ctx_user_psize(&mm->context),
 -				   mm_ctx_user_psize(&mm->context),
 +				   mm->context.user_psize,
 +				   mm->context.user_psize,
  				   pte_val(*ptep));
- out_exit:
- 	local_irq_restore(flags);
  }
  
 +#ifdef CONFIG_PPC_MEM_KEYS
  /*
 - * This is called at the end of handling a user page fault, when the
 - * fault has been handled by updating a PTE in the linux page tables.
 - * We use it to preload an HPTE into the hash table corresponding to
 - * the updated linux PTE.
 - *
 - * This must always be called with the pte lock held.
 + * Return the protection key associated with the given address and the
 + * mm_struct.
   */
 -void update_mmu_cache(struct vm_area_struct *vma, unsigned long address,
 -		      pte_t *ptep)
 +u16 get_mm_addr_key(struct mm_struct *mm, unsigned long address)
  {
 -	/*
 -	 * We don't need to worry about _PAGE_PRESENT here because we are
 -	 * called with either mm->page_table_lock held or ptl lock held
 -	 */
 -	unsigned long trap;
 -	bool is_exec;
 +	pte_t *ptep;
 +	u16 pkey = 0;
 +	unsigned long flags;
  
 -	if (radix_enabled()) {
 -		prefetch((void *)address);
 -		return;
 -	}
 +	if (!mm || !mm->pgd)
 +		return 0;
  
 -	/* We only want HPTEs for linux PTEs that have _PAGE_ACCESSED set */
 -	if (!pte_young(*ptep) || address >= TASK_SIZE)
 -		return;
 +	local_irq_save(flags);
 +	ptep = find_linux_pte(mm->pgd, address, NULL, NULL);
 +	if (ptep)
 +		pkey = pte_to_pkey_bits(pte_val(READ_ONCE(*ptep)));
 +	local_irq_restore(flags);
  
++<<<<<<< HEAD
 +	return pkey;
++=======
+ 	/*
+ 	 * We try to figure out if we are coming from an instruction
+ 	 * access fault and pass that down to __hash_page so we avoid
+ 	 * double-faulting on execution of fresh text. We have to test
+ 	 * for regs NULL since init will get here first thing at boot.
+ 	 *
+ 	 * We also avoid filling the hash if not coming from a fault.
+ 	 */
+ 
+ 	trap = current->thread.regs ? TRAP(current->thread.regs) : 0UL;
+ 	switch (trap) {
+ 	case 0x300:
+ 		is_exec = false;
+ 		break;
+ 	case 0x400:
+ 		is_exec = true;
+ 		break;
+ 	default:
+ 		return;
+ 	}
+ 
+ 	hash_preload(vma->vm_mm, ptep, address, is_exec, trap);
++>>>>>>> 2f92447f9f96 (powerpc/book3s64/hash: Use the pte_t address from the caller)
  }
 +#endif /* CONFIG_PPC_MEM_KEYS */
  
  #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
  static inline void tm_flush_hash_page(int local)
* Unmerged path arch/powerpc/mm/book3s64/hash_utils.c
