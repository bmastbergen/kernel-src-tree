KVM: PPC: Add skip_page_out parameter to uvmem functions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sukadev Bhattiprolu <sukadev@linux.ibm.com>
commit ce477a7a1cdfc9aaafcfd03b45bde131a88d51de
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/ce477a7a.failed

Add 'skip_page_out' parameter to kvmppc_uvmem_drop_pages() so the
callers can specify whetheter or not to skip paging out pages. This
will be needed in a follow-on patch that implements H_SVM_INIT_ABORT
hcall.

	Signed-off-by: Sukadev Bhattiprolu <sukadev@linux.ibm.com>
	Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
(cherry picked from commit ce477a7a1cdfc9aaafcfd03b45bde131a88d51de)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/kvm_book3s_uvmem.h
#	arch/powerpc/kvm/book3s_64_mmu_radix.c
#	arch/powerpc/kvm/book3s_hv.c
#	arch/powerpc/kvm/book3s_hv_uvmem.c
diff --cc arch/powerpc/kvm/book3s_64_mmu_radix.c
index 739cefd2ed03,744dba98e5d1..000000000000
--- a/arch/powerpc/kvm/book3s_64_mmu_radix.c
+++ b/arch/powerpc/kvm/book3s_64_mmu_radix.c
@@@ -1091,6 -1101,12 +1091,15 @@@ void kvmppc_radix_flush_memslot(struct 
  	unsigned long gpa;
  	unsigned int shift;
  
++<<<<<<< HEAD
++=======
+ 	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_START)
+ 		kvmppc_uvmem_drop_pages(memslot, kvm, true);
+ 
+ 	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_DONE)
+ 		return;
+ 
++>>>>>>> ce477a7a1cdf (KVM: PPC: Add skip_page_out parameter to uvmem functions)
  	gpa = memslot->base_gfn << PAGE_SHIFT;
  	spin_lock(&kvm->mmu_lock);
  	for (n = memslot->npages; n; --n) {
diff --cc arch/powerpc/kvm/book3s_hv.c
index 46a62698fcb1,47ffc7f1b104..000000000000
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@@ -5362,6 -5427,94 +5362,97 @@@ static int kvmhv_store_to_eaddr(struct 
  	return rc;
  }
  
++<<<<<<< HEAD
++=======
+ static void unpin_vpa_reset(struct kvm *kvm, struct kvmppc_vpa *vpa)
+ {
+ 	unpin_vpa(kvm, vpa);
+ 	vpa->gpa = 0;
+ 	vpa->pinned_addr = NULL;
+ 	vpa->dirty = false;
+ 	vpa->update_pending = 0;
+ }
+ 
+ /*
+  *  IOCTL handler to turn off secure mode of guest
+  *
+  * - Release all device pages
+  * - Issue ucall to terminate the guest on the UV side
+  * - Unpin the VPA pages.
+  * - Reinit the partition scoped page tables
+  */
+ static int kvmhv_svm_off(struct kvm *kvm)
+ {
+ 	struct kvm_vcpu *vcpu;
+ 	int mmu_was_ready;
+ 	int srcu_idx;
+ 	int ret = 0;
+ 	int i;
+ 
+ 	if (!(kvm->arch.secure_guest & KVMPPC_SECURE_INIT_START))
+ 		return ret;
+ 
+ 	mutex_lock(&kvm->arch.mmu_setup_lock);
+ 	mmu_was_ready = kvm->arch.mmu_ready;
+ 	if (kvm->arch.mmu_ready) {
+ 		kvm->arch.mmu_ready = 0;
+ 		/* order mmu_ready vs. vcpus_running */
+ 		smp_mb();
+ 		if (atomic_read(&kvm->arch.vcpus_running)) {
+ 			kvm->arch.mmu_ready = 1;
+ 			ret = -EBUSY;
+ 			goto out;
+ 		}
+ 	}
+ 
+ 	srcu_idx = srcu_read_lock(&kvm->srcu);
+ 	for (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++) {
+ 		struct kvm_memory_slot *memslot;
+ 		struct kvm_memslots *slots = __kvm_memslots(kvm, i);
+ 
+ 		if (!slots)
+ 			continue;
+ 
+ 		kvm_for_each_memslot(memslot, slots) {
+ 			kvmppc_uvmem_drop_pages(memslot, kvm, true);
+ 			uv_unregister_mem_slot(kvm->arch.lpid, memslot->id);
+ 		}
+ 	}
+ 	srcu_read_unlock(&kvm->srcu, srcu_idx);
+ 
+ 	ret = uv_svm_terminate(kvm->arch.lpid);
+ 	if (ret != U_SUCCESS) {
+ 		ret = -EINVAL;
+ 		goto out;
+ 	}
+ 
+ 	/*
+ 	 * When secure guest is reset, all the guest pages are sent
+ 	 * to UV via UV_PAGE_IN before the non-boot vcpus get a
+ 	 * chance to run and unpin their VPA pages. Unpinning of all
+ 	 * VPA pages is done here explicitly so that VPA pages
+ 	 * can be migrated to the secure side.
+ 	 *
+ 	 * This is required to for the secure SMP guest to reboot
+ 	 * correctly.
+ 	 */
+ 	kvm_for_each_vcpu(i, vcpu, kvm) {
+ 		spin_lock(&vcpu->arch.vpa_update_lock);
+ 		unpin_vpa_reset(kvm, &vcpu->arch.dtl);
+ 		unpin_vpa_reset(kvm, &vcpu->arch.slb_shadow);
+ 		unpin_vpa_reset(kvm, &vcpu->arch.vpa);
+ 		spin_unlock(&vcpu->arch.vpa_update_lock);
+ 	}
+ 
+ 	kvmppc_setup_partition_table(kvm);
+ 	kvm->arch.secure_guest = 0;
+ 	kvm->arch.mmu_ready = mmu_was_ready;
+ out:
+ 	mutex_unlock(&kvm->arch.mmu_setup_lock);
+ 	return ret;
+ }
+ 
++>>>>>>> ce477a7a1cdf (KVM: PPC: Add skip_page_out parameter to uvmem functions)
  static struct kvmppc_ops kvm_ops_hv = {
  	.get_sregs = kvm_arch_vcpu_ioctl_get_sregs_hv,
  	.set_sregs = kvm_arch_vcpu_ioctl_set_sregs_hv,
* Unmerged path arch/powerpc/include/asm/kvm_book3s_uvmem.h
* Unmerged path arch/powerpc/kvm/book3s_hv_uvmem.c
* Unmerged path arch/powerpc/include/asm/kvm_book3s_uvmem.h
* Unmerged path arch/powerpc/kvm/book3s_64_mmu_radix.c
* Unmerged path arch/powerpc/kvm/book3s_hv.c
* Unmerged path arch/powerpc/kvm/book3s_hv_uvmem.c
