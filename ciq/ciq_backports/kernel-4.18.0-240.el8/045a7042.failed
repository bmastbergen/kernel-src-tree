iommu: Rename struct iommu_param to dev_iommu

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Joerg Roedel <jroedel@suse.de>
commit 045a70426067d6a22e3e5745b55efc18fa75aabf
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/045a7042.failed

The term dev_iommu aligns better with other existing structures and
their accessor functions.

	Signed-off-by: Joerg Roedel <jroedel@suse.de>
	Tested-by: Will Deacon <will@kernel.org> # arm-smmu
	Reviewed-by: Jean-Philippe Brucker <jean-philippe@linaro.org>
	Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Link: https://lore.kernel.org/r/20200326150841.10083-6-joro@8bytes.org
(cherry picked from commit 045a70426067d6a22e3e5745b55efc18fa75aabf)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/iommu.c
#	include/linux/iommu.h
diff --cc drivers/iommu/iommu.c
index be043063e8fb,15d64a175d92..000000000000
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@@ -161,17 -150,57 +161,64 @@@ void iommu_device_unregister(struct iom
  	list_del(&iommu->list);
  	spin_unlock(&iommu_device_lock);
  }
++<<<<<<< HEAD
++=======
+ EXPORT_SYMBOL_GPL(iommu_device_unregister);
+ 
+ static struct dev_iommu *dev_iommu_get(struct device *dev)
+ {
+ 	struct dev_iommu *param = dev->iommu;
+ 
+ 	if (param)
+ 		return param;
+ 
+ 	param = kzalloc(sizeof(*param), GFP_KERNEL);
+ 	if (!param)
+ 		return NULL;
+ 
+ 	mutex_init(&param->lock);
+ 	dev->iommu = param;
+ 	return param;
+ }
+ 
+ static void dev_iommu_free(struct device *dev)
+ {
+ 	kfree(dev->iommu);
+ 	dev->iommu = NULL;
+ }
++>>>>>>> 045a70426067 (iommu: Rename struct iommu_param to dev_iommu)
  
  int iommu_probe_device(struct device *dev)
  {
  	const struct iommu_ops *ops = dev->bus->iommu_ops;
 -	int ret;
 +	int ret = -EINVAL;
  
  	WARN_ON(dev->iommu_group);
 -	if (!ops)
 -		return -EINVAL;
  
++<<<<<<< HEAD
 +	if (ops)
 +		ret = ops->add_device(dev);
 +
++=======
+ 	if (!dev_iommu_get(dev))
+ 		return -ENOMEM;
+ 
+ 	if (!try_module_get(ops->owner)) {
+ 		ret = -EINVAL;
+ 		goto err_free_dev_param;
+ 	}
+ 
+ 	ret = ops->add_device(dev);
+ 	if (ret)
+ 		goto err_module_put;
+ 
+ 	return 0;
+ 
+ err_module_put:
+ 	module_put(ops->owner);
+ err_free_dev_param:
+ 	dev_iommu_free(dev);
++>>>>>>> 045a70426067 (iommu: Rename struct iommu_param to dev_iommu)
  	return ret;
  }
  
@@@ -181,6 -210,11 +228,14 @@@ void iommu_release_device(struct devic
  
  	if (dev->iommu_group)
  		ops->remove_device(dev);
++<<<<<<< HEAD
++=======
+ 
+ 	if (dev->iommu) {
+ 		module_put(ops->owner);
+ 		dev_iommu_free(dev);
+ 	}
++>>>>>>> 045a70426067 (iommu: Rename struct iommu_param to dev_iommu)
  }
  
  static struct iommu_domain *__iommu_domain_alloc(struct bus_type *bus,
@@@ -916,6 -951,206 +971,209 @@@ int iommu_group_unregister_notifier(str
  EXPORT_SYMBOL_GPL(iommu_group_unregister_notifier);
  
  /**
++<<<<<<< HEAD
++=======
+  * iommu_register_device_fault_handler() - Register a device fault handler
+  * @dev: the device
+  * @handler: the fault handler
+  * @data: private data passed as argument to the handler
+  *
+  * When an IOMMU fault event is received, this handler gets called with the
+  * fault event and data as argument. The handler should return 0 on success. If
+  * the fault is recoverable (IOMMU_FAULT_PAGE_REQ), the consumer should also
+  * complete the fault by calling iommu_page_response() with one of the following
+  * response code:
+  * - IOMMU_PAGE_RESP_SUCCESS: retry the translation
+  * - IOMMU_PAGE_RESP_INVALID: terminate the fault
+  * - IOMMU_PAGE_RESP_FAILURE: terminate the fault and stop reporting
+  *   page faults if possible.
+  *
+  * Return 0 if the fault handler was installed successfully, or an error.
+  */
+ int iommu_register_device_fault_handler(struct device *dev,
+ 					iommu_dev_fault_handler_t handler,
+ 					void *data)
+ {
+ 	struct dev_iommu *param = dev->iommu;
+ 	int ret = 0;
+ 
+ 	if (!param)
+ 		return -EINVAL;
+ 
+ 	mutex_lock(&param->lock);
+ 	/* Only allow one fault handler registered for each device */
+ 	if (param->fault_param) {
+ 		ret = -EBUSY;
+ 		goto done_unlock;
+ 	}
+ 
+ 	get_device(dev);
+ 	param->fault_param = kzalloc(sizeof(*param->fault_param), GFP_KERNEL);
+ 	if (!param->fault_param) {
+ 		put_device(dev);
+ 		ret = -ENOMEM;
+ 		goto done_unlock;
+ 	}
+ 	param->fault_param->handler = handler;
+ 	param->fault_param->data = data;
+ 	mutex_init(&param->fault_param->lock);
+ 	INIT_LIST_HEAD(&param->fault_param->faults);
+ 
+ done_unlock:
+ 	mutex_unlock(&param->lock);
+ 
+ 	return ret;
+ }
+ EXPORT_SYMBOL_GPL(iommu_register_device_fault_handler);
+ 
+ /**
+  * iommu_unregister_device_fault_handler() - Unregister the device fault handler
+  * @dev: the device
+  *
+  * Remove the device fault handler installed with
+  * iommu_register_device_fault_handler().
+  *
+  * Return 0 on success, or an error.
+  */
+ int iommu_unregister_device_fault_handler(struct device *dev)
+ {
+ 	struct dev_iommu *param = dev->iommu;
+ 	int ret = 0;
+ 
+ 	if (!param)
+ 		return -EINVAL;
+ 
+ 	mutex_lock(&param->lock);
+ 
+ 	if (!param->fault_param)
+ 		goto unlock;
+ 
+ 	/* we cannot unregister handler if there are pending faults */
+ 	if (!list_empty(&param->fault_param->faults)) {
+ 		ret = -EBUSY;
+ 		goto unlock;
+ 	}
+ 
+ 	kfree(param->fault_param);
+ 	param->fault_param = NULL;
+ 	put_device(dev);
+ unlock:
+ 	mutex_unlock(&param->lock);
+ 
+ 	return ret;
+ }
+ EXPORT_SYMBOL_GPL(iommu_unregister_device_fault_handler);
+ 
+ /**
+  * iommu_report_device_fault() - Report fault event to device driver
+  * @dev: the device
+  * @evt: fault event data
+  *
+  * Called by IOMMU drivers when a fault is detected, typically in a threaded IRQ
+  * handler. When this function fails and the fault is recoverable, it is the
+  * caller's responsibility to complete the fault.
+  *
+  * Return 0 on success, or an error.
+  */
+ int iommu_report_device_fault(struct device *dev, struct iommu_fault_event *evt)
+ {
+ 	struct dev_iommu *param = dev->iommu;
+ 	struct iommu_fault_event *evt_pending = NULL;
+ 	struct iommu_fault_param *fparam;
+ 	int ret = 0;
+ 
+ 	if (!param || !evt)
+ 		return -EINVAL;
+ 
+ 	/* we only report device fault if there is a handler registered */
+ 	mutex_lock(&param->lock);
+ 	fparam = param->fault_param;
+ 	if (!fparam || !fparam->handler) {
+ 		ret = -EINVAL;
+ 		goto done_unlock;
+ 	}
+ 
+ 	if (evt->fault.type == IOMMU_FAULT_PAGE_REQ &&
+ 	    (evt->fault.prm.flags & IOMMU_FAULT_PAGE_REQUEST_LAST_PAGE)) {
+ 		evt_pending = kmemdup(evt, sizeof(struct iommu_fault_event),
+ 				      GFP_KERNEL);
+ 		if (!evt_pending) {
+ 			ret = -ENOMEM;
+ 			goto done_unlock;
+ 		}
+ 		mutex_lock(&fparam->lock);
+ 		list_add_tail(&evt_pending->list, &fparam->faults);
+ 		mutex_unlock(&fparam->lock);
+ 	}
+ 
+ 	ret = fparam->handler(&evt->fault, fparam->data);
+ 	if (ret && evt_pending) {
+ 		mutex_lock(&fparam->lock);
+ 		list_del(&evt_pending->list);
+ 		mutex_unlock(&fparam->lock);
+ 		kfree(evt_pending);
+ 	}
+ done_unlock:
+ 	mutex_unlock(&param->lock);
+ 	return ret;
+ }
+ EXPORT_SYMBOL_GPL(iommu_report_device_fault);
+ 
+ int iommu_page_response(struct device *dev,
+ 			struct iommu_page_response *msg)
+ {
+ 	bool pasid_valid;
+ 	int ret = -EINVAL;
+ 	struct iommu_fault_event *evt;
+ 	struct iommu_fault_page_request *prm;
+ 	struct dev_iommu *param = dev->iommu;
+ 	struct iommu_domain *domain = iommu_get_domain_for_dev(dev);
+ 
+ 	if (!domain || !domain->ops->page_response)
+ 		return -ENODEV;
+ 
+ 	if (!param || !param->fault_param)
+ 		return -EINVAL;
+ 
+ 	if (msg->version != IOMMU_PAGE_RESP_VERSION_1 ||
+ 	    msg->flags & ~IOMMU_PAGE_RESP_PASID_VALID)
+ 		return -EINVAL;
+ 
+ 	/* Only send response if there is a fault report pending */
+ 	mutex_lock(&param->fault_param->lock);
+ 	if (list_empty(&param->fault_param->faults)) {
+ 		dev_warn_ratelimited(dev, "no pending PRQ, drop response\n");
+ 		goto done_unlock;
+ 	}
+ 	/*
+ 	 * Check if we have a matching page request pending to respond,
+ 	 * otherwise return -EINVAL
+ 	 */
+ 	list_for_each_entry(evt, &param->fault_param->faults, list) {
+ 		prm = &evt->fault.prm;
+ 		pasid_valid = prm->flags & IOMMU_FAULT_PAGE_REQUEST_PASID_VALID;
+ 
+ 		if ((pasid_valid && prm->pasid != msg->pasid) ||
+ 		    prm->grpid != msg->grpid)
+ 			continue;
+ 
+ 		/* Sanitize the reply */
+ 		msg->flags = pasid_valid ? IOMMU_PAGE_RESP_PASID_VALID : 0;
+ 
+ 		ret = domain->ops->page_response(dev, evt, msg);
+ 		list_del(&evt->list);
+ 		kfree(evt);
+ 		break;
+ 	}
+ 
+ done_unlock:
+ 	mutex_unlock(&param->fault_param->lock);
+ 	return ret;
+ }
+ EXPORT_SYMBOL_GPL(iommu_page_response);
+ 
+ /**
++>>>>>>> 045a70426067 (iommu: Rename struct iommu_param to dev_iommu)
   * iommu_group_id - Return ID for a group
   * @group: the group to ID
   *
diff --cc include/linux/iommu.h
index 8e26403172ec,843baaa65f10..000000000000
--- a/include/linux/iommu.h
+++ b/include/linux/iommu.h
@@@ -343,6 -336,48 +343,51 @@@ struct iommu_device 
  	struct device *dev;
  };
  
++<<<<<<< HEAD
++=======
+ /**
+  * struct iommu_fault_event - Generic fault event
+  *
+  * Can represent recoverable faults such as a page requests or
+  * unrecoverable faults such as DMA or IRQ remapping faults.
+  *
+  * @fault: fault descriptor
+  * @list: pending fault event list, used for tracking responses
+  */
+ struct iommu_fault_event {
+ 	struct iommu_fault fault;
+ 	struct list_head list;
+ };
+ 
+ /**
+  * struct iommu_fault_param - per-device IOMMU fault data
+  * @handler: Callback function to handle IOMMU faults at device level
+  * @data: handler private data
+  * @faults: holds the pending faults which needs response
+  * @lock: protect pending faults list
+  */
+ struct iommu_fault_param {
+ 	iommu_dev_fault_handler_t handler;
+ 	void *data;
+ 	struct list_head faults;
+ 	struct mutex lock;
+ };
+ 
+ /**
+  * struct dev_iommu - Collection of per-device IOMMU data
+  *
+  * @fault_param: IOMMU detected device fault reporting data
+  *
+  * TODO: migrate other per device data pointers under iommu_dev_data, e.g.
+  *	struct iommu_group	*iommu_group;
+  *	struct iommu_fwspec	*iommu_fwspec;
+  */
+ struct dev_iommu {
+ 	struct mutex lock;
+ 	struct iommu_fault_param *fault_param;
+ };
+ 
++>>>>>>> 045a70426067 (iommu: Rename struct iommu_param to dev_iommu)
  int  iommu_device_register(struct iommu_device *iommu);
  void iommu_device_unregister(struct iommu_device *iommu);
  int  iommu_device_sysfs_add(struct iommu_device *iommu,
* Unmerged path drivers/iommu/iommu.c
diff --git a/include/linux/device.h b/include/linux/device.h
index a7e07e1be4e6..fc3f23153d11 100644
--- a/include/linux/device.h
+++ b/include/linux/device.h
@@ -43,7 +43,7 @@ struct iommu_ops;
 struct iommu_group;
 struct iommu_fwspec;
 struct dev_pin_info;
-struct iommu_param;
+struct dev_iommu;
 
 struct bus_attribute {
 	struct attribute	attr;
@@ -954,7 +954,7 @@ struct device_extended_rh {
  * 		device (i.e. the bus driver that discovered the device).
  * @iommu_group: IOMMU group the device belongs to.
  * @iommu_fwspec: IOMMU-specific properties supplied by firmware.
- * @iommu_param: Per device generic IOMMU runtime data
+ * @iommu:	Per device generic IOMMU runtime data
  *
  * @offline_disabled: If set, the device is permanently online.
  * @offline:	Set after successful invocation of bus type's .offline().
@@ -1047,7 +1047,7 @@ struct device {
 	void	(*release)(struct device *dev);
 	struct iommu_group	*iommu_group;
 	struct iommu_fwspec	*iommu_fwspec;
-	struct iommu_param	*iommu_param;
+	struct dev_iommu	*iommu;
 
 	/* RHEL8 kabi note: Total of 64-bits of bool can be defined. */
 	bool			offline_disabled:1;
* Unmerged path include/linux/iommu.h
