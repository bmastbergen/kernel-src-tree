io_uring: move all prep state for IORING_OP_CONNECT to prep handler

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit 3fbb51c18f5c15a23db74c4da79d3d035176c480
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/3fbb51c1.failed

Add struct io_connect in our io_kiocb per-command union, and ensure
that io_connect_prep() has grabbed what it needs from the SQE.

	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 3fbb51c18f5c15a23db74c4da79d3d035176c480)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index ab99aea677bc,2a173f54ec8e..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -308,6 -299,80 +308,83 @@@ struct io_poll_iocb 
  	struct wait_queue_entry		wait;
  };
  
++<<<<<<< HEAD
++=======
+ struct io_timeout_data {
+ 	struct io_kiocb			*req;
+ 	struct hrtimer			timer;
+ 	struct timespec64		ts;
+ 	enum hrtimer_mode		mode;
+ 	u32				seq_offset;
+ };
+ 
+ struct io_accept {
+ 	struct file			*file;
+ 	struct sockaddr __user		*addr;
+ 	int __user			*addr_len;
+ 	int				flags;
+ };
+ 
+ struct io_sync {
+ 	struct file			*file;
+ 	loff_t				len;
+ 	loff_t				off;
+ 	int				flags;
+ };
+ 
+ struct io_cancel {
+ 	struct file			*file;
+ 	u64				addr;
+ };
+ 
+ struct io_timeout {
+ 	struct file			*file;
+ 	u64				addr;
+ 	int				flags;
+ };
+ 
+ struct io_rw {
+ 	/* NOTE: kiocb has the file as the first member, so don't do it here */
+ 	struct kiocb			kiocb;
+ 	u64				addr;
+ 	u64				len;
+ };
+ 
+ struct io_connect {
+ 	struct file			*file;
+ 	struct sockaddr __user		*addr;
+ 	int				addr_len;
+ };
+ 
+ struct io_async_connect {
+ 	struct sockaddr_storage		address;
+ };
+ 
+ struct io_async_msghdr {
+ 	struct iovec			fast_iov[UIO_FASTIOV];
+ 	struct iovec			*iov;
+ 	struct sockaddr __user		*uaddr;
+ 	struct msghdr			msg;
+ };
+ 
+ struct io_async_rw {
+ 	struct iovec			fast_iov[UIO_FASTIOV];
+ 	struct iovec			*iov;
+ 	ssize_t				nr_segs;
+ 	ssize_t				size;
+ };
+ 
+ struct io_async_ctx {
+ 	struct io_uring_sqe		sqe;
+ 	union {
+ 		struct io_async_rw	rw;
+ 		struct io_async_msghdr	msg;
+ 		struct io_async_connect	connect;
+ 		struct io_timeout_data	timeout;
+ 	};
+ };
+ 
++>>>>>>> 3fbb51c18f5c (io_uring: move all prep state for IORING_OP_CONNECT to prep handler)
  /*
   * NOTE! Each of the iocb union members has the file pointer
   * as the first entry in their struct definition. So you can
@@@ -317,14 -382,29 +394,22 @@@
  struct io_kiocb {
  	union {
  		struct file		*file;
 -		struct io_rw		rw;
 +		struct kiocb		rw;
  		struct io_poll_iocb	poll;
++<<<<<<< HEAD
++=======
+ 		struct io_accept	accept;
+ 		struct io_sync		sync;
+ 		struct io_cancel	cancel;
+ 		struct io_timeout	timeout;
+ 		struct io_connect	connect;
++>>>>>>> 3fbb51c18f5c (io_uring: move all prep state for IORING_OP_CONNECT to prep handler)
  	};
  
 -	const struct io_uring_sqe	*sqe;
 -	struct io_async_ctx		*io;
 -	struct file			*ring_file;
 -	int				ring_fd;
 -	bool				has_user;
 -	bool				in_async;
 -	bool				needs_fixed_file;
 -	u8				opcode;
 +	struct sqe_submit	submit;
  
  	struct io_ring_ctx	*ctx;
 -	union {
 -		struct list_head	list;
 -		struct hlist_node	hash_node;
 -	};
 +	struct list_head	list;
  	struct list_head	link_list;
  	unsigned int		flags;
  	refcount_t		refs;
@@@ -1610,13 -2229,37 +1695,14 @@@ static int io_send_recvmsg(struct io_ki
  			ret = -EINTR;
  	}
  
 -out:
 -	if (!io_wq_current_is_worker() && kmsg && kmsg->iov != kmsg->fast_iov)
 -		kfree(kmsg->iov);
 -	io_cqring_add_event(req, ret);
 -	if (ret < 0)
 -		req_set_fail_links(req);
 -	io_put_req_find_next(req, nxt);
 +	io_cqring_add_event(req->ctx, sqe->user_data, ret);
 +	io_put_req(req);
  	return 0;
 -#else
 -	return -EOPNOTSUPP;
 -#endif
  }
 -
 -static int io_recvmsg_prep(struct io_kiocb *req, struct io_async_ctx *io)
 -{
 -#if defined(CONFIG_NET)
 -	const struct io_uring_sqe *sqe = req->sqe;
 -	struct user_msghdr __user *msg;
 -	unsigned flags;
 -
 -	flags = READ_ONCE(sqe->msg_flags);
 -	msg = u64_to_user_ptr(READ_ONCE(sqe->addr));
 -	io->msg.iov = io->msg.fast_iov;
 -	return recvmsg_copy_msghdr(&io->msg.msg, msg, flags, &io->msg.uaddr,
 -					&io->msg.iov);
 -#else
 -	return 0;
  #endif
 -}
  
 -static int io_recvmsg(struct io_kiocb *req, struct io_kiocb **nxt,
++<<<<<<< HEAD
 +static int io_sendmsg(struct io_kiocb *req, const struct io_uring_sqe *sqe,
  		      bool force_nonblock)
  {
  #if defined(CONFIG_NET)
@@@ -1626,11 -2327,146 +1712,94 @@@
  #endif
  }
  
 -static int io_accept_prep(struct io_kiocb *req)
 +static int io_recvmsg(struct io_kiocb *req, const struct io_uring_sqe *sqe,
 +		      bool force_nonblock)
  {
  #if defined(CONFIG_NET)
 -	const struct io_uring_sqe *sqe = req->sqe;
 -	struct io_accept *accept = &req->accept;
 -
 -	if (req->flags & REQ_F_PREPPED)
 -		return 0;
 -
 -	if (unlikely(req->ctx->flags & (IORING_SETUP_IOPOLL|IORING_SETUP_SQPOLL)))
 -		return -EINVAL;
 -	if (sqe->ioprio || sqe->len || sqe->buf_index)
 -		return -EINVAL;
 -
 -	accept->addr = u64_to_user_ptr(READ_ONCE(sqe->addr));
 -	accept->addr_len = u64_to_user_ptr(READ_ONCE(sqe->addr2));
 -	accept->flags = READ_ONCE(sqe->accept_flags);
 -	req->flags |= REQ_F_PREPPED;
 -	return 0;
 -#else
 -	return -EOPNOTSUPP;
 -#endif
 -}
 -
 -#if defined(CONFIG_NET)
 -static int __io_accept(struct io_kiocb *req, struct io_kiocb **nxt,
 -		       bool force_nonblock)
 -{
 -	struct io_accept *accept = &req->accept;
 -	unsigned file_flags;
 -	int ret;
 -
 -	file_flags = force_nonblock ? O_NONBLOCK : 0;
 -	ret = __sys_accept4_file(req->file, file_flags, accept->addr,
 -					accept->addr_len, accept->flags);
 -	if (ret == -EAGAIN && force_nonblock)
 -		return -EAGAIN;
 -	if (ret == -ERESTARTSYS)
 -		ret = -EINTR;
 -	if (ret < 0)
 -		req_set_fail_links(req);
 -	io_cqring_add_event(req, ret);
 -	io_put_req_find_next(req, nxt);
 -	return 0;
 -}
 -
 -static void io_accept_finish(struct io_wq_work **workptr)
 -{
 -	struct io_kiocb *req = container_of(*workptr, struct io_kiocb, work);
 -	struct io_kiocb *nxt = NULL;
 -
 -	if (io_req_cancelled(req))
 -		return;
 -	__io_accept(req, &nxt, false);
 -	if (nxt)
 -		*workptr = &nxt->work;
 -}
 -#endif
 -
 +	return io_send_recvmsg(req, sqe, force_nonblock, __sys_recvmsg_sock);
++=======
+ static int io_accept(struct io_kiocb *req, struct io_kiocb **nxt,
+ 		     bool force_nonblock)
+ {
+ #if defined(CONFIG_NET)
+ 	int ret;
+ 
+ 	ret = io_accept_prep(req);
+ 	if (ret)
+ 		return ret;
+ 
+ 	ret = __io_accept(req, nxt, force_nonblock);
+ 	if (ret == -EAGAIN && force_nonblock) {
+ 		req->work.func = io_accept_finish;
+ 		req->work.flags |= IO_WQ_WORK_NEEDS_FILES;
+ 		io_put_req(req);
+ 		return -EAGAIN;
+ 	}
+ 	return 0;
+ #else
+ 	return -EOPNOTSUPP;
+ #endif
+ }
+ 
+ static int io_connect_prep(struct io_kiocb *req, struct io_async_ctx *io)
+ {
+ #if defined(CONFIG_NET)
+ 	const struct io_uring_sqe *sqe = req->sqe;
+ 
+ 	if (unlikely(req->ctx->flags & (IORING_SETUP_IOPOLL|IORING_SETUP_SQPOLL)))
+ 		return -EINVAL;
+ 	if (sqe->ioprio || sqe->len || sqe->buf_index || sqe->rw_flags)
+ 		return -EINVAL;
+ 
+ 	req->connect.addr = u64_to_user_ptr(READ_ONCE(sqe->addr));
+ 	req->connect.addr_len =  READ_ONCE(sqe->addr2);
+ 	return move_addr_to_kernel(req->connect.addr, req->connect.addr_len,
+ 					&io->connect.address);
+ #else
+ 	return -EOPNOTSUPP;
+ #endif
+ }
+ 
+ static int io_connect(struct io_kiocb *req, struct io_kiocb **nxt,
+ 		      bool force_nonblock)
+ {
+ #if defined(CONFIG_NET)
+ 	struct io_async_ctx __io, *io;
+ 	unsigned file_flags;
+ 	int ret;
+ 
+ 	if (req->io) {
+ 		io = req->io;
+ 	} else {
+ 		ret = io_connect_prep(req, &__io);
+ 		if (ret)
+ 			goto out;
+ 		io = &__io;
+ 	}
+ 
+ 	file_flags = force_nonblock ? O_NONBLOCK : 0;
+ 
+ 	ret = __sys_connect_file(req->file, &io->connect.address,
+ 					req->connect.addr_len, file_flags);
+ 	if ((ret == -EAGAIN || ret == -EINPROGRESS) && force_nonblock) {
+ 		if (req->io)
+ 			return -EAGAIN;
+ 		if (io_alloc_async_ctx(req)) {
+ 			ret = -ENOMEM;
+ 			goto out;
+ 		}
+ 		memcpy(&req->io->connect, &__io.connect, sizeof(__io.connect));
+ 		return -EAGAIN;
+ 	}
+ 	if (ret == -ERESTARTSYS)
+ 		ret = -EINTR;
+ out:
+ 	if (ret < 0)
+ 		req_set_fail_links(req);
+ 	io_cqring_add_event(req, ret);
+ 	io_put_req_find_next(req, nxt);
+ 	return 0;
++>>>>>>> 3fbb51c18f5c (io_uring: move all prep state for IORING_OP_CONNECT to prep handler)
  #else
  	return -EOPNOTSUPP;
  #endif
* Unmerged path fs/io_uring.c
