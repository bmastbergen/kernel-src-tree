io_uring: don't cancel all work on process exit

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit ebe10026210f9ea740b9a050ee84a166690fddde
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/ebe10026.failed

If we're sharing the ring across forks, then one process exiting means
that we cancel ALL work and prevent future work. This is overly
restrictive. As long as we cancel the work associated with the files
from the current task, it's safe to let others persist. Normal fd close
on exit will still wait (and cancel) pending work.

Fixes: fcb323cc53e2 ("io_uring: io_uring: add support for async work inheriting files")
	Reported-by: Andres Freund <andres@anarazel.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit ebe10026210f9ea740b9a050ee84a166690fddde)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index e4dddc0b25db,e54556b0fcc6..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -3582,12 -5004,54 +3582,25 @@@ static int io_uring_release(struct inod
  	return 0;
  }
  
 -static void io_uring_cancel_files(struct io_ring_ctx *ctx,
 -				  struct files_struct *files)
 -{
 -	struct io_kiocb *req;
 -	DEFINE_WAIT(wait);
 -
 -	while (!list_empty_careful(&ctx->inflight_list)) {
 -		struct io_kiocb *cancel_req = NULL;
 -
 -		spin_lock_irq(&ctx->inflight_lock);
 -		list_for_each_entry(req, &ctx->inflight_list, inflight_entry) {
 -			if (req->work.files != files)
 -				continue;
 -			/* req is being completed, ignore */
 -			if (!refcount_inc_not_zero(&req->refs))
 -				continue;
 -			cancel_req = req;
 -			break;
 -		}
 -		if (cancel_req)
 -			prepare_to_wait(&ctx->inflight_wait, &wait,
 -						TASK_UNINTERRUPTIBLE);
 -		spin_unlock_irq(&ctx->inflight_lock);
 -
 -		/* We need to keep going until we don't find a matching req */
 -		if (!cancel_req)
 -			break;
 -
 -		io_wq_cancel_work(ctx->io_wq, &cancel_req->work);
 -		io_put_req(cancel_req);
 -		schedule();
 -	}
 -	finish_wait(&ctx->inflight_wait, &wait);
 -}
 -
 -static int io_uring_flush(struct file *file, void *data)
 +static int io_uring_mmap(struct file *file, struct vm_area_struct *vma)
  {
 +	loff_t offset = (loff_t) vma->vm_pgoff << PAGE_SHIFT;
 +	unsigned long sz = vma->vm_end - vma->vm_start;
  	struct io_ring_ctx *ctx = file->private_data;
++<<<<<<< HEAD
 +	unsigned long pfn;
++=======
+ 
+ 	io_uring_cancel_files(ctx, data);
+ 	return 0;
+ }
+ 
+ static void *io_uring_validate_mmap_request(struct file *file,
+ 					    loff_t pgoff, size_t sz)
+ {
+ 	struct io_ring_ctx *ctx = file->private_data;
+ 	loff_t offset = pgoff << PAGE_SHIFT;
++>>>>>>> ebe10026210f (io_uring: don't cancel all work on process exit)
  	struct page *page;
  	void *ptr;
  
* Unmerged path fs/io_uring.c
