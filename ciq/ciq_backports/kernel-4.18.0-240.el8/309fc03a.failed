io_uring: account user memory freed when exit has been queued

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit 309fc03a3284af62eb6082fb60327045a1dabf57
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/309fc03a.failed

We currently account the memory after the exit work has been run, but
that leaves a gap where a process has closed its ring and until the
memory has been accounted as freed. If the memlocked ulimit is
borderline, then that can introduce spurious setup errors returning
-ENOMEM because the free work hasn't been run yet.

Account this as freed when we close the ring, as not to expose a tiny
gap where setting up a new ring can fail.

Fixes: 85faa7b8346e ("io_uring: punt final io_ring_ctx wait-and-free to workqueue")
	Cc: stable@vger.kernel.org # v5.7
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 309fc03a3284af62eb6082fb60327045a1dabf57)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index bff2058d3f07,ca8abde48b6c..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -3528,15 -7347,14 +3528,12 @@@ static void io_ring_ctx_free(struct io_
  	}
  #endif
  
 -	io_mem_free(ctx->rings);
 +	io_mem_free(ctx->sq_ring);
  	io_mem_free(ctx->sq_sqes);
 +	io_mem_free(ctx->cq_ring);
  
  	percpu_ref_exit(&ctx->refs);
- 	if (ctx->account_mem)
- 		io_unaccount_mem(ctx->user,
- 				ring_pages(ctx->sq_entries, ctx->cq_entries));
  	free_uid(ctx->user);
 -	put_cred(ctx->creds);
 -	kfree(ctx->cancel_hash);
 -	kmem_cache_free(req_cachep, ctx->fallback_req);
  	kfree(ctx);
  }
  
@@@ -3573,10 -7424,29 +3570,29 @@@ static void io_ring_ctx_wait_and_kill(s
  	percpu_ref_kill(&ctx->refs);
  	mutex_unlock(&ctx->uring_lock);
  
 -	io_kill_timeouts(ctx);
  	io_poll_remove_all(ctx);
 -
 -	if (ctx->io_wq)
 -		io_wq_cancel_all(ctx->io_wq);
 -
  	io_iopoll_reap_events(ctx);
++<<<<<<< HEAD
 +	wait_for_completion(&ctx->ctx_done);
 +	io_ring_ctx_free(ctx);
++=======
+ 	/* if we failed setting up the ctx, we might not have any rings */
+ 	if (ctx->rings)
+ 		io_cqring_overflow_flush(ctx, true);
+ 	idr_for_each(&ctx->personality_idr, io_remove_personalities, ctx);
+ 
+ 	/*
+ 	 * Do this upfront, so we won't have a grace period where the ring
+ 	 * is closed but resources aren't reaped yet. This can cause
+ 	 * spurious failure in setting up a new ring.
+ 	 */
+ 	if (ctx->account_mem)
+ 		io_unaccount_mem(ctx->user,
+ 				ring_pages(ctx->sq_entries, ctx->cq_entries));
+ 
+ 	INIT_WORK(&ctx->exit_work, io_ring_exit_work);
+ 	queue_work(system_wq, &ctx->exit_work);
++>>>>>>> 309fc03a3284 (io_uring: account user memory freed when exit has been queued)
  }
  
  static int io_uring_release(struct inode *inode, struct file *file)
* Unmerged path fs/io_uring.c
