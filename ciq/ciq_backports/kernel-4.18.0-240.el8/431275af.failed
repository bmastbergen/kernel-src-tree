iommu: Check for deferred attach in iommu_group_do_dma_attach()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Joerg Roedel <jroedel@suse.de>
commit 431275afdc7155415254aef4bd3816a1b8a2ead0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/431275af.failed

The iommu_group_do_dma_attach() must not attach devices which have
deferred_attach set. Otherwise devices could cause IOMMU faults when
re-initialized in a kdump kernel.

Fixes: deac0b3bed26 ("iommu: Split off default domain allocation from group assignment")
	Reported-by: Jerry Snitselaar <jsnitsel@redhat.com>
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
	Tested-by: Jerry Snitselaar <jsnitsel@redhat.com>
	Reviewed-by: Jerry Snitselaar <jsnitsel@redhat.com>
Link: https://lore.kernel.org/r/20200604091944.26402-1-joro@8bytes.org
(cherry picked from commit 431275afdc7155415254aef4bd3816a1b8a2ead0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/iommu.c
diff --cc drivers/iommu/iommu.c
index 7997fcb701e0,d43120eb1dc5..000000000000
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@@ -1283,10 -1627,152 +1283,155 @@@ static int iommu_bus_notifier(struct no
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ struct __group_domain_type {
+ 	struct device *dev;
+ 	unsigned int type;
+ };
+ 
+ static int probe_get_default_domain_type(struct device *dev, void *data)
+ {
+ 	const struct iommu_ops *ops = dev->bus->iommu_ops;
+ 	struct __group_domain_type *gtype = data;
+ 	unsigned int type = 0;
+ 
+ 	if (ops->def_domain_type)
+ 		type = ops->def_domain_type(dev);
+ 
+ 	if (type) {
+ 		if (gtype->type && gtype->type != type) {
+ 			dev_warn(dev, "Device needs domain type %s, but device %s in the same iommu group requires type %s - using default\n",
+ 				 iommu_domain_type_str(type),
+ 				 dev_name(gtype->dev),
+ 				 iommu_domain_type_str(gtype->type));
+ 			gtype->type = 0;
+ 		}
+ 
+ 		if (!gtype->dev) {
+ 			gtype->dev  = dev;
+ 			gtype->type = type;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void probe_alloc_default_domain(struct bus_type *bus,
+ 				       struct iommu_group *group)
+ {
+ 	struct __group_domain_type gtype;
+ 
+ 	memset(&gtype, 0, sizeof(gtype));
+ 
+ 	/* Ask for default domain requirements of all devices in the group */
+ 	__iommu_group_for_each_dev(group, &gtype,
+ 				   probe_get_default_domain_type);
+ 
+ 	if (!gtype.type)
+ 		gtype.type = iommu_def_domain_type;
+ 
+ 	iommu_group_alloc_default_domain(bus, group, gtype.type);
+ 
+ }
+ 
+ static int iommu_group_do_dma_attach(struct device *dev, void *data)
+ {
+ 	struct iommu_domain *domain = data;
+ 	int ret = 0;
+ 
+ 	if (!iommu_is_attach_deferred(domain, dev))
+ 		ret = __iommu_attach_device(domain, dev);
+ 
+ 	return ret;
+ }
+ 
+ static int __iommu_group_dma_attach(struct iommu_group *group)
+ {
+ 	return __iommu_group_for_each_dev(group, group->default_domain,
+ 					  iommu_group_do_dma_attach);
+ }
+ 
+ static int iommu_group_do_probe_finalize(struct device *dev, void *data)
+ {
+ 	struct iommu_domain *domain = data;
+ 
+ 	if (domain->ops->probe_finalize)
+ 		domain->ops->probe_finalize(dev);
+ 
+ 	return 0;
+ }
+ 
+ static void __iommu_group_dma_finalize(struct iommu_group *group)
+ {
+ 	__iommu_group_for_each_dev(group, group->default_domain,
+ 				   iommu_group_do_probe_finalize);
+ }
+ 
+ static int iommu_do_create_direct_mappings(struct device *dev, void *data)
+ {
+ 	struct iommu_group *group = data;
+ 
+ 	iommu_create_device_direct_mappings(group, dev);
+ 
+ 	return 0;
+ }
+ 
+ static int iommu_group_create_direct_mappings(struct iommu_group *group)
+ {
+ 	return __iommu_group_for_each_dev(group, group,
+ 					  iommu_do_create_direct_mappings);
+ }
+ 
+ int bus_iommu_probe(struct bus_type *bus)
+ {
+ 	struct iommu_group *group, *next;
+ 	LIST_HEAD(group_list);
+ 	int ret;
+ 
+ 	/*
+ 	 * This code-path does not allocate the default domain when
+ 	 * creating the iommu group, so do it after the groups are
+ 	 * created.
+ 	 */
+ 	ret = bus_for_each_dev(bus, NULL, &group_list, probe_iommu_group);
+ 	if (ret)
+ 		return ret;
+ 
+ 	list_for_each_entry_safe(group, next, &group_list, entry) {
+ 		/* Remove item from the list */
+ 		list_del_init(&group->entry);
+ 
+ 		mutex_lock(&group->mutex);
+ 
+ 		/* Try to allocate default domain */
+ 		probe_alloc_default_domain(bus, group);
+ 
+ 		if (!group->default_domain) {
+ 			mutex_unlock(&group->mutex);
+ 			continue;
+ 		}
+ 
+ 		iommu_group_create_direct_mappings(group);
+ 
+ 		ret = __iommu_group_dma_attach(group);
+ 
+ 		mutex_unlock(&group->mutex);
+ 
+ 		if (ret)
+ 			break;
+ 
+ 		__iommu_group_dma_finalize(group);
+ 	}
+ 
+ 	return ret;
+ }
+ 
++>>>>>>> 431275afdc71 (iommu: Check for deferred attach in iommu_group_do_dma_attach())
  static int iommu_bus_init(struct bus_type *bus, const struct iommu_ops *ops)
  {
 -	struct notifier_block *nb;
  	int err;
 +	struct notifier_block *nb;
  
  	nb = kzalloc(sizeof(struct notifier_block), GFP_KERNEL);
  	if (!nb)
* Unmerged path drivers/iommu/iommu.c
