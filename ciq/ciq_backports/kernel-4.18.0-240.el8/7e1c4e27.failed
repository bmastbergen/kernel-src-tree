memblock: stop using implicit alignment to SMP_CACHE_BYTES

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Mike Rapoport <rppt@linux.vnet.ibm.com>
commit 7e1c4e27928e5f87b9b1eaf06dc31773b2f1e7f1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/7e1c4e27.failed

When a memblock allocation APIs are called with align = 0, the alignment
is implicitly set to SMP_CACHE_BYTES.

Implicit alignment is done deep in the memblock allocator and it can
come as a surprise.  Not that such an alignment would be wrong even
when used incorrectly but it is better to be explicit for the sake of
clarity and the prinicple of the least surprise.

Replace all such uses of memblock APIs with the 'align' parameter
explicitly set to SMP_CACHE_BYTES and stop implicit alignment assignment
in the memblock internal allocation functions.

For the case when memblock APIs are used via helper functions, e.g.  like
iommu_arena_new_node() in Alpha, the helper functions were detected with
Coccinelle's help and then manually examined and updated where
appropriate.

The direct memblock APIs users were updated using the semantic patch below:

@@
expression size, min_addr, max_addr, nid;
@@
(
|
- memblock_alloc_try_nid_raw(size, 0, min_addr, max_addr, nid)
+ memblock_alloc_try_nid_raw(size, SMP_CACHE_BYTES, min_addr, max_addr,
nid)
|
- memblock_alloc_try_nid_nopanic(size, 0, min_addr, max_addr, nid)
+ memblock_alloc_try_nid_nopanic(size, SMP_CACHE_BYTES, min_addr, max_addr,
nid)
|
- memblock_alloc_try_nid(size, 0, min_addr, max_addr, nid)
+ memblock_alloc_try_nid(size, SMP_CACHE_BYTES, min_addr, max_addr, nid)
|
- memblock_alloc(size, 0)
+ memblock_alloc(size, SMP_CACHE_BYTES)
|
- memblock_alloc_raw(size, 0)
+ memblock_alloc_raw(size, SMP_CACHE_BYTES)
|
- memblock_alloc_from(size, 0, min_addr)
+ memblock_alloc_from(size, SMP_CACHE_BYTES, min_addr)
|
- memblock_alloc_nopanic(size, 0)
+ memblock_alloc_nopanic(size, SMP_CACHE_BYTES)
|
- memblock_alloc_low(size, 0)
+ memblock_alloc_low(size, SMP_CACHE_BYTES)
|
- memblock_alloc_low_nopanic(size, 0)
+ memblock_alloc_low_nopanic(size, SMP_CACHE_BYTES)
|
- memblock_alloc_from_nopanic(size, 0, min_addr)
+ memblock_alloc_from_nopanic(size, SMP_CACHE_BYTES, min_addr)
|
- memblock_alloc_node(size, 0, nid)
+ memblock_alloc_node(size, SMP_CACHE_BYTES, nid)
)

[mhocko@suse.com: changelog update]
[akpm@linux-foundation.org: coding-style fixes]
[rppt@linux.ibm.com: fix missed uses of implicit alignment]
  Link: http://lkml.kernel.org/r/20181016133656.GA10925@rapoport-lnx
Link: http://lkml.kernel.org/r/1538687224-17535-1-git-send-email-rppt@linux.vnet.ibm.com
	Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Suggested-by: Michal Hocko <mhocko@suse.com>
	Acked-by: Paul Burton <paul.burton@mips.com>	[MIPS]
	Acked-by: Michael Ellerman <mpe@ellerman.id.au>	[powerpc]
	Acked-by: Michal Hocko <mhocko@suse.com>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Chris Zankel <chris@zankel.net>
	Cc: Geert Uytterhoeven <geert@linux-m68k.org>
	Cc: Guan Xuetao <gxt@pku.edu.cn>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: Matt Turner <mattst88@gmail.com>
	Cc: Michal Simek <monstr@monstr.eu>
	Cc: Richard Weinberger <richard@nod.at>
	Cc: Russell King <linux@armlinux.org.uk>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Tony Luck <tony.luck@intel.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 7e1c4e27928e5f87b9b1eaf06dc31773b2f1e7f1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/alpha/kernel/core_marvel.c
#	arch/alpha/kernel/pci-noop.c
#	arch/alpha/kernel/pci.c
#	arch/alpha/kernel/pci_iommu.c
#	arch/arm/kernel/setup.c
#	arch/arm/mach-omap2/omap_hwmod.c
#	arch/ia64/kernel/mca.c
#	arch/ia64/mm/tlb.c
#	arch/ia64/sn/kernel/io_common.c
#	arch/ia64/sn/kernel/setup.c
#	arch/m68k/sun3/sun3dvma.c
#	arch/microblaze/mm/init.c
#	arch/mips/kernel/setup.c
#	arch/powerpc/kernel/pci_32.c
#	arch/powerpc/lib/alloc.c
#	arch/powerpc/mm/mmu_context_nohash.c
#	arch/powerpc/platforms/powermac/nvram.c
#	arch/powerpc/platforms/powernv/pci-ioda.c
#	arch/powerpc/sysdev/msi_bitmap.c
#	arch/um/drivers/net_kern.c
#	arch/um/drivers/vector_kern.c
#	arch/um/kernel/initrd.c
#	arch/x86/kernel/acpi/boot.c
#	arch/x86/kernel/apic/io_apic.c
#	arch/x86/kernel/e820.c
#	arch/x86/platform/olpc/olpc_dt.c
#	arch/xtensa/platforms/iss/network.c
#	drivers/clk/ti/clk.c
#	drivers/firmware/memmap.c
#	drivers/macintosh/smu.c
#	include/linux/memblock.h
#	init/main.c
#	kernel/power/snapshot.c
#	lib/cpumask.c
#	mm/page_alloc.c
#	mm/percpu.c
#	mm/sparse.c
diff --cc arch/alpha/kernel/core_marvel.c
index bdebb8c206f1,c1d0c18c71ca..000000000000
--- a/arch/alpha/kernel/core_marvel.c
+++ b/arch/alpha/kernel/core_marvel.c
@@@ -82,7 -82,7 +82,11 @@@ mk_resource_name(int pe, int port, cha
  	char *name;
  	
  	sprintf(tmp, "PCI %s PE %d PORT %d", str, pe, port);
++<<<<<<< HEAD
 +	name = alloc_bootmem(strlen(tmp) + 1);
++=======
+ 	name = memblock_alloc(strlen(tmp) + 1, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	strcpy(name, tmp);
  
  	return name;
@@@ -117,7 -117,7 +121,11 @@@ alloc_io7(unsigned int pe
  		return NULL;
  	}
  
++<<<<<<< HEAD
 +	io7 = alloc_bootmem(sizeof(*io7));
++=======
+ 	io7 = memblock_alloc(sizeof(*io7), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	io7->pe = pe;
  	raw_spin_lock_init(&io7->irq_lock);
  
diff --cc arch/alpha/kernel/pci-noop.c
index c7c5879869d3,091cff3c68fd..000000000000
--- a/arch/alpha/kernel/pci-noop.c
+++ b/arch/alpha/kernel/pci-noop.c
@@@ -33,7 -33,7 +33,11 @@@ alloc_pci_controller(void
  {
  	struct pci_controller *hose;
  
++<<<<<<< HEAD
 +	hose = alloc_bootmem(sizeof(*hose));
++=======
+ 	hose = memblock_alloc(sizeof(*hose), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	*hose_tail = hose;
  	hose_tail = &hose->next;
@@@ -44,7 -44,7 +48,11 @@@
  struct resource * __init
  alloc_resource(void)
  {
++<<<<<<< HEAD
 +	return alloc_bootmem(sizeof(struct resource));
++=======
+ 	return memblock_alloc(sizeof(struct resource), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  }
  
  SYSCALL_DEFINE3(pciconfig_iobase, long, which, unsigned long, bus,
diff --cc arch/alpha/kernel/pci.c
index c668c3b7a167,97098127df83..000000000000
--- a/arch/alpha/kernel/pci.c
+++ b/arch/alpha/kernel/pci.c
@@@ -392,7 -392,7 +392,11 @@@ alloc_pci_controller(void
  {
  	struct pci_controller *hose;
  
++<<<<<<< HEAD
 +	hose = alloc_bootmem(sizeof(*hose));
++=======
+ 	hose = memblock_alloc(sizeof(*hose), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	*hose_tail = hose;
  	hose_tail = &hose->next;
@@@ -403,7 -403,7 +407,11 @@@
  struct resource * __init
  alloc_resource(void)
  {
++<<<<<<< HEAD
 +	return alloc_bootmem(sizeof(struct resource));
++=======
+ 	return memblock_alloc(sizeof(struct resource), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  }
  
  
diff --cc arch/alpha/kernel/pci_iommu.c
index 6923b0d9c1e1,46e08e0d9181..000000000000
--- a/arch/alpha/kernel/pci_iommu.c
+++ b/arch/alpha/kernel/pci_iommu.c
@@@ -79,10 -79,10 +79,14 @@@ iommu_arena_new_node(int nid, struct pc
  		printk("%s: couldn't allocate arena from node %d\n"
  		       "    falling back to system-wide allocation\n",
  		       __func__, nid);
++<<<<<<< HEAD
 +		arena = alloc_bootmem(sizeof(*arena));
++=======
+ 		arena = memblock_alloc(sizeof(*arena), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	}
  
 -	arena->ptes = memblock_alloc_node(sizeof(*arena), align, nid);
 +	arena->ptes = __alloc_bootmem_node(NODE_DATA(nid), mem_size, align, 0);
  	if (!NODE_DATA(nid) || !arena->ptes) {
  		printk("%s: couldn't allocate arena ptes from node %d\n"
  		       "    falling back to system-wide allocation\n",
@@@ -92,8 -92,8 +96,13 @@@
  
  #else /* CONFIG_DISCONTIGMEM */
  
++<<<<<<< HEAD
 +	arena = alloc_bootmem(sizeof(*arena));
 +	arena->ptes = __alloc_bootmem(mem_size, align, 0);
++=======
+ 	arena = memblock_alloc(sizeof(*arena), SMP_CACHE_BYTES);
+ 	arena->ptes = memblock_alloc_from(mem_size, align, 0);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  #endif /* CONFIG_DISCONTIGMEM */
  
diff --cc arch/arm/kernel/setup.c
index 35ca494c028c,ac7e08886863..000000000000
--- a/arch/arm/kernel/setup.c
+++ b/arch/arm/kernel/setup.c
@@@ -857,7 -856,7 +857,11 @@@ static void __init request_standard_res
  		 */
  		boot_alias_start = phys_to_idmap(start);
  		if (arm_has_idmap_alias() && boot_alias_start != IDMAP_INVALID_ADDR) {
++<<<<<<< HEAD
 +			res = memblock_virt_alloc(sizeof(*res), 0);
++=======
+ 			res = memblock_alloc(sizeof(*res), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  			res->name = "System RAM (boot alias)";
  			res->start = boot_alias_start;
  			res->end = phys_to_idmap(end);
@@@ -865,7 -864,7 +869,11 @@@
  			request_resource(&iomem_resource, res);
  		}
  
++<<<<<<< HEAD
 +		res = memblock_virt_alloc(sizeof(*res), 0);
++=======
+ 		res = memblock_alloc(sizeof(*res), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  		res->name  = "System RAM";
  		res->start = start;
  		res->end = end;
diff --cc arch/arm/mach-omap2/omap_hwmod.c
index 2ceffd85dd3d,083dcd9942ce..000000000000
--- a/arch/arm/mach-omap2/omap_hwmod.c
+++ b/arch/arm/mach-omap2/omap_hwmod.c
@@@ -724,23 -724,36 +724,52 @@@ static int __init _setup_clkctrl_provid
  	const __be32 *addrp;
  	struct clkctrl_provider *provider;
  	u64 size;
 -	int i;
  
++<<<<<<< HEAD
 +	provider = memblock_virt_alloc(sizeof(*provider), 0);
++=======
+ 	provider = memblock_alloc(sizeof(*provider), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	if (!provider)
  		return -ENOMEM;
  
 +	addrp = of_get_address(np, 0, &size, NULL);
 +	provider->addr = (u32)of_translate_address(np, addrp);
 +	addrp = of_get_address(np->parent, 0, NULL, NULL);
 +	provider->offset = provider->addr -
 +			   (u32)of_translate_address(np->parent, addrp);
 +	provider->addr &= ~0xff;
 +	provider->size = size | 0xff;
  	provider->node = np;
  
++<<<<<<< HEAD
 +	pr_debug("%s: %s: %x...%x [+%x]\n", __func__, np->parent->name,
 +		 provider->addr, provider->addr + provider->size,
 +		 provider->offset);
++=======
+ 	provider->num_addrs =
+ 		of_property_count_elems_of_size(np, "reg", sizeof(u32)) / 2;
+ 
+ 	provider->addr =
+ 		memblock_alloc(sizeof(void *) * provider->num_addrs,
+ 			       SMP_CACHE_BYTES);
+ 	if (!provider->addr)
+ 		return -ENOMEM;
+ 
+ 	provider->size =
+ 		memblock_alloc(sizeof(u32) * provider->num_addrs,
+ 			       SMP_CACHE_BYTES);
+ 	if (!provider->size)
+ 		return -ENOMEM;
+ 
+ 	for (i = 0; i < provider->num_addrs; i++) {
+ 		addrp = of_get_address(np, i, &size, NULL);
+ 		provider->addr[i] = (u32)of_translate_address(np, addrp);
+ 		provider->size[i] = size;
+ 		pr_debug("%s: %pOF: %x...%x\n", __func__, np, provider->addr[i],
+ 			 provider->addr[i] + provider->size[i]);
+ 	}
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	list_add(&provider->link, &clkctrl_providers);
  
diff --cc arch/ia64/kernel/mca.c
index 6115464d5f03,91bd1e129379..000000000000
--- a/arch/ia64/kernel/mca.c
+++ b/arch/ia64/kernel/mca.c
@@@ -361,9 -361,9 +361,15 @@@ static ia64_state_log_t ia64_state_log[
  
  #define IA64_LOG_ALLOCATE(it, size) \
  	{ia64_state_log[it].isl_log[IA64_LOG_CURR_INDEX(it)] = \
++<<<<<<< HEAD
 +		(ia64_err_rec_t *)alloc_bootmem(size); \
 +	ia64_state_log[it].isl_log[IA64_LOG_NEXT_INDEX(it)] = \
 +		(ia64_err_rec_t *)alloc_bootmem(size);}
++=======
+ 		(ia64_err_rec_t *)memblock_alloc(size, SMP_CACHE_BYTES); \
+ 	ia64_state_log[it].isl_log[IA64_LOG_NEXT_INDEX(it)] = \
+ 		(ia64_err_rec_t *)memblock_alloc(size, SMP_CACHE_BYTES);}
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  #define IA64_LOG_LOCK_INIT(it) spin_lock_init(&ia64_state_log[it].isl_lock)
  #define IA64_LOG_LOCK(it)      spin_lock_irqsave(&ia64_state_log[it].isl_lock, s)
  #define IA64_LOG_UNLOCK(it)    spin_unlock_irqrestore(&ia64_state_log[it].isl_lock,s)
diff --cc arch/ia64/mm/tlb.c
index acf10eb9da15,9340bcb4f29c..000000000000
--- a/arch/ia64/mm/tlb.c
+++ b/arch/ia64/mm/tlb.c
@@@ -59,8 -59,10 +59,15 @@@ struct ia64_tr_entry *ia64_idtrs[NR_CPU
  void __init
  mmu_context_init (void)
  {
++<<<<<<< HEAD
 +	ia64_ctx.bitmap = alloc_bootmem((ia64_ctx.max_ctx+1)>>3);
 +	ia64_ctx.flushmap = alloc_bootmem((ia64_ctx.max_ctx+1)>>3);
++=======
+ 	ia64_ctx.bitmap = memblock_alloc((ia64_ctx.max_ctx + 1) >> 3,
+ 					 SMP_CACHE_BYTES);
+ 	ia64_ctx.flushmap = memblock_alloc((ia64_ctx.max_ctx + 1) >> 3,
+ 					   SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  }
  
  /*
diff --cc arch/ia64/sn/kernel/io_common.c
index 102aabad6d20,8df13d0d96fa..000000000000
--- a/arch/ia64/sn/kernel/io_common.c
+++ b/arch/ia64/sn/kernel/io_common.c
@@@ -390,11 -389,11 +390,17 @@@ void __init hubdev_init_node(nodepda_t 
  	size = sizeof(struct hubdev_info);
  
  	if (node >= num_online_nodes())	/* Headless/memless IO nodes */
 -		node = 0;
 +		pg = NODE_DATA(0);
 +	else
 +		pg = NODE_DATA(node);
  
++<<<<<<< HEAD
 +	hubdev_info = (struct hubdev_info *)alloc_bootmem_node(pg, size);
++=======
+ 	hubdev_info = (struct hubdev_info *)memblock_alloc_node(size,
+ 								SMP_CACHE_BYTES,
+ 								node);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	npda->pdinfo = (void *)hubdev_info;
  }
diff --cc arch/ia64/sn/kernel/setup.c
index 5f6b6b48c1d5,a6d40a2c5bff..000000000000
--- a/arch/ia64/sn/kernel/setup.c
+++ b/arch/ia64/sn/kernel/setup.c
@@@ -511,7 -511,8 +511,12 @@@ static void __init sn_init_pdas(char **
  	 */
  	for_each_online_node(cnode) {
  		nodepdaindr[cnode] =
++<<<<<<< HEAD
 +		    alloc_bootmem_node(NODE_DATA(cnode), sizeof(nodepda_t));
++=======
+ 		    memblock_alloc_node(sizeof(nodepda_t), SMP_CACHE_BYTES,
+ 					cnode);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  		memset(nodepdaindr[cnode]->phys_cpuid, -1,
  		    sizeof(nodepdaindr[cnode]->phys_cpuid));
  		spin_lock_init(&nodepdaindr[cnode]->ptc_lock);
@@@ -522,7 -523,7 +527,11 @@@
  	 */
  	for (cnode = num_online_nodes(); cnode < num_cnodes; cnode++)
  		nodepdaindr[cnode] =
++<<<<<<< HEAD
 +		    alloc_bootmem_node(NODE_DATA(0), sizeof(nodepda_t));
++=======
+ 		    memblock_alloc_node(sizeof(nodepda_t), SMP_CACHE_BYTES, 0);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	/*
  	 * Now copy the array of nodepda pointers to each nodepda.
diff --cc arch/m68k/sun3/sun3dvma.c
index 8546922adb47,4d64711d3d47..000000000000
--- a/arch/m68k/sun3/sun3dvma.c
+++ b/arch/m68k/sun3/sun3dvma.c
@@@ -267,7 -267,8 +267,12 @@@ void __init dvma_init(void
  
  	list_add(&(hole->list), &hole_list);
  
++<<<<<<< HEAD
 +	iommu_use = alloc_bootmem(IOMMU_TOTAL_ENTRIES * sizeof(unsigned long));
++=======
+ 	iommu_use = memblock_alloc(IOMMU_TOTAL_ENTRIES * sizeof(unsigned long),
+ 				   SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	dvma_unmap_iommu(DVMA_START, DVMA_SIZE);
  
diff --cc arch/microblaze/mm/init.c
index df6de7ccdc2e,b17fd8aafd64..000000000000
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@@ -377,7 -376,7 +377,11 @@@ void * __ref zalloc_maybe_bootmem(size_
  	if (mem_init_done)
  		p = kzalloc(size, mask);
  	else {
++<<<<<<< HEAD
 +		p = alloc_bootmem(size);
++=======
+ 		p = memblock_alloc(size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  		if (p)
  			memset(p, 0, size);
  	}
diff --cc arch/mips/kernel/setup.c
index 2c96c0c68116,ea09ed6a80a9..000000000000
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@@ -952,7 -916,7 +952,11 @@@ static void __init resource_init(void
  		if (end >= HIGHMEM_START)
  			end = HIGHMEM_START - 1;
  
++<<<<<<< HEAD
 +		res = alloc_bootmem(sizeof(struct resource));
++=======
+ 		res = memblock_alloc(sizeof(struct resource), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  		res->start = start;
  		res->end = end;
diff --cc arch/powerpc/kernel/pci_32.c
index d63b488d34d7,d3f04f2d8249..000000000000
--- a/arch/powerpc/kernel/pci_32.c
+++ b/arch/powerpc/kernel/pci_32.c
@@@ -204,7 -203,8 +204,12 @@@ pci_create_OF_bus_map(void
  	struct property* of_prop;
  	struct device_node *dn;
  
++<<<<<<< HEAD
 +	of_prop = memblock_virt_alloc(sizeof(struct property) + 256, 0);
++=======
+ 	of_prop = memblock_alloc(sizeof(struct property) + 256,
+ 				 SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	dn = of_find_node_by_path("/");
  	if (dn) {
  		memset(of_prop, -1, sizeof(struct property) + 256);
diff --cc arch/powerpc/lib/alloc.c
index 06796dec01ea,dedf88a76f58..000000000000
--- a/arch/powerpc/lib/alloc.c
+++ b/arch/powerpc/lib/alloc.c
@@@ -14,7 -14,7 +14,11 @@@ void * __ref zalloc_maybe_bootmem(size_
  	if (slab_is_available())
  		p = kzalloc(size, mask);
  	else {
++<<<<<<< HEAD
 +		p = memblock_virt_alloc(size, 0);
++=======
+ 		p = memblock_alloc(size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	}
  	return p;
  }
diff --cc arch/powerpc/mm/mmu_context_nohash.c
index e50c3c7c2401,2faca46ad720..000000000000
--- a/arch/powerpc/mm/mmu_context_nohash.c
+++ b/arch/powerpc/mm/mmu_context_nohash.c
@@@ -461,10 -461,11 +461,18 @@@ void __init mmu_context_init(void
  	/*
  	 * Allocate the maps used by context management
  	 */
++<<<<<<< HEAD
 +	context_map = memblock_virt_alloc(CTX_MAP_SIZE, 0);
 +	context_mm = memblock_virt_alloc(sizeof(void *) * (LAST_CONTEXT + 1), 0);
 +#ifdef CONFIG_SMP
 +	stale_map[boot_cpuid] = memblock_virt_alloc(CTX_MAP_SIZE, 0);
++=======
+ 	context_map = memblock_alloc(CTX_MAP_SIZE, SMP_CACHE_BYTES);
+ 	context_mm = memblock_alloc(sizeof(void *) * (LAST_CONTEXT + 1),
+ 				    SMP_CACHE_BYTES);
+ #ifdef CONFIG_SMP
+ 	stale_map[boot_cpuid] = memblock_alloc(CTX_MAP_SIZE, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	cpuhp_setup_state_nocalls(CPUHP_POWERPC_MMU_CTX_PREPARE,
  				  "powerpc/mmu/ctx:prepare",
diff --cc arch/powerpc/platforms/powermac/nvram.c
index 60b03a1703d1,ae54d7fe68f3..000000000000
--- a/arch/powerpc/platforms/powermac/nvram.c
+++ b/arch/powerpc/platforms/powermac/nvram.c
@@@ -513,7 -513,7 +513,11 @@@ static int __init core99_nvram_setup(st
  		printk(KERN_ERR "nvram: no address\n");
  		return -EINVAL;
  	}
++<<<<<<< HEAD
 +	nvram_image = memblock_virt_alloc(NVRAM_SIZE, 0);
++=======
+ 	nvram_image = memblock_alloc(NVRAM_SIZE, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	nvram_data = ioremap(addr, NVRAM_SIZE*2);
  	nvram_naddrs = 1; /* Make sure we get the correct case */
  
diff --cc arch/powerpc/platforms/powernv/pci-ioda.c
index efb558ad5aa1,dd807446801e..000000000000
--- a/arch/powerpc/platforms/powernv/pci-ioda.c
+++ b/arch/powerpc/platforms/powernv/pci-ioda.c
@@@ -3776,7 -3769,7 +3776,11 @@@ static void __init pnv_pci_init_ioda_ph
  	phb_id = be64_to_cpup(prop64);
  	pr_debug("  PHB-ID  : 0x%016llx\n", phb_id);
  
++<<<<<<< HEAD
 +	phb = memblock_virt_alloc(sizeof(*phb), 0);
++=======
+ 	phb = memblock_alloc(sizeof(*phb), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	/* Allocate PCI controller */
  	phb->hose = hose = pcibios_alloc_controller(np);
@@@ -3822,7 -3815,7 +3826,11 @@@
  	else
  		phb->diag_data_size = PNV_PCI_DIAG_BUF_SIZE;
  
++<<<<<<< HEAD
 +	phb->diag_data = memblock_virt_alloc(phb->diag_data_size, 0);
++=======
+ 	phb->diag_data = memblock_alloc(phb->diag_data_size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	/* Parse 32-bit and IO ranges (if any) */
  	pci_process_bridge_OF_ranges(hose, np, !hose->global_number);
@@@ -3881,7 -3874,7 +3889,11 @@@
  	}
  	pemap_off = size;
  	size += phb->ioda.total_pe_num * sizeof(struct pnv_ioda_pe);
++<<<<<<< HEAD
 +	aux = memblock_virt_alloc(size, 0);
++=======
+ 	aux = memblock_alloc(size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	phb->ioda.pe_alloc = aux;
  	phb->ioda.m64_segmap = aux + m64map_off;
  	phb->ioda.m32_segmap = aux + m32map_off;
diff --cc arch/powerpc/sysdev/msi_bitmap.c
index 6243a7e537d0,d45450f6666a..000000000000
--- a/arch/powerpc/sysdev/msi_bitmap.c
+++ b/arch/powerpc/sysdev/msi_bitmap.c
@@@ -128,7 -128,7 +128,11 @@@ int __ref msi_bitmap_alloc(struct msi_b
  	if (bmp->bitmap_from_slab)
  		bmp->bitmap = kzalloc(size, GFP_KERNEL);
  	else {
++<<<<<<< HEAD
 +		bmp->bitmap = memblock_virt_alloc(size, 0);
++=======
+ 		bmp->bitmap = memblock_alloc(size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  		/* the bitmap won't be freed from memblock allocator */
  		kmemleak_not_leak(bmp->bitmap);
  	}
diff --cc arch/um/drivers/net_kern.c
index 3ef1b48e064a,624cb47cc9cd..000000000000
--- a/arch/um/drivers/net_kern.c
+++ b/arch/um/drivers/net_kern.c
@@@ -650,7 -650,7 +650,11 @@@ static int __init eth_setup(char *str
  		return 1;
  	}
  
++<<<<<<< HEAD
 +	new = alloc_bootmem(sizeof(*new));
++=======
+ 	new = memblock_alloc(sizeof(*new), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	INIT_LIST_HEAD(&new->list);
  	new->index = n;
diff --cc arch/um/drivers/vector_kern.c
index d516cb6e1dd2,10d8d20eb9ec..000000000000
--- a/arch/um/drivers/vector_kern.c
+++ b/arch/um/drivers/vector_kern.c
@@@ -1580,7 -1580,7 +1580,11 @@@ static int __init vector_setup(char *st
  				 str, error);
  		return 1;
  	}
++<<<<<<< HEAD
 +	new = alloc_bootmem(sizeof(*new));
++=======
+ 	new = memblock_alloc(sizeof(*new), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	INIT_LIST_HEAD(&new->list);
  	new->unit = n;
  	new->arguments = str;
diff --cc arch/um/kernel/initrd.c
index 6f6e7896e53f,ce169ea87e61..000000000000
--- a/arch/um/kernel/initrd.c
+++ b/arch/um/kernel/initrd.c
@@@ -36,7 -36,7 +36,11 @@@ int __init read_initrd(void
  		return 0;
  	}
  
++<<<<<<< HEAD
 +	area = alloc_bootmem(size);
++=======
+ 	area = memblock_alloc(size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	if (load_initrd(initrd, area, size) == -1)
  		return 0;
diff --cc arch/x86/kernel/acpi/boot.c
index 205546b25744,92c76bf97ad8..000000000000
--- a/arch/x86/kernel/acpi/boot.c
+++ b/arch/x86/kernel/acpi/boot.c
@@@ -933,7 -933,8 +933,12 @@@ static int __init acpi_parse_hpet(struc
  	 * the resource tree during the lateinit timeframe.
  	 */
  #define HPET_RESOURCE_NAME_SIZE 9
++<<<<<<< HEAD
 +	hpet_res = alloc_bootmem(sizeof(*hpet_res) + HPET_RESOURCE_NAME_SIZE);
++=======
+ 	hpet_res = memblock_alloc(sizeof(*hpet_res) + HPET_RESOURCE_NAME_SIZE,
+ 				  SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	hpet_res->name = (void *)&hpet_res[1];
  	hpet_res->flags = IORESOURCE_MEM;
diff --cc arch/x86/kernel/apic/io_apic.c
index c746c0d007bd,2953bbf05c08..000000000000
--- a/arch/x86/kernel/apic/io_apic.c
+++ b/arch/x86/kernel/apic/io_apic.c
@@@ -2624,7 -2578,7 +2624,11 @@@ static struct resource * __init ioapic_
  	n = IOAPIC_RESOURCE_NAME_SIZE + sizeof(struct resource);
  	n *= nr_ioapics;
  
++<<<<<<< HEAD
 +	mem = alloc_bootmem(n);
++=======
+ 	mem = memblock_alloc(n, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	res = (void *)mem;
  
  	mem += sizeof(struct resource) * nr_ioapics;
diff --cc arch/x86/kernel/e820.c
index f02c2a778ffa,50895c2f937d..000000000000
--- a/arch/x86/kernel/e820.c
+++ b/arch/x86/kernel/e820.c
@@@ -1111,7 -1093,8 +1111,12 @@@ void __init e820__reserve_resources(voi
  	struct resource *res;
  	u64 end;
  
++<<<<<<< HEAD
 +	res = alloc_bootmem(sizeof(*res) * e820_table->nr_entries);
++=======
+ 	res = memblock_alloc(sizeof(*res) * e820_table->nr_entries,
+ 			     SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	e820_res = res;
  
  	for (i = 0; i < e820_table->nr_entries; i++) {
diff --cc arch/x86/platform/olpc/olpc_dt.c
index d6ee92986920,24d2175a9480..000000000000
--- a/arch/x86/platform/olpc/olpc_dt.c
+++ b/arch/x86/platform/olpc/olpc_dt.c
@@@ -141,7 -141,7 +141,11 @@@ void * __init prom_early_alloc(unsigne
  		 * fast enough on the platforms we care about while minimizing
  		 * wasted bootmem) and hand off chunks of it to callers.
  		 */
++<<<<<<< HEAD
 +		res = alloc_bootmem(chunk_size);
++=======
+ 		res = memblock_alloc(chunk_size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  		BUG_ON(!res);
  		prom_early_allocated += chunk_size;
  		memset(res, 0, chunk_size);
diff --cc arch/xtensa/platforms/iss/network.c
index d027dddc41ca,d052712373b6..000000000000
--- a/arch/xtensa/platforms/iss/network.c
+++ b/arch/xtensa/platforms/iss/network.c
@@@ -646,7 -646,7 +646,11 @@@ static int __init iss_net_setup(char *s
  		return 1;
  	}
  
++<<<<<<< HEAD
 +	new = alloc_bootmem(sizeof(*new));
++=======
+ 	new = memblock_alloc(sizeof(*new), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	if (new == NULL) {
  		pr_err("Alloc_bootmem failed\n");
  		return 1;
diff --cc drivers/clk/ti/clk.c
index 7d22e1af2247,e205af814582..000000000000
--- a/drivers/clk/ti/clk.c
+++ b/drivers/clk/ti/clk.c
@@@ -342,7 -342,7 +342,11 @@@ void __init omap2_clk_legacy_provider_i
  {
  	struct clk_iomap *io;
  
++<<<<<<< HEAD
 +	io = memblock_virt_alloc(sizeof(*io), 0);
++=======
+ 	io = memblock_alloc(sizeof(*io), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	io->mem = mem;
  
diff --cc drivers/firmware/memmap.c
index 5de3ed29282c,d168c87c7d30..000000000000
--- a/drivers/firmware/memmap.c
+++ b/drivers/firmware/memmap.c
@@@ -333,7 -333,8 +333,12 @@@ int __init firmware_map_add_early(u64 s
  {
  	struct firmware_map_entry *entry;
  
++<<<<<<< HEAD
 +	entry = memblock_virt_alloc(sizeof(struct firmware_map_entry), 0);
++=======
+ 	entry = memblock_alloc(sizeof(struct firmware_map_entry),
+ 			       SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	if (WARN_ON(!entry))
  		return -ENOMEM;
  
diff --cc drivers/macintosh/smu.c
index e8ae2e54151c,0a0b8e1f4236..000000000000
--- a/drivers/macintosh/smu.c
+++ b/drivers/macintosh/smu.c
@@@ -493,7 -492,7 +493,11 @@@ int __init smu_init (void
  		goto fail_np;
  	}
  
++<<<<<<< HEAD
 +	smu = alloc_bootmem(sizeof(struct smu_device));
++=======
+ 	smu = memblock_alloc(sizeof(struct smu_device), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	spin_lock_init(&smu->lock);
  	INIT_LIST_HEAD(&smu->cmd_list);
diff --cc include/linux/memblock.h
index 292364d04d2f,aee299a6aa76..000000000000
--- a/include/linux/memblock.h
+++ b/include/linux/memblock.h
@@@ -306,6 -333,101 +306,104 @@@ phys_addr_t memblock_phys_alloc_try_nid
  
  phys_addr_t memblock_phys_alloc(phys_addr_t size, phys_addr_t align);
  
++<<<<<<< HEAD
++=======
+ void *memblock_alloc_try_nid_raw(phys_addr_t size, phys_addr_t align,
+ 				 phys_addr_t min_addr, phys_addr_t max_addr,
+ 				 int nid);
+ void *memblock_alloc_try_nid_nopanic(phys_addr_t size, phys_addr_t align,
+ 				     phys_addr_t min_addr, phys_addr_t max_addr,
+ 				     int nid);
+ void *memblock_alloc_try_nid(phys_addr_t size, phys_addr_t align,
+ 			     phys_addr_t min_addr, phys_addr_t max_addr,
+ 			     int nid);
+ 
+ static inline void * __init memblock_alloc(phys_addr_t size,  phys_addr_t align)
+ {
+ 	return memblock_alloc_try_nid(size, align, MEMBLOCK_LOW_LIMIT,
+ 				      MEMBLOCK_ALLOC_ACCESSIBLE, NUMA_NO_NODE);
+ }
+ 
+ static inline void * __init memblock_alloc_raw(phys_addr_t size,
+ 					       phys_addr_t align)
+ {
+ 	return memblock_alloc_try_nid_raw(size, align, MEMBLOCK_LOW_LIMIT,
+ 					  MEMBLOCK_ALLOC_ACCESSIBLE,
+ 					  NUMA_NO_NODE);
+ }
+ 
+ static inline void * __init memblock_alloc_from(phys_addr_t size,
+ 						phys_addr_t align,
+ 						phys_addr_t min_addr)
+ {
+ 	return memblock_alloc_try_nid(size, align, min_addr,
+ 				      MEMBLOCK_ALLOC_ACCESSIBLE, NUMA_NO_NODE);
+ }
+ 
+ static inline void * __init memblock_alloc_nopanic(phys_addr_t size,
+ 						   phys_addr_t align)
+ {
+ 	return memblock_alloc_try_nid_nopanic(size, align, MEMBLOCK_LOW_LIMIT,
+ 					      MEMBLOCK_ALLOC_ACCESSIBLE,
+ 					      NUMA_NO_NODE);
+ }
+ 
+ static inline void * __init memblock_alloc_low(phys_addr_t size,
+ 					       phys_addr_t align)
+ {
+ 	return memblock_alloc_try_nid(size, align, MEMBLOCK_LOW_LIMIT,
+ 				      ARCH_LOW_ADDRESS_LIMIT, NUMA_NO_NODE);
+ }
+ static inline void * __init memblock_alloc_low_nopanic(phys_addr_t size,
+ 						       phys_addr_t align)
+ {
+ 	return memblock_alloc_try_nid_nopanic(size, align, MEMBLOCK_LOW_LIMIT,
+ 					      ARCH_LOW_ADDRESS_LIMIT,
+ 					      NUMA_NO_NODE);
+ }
+ 
+ static inline void * __init memblock_alloc_from_nopanic(phys_addr_t size,
+ 							phys_addr_t align,
+ 							phys_addr_t min_addr)
+ {
+ 	return memblock_alloc_try_nid_nopanic(size, align, min_addr,
+ 					      MEMBLOCK_ALLOC_ACCESSIBLE,
+ 					      NUMA_NO_NODE);
+ }
+ 
+ static inline void * __init memblock_alloc_node(phys_addr_t size,
+ 						phys_addr_t align, int nid)
+ {
+ 	return memblock_alloc_try_nid(size, align, MEMBLOCK_LOW_LIMIT,
+ 				      MEMBLOCK_ALLOC_ACCESSIBLE, nid);
+ }
+ 
+ static inline void * __init memblock_alloc_node_nopanic(phys_addr_t size,
+ 							int nid)
+ {
+ 	return memblock_alloc_try_nid_nopanic(size, SMP_CACHE_BYTES,
+ 					      MEMBLOCK_LOW_LIMIT,
+ 					      MEMBLOCK_ALLOC_ACCESSIBLE, nid);
+ }
+ 
+ static inline void __init memblock_free_early(phys_addr_t base,
+ 					      phys_addr_t size)
+ {
+ 	__memblock_free_early(base, size);
+ }
+ 
+ static inline void __init memblock_free_early_nid(phys_addr_t base,
+ 						  phys_addr_t size, int nid)
+ {
+ 	__memblock_free_early(base, size);
+ }
+ 
+ static inline void __init memblock_free_late(phys_addr_t base, phys_addr_t size)
+ {
+ 	__memblock_free_late(base, size);
+ }
+ 
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  /*
   * Set the allocation direction to bottom-up or top-down.
   */
diff --cc init/main.c
index 0b1da34b3bf4,ee147103ba1b..000000000000
--- a/init/main.c
+++ b/init/main.c
@@@ -376,10 -375,11 +376,18 @@@ static inline void smp_prepare_cpus(uns
  static void __init setup_command_line(char *command_line)
  {
  	saved_command_line =
++<<<<<<< HEAD
 +		memblock_virt_alloc(strlen(boot_command_line) + 1, 0);
 +	initcall_command_line =
 +		memblock_virt_alloc(strlen(boot_command_line) + 1, 0);
 +	static_command_line = memblock_virt_alloc(strlen(command_line) + 1, 0);
++=======
+ 		memblock_alloc(strlen(boot_command_line) + 1, SMP_CACHE_BYTES);
+ 	initcall_command_line =
+ 		memblock_alloc(strlen(boot_command_line) + 1, SMP_CACHE_BYTES);
+ 	static_command_line = memblock_alloc(strlen(command_line) + 1,
+ 					     SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	strcpy(saved_command_line, boot_command_line);
  	strcpy(static_command_line, command_line);
  }
@@@ -776,8 -774,10 +784,15 @@@ static int __init initcall_blacklist(ch
  		str_entry = strsep(&str, ",");
  		if (str_entry) {
  			pr_debug("blacklisting initcall %s\n", str_entry);
++<<<<<<< HEAD
 +			entry = alloc_bootmem(sizeof(*entry));
 +			entry->buf = alloc_bootmem(strlen(str_entry) + 1);
++=======
+ 			entry = memblock_alloc(sizeof(*entry),
+ 					       SMP_CACHE_BYTES);
+ 			entry->buf = memblock_alloc(strlen(str_entry) + 1,
+ 						    SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  			strcpy(entry->buf, str_entry);
  			list_add(&entry->next, &blacklisted_initcalls);
  		}
diff --cc kernel/power/snapshot.c
index c6550dbba7e2,b0308a2c6000..000000000000
--- a/kernel/power/snapshot.c
+++ b/kernel/power/snapshot.c
@@@ -963,7 -963,8 +963,12 @@@ void __init __register_nosave_region(un
  		BUG_ON(!region);
  	} else {
  		/* This allocation cannot fail */
++<<<<<<< HEAD
 +		region = memblock_virt_alloc(sizeof(struct nosave_region), 0);
++=======
+ 		region = memblock_alloc(sizeof(struct nosave_region),
+ 					SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	}
  	region->start_pfn = start_pfn;
  	region->end_pfn = end_pfn;
diff --cc lib/cpumask.c
index beca6244671a,8d666ab84b5c..000000000000
--- a/lib/cpumask.c
+++ b/lib/cpumask.c
@@@ -163,7 -163,7 +163,11 @@@ EXPORT_SYMBOL(zalloc_cpumask_var)
   */
  void __init alloc_bootmem_cpumask_var(cpumask_var_t *mask)
  {
++<<<<<<< HEAD
 +	*mask = memblock_virt_alloc(cpumask_size(), 0);
++=======
+ 	*mask = memblock_alloc(cpumask_size(), SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  }
  
  /**
diff --cc mm/page_alloc.c
index d8bc90160e87,a919ba5cb3c8..000000000000
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@@ -7696,9 -7710,11 +7696,17 @@@ void *__init alloc_large_system_hash(co
  		size = bucketsize << log2qty;
  		if (flags & HASH_EARLY) {
  			if (flags & HASH_ZERO)
++<<<<<<< HEAD
 +				table = memblock_virt_alloc_nopanic(size, 0);
 +			else
 +				table = memblock_virt_alloc_raw(size, 0);
++=======
+ 				table = memblock_alloc_nopanic(size,
+ 							       SMP_CACHE_BYTES);
+ 			else
+ 				table = memblock_alloc_raw(size,
+ 							   SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  		} else if (hashdist) {
  			table = __vmalloc(size, gfp_flags, PAGE_KERNEL);
  		} else {
diff --cc mm/percpu.c
index 2dcd250ad0b7,a6b74c6fe0be..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -1328,12 -1101,9 +1328,18 @@@ static struct pcpu_chunk * __init pcpu_
  	region_size = ALIGN(start_offset + map_size, lcm_align);
  
  	/* allocate chunk */
++<<<<<<< HEAD
 +	alloc_size = sizeof(struct pcpu_chunk) +
 +		BITS_TO_LONGS(region_size >> PAGE_SHIFT);
 +	chunk = memblock_virt_alloc(alloc_size, 0);
 +	if (!chunk)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
++=======
+ 	chunk = memblock_alloc(sizeof(struct pcpu_chunk) +
+ 			       BITS_TO_LONGS(region_size >> PAGE_SHIFT),
+ 			       SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	INIT_LIST_HEAD(&chunk->list);
  
@@@ -1344,25 -1114,12 +1350,34 @@@
  	chunk->nr_pages = region_size >> PAGE_SHIFT;
  	region_bits = pcpu_chunk_map_bits(chunk);
  
++<<<<<<< HEAD
 +	alloc_size = BITS_TO_LONGS(region_bits) * sizeof(chunk->alloc_map[0]);
 +	chunk->alloc_map = memblock_virt_alloc(alloc_size, 0);
 +	if (!chunk->alloc_map)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size =
 +		BITS_TO_LONGS(region_bits + 1) * sizeof(chunk->bound_map[0]);
 +	chunk->bound_map = memblock_virt_alloc(alloc_size, 0);
 +	if (!chunk->bound_map)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size = pcpu_chunk_nr_blocks(chunk) * sizeof(chunk->md_blocks[0]);
 +	chunk->md_blocks = memblock_virt_alloc(alloc_size, 0);
 +	if (!chunk->md_blocks)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
++=======
+ 	chunk->alloc_map = memblock_alloc(BITS_TO_LONGS(region_bits) * sizeof(chunk->alloc_map[0]),
+ 					  SMP_CACHE_BYTES);
+ 	chunk->bound_map = memblock_alloc(BITS_TO_LONGS(region_bits + 1) * sizeof(chunk->bound_map[0]),
+ 					  SMP_CACHE_BYTES);
+ 	chunk->md_blocks = memblock_alloc(pcpu_chunk_nr_blocks(chunk) * sizeof(chunk->md_blocks[0]),
+ 					  SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	pcpu_init_md_blocks(chunk);
  
  	/* manage populated page bitmap */
@@@ -2318,29 -2075,14 +2333,40 @@@ int __init pcpu_setup_first_chunk(cons
  	PCPU_SETUP_BUG_ON(pcpu_verify_alloc_info(ai) < 0);
  
  	/* process group information and build config tables accordingly */
++<<<<<<< HEAD
 +	alloc_size = ai->nr_groups * sizeof(group_offsets[0]);
 +	group_offsets = memblock_virt_alloc(alloc_size, 0);
 +	if (!group_offsets)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size = ai->nr_groups * sizeof(group_sizes[0]);
 +	group_sizes = memblock_virt_alloc(alloc_size, 0);
 +	if (!group_sizes)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size = nr_cpu_ids * sizeof(unit_map[0]);
 +	unit_map = memblock_virt_alloc(alloc_size, 0);
 +	if (!unit_map)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size = nr_cpu_ids * sizeof(unit_off[0]);
 +	unit_off = memblock_virt_alloc(alloc_size, 0);
 +	if (!unit_off)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
++=======
+ 	group_offsets = memblock_alloc(ai->nr_groups * sizeof(group_offsets[0]),
+ 				       SMP_CACHE_BYTES);
+ 	group_sizes = memblock_alloc(ai->nr_groups * sizeof(group_sizes[0]),
+ 				     SMP_CACHE_BYTES);
+ 	unit_map = memblock_alloc(nr_cpu_ids * sizeof(unit_map[0]),
+ 				  SMP_CACHE_BYTES);
+ 	unit_off = memblock_alloc(nr_cpu_ids * sizeof(unit_off[0]),
+ 				  SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	for (cpu = 0; cpu < nr_cpu_ids; cpu++)
  		unit_map[cpu] = UINT_MAX;
@@@ -2404,11 -2146,8 +2430,16 @@@
  	 * empty chunks.
  	 */
  	pcpu_nr_slots = __pcpu_size_to_slot(pcpu_unit_size) + 2;
++<<<<<<< HEAD
 +	pcpu_slot = memblock_virt_alloc(pcpu_nr_slots * sizeof(pcpu_slot[0]),
 +				   0);
 +	if (!pcpu_slot)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      pcpu_nr_slots * sizeof(pcpu_slot[0]));
++=======
+ 	pcpu_slot = memblock_alloc(pcpu_nr_slots * sizeof(pcpu_slot[0]),
+ 				   SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	for (i = 0; i < pcpu_nr_slots; i++)
  		INIT_LIST_HEAD(&pcpu_slot[i]);
  
@@@ -2721,7 -2460,7 +2752,11 @@@ int __init pcpu_embed_first_chunk(size_
  	size_sum = ai->static_size + ai->reserved_size + ai->dyn_size;
  	areas_size = PFN_ALIGN(ai->nr_groups * sizeof(void *));
  
++<<<<<<< HEAD
 +	areas = memblock_virt_alloc_nopanic(areas_size, 0);
++=======
+ 	areas = memblock_alloc_nopanic(areas_size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  	if (!areas) {
  		rc = -ENOMEM;
  		goto out_free;
@@@ -2862,10 -2601,7 +2897,14 @@@ int __init pcpu_page_first_chunk(size_
  	/* unaligned allocations can't be freed, round up to page size */
  	pages_size = PFN_ALIGN(unit_pages * num_possible_cpus() *
  			       sizeof(pages[0]));
++<<<<<<< HEAD
 +	pages = memblock_virt_alloc(pages_size, 0);
 +	if (!pages)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      pages_size);
++=======
+ 	pages = memblock_alloc(pages_size, SMP_CACHE_BYTES);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	/* allocate pages */
  	j = 0;
diff --cc mm/sparse.c
index 743faed13a8f,33307fc05c4d..000000000000
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@@ -68,7 -68,8 +68,12 @@@ static noinline struct mem_section __re
  	if (slab_is_available())
  		section = kzalloc_node(array_size, GFP_KERNEL, nid);
  	else
++<<<<<<< HEAD
 +		section = memblock_virt_alloc_node(array_size, nid);
++=======
+ 		section = memblock_alloc_node(array_size, SMP_CACHE_BYTES,
+ 					      nid);
++>>>>>>> 7e1c4e27928e (memblock: stop using implicit alignment to SMP_CACHE_BYTES)
  
  	return section;
  }
diff --git a/arch/alpha/kernel/core_apecs.c b/arch/alpha/kernel/core_apecs.c
index 1bf3eef34c22..6df765ff2b10 100644
--- a/arch/alpha/kernel/core_apecs.c
+++ b/arch/alpha/kernel/core_apecs.c
@@ -346,7 +346,8 @@ apecs_init_arch(void)
 	 * Window 1 is direct access 1GB at 1GB
 	 * Window 2 is scatter-gather 8MB at 8MB (for isa)
 	 */
-	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000, 0);
+	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000,
+				       SMP_CACHE_BYTES);
 	hose->sg_pci = NULL;
 	__direct_map_base = 0x40000000;
 	__direct_map_size = 0x40000000;
diff --git a/arch/alpha/kernel/core_lca.c b/arch/alpha/kernel/core_lca.c
index 81c0c43635b0..57e0750419f2 100644
--- a/arch/alpha/kernel/core_lca.c
+++ b/arch/alpha/kernel/core_lca.c
@@ -275,7 +275,8 @@ lca_init_arch(void)
 	 * Note that we do not try to save any of the DMA window CSRs
 	 * before setting them, since we cannot read those CSRs on LCA.
 	 */
-	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000, 0);
+	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000,
+				       SMP_CACHE_BYTES);
 	hose->sg_pci = NULL;
 	__direct_map_base = 0x40000000;
 	__direct_map_size = 0x40000000;
* Unmerged path arch/alpha/kernel/core_marvel.c
diff --git a/arch/alpha/kernel/core_mcpcia.c b/arch/alpha/kernel/core_mcpcia.c
index b1549db54260..74b1d018124c 100644
--- a/arch/alpha/kernel/core_mcpcia.c
+++ b/arch/alpha/kernel/core_mcpcia.c
@@ -364,9 +364,11 @@ mcpcia_startup_hose(struct pci_controller *hose)
 	 * Window 1 is scatter-gather (up to) 1GB at 1GB (for pci)
 	 * Window 2 is direct access 2GB at 2GB
 	 */
-	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000, 0);
+	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000,
+				       SMP_CACHE_BYTES);
 	hose->sg_pci = iommu_arena_new(hose, 0x40000000,
-				       size_for_memory(0x40000000), 0);
+				       size_for_memory(0x40000000),
+				       SMP_CACHE_BYTES);
 
 	__direct_map_base = 0x80000000;
 	__direct_map_size = 0x80000000;
diff --git a/arch/alpha/kernel/core_t2.c b/arch/alpha/kernel/core_t2.c
index 2c00b61ca379..98d5b6ff8a76 100644
--- a/arch/alpha/kernel/core_t2.c
+++ b/arch/alpha/kernel/core_t2.c
@@ -351,7 +351,7 @@ t2_sg_map_window2(struct pci_controller *hose,
 
 	/* Note we can only do 1 SG window, as the other is for direct, so
 	   do an ISA SG area, especially for the floppy. */
-	hose->sg_isa = iommu_arena_new(hose, base, length, 0);
+	hose->sg_isa = iommu_arena_new(hose, base, length, SMP_CACHE_BYTES);
 	hose->sg_pci = NULL;
 
 	temp = (base & 0xfff00000UL) | ((base + length - 1) >> 20);
diff --git a/arch/alpha/kernel/core_titan.c b/arch/alpha/kernel/core_titan.c
index 132b06bdf903..71a0dd835506 100644
--- a/arch/alpha/kernel/core_titan.c
+++ b/arch/alpha/kernel/core_titan.c
@@ -316,10 +316,12 @@ titan_init_one_pachip_port(titan_pachip_port *port, int index)
 	 * Window 1 is direct access 1GB at 2GB
 	 * Window 2 is scatter-gather 1GB at 3GB
 	 */
-	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000, 0);
+	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000,
+				       SMP_CACHE_BYTES);
 	hose->sg_isa->align_entry = 8; /* 64KB for ISA */
 
-	hose->sg_pci = iommu_arena_new(hose, 0xc0000000, 0x40000000, 0);
+	hose->sg_pci = iommu_arena_new(hose, 0xc0000000, 0x40000000,
+				       SMP_CACHE_BYTES);
 	hose->sg_pci->align_entry = 4; /* Titan caches 4 PTEs at a time */
 
 	port->wsba[0].csr = hose->sg_isa->dma_base | 3;
diff --git a/arch/alpha/kernel/core_tsunami.c b/arch/alpha/kernel/core_tsunami.c
index e7c956ea46b6..85d1be77a8d5 100644
--- a/arch/alpha/kernel/core_tsunami.c
+++ b/arch/alpha/kernel/core_tsunami.c
@@ -319,12 +319,14 @@ tsunami_init_one_pchip(tsunami_pchip *pchip, int index)
 	 * NOTE: we need the align_entry settings for Acer devices on ES40,
 	 * specifically floppy and IDE when memory is larger than 2GB.
 	 */
-	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000, 0);
+	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000,
+				       SMP_CACHE_BYTES);
 	/* Initially set for 4 PTEs, but will be overridden to 64K for ISA. */
         hose->sg_isa->align_entry = 4;
 
 	hose->sg_pci = iommu_arena_new(hose, 0x40000000,
-				       size_for_memory(0x40000000), 0);
+				       size_for_memory(0x40000000),
+				       SMP_CACHE_BYTES);
         hose->sg_pci->align_entry = 4; /* Tsunami caches 4 PTEs at a time */
 
 	__direct_map_base = 0x80000000;
diff --git a/arch/alpha/kernel/core_wildfire.c b/arch/alpha/kernel/core_wildfire.c
index cad36fc6ed7d..353c03d15442 100644
--- a/arch/alpha/kernel/core_wildfire.c
+++ b/arch/alpha/kernel/core_wildfire.c
@@ -111,8 +111,10 @@ wildfire_init_hose(int qbbno, int hoseno)
          * ??? We ought to scale window 3 memory.
          *
          */
-        hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000, 0);
-        hose->sg_pci = iommu_arena_new(hose, 0xc0000000, 0x08000000, 0);
+	hose->sg_isa = iommu_arena_new(hose, 0x00800000, 0x00800000,
+				       SMP_CACHE_BYTES);
+	hose->sg_pci = iommu_arena_new(hose, 0xc0000000, 0x08000000,
+				       SMP_CACHE_BYTES);
 
 	pci = WILDFIRE_pci(qbbno, hoseno);
 
* Unmerged path arch/alpha/kernel/pci-noop.c
* Unmerged path arch/alpha/kernel/pci.c
* Unmerged path arch/alpha/kernel/pci_iommu.c
* Unmerged path arch/arm/kernel/setup.c
* Unmerged path arch/arm/mach-omap2/omap_hwmod.c
diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index 4cc95606511d..21615ccfdff4 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -219,7 +219,7 @@ static void __init request_standard_resources(void)
 	num_standard_resources = memblock.memory.cnt;
 	standard_resources = memblock_alloc_low(num_standard_resources *
 					        sizeof(*standard_resources),
-					        0);
+					        SMP_CACHE_BYTES);
 
 	for_each_memblock(memory, region) {
 		res = &standard_resources[i++];
* Unmerged path arch/ia64/kernel/mca.c
* Unmerged path arch/ia64/mm/tlb.c
* Unmerged path arch/ia64/sn/kernel/io_common.c
* Unmerged path arch/ia64/sn/kernel/setup.c
* Unmerged path arch/m68k/sun3/sun3dvma.c
* Unmerged path arch/microblaze/mm/init.c
* Unmerged path arch/mips/kernel/setup.c
diff --git a/arch/powerpc/kernel/paca.c b/arch/powerpc/kernel/paca.c
index f331a0054b3a..913bfca09c4f 100644
--- a/arch/powerpc/kernel/paca.c
+++ b/arch/powerpc/kernel/paca.c
@@ -198,7 +198,7 @@ void __init allocate_paca_ptrs(void)
 	paca_nr_cpu_ids = nr_cpu_ids;
 
 	paca_ptrs_size = sizeof(struct paca_struct *) * nr_cpu_ids;
-	paca_ptrs = __va(memblock_phys_alloc(paca_ptrs_size, 0));
+	paca_ptrs = __va(memblock_phys_alloc(paca_ptrs_size, SMP_CACHE_BYTES));
 	memset(paca_ptrs, 0x88, paca_ptrs_size);
 }
 
* Unmerged path arch/powerpc/kernel/pci_32.c
* Unmerged path arch/powerpc/lib/alloc.c
* Unmerged path arch/powerpc/mm/mmu_context_nohash.c
* Unmerged path arch/powerpc/platforms/powermac/nvram.c
* Unmerged path arch/powerpc/platforms/powernv/pci-ioda.c
* Unmerged path arch/powerpc/sysdev/msi_bitmap.c
* Unmerged path arch/um/drivers/net_kern.c
* Unmerged path arch/um/drivers/vector_kern.c
* Unmerged path arch/um/kernel/initrd.c
diff --git a/arch/unicore32/kernel/setup.c b/arch/unicore32/kernel/setup.c
index 9f163f976315..488c99991129 100644
--- a/arch/unicore32/kernel/setup.c
+++ b/arch/unicore32/kernel/setup.c
@@ -207,7 +207,7 @@ request_standard_resources(struct meminfo *mi)
 		if (mi->bank[i].size == 0)
 			continue;
 
-		res = memblock_alloc_low(sizeof(*res), 0);
+		res = memblock_alloc_low(sizeof(*res), SMP_CACHE_BYTES);
 		res->name  = "System RAM";
 		res->start = mi->bank[i].start;
 		res->end   = mi->bank[i].start + mi->bank[i].size - 1;
* Unmerged path arch/x86/kernel/acpi/boot.c
* Unmerged path arch/x86/kernel/apic/io_apic.c
* Unmerged path arch/x86/kernel/e820.c
* Unmerged path arch/x86/platform/olpc/olpc_dt.c
* Unmerged path arch/xtensa/platforms/iss/network.c
* Unmerged path drivers/clk/ti/clk.c
diff --git a/drivers/firmware/efi/memmap.c b/drivers/firmware/efi/memmap.c
index 3da38a20bd01..38b686c67b17 100644
--- a/drivers/firmware/efi/memmap.c
+++ b/drivers/firmware/efi/memmap.c
@@ -15,7 +15,7 @@
 
 static phys_addr_t __init __efi_memmap_alloc_early(unsigned long size)
 {
-	return memblock_phys_alloc(size, 0);
+	return memblock_phys_alloc(size, SMP_CACHE_BYTES);
 }
 
 static phys_addr_t __init __efi_memmap_alloc_late(unsigned long size)
* Unmerged path drivers/firmware/memmap.c
* Unmerged path drivers/macintosh/smu.c
diff --git a/drivers/of/of_reserved_mem.c b/drivers/of/of_reserved_mem.c
index 895c83e0c7b6..54c6c707f149 100644
--- a/drivers/of/of_reserved_mem.c
+++ b/drivers/of/of_reserved_mem.c
@@ -37,6 +37,7 @@ int __init __weak early_init_dt_alloc_reserved_memory_arch(phys_addr_t size,
 	 * panic()s on allocation failure.
 	 */
 	end = !end ? MEMBLOCK_ALLOC_ANYWHERE : end;
+	align = !align ? SMP_CACHE_BYTES : align;
 	base = __memblock_alloc_base(size, align, end);
 	if (!base)
 		return -ENOMEM;
* Unmerged path include/linux/memblock.h
* Unmerged path init/main.c
* Unmerged path kernel/power/snapshot.c
* Unmerged path lib/cpumask.c
diff --git a/mm/memblock.c b/mm/memblock.c
index cd97dba20bb1..84febb45b3ef 100644
--- a/mm/memblock.c
+++ b/mm/memblock.c
@@ -1239,9 +1239,6 @@ static phys_addr_t __init memblock_alloc_range_nid(phys_addr_t size,
 {
 	phys_addr_t found;
 
-	if (!align)
-		align = SMP_CACHE_BYTES;
-
 	found = memblock_find_in_range_node(size, align, start, end, nid,
 					    flags);
 	if (found && !memblock_reserve(found, size)) {
@@ -1336,8 +1333,6 @@ phys_addr_t __init memblock_phys_alloc_try_nid(phys_addr_t size, phys_addr_t ali
  * The allocation is performed from memory region limited by
  * memblock.current_limit if @max_addr == %BOOTMEM_ALLOC_ACCESSIBLE.
  *
- * The memory block is aligned on %SMP_CACHE_BYTES if @align == 0.
- *
  * The phys address of allocated boot memory block is converted to virtual and
  * allocated memory is reset to 0.
  *
@@ -1367,9 +1362,6 @@ static void * __init memblock_virt_alloc_internal(
 	if (WARN_ON_ONCE(slab_is_available()))
 		return kzalloc_node(size, GFP_NOWAIT, nid);
 
-	if (!align)
-		align = SMP_CACHE_BYTES;
-
 	if (max_addr > memblock.current_limit)
 		max_addr = memblock.current_limit;
 again:
* Unmerged path mm/page_alloc.c
* Unmerged path mm/percpu.c
* Unmerged path mm/sparse.c
