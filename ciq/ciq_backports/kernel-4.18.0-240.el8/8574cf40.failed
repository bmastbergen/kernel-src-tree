net/smc: allocate index for a new link

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Karsten Graul <kgraul@linux.ibm.com>
commit 8574cf4055ab44724ee9a4c30921d3ed853d787c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/8574cf40.failed

Add smc_llc_alloc_alt_link() to find a free link index for a new link,
depending on the new link group type. And update constants for the
maximum number of links to 3 (2 symmetric and 1 dangling asymmetric link).
These maximum numbers are the same as used by other implementations of the
SMC-R protocol.

	Signed-off-by: Karsten Graul <kgraul@linux.ibm.com>
	Reviewed-by: Ursula Braun <ubraun@linux.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 8574cf4055ab44724ee9a4c30921d3ed853d787c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/smc/smc_llc.c
diff --cc net/smc/smc_llc.c
index 4119cdb6b6bf,3a25b6ebe3a8..000000000000
--- a/net/smc/smc_llc.c
+++ b/net/smc/smc_llc.c
@@@ -400,60 -541,28 +400,85 @@@ static int smc_llc_send_message(struct 
  
  /********************************* receive ***********************************/
  
++<<<<<<< HEAD
 +static void smc_llc_rx_confirm_link(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_link *llc)
 +{
 +	struct smc_link_group *lgr = smc_get_lgr(link);
 +	int conf_rc;
 +
 +	/* RMBE eyecatchers are not supported */
 +	if (llc->hd.flags & SMC_LLC_FLAG_NO_RMBE_EYEC)
 +		conf_rc = 0;
 +	else
 +		conf_rc = ENOTSUPP;
 +
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_resp_rc = conf_rc;
 +			complete(&link->llc_confirm_resp);
 +		}
 +	} else {
 +		if (lgr->role == SMC_CLNT &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_rc = conf_rc;
 +			link->link_id = llc->link_num;
 +			complete(&link->llc_confirm);
 +		}
 +	}
 +}
 +
 +static void smc_llc_rx_add_link(struct smc_link *link,
 +				struct smc_llc_msg_add_link *llc)
 +{
 +	struct smc_link_group *lgr = smc_get_lgr(link);
 +
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVATING)
 +			complete(&link->llc_add_resp);
 +	} else {
 +		if (link->state == SMC_LNK_ACTIVATING) {
 +			complete(&link->llc_add);
 +			return;
 +		}
 +
 +		if (lgr->role == SMC_SERV) {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_REQ);
 +
 +		} else {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_RESP);
 +		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
++=======
+ static int smc_llc_alloc_alt_link(struct smc_link_group *lgr,
+ 				  enum smc_lgr_type lgr_new_t)
+ {
+ 	int i;
+ 
+ 	if (lgr->type == SMC_LGR_SYMMETRIC ||
+ 	    (lgr->type != SMC_LGR_SINGLE &&
+ 	     (lgr_new_t == SMC_LGR_ASYMMETRIC_LOCAL ||
+ 	      lgr_new_t == SMC_LGR_ASYMMETRIC_PEER)))
+ 		return -EMLINK;
+ 
+ 	if (lgr_new_t == SMC_LGR_ASYMMETRIC_LOCAL ||
+ 	    lgr_new_t == SMC_LGR_ASYMMETRIC_PEER) {
+ 		for (i = SMC_LINKS_PER_LGR_MAX - 1; i >= 0; i--)
+ 			if (lgr->lnk[i].state == SMC_LNK_UNUSED)
+ 				return i;
+ 	} else {
+ 		for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++)
+ 			if (lgr->lnk[i].state == SMC_LNK_UNUSED)
+ 				return i;
+ 	}
+ 	return -EMLINK;
++>>>>>>> 8574cf4055ab (net/smc: allocate index for a new link)
  }
  
  static void smc_llc_rx_delete_link(struct smc_link *link,
diff --git a/net/smc/smc_core.h b/net/smc/smc_core.h
index fd2bbf547caf..3d674b74dfd2 100644
--- a/net/smc/smc_core.h
+++ b/net/smc/smc_core.h
@@ -139,7 +139,7 @@ struct smc_link {
 /* For now we just allow one parallel link per link group. The SMC protocol
  * allows more (up to 8).
  */
-#define SMC_LINKS_PER_LGR_MAX	1
+#define SMC_LINKS_PER_LGR_MAX	3
 #define SMC_SINGLE_LINK		0
 
 #define SMC_FIRST_CONTACT	1		/* first contact to a peer */
* Unmerged path net/smc/smc_llc.c
