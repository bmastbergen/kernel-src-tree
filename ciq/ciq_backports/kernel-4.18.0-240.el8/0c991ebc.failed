bpf: Implement bpf_prog replacement for an active bpf_cgroup_link

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Andrii Nakryiko <andriin@fb.com>
commit 0c991ebc8c69d29b7fc44db17075c5aa5253e2ab
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/0c991ebc.failed

Add new operation (LINK_UPDATE), which allows to replace active bpf_prog from
under given bpf_link. Currently this is only supported for bpf_cgroup_link,
but will be extended to other kinds of bpf_links in follow-up patches.

For bpf_cgroup_link, implemented functionality matches existing semantics for
direct bpf_prog attachment (including BPF_F_REPLACE flag). User can either
unconditionally set new bpf_prog regardless of which bpf_prog is currently
active under given bpf_link, or, optionally, can specify expected active
bpf_prog. If active bpf_prog doesn't match expected one, no changes are
performed, old bpf_link stays intact and attached, operation returns
a failure.

cgroup_bpf_replace() operation is resolving race between auto-detachment and
bpf_prog update in the same fashion as it's done for bpf_link detachment,
except in this case update has no way of succeeding because of target cgroup
marked as dying. So in this case error is returned.

	Signed-off-by: Andrii Nakryiko <andriin@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20200330030001.2312810-3-andriin@fb.com
(cherry picked from commit 0c991ebc8c69d29b7fc44db17075c5aa5253e2ab)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf-cgroup.h
#	include/uapi/linux/bpf.h
#	kernel/bpf/cgroup.c
#	kernel/bpf/syscall.c
#	kernel/cgroup/cgroup.c
diff --cc include/linux/bpf-cgroup.h
index 63c168a1495a,c11b413d5b1a..000000000000
--- a/include/linux/bpf-cgroup.h
+++ b/include/linux/bpf-cgroup.h
@@@ -116,18 -93,27 +116,26 @@@ struct cgroup_bpf 
  int cgroup_bpf_inherit(struct cgroup *cgrp);
  void cgroup_bpf_offline(struct cgroup *cgrp);
  
 -int __cgroup_bpf_attach(struct cgroup *cgrp,
 -			struct bpf_prog *prog, struct bpf_prog *replace_prog,
 -			struct bpf_cgroup_link *link,
 +int __cgroup_bpf_attach(struct cgroup *cgrp, struct bpf_prog *prog,
  			enum bpf_attach_type type, u32 flags);
  int __cgroup_bpf_detach(struct cgroup *cgrp, struct bpf_prog *prog,
 -			struct bpf_cgroup_link *link,
  			enum bpf_attach_type type);
+ int __cgroup_bpf_replace(struct cgroup *cgrp, struct bpf_cgroup_link *link,
+ 			 struct bpf_prog *new_prog);
  int __cgroup_bpf_query(struct cgroup *cgrp, const union bpf_attr *attr,
  		       union bpf_attr __user *uattr);
  
  /* Wrapper for __cgroup_bpf_*() protected by cgroup_mutex */
 -int cgroup_bpf_attach(struct cgroup *cgrp,
 -		      struct bpf_prog *prog, struct bpf_prog *replace_prog,
 -		      struct bpf_cgroup_link *link, enum bpf_attach_type type,
 -		      u32 flags);
 +int cgroup_bpf_attach(struct cgroup *cgrp, struct bpf_prog *prog,
 +		      enum bpf_attach_type type, u32 flags);
  int cgroup_bpf_detach(struct cgroup *cgrp, struct bpf_prog *prog,
++<<<<<<< HEAD
 +		      enum bpf_attach_type type, u32 flags);
++=======
+ 		      enum bpf_attach_type type);
+ int cgroup_bpf_replace(struct bpf_link *link, struct bpf_prog *old_prog,
+ 		       struct bpf_prog *new_prog);
++>>>>>>> 0c991ebc8c69 (bpf: Implement bpf_prog replacement for an active bpf_cgroup_link)
  int cgroup_bpf_query(struct cgroup *cgrp, const union bpf_attr *attr,
  		     union bpf_attr __user *uattr);
  
@@@ -384,6 -372,19 +393,22 @@@ static inline int cgroup_bpf_prog_detac
  	return -EINVAL;
  }
  
++<<<<<<< HEAD
++=======
+ static inline int cgroup_bpf_link_attach(const union bpf_attr *attr,
+ 					 struct bpf_prog *prog)
+ {
+ 	return -EINVAL;
+ }
+ 
+ static inline int cgroup_bpf_replace(struct bpf_link *link,
+ 				     struct bpf_prog *old_prog,
+ 				     struct bpf_prog *new_prog)
+ {
+ 	return -EINVAL;
+ }
+ 
++>>>>>>> 0c991ebc8c69 (bpf: Implement bpf_prog replacement for an active bpf_cgroup_link)
  static inline int cgroup_bpf_prog_query(const union bpf_attr *attr,
  					union bpf_attr __user *uattr)
  {
diff --cc include/uapi/linux/bpf.h
index c9871d53e313,2e29a671d67e..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -107,6 -107,12 +107,15 @@@ enum bpf_cmd 
  	BPF_MAP_LOOKUP_AND_DELETE_ELEM,
  	BPF_MAP_FREEZE,
  	BPF_BTF_GET_NEXT_ID,
++<<<<<<< HEAD
++=======
+ 	BPF_MAP_LOOKUP_BATCH,
+ 	BPF_MAP_LOOKUP_AND_DELETE_BATCH,
+ 	BPF_MAP_UPDATE_BATCH,
+ 	BPF_MAP_DELETE_BATCH,
+ 	BPF_LINK_CREATE,
+ 	BPF_LINK_UPDATE,
++>>>>>>> 0c991ebc8c69 (bpf: Implement bpf_prog replacement for an active bpf_cgroup_link)
  };
  
  enum bpf_map_type {
@@@ -519,6 -571,24 +528,27 @@@ union bpf_attr 
  		__u64		probe_offset;	/* output: probe_offset */
  		__u64		probe_addr;	/* output: probe_addr */
  	} task_fd_query;
++<<<<<<< HEAD
++=======
+ 
+ 	struct { /* struct used by BPF_LINK_CREATE command */
+ 		__u32		prog_fd;	/* eBPF program to attach */
+ 		__u32		target_fd;	/* object to attach to */
+ 		__u32		attach_type;	/* attach type */
+ 		__u32		flags;		/* extra flags */
+ 	} link_create;
+ 
+ 	struct { /* struct used by BPF_LINK_UPDATE command */
+ 		__u32		link_fd;	/* link fd */
+ 		/* new program fd to update link with */
+ 		__u32		new_prog_fd;
+ 		__u32		flags;		/* extra flags */
+ 		/* expected link's program fd; is specified only if
+ 		 * BPF_F_REPLACE flag is set in flags */
+ 		__u32		old_prog_fd;
+ 	} link_update;
+ 
++>>>>>>> 0c991ebc8c69 (bpf: Implement bpf_prog replacement for an active bpf_cgroup_link)
  } __attribute__((aligned(8)));
  
  /* The description below is an attempt at providing documentation to eBPF
diff --cc kernel/bpf/cgroup.c
index 5b8da1ceafe3,80676fc00d81..000000000000
--- a/kernel/bpf/cgroup.c
+++ b/kernel/bpf/cgroup.c
@@@ -407,8 -500,120 +407,123 @@@ cleanup
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ /* Swap updated BPF program for given link in effective program arrays across
+  * all descendant cgroups. This function is guaranteed to succeed.
+  */
+ static void replace_effective_prog(struct cgroup *cgrp,
+ 				   enum bpf_attach_type type,
+ 				   struct bpf_cgroup_link *link)
+ {
+ 	struct bpf_prog_array_item *item;
+ 	struct cgroup_subsys_state *css;
+ 	struct bpf_prog_array *progs;
+ 	struct bpf_prog_list *pl;
+ 	struct list_head *head;
+ 	struct cgroup *cg;
+ 	int pos;
+ 
+ 	css_for_each_descendant_pre(css, &cgrp->self) {
+ 		struct cgroup *desc = container_of(css, struct cgroup, self);
+ 
+ 		if (percpu_ref_is_zero(&desc->bpf.refcnt))
+ 			continue;
+ 
+ 		/* find position of link in effective progs array */
+ 		for (pos = 0, cg = desc; cg; cg = cgroup_parent(cg)) {
+ 			if (pos && !(cg->bpf.flags[type] & BPF_F_ALLOW_MULTI))
+ 				continue;
+ 
+ 			head = &cg->bpf.progs[type];
+ 			list_for_each_entry(pl, head, node) {
+ 				if (!prog_list_prog(pl))
+ 					continue;
+ 				if (pl->link == link)
+ 					goto found;
+ 				pos++;
+ 			}
+ 		}
+ found:
+ 		BUG_ON(!cg);
+ 		progs = rcu_dereference_protected(
+ 				desc->bpf.effective[type],
+ 				lockdep_is_held(&cgroup_mutex));
+ 		item = &progs->items[pos];
+ 		WRITE_ONCE(item->prog, link->link.prog);
+ 	}
+ }
+ 
+ /**
+  * __cgroup_bpf_replace() - Replace link's program and propagate the change
+  *                          to descendants
+  * @cgrp: The cgroup which descendants to traverse
+  * @link: A link for which to replace BPF program
+  * @type: Type of attach operation
+  *
+  * Must be called with cgroup_mutex held.
+  */
+ int __cgroup_bpf_replace(struct cgroup *cgrp, struct bpf_cgroup_link *link,
+ 			 struct bpf_prog *new_prog)
+ {
+ 	struct list_head *progs = &cgrp->bpf.progs[link->type];
+ 	struct bpf_prog *old_prog;
+ 	struct bpf_prog_list *pl;
+ 	bool found = false;
+ 
+ 	if (link->link.prog->type != new_prog->type)
+ 		return -EINVAL;
+ 
+ 	list_for_each_entry(pl, progs, node) {
+ 		if (pl->link == link) {
+ 			found = true;
+ 			break;
+ 		}
+ 	}
+ 	if (!found)
+ 		return -ENOENT;
+ 
+ 	old_prog = xchg(&link->link.prog, new_prog);
+ 	replace_effective_prog(cgrp, link->type, link);
+ 	bpf_prog_put(old_prog);
+ 	return 0;
+ }
+ 
+ static struct bpf_prog_list *find_detach_entry(struct list_head *progs,
+ 					       struct bpf_prog *prog,
+ 					       struct bpf_cgroup_link *link,
+ 					       bool allow_multi)
+ {
+ 	struct bpf_prog_list *pl;
+ 
+ 	if (!allow_multi) {
+ 		if (list_empty(progs))
+ 			/* report error when trying to detach and nothing is attached */
+ 			return ERR_PTR(-ENOENT);
+ 
+ 		/* to maintain backward compatibility NONE and OVERRIDE cgroups
+ 		 * allow detaching with invalid FD (prog==NULL) in legacy mode
+ 		 */
+ 		return list_first_entry(progs, typeof(*pl), node);
+ 	}
+ 
+ 	if (!prog && !link)
+ 		/* to detach MULTI prog the user has to specify valid FD
+ 		 * of the program or link to be detached
+ 		 */
+ 		return ERR_PTR(-EINVAL);
+ 
+ 	/* find the prog or link and detach it */
+ 	list_for_each_entry(pl, progs, node) {
+ 		if (pl->prog == prog && pl->link == link)
+ 			return pl;
+ 	}
+ 	return ERR_PTR(-ENOENT);
+ }
+ 
++>>>>>>> 0c991ebc8c69 (bpf: Implement bpf_prog replacement for an active bpf_cgroup_link)
  /**
 - * __cgroup_bpf_detach() - Detach the program or link from a cgroup, and
 + * __cgroup_bpf_detach() - Detach the program from a cgroup, and
   *                         propagate the change to descendants
   * @cgrp: The cgroup which descendants to traverse
   * @prog: A program to detach or NULL
diff --cc kernel/bpf/syscall.c
index b5b79e59cfd4,e0a3b34d7039..000000000000
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@@ -2908,9 -3495,162 +2908,165 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ #define BPF_MAP_BATCH_LAST_FIELD batch.flags
+ 
+ #define BPF_DO_BATCH(fn)			\
+ 	do {					\
+ 		if (!fn) {			\
+ 			err = -ENOTSUPP;	\
+ 			goto err_put;		\
+ 		}				\
+ 		err = fn(map, attr, uattr);	\
+ 	} while (0)
+ 
+ static int bpf_map_do_batch(const union bpf_attr *attr,
+ 			    union bpf_attr __user *uattr,
+ 			    int cmd)
+ {
+ 	struct bpf_map *map;
+ 	int err, ufd;
+ 	struct fd f;
+ 
+ 	if (CHECK_ATTR(BPF_MAP_BATCH))
+ 		return -EINVAL;
+ 
+ 	ufd = attr->batch.map_fd;
+ 	f = fdget(ufd);
+ 	map = __bpf_map_get(f);
+ 	if (IS_ERR(map))
+ 		return PTR_ERR(map);
+ 
+ 	if ((cmd == BPF_MAP_LOOKUP_BATCH ||
+ 	     cmd == BPF_MAP_LOOKUP_AND_DELETE_BATCH) &&
+ 	    !(map_get_sys_perms(map, f) & FMODE_CAN_READ)) {
+ 		err = -EPERM;
+ 		goto err_put;
+ 	}
+ 
+ 	if (cmd != BPF_MAP_LOOKUP_BATCH &&
+ 	    !(map_get_sys_perms(map, f) & FMODE_CAN_WRITE)) {
+ 		err = -EPERM;
+ 		goto err_put;
+ 	}
+ 
+ 	if (cmd == BPF_MAP_LOOKUP_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_lookup_batch);
+ 	else if (cmd == BPF_MAP_LOOKUP_AND_DELETE_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_lookup_and_delete_batch);
+ 	else if (cmd == BPF_MAP_UPDATE_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_update_batch);
+ 	else
+ 		BPF_DO_BATCH(map->ops->map_delete_batch);
+ 
+ err_put:
+ 	fdput(f);
+ 	return err;
+ }
+ 
+ #define BPF_LINK_CREATE_LAST_FIELD link_create.flags
+ static int link_create(union bpf_attr *attr)
+ {
+ 	enum bpf_prog_type ptype;
+ 	struct bpf_prog *prog;
+ 	int ret;
+ 
+ 	if (!capable(CAP_NET_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (CHECK_ATTR(BPF_LINK_CREATE))
+ 		return -EINVAL;
+ 
+ 	ptype = attach_type_to_prog_type(attr->link_create.attach_type);
+ 	if (ptype == BPF_PROG_TYPE_UNSPEC)
+ 		return -EINVAL;
+ 
+ 	prog = bpf_prog_get_type(attr->link_create.prog_fd, ptype);
+ 	if (IS_ERR(prog))
+ 		return PTR_ERR(prog);
+ 
+ 	ret = bpf_prog_attach_check_attach_type(prog,
+ 						attr->link_create.attach_type);
+ 	if (ret)
+ 		goto err_out;
+ 
+ 	switch (ptype) {
+ 	case BPF_PROG_TYPE_CGROUP_SKB:
+ 	case BPF_PROG_TYPE_CGROUP_SOCK:
+ 	case BPF_PROG_TYPE_CGROUP_SOCK_ADDR:
+ 	case BPF_PROG_TYPE_SOCK_OPS:
+ 	case BPF_PROG_TYPE_CGROUP_DEVICE:
+ 	case BPF_PROG_TYPE_CGROUP_SYSCTL:
+ 	case BPF_PROG_TYPE_CGROUP_SOCKOPT:
+ 		ret = cgroup_bpf_link_attach(attr, prog);
+ 		break;
+ 	default:
+ 		ret = -EINVAL;
+ 	}
+ 
+ err_out:
+ 	if (ret < 0)
+ 		bpf_prog_put(prog);
+ 	return ret;
+ }
+ 
+ #define BPF_LINK_UPDATE_LAST_FIELD link_update.old_prog_fd
+ 
+ static int link_update(union bpf_attr *attr)
+ {
+ 	struct bpf_prog *old_prog = NULL, *new_prog;
+ 	struct bpf_link *link;
+ 	u32 flags;
+ 	int ret;
+ 
+ 	if (!capable(CAP_NET_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (CHECK_ATTR(BPF_LINK_UPDATE))
+ 		return -EINVAL;
+ 
+ 	flags = attr->link_update.flags;
+ 	if (flags & ~BPF_F_REPLACE)
+ 		return -EINVAL;
+ 
+ 	link = bpf_link_get_from_fd(attr->link_update.link_fd);
+ 	if (IS_ERR(link))
+ 		return PTR_ERR(link);
+ 
+ 	new_prog = bpf_prog_get(attr->link_update.new_prog_fd);
+ 	if (IS_ERR(new_prog))
+ 		return PTR_ERR(new_prog);
+ 
+ 	if (flags & BPF_F_REPLACE) {
+ 		old_prog = bpf_prog_get(attr->link_update.old_prog_fd);
+ 		if (IS_ERR(old_prog)) {
+ 			ret = PTR_ERR(old_prog);
+ 			old_prog = NULL;
+ 			goto out_put_progs;
+ 		}
+ 	}
+ 
+ #ifdef CONFIG_CGROUP_BPF
+ 	if (link->ops == &bpf_cgroup_link_lops) {
+ 		ret = cgroup_bpf_replace(link, old_prog, new_prog);
+ 		goto out_put_progs;
+ 	}
+ #endif
+ 	ret = -EINVAL;
+ 
+ out_put_progs:
+ 	if (old_prog)
+ 		bpf_prog_put(old_prog);
+ 	if (ret)
+ 		bpf_prog_put(new_prog);
+ 	return ret;
+ }
+ 
++>>>>>>> 0c991ebc8c69 (bpf: Implement bpf_prog replacement for an active bpf_cgroup_link)
  SYSCALL_DEFINE3(bpf, int, cmd, union bpf_attr __user *, uattr, unsigned int, size)
  {
 -	union bpf_attr attr = {};
 +	union bpf_attr attr;
  	int err;
  
  	if (sysctl_unprivileged_bpf_disabled && !capable(CAP_SYS_ADMIN))
@@@ -3006,6 -3745,25 +3162,28 @@@
  	case BPF_MAP_LOOKUP_AND_DELETE_ELEM:
  		err = map_lookup_and_delete_elem(&attr);
  		break;
++<<<<<<< HEAD
++=======
+ 	case BPF_MAP_LOOKUP_BATCH:
+ 		err = bpf_map_do_batch(&attr, uattr, BPF_MAP_LOOKUP_BATCH);
+ 		break;
+ 	case BPF_MAP_LOOKUP_AND_DELETE_BATCH:
+ 		err = bpf_map_do_batch(&attr, uattr,
+ 				       BPF_MAP_LOOKUP_AND_DELETE_BATCH);
+ 		break;
+ 	case BPF_MAP_UPDATE_BATCH:
+ 		err = bpf_map_do_batch(&attr, uattr, BPF_MAP_UPDATE_BATCH);
+ 		break;
+ 	case BPF_MAP_DELETE_BATCH:
+ 		err = bpf_map_do_batch(&attr, uattr, BPF_MAP_DELETE_BATCH);
+ 		break;
+ 	case BPF_LINK_CREATE:
+ 		err = link_create(&attr);
+ 		break;
+ 	case BPF_LINK_UPDATE:
+ 		err = link_update(&attr);
+ 		break;
++>>>>>>> 0c991ebc8c69 (bpf: Implement bpf_prog replacement for an active bpf_cgroup_link)
  	default:
  		err = -EINVAL;
  		break;
diff --cc kernel/cgroup/cgroup.c
index 0ae03b38e5a0,915dda3f7f19..000000000000
--- a/kernel/cgroup/cgroup.c
+++ b/kernel/cgroup/cgroup.c
@@@ -6335,8 -6316,36 +6335,39 @@@ int cgroup_bpf_attach(struct cgroup *cg
  	mutex_unlock(&cgroup_mutex);
  	return ret;
  }
++<<<<<<< HEAD
++=======
+ 
+ int cgroup_bpf_replace(struct bpf_link *link, struct bpf_prog *old_prog,
+ 		       struct bpf_prog *new_prog)
+ {
+ 	struct bpf_cgroup_link *cg_link;
+ 	int ret;
+ 
+ 	if (link->ops != &bpf_cgroup_link_lops)
+ 		return -EINVAL;
+ 
+ 	cg_link = container_of(link, struct bpf_cgroup_link, link);
+ 
+ 	mutex_lock(&cgroup_mutex);
+ 	/* link might have been auto-released by dying cgroup, so fail */
+ 	if (!cg_link->cgroup) {
+ 		ret = -EINVAL;
+ 		goto out_unlock;
+ 	}
+ 	if (old_prog && link->prog != old_prog) {
+ 		ret = -EPERM;
+ 		goto out_unlock;
+ 	}
+ 	ret = __cgroup_bpf_replace(cg_link->cgroup, cg_link, new_prog);
+ out_unlock:
+ 	mutex_unlock(&cgroup_mutex);
+ 	return ret;
+ }
+ 
++>>>>>>> 0c991ebc8c69 (bpf: Implement bpf_prog replacement for an active bpf_cgroup_link)
  int cgroup_bpf_detach(struct cgroup *cgrp, struct bpf_prog *prog,
 -		      enum bpf_attach_type type)
 +		      enum bpf_attach_type type, u32 flags)
  {
  	int ret;
  
* Unmerged path include/linux/bpf-cgroup.h
* Unmerged path include/uapi/linux/bpf.h
* Unmerged path kernel/bpf/cgroup.c
* Unmerged path kernel/bpf/syscall.c
* Unmerged path kernel/cgroup/cgroup.c
