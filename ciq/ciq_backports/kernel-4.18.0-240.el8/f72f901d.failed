libperf: Add cpus to struct perf_evlist

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jiri Olsa <jolsa@kernel.org>
commit f72f901d90b00aaf2a6c1335b41311687b3f2dec
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/f72f901d.failed

Move cpus from tools/perf's evlist to libperf's perf_evlist struct.

Committer notes:

Fixed up this one:

  tools/perf/arch/arm/util/cs-etm.c

	Signed-off-by: Jiri Olsa <jolsa@kernel.org>
	Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
	Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
	Cc: Andi Kleen <ak@linux.intel.com>
	Cc: Michael Petlan <mpetlan@redhat.com>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
Link: http://lkml.kernel.org/r/20190721112506.12306-55-jolsa@kernel.org
	Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
(cherry picked from commit f72f901d90b00aaf2a6c1335b41311687b3f2dec)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/perf/arch/arm/util/cs-etm.c
#	tools/perf/arch/x86/util/intel-bts.c
#	tools/perf/arch/x86/util/intel-pt.c
#	tools/perf/builtin-ftrace.c
#	tools/perf/builtin-top.c
#	tools/perf/lib/include/internal/evlist.h
#	tools/perf/util/evlist.c
#	tools/perf/util/evlist.h
#	tools/perf/util/record.c
diff --cc tools/perf/arch/arm/util/cs-etm.c
index 4208974c24f8,5cb07e8cb296..000000000000
--- a/tools/perf/arch/arm/util/cs-etm.c
+++ b/tools/perf/arch/arm/util/cs-etm.c
@@@ -152,11 -152,11 +152,16 @@@ out
  }
  
  static int cs_etm_set_option(struct auxtrace_record *itr,
 -			     struct evsel *evsel, u32 option)
 +			     struct perf_evsel *evsel, u32 option)
  {
  	int i, err = -EINVAL;
++<<<<<<< HEAD
 +	struct cpu_map *event_cpus = evsel->evlist->cpus;
 +	struct cpu_map *online_cpus = cpu_map__new(NULL);
++=======
+ 	struct perf_cpu_map *event_cpus = evsel->evlist->core.cpus;
+ 	struct perf_cpu_map *online_cpus = perf_cpu_map__new(NULL);
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  
  	/* Set option of each CPU we have */
  	for (i = 0; i < cpu__max_cpu(); i++) {
@@@ -252,8 -252,8 +257,13 @@@ static int cs_etm_recording_options(str
  	struct cs_etm_recording *ptr =
  				container_of(itr, struct cs_etm_recording, itr);
  	struct perf_pmu *cs_etm_pmu = ptr->cs_etm_pmu;
++<<<<<<< HEAD
 +	struct perf_evsel *evsel, *cs_etm_evsel = NULL;
 +	struct cpu_map *cpus = evlist->cpus;
++=======
+ 	struct evsel *evsel, *cs_etm_evsel = NULL;
+ 	struct perf_cpu_map *cpus = evlist->core.cpus;
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	bool privileged = (geteuid() == 0 || perf_event_paranoid() < 0);
  	int err = 0;
  
@@@ -489,8 -489,8 +499,13 @@@ cs_etm_info_priv_size(struct auxtrace_r
  {
  	int i;
  	int etmv3 = 0, etmv4 = 0;
++<<<<<<< HEAD
 +	struct cpu_map *event_cpus = evlist->cpus;
 +	struct cpu_map *online_cpus = cpu_map__new(NULL);
++=======
+ 	struct perf_cpu_map *event_cpus = evlist->core.cpus;
+ 	struct perf_cpu_map *online_cpus = perf_cpu_map__new(NULL);
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  
  	/* cpu map is not empty, we have specific CPUs to work with */
  	if (!cpu_map__empty(event_cpus)) {
@@@ -635,9 -635,9 +650,15 @@@ static int cs_etm_info_fill(struct auxt
  	int i;
  	u32 offset;
  	u64 nr_cpu, type;
++<<<<<<< HEAD
 +	struct cpu_map *cpu_map;
 +	struct cpu_map *event_cpus = session->evlist->cpus;
 +	struct cpu_map *online_cpus = cpu_map__new(NULL);
++=======
+ 	struct perf_cpu_map *cpu_map;
+ 	struct perf_cpu_map *event_cpus = session->evlist->core.cpus;
+ 	struct perf_cpu_map *online_cpus = perf_cpu_map__new(NULL);
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	struct cs_etm_recording *ptr =
  			container_of(itr, struct cs_etm_recording, itr);
  	struct perf_pmu *cs_etm_pmu = ptr->cs_etm_pmu;
diff --cc tools/perf/arch/x86/util/intel-bts.c
index 4cbd3d775c19,7b23318ebd7b..000000000000
--- a/tools/perf/arch/x86/util/intel-bts.c
+++ b/tools/perf/arch/x86/util/intel-bts.c
@@@ -114,8 -105,8 +114,13 @@@ static int intel_bts_recording_options(
  	struct intel_bts_recording *btsr =
  			container_of(itr, struct intel_bts_recording, itr);
  	struct perf_pmu *intel_bts_pmu = btsr->intel_bts_pmu;
++<<<<<<< HEAD
 +	struct perf_evsel *evsel, *intel_bts_evsel = NULL;
 +	const struct cpu_map *cpus = evlist->cpus;
++=======
+ 	struct evsel *evsel, *intel_bts_evsel = NULL;
+ 	const struct perf_cpu_map *cpus = evlist->core.cpus;
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	bool privileged = geteuid() == 0 || perf_event_paranoid() < 0;
  
  	btsr->evlist = evlist;
diff --cc tools/perf/arch/x86/util/intel-pt.c
index 3a851647e6f4,218a4e694618..000000000000
--- a/tools/perf/arch/x86/util/intel-pt.c
+++ b/tools/perf/arch/x86/util/intel-pt.c
@@@ -565,8 -556,8 +565,13 @@@ static int intel_pt_recording_options(s
  			container_of(itr, struct intel_pt_recording, itr);
  	struct perf_pmu *intel_pt_pmu = ptr->intel_pt_pmu;
  	bool have_timing_info, need_immediate = false;
++<<<<<<< HEAD
 +	struct perf_evsel *evsel, *intel_pt_evsel = NULL;
 +	const struct cpu_map *cpus = evlist->cpus;
++=======
+ 	struct evsel *evsel, *intel_pt_evsel = NULL;
+ 	const struct perf_cpu_map *cpus = evlist->core.cpus;
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	bool privileged = geteuid() == 0 || perf_event_paranoid() < 0;
  	u64 tsc_bit;
  	int err;
diff --cc tools/perf/builtin-ftrace.c
index f0a576403ecd,f481a870e728..000000000000
--- a/tools/perf/builtin-ftrace.c
+++ b/tools/perf/builtin-ftrace.c
@@@ -193,7 -192,7 +193,11 @@@ static int set_tracing_cpumask(struct c
  
  static int set_tracing_cpu(struct perf_ftrace *ftrace)
  {
++<<<<<<< HEAD
 +	struct cpu_map *cpumap = ftrace->evlist->cpus;
++=======
+ 	struct perf_cpu_map *cpumap = ftrace->evlist->core.cpus;
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  
  	if (!target__has_cpu(&ftrace->target))
  		return 0;
diff --cc tools/perf/builtin-top.c
index 6d6fb101231d,947f83e53272..000000000000
--- a/tools/perf/builtin-top.c
+++ b/tools/perf/builtin-top.c
@@@ -991,7 -989,7 +991,11 @@@ static int perf_top__start_counters(str
  
  	evlist__for_each_entry(evlist, counter) {
  try_again:
++<<<<<<< HEAD
 +		if (perf_evsel__open(counter, top->evlist->cpus,
++=======
+ 		if (evsel__open(counter, top->evlist->core.cpus,
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  				     top->evlist->threads) < 0) {
  
  			/*
diff --cc tools/perf/util/evlist.c
index 4739b7914374,977b9291fb0d..000000000000
--- a/tools/perf/util/evlist.c
+++ b/tools/perf/util/evlist.c
@@@ -141,10 -142,10 +141,17 @@@ void perf_evlist__delete(struct perf_ev
  		return;
  
  	perf_evlist__munmap(evlist);
++<<<<<<< HEAD
 +	perf_evlist__close(evlist);
 +	cpu_map__put(evlist->cpus);
 +	thread_map__put(evlist->threads);
 +	evlist->cpus = NULL;
++=======
+ 	evlist__close(evlist);
+ 	perf_cpu_map__put(evlist->core.cpus);
+ 	perf_thread_map__put(evlist->threads);
+ 	evlist->core.cpus = NULL;
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	evlist->threads = NULL;
  	perf_evlist__purge(evlist);
  	perf_evlist__exit(evlist);
@@@ -158,21 -159,21 +165,30 @@@ static void __perf_evlist__propagate_ma
  	 * We already have cpus for evsel (via PMU sysfs) so
  	 * keep it, if there's no target cpu list defined.
  	 */
++<<<<<<< HEAD
 +	if (!evsel->own_cpus || evlist->has_user_cpus) {
 +		cpu_map__put(evsel->cpus);
 +		evsel->cpus = cpu_map__get(evlist->cpus);
 +	} else if (evsel->cpus != evsel->own_cpus) {
 +		cpu_map__put(evsel->cpus);
 +		evsel->cpus = cpu_map__get(evsel->own_cpus);
++=======
+ 	if (!evsel->core.own_cpus || evlist->core.has_user_cpus) {
+ 		perf_cpu_map__put(evsel->core.cpus);
+ 		evsel->core.cpus = perf_cpu_map__get(evlist->core.cpus);
+ 	} else if (evsel->core.cpus != evsel->core.own_cpus) {
+ 		perf_cpu_map__put(evsel->core.cpus);
+ 		evsel->core.cpus = perf_cpu_map__get(evsel->core.own_cpus);
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	}
  
 -	perf_thread_map__put(evsel->core.threads);
 -	evsel->core.threads = perf_thread_map__get(evlist->threads);
 +	thread_map__put(evsel->threads);
 +	evsel->threads = thread_map__get(evlist->threads);
  }
  
 -static void perf_evlist__propagate_maps(struct evlist *evlist)
 +static void perf_evlist__propagate_maps(struct perf_evlist *evlist)
  {
 -	struct evsel *evsel;
 +	struct perf_evsel *evsel;
  
  	evlist__for_each_entry(evlist, evsel)
  		__perf_evlist__propagate_maps(evlist, evsel);
@@@ -410,10 -411,10 +426,10 @@@ static int perf_evlist__enable_event_th
  	return 0;
  }
  
 -int perf_evlist__enable_event_idx(struct evlist *evlist,
 -				  struct evsel *evsel, int idx)
 +int perf_evlist__enable_event_idx(struct perf_evlist *evlist,
 +				  struct perf_evsel *evsel, int idx)
  {
- 	bool per_cpu_mmaps = !cpu_map__empty(evlist->cpus);
+ 	bool per_cpu_mmaps = !cpu_map__empty(evlist->core.cpus);
  
  	if (per_cpu_mmaps)
  		return perf_evlist__enable_event_cpu(evlist, evsel, idx);
@@@ -421,12 -422,12 +437,12 @@@
  		return perf_evlist__enable_event_thread(evlist, evsel, idx);
  }
  
 -int perf_evlist__alloc_pollfd(struct evlist *evlist)
 +int perf_evlist__alloc_pollfd(struct perf_evlist *evlist)
  {
- 	int nr_cpus = cpu_map__nr(evlist->cpus);
+ 	int nr_cpus = cpu_map__nr(evlist->core.cpus);
  	int nr_threads = thread_map__nr(evlist->threads);
  	int nfds = 0;
 -	struct evsel *evsel;
 +	struct perf_evsel *evsel;
  
  	evlist__for_each_entry(evlist, evsel) {
  		if (evsel->system_wide)
@@@ -756,9 -757,9 +772,9 @@@ static int perf_evlist__mmap_per_evsel(
  				       struct mmap_params *mp, int cpu_idx,
  				       int thread, int *_output, int *_output_overwrite)
  {
 -	struct evsel *evsel;
 +	struct perf_evsel *evsel;
  	int revent;
- 	int evlist_cpu = cpu_map__cpu(evlist->cpus, cpu_idx);
+ 	int evlist_cpu = cpu_map__cpu(evlist->core.cpus, cpu_idx);
  
  	evlist__for_each_entry(evlist, evsel) {
  		struct perf_mmap *maps = evlist->mmap;
@@@ -1012,9 -1013,9 +1028,15 @@@ int perf_evlist__mmap_ex(struct perf_ev
  			 bool auxtrace_overwrite, int nr_cblocks, int affinity, int flush,
  			 int comp_level)
  {
++<<<<<<< HEAD
 +	struct perf_evsel *evsel;
 +	const struct cpu_map *cpus = evlist->cpus;
 +	const struct thread_map *threads = evlist->threads;
++=======
+ 	struct evsel *evsel;
+ 	const struct perf_cpu_map *cpus = evlist->core.cpus;
+ 	const struct perf_thread_map *threads = evlist->threads;
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	/*
  	 * Delay setting mp.prot: set it before calling perf_mmap__mmap.
  	 * Its value is decided by evsel's write_backward.
@@@ -1115,9 -1116,9 +1137,15 @@@ void perf_evlist__set_maps(struct perf_
  	 * original reference count of 1.  If that is not the case it is up to
  	 * the caller to increase the reference count.
  	 */
++<<<<<<< HEAD
 +	if (cpus != evlist->cpus) {
 +		cpu_map__put(evlist->cpus);
 +		evlist->cpus = cpu_map__get(cpus);
++=======
+ 	if (cpus != evlist->core.cpus) {
+ 		perf_cpu_map__put(evlist->core.cpus);
+ 		evlist->core.cpus = perf_cpu_map__get(cpus);
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	}
  
  	if (threads != evlist->threads) {
@@@ -1919,7 -1920,7 +1947,11 @@@ int perf_evlist__start_sb_thread(struc
  		goto out_delete_evlist;
  
  	evlist__for_each_entry(evlist, counter) {
++<<<<<<< HEAD
 +		if (perf_evsel__open(counter, evlist->cpus,
++=======
+ 		if (evsel__open(counter, evlist->core.cpus,
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  				     evlist->threads) < 0)
  			goto out_delete_evlist;
  	}
diff --cc tools/perf/util/evlist.h
index 49354fe24d5f,fdd8f83eac2d..000000000000
--- a/tools/perf/util/evlist.h
+++ b/tools/perf/util/evlist.h
@@@ -44,12 -43,11 +44,17 @@@ struct perf_evlist 
  	struct fdarray	 pollfd;
  	struct perf_mmap *mmap;
  	struct perf_mmap *overwrite_mmap;
++<<<<<<< HEAD
 +	struct thread_map *threads;
 +	struct cpu_map	  *cpus;
 +	struct perf_evsel *selected;
++=======
+ 	struct perf_thread_map *threads;
+ 	struct evsel *selected;
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  	struct events_stats stats;
  	struct perf_env	*env;
 -	void (*trace_event_sample_raw)(struct evlist *evlist,
 +	void (*trace_event_sample_raw)(struct perf_evlist *evlist,
  				       union perf_event *event,
  				       struct perf_sample *sample);
  	u64		first_sample_time;
diff --cc tools/perf/util/record.c
index 9cfc7bf16531,e59382d99196..000000000000
--- a/tools/perf/util/record.c
+++ b/tools/perf/util/record.c
@@@ -274,13 -275,13 +274,18 @@@ bool perf_evlist__can_select_event(stru
  
  	evsel = perf_evlist__last(temp_evlist);
  
++<<<<<<< HEAD
 +	if (!evlist || cpu_map__empty(evlist->cpus)) {
 +		struct cpu_map *cpus = cpu_map__new(NULL);
++=======
+ 	if (!evlist || cpu_map__empty(evlist->core.cpus)) {
+ 		struct perf_cpu_map *cpus = perf_cpu_map__new(NULL);
++>>>>>>> f72f901d90b0 (libperf: Add cpus to struct perf_evlist)
  
  		cpu =  cpus ? cpus->map[0] : 0;
 -		perf_cpu_map__put(cpus);
 +		cpu_map__put(cpus);
  	} else {
- 		cpu = evlist->cpus->map[0];
+ 		cpu = evlist->core.cpus->map[0];
  	}
  
  	while (1) {
* Unmerged path tools/perf/lib/include/internal/evlist.h
* Unmerged path tools/perf/arch/arm/util/cs-etm.c
* Unmerged path tools/perf/arch/x86/util/intel-bts.c
* Unmerged path tools/perf/arch/x86/util/intel-pt.c
* Unmerged path tools/perf/builtin-ftrace.c
diff --git a/tools/perf/builtin-record.c b/tools/perf/builtin-record.c
index 6dccaf4058f3..39b07b67108c 100644
--- a/tools/perf/builtin-record.c
+++ b/tools/perf/builtin-record.c
@@ -1284,7 +1284,7 @@ static int record__synthesize(struct record *rec, bool tail)
 		return err;
 	}
 
-	err = perf_event__synthesize_cpu_map(&rec->tool, rec->evlist->cpus,
+	err = perf_event__synthesize_cpu_map(&rec->tool, rec->evlist->core.cpus,
 					     process_synthesized_event, NULL);
 	if (err < 0) {
 		pr_err("Couldn't synthesize cpu map.\n");
diff --git a/tools/perf/builtin-stat.c b/tools/perf/builtin-stat.c
index b71c4390d333..13bc59b081e4 100644
--- a/tools/perf/builtin-stat.c
+++ b/tools/perf/builtin-stat.c
@@ -886,21 +886,21 @@ static int perf_stat_init_aggr_mode(void)
 
 	switch (stat_config.aggr_mode) {
 	case AGGR_SOCKET:
-		if (cpu_map__build_socket_map(evsel_list->cpus, &stat_config.aggr_map)) {
+		if (cpu_map__build_socket_map(evsel_list->core.cpus, &stat_config.aggr_map)) {
 			perror("cannot build socket map");
 			return -1;
 		}
 		stat_config.aggr_get_id = perf_stat__get_socket_cached;
 		break;
 	case AGGR_DIE:
-		if (cpu_map__build_die_map(evsel_list->cpus, &stat_config.aggr_map)) {
+		if (cpu_map__build_die_map(evsel_list->core.cpus, &stat_config.aggr_map)) {
 			perror("cannot build die map");
 			return -1;
 		}
 		stat_config.aggr_get_id = perf_stat__get_die_cached;
 		break;
 	case AGGR_CORE:
-		if (cpu_map__build_core_map(evsel_list->cpus, &stat_config.aggr_map)) {
+		if (cpu_map__build_core_map(evsel_list->core.cpus, &stat_config.aggr_map)) {
 			perror("cannot build core map");
 			return -1;
 		}
@@ -908,7 +908,7 @@ static int perf_stat_init_aggr_mode(void)
 		break;
 	case AGGR_NONE:
 		if (term_percore_set()) {
-			if (cpu_map__build_core_map(evsel_list->cpus,
+			if (cpu_map__build_core_map(evsel_list->core.cpus,
 						    &stat_config.aggr_map)) {
 				perror("cannot build core map");
 				return -1;
@@ -928,7 +928,7 @@ static int perf_stat_init_aggr_mode(void)
 	 * taking the highest cpu number to be the size of
 	 * the aggregation translate cpumap.
 	 */
-	nr = cpu_map__get_max(evsel_list->cpus);
+	nr = cpu_map__get_max(evsel_list->core.cpus);
 	stat_config.cpus_aggr_map = cpu_map__empty_new(nr + 1);
 	return stat_config.cpus_aggr_map ? 0 : -ENOMEM;
 }
@@ -1059,21 +1059,21 @@ static int perf_stat_init_aggr_mode_file(struct perf_stat *st)
 
 	switch (stat_config.aggr_mode) {
 	case AGGR_SOCKET:
-		if (perf_env__build_socket_map(env, evsel_list->cpus, &stat_config.aggr_map)) {
+		if (perf_env__build_socket_map(env, evsel_list->core.cpus, &stat_config.aggr_map)) {
 			perror("cannot build socket map");
 			return -1;
 		}
 		stat_config.aggr_get_id = perf_stat__get_socket_file;
 		break;
 	case AGGR_DIE:
-		if (perf_env__build_die_map(env, evsel_list->cpus, &stat_config.aggr_map)) {
+		if (perf_env__build_die_map(env, evsel_list->core.cpus, &stat_config.aggr_map)) {
 			perror("cannot build die map");
 			return -1;
 		}
 		stat_config.aggr_get_id = perf_stat__get_die_file;
 		break;
 	case AGGR_CORE:
-		if (perf_env__build_core_map(env, evsel_list->cpus, &stat_config.aggr_map)) {
+		if (perf_env__build_core_map(env, evsel_list->core.cpus, &stat_config.aggr_map)) {
 			perror("cannot build core map");
 			return -1;
 		}
* Unmerged path tools/perf/builtin-top.c
* Unmerged path tools/perf/lib/include/internal/evlist.h
diff --git a/tools/perf/util/auxtrace.c b/tools/perf/util/auxtrace.c
index 7479b73720be..9dda7cca0549 100644
--- a/tools/perf/util/auxtrace.c
+++ b/tools/perf/util/auxtrace.c
@@ -139,7 +139,7 @@ void auxtrace_mmap_params__set_idx(struct auxtrace_mmap_params *mp,
 	mp->idx = idx;
 
 	if (per_cpu) {
-		mp->cpu = evlist->cpus->map[idx];
+		mp->cpu = evlist->core.cpus->map[idx];
 		if (evlist->threads)
 			mp->tid = thread_map__pid(evlist->threads, 0);
 		else
* Unmerged path tools/perf/util/evlist.c
* Unmerged path tools/perf/util/evlist.h
* Unmerged path tools/perf/util/record.c
diff --git a/tools/perf/util/stat-display.c b/tools/perf/util/stat-display.c
index 58df6a0dbb9f..899b8c4219c9 100644
--- a/tools/perf/util/stat-display.c
+++ b/tools/perf/util/stat-display.c
@@ -327,7 +327,7 @@ static int first_shadow_cpu(struct perf_stat_config *config,
 	for (i = 0; i < perf_evsel__nr_cpus(evsel); i++) {
 		int cpu2 = perf_evsel__cpus(evsel)->map[i];
 
-		if (config->aggr_get_id(config, evlist->cpus, cpu2) == id)
+		if (config->aggr_get_id(config, evlist->core.cpus, cpu2) == id)
 			return cpu2;
 	}
 	return 0;
@@ -500,7 +500,7 @@ static void aggr_update_shadow(struct perf_stat_config *config,
 		evlist__for_each_entry(evlist, counter) {
 			val = 0;
 			for (cpu = 0; cpu < perf_evsel__nr_cpus(counter); cpu++) {
-				s2 = config->aggr_get_id(config, evlist->cpus, cpu);
+				s2 = config->aggr_get_id(config, evlist->core.cpus, cpu);
 				if (s2 != id)
 					continue;
 				val += perf_counts(counter->counts, cpu, 0)->val;
@@ -868,7 +868,7 @@ static void print_no_aggr_metric(struct perf_stat_config *config,
 	u64 ena, run, val;
 	double uval;
 
-	nrcpus = evlist->cpus->nr;
+	nrcpus = evlist->core.cpus->nr;
 	for (cpu = 0; cpu < nrcpus; cpu++) {
 		bool first = true;
 
diff --git a/tools/perf/util/stat.c b/tools/perf/util/stat.c
index da269d46c09f..2944e65697b6 100644
--- a/tools/perf/util/stat.c
+++ b/tools/perf/util/stat.c
@@ -514,7 +514,7 @@ int perf_stat_synthesize_config(struct perf_stat_config *config,
 		return err;
 	}
 
-	err = perf_event__synthesize_cpu_map(tool, evlist->cpus,
+	err = perf_event__synthesize_cpu_map(tool, evlist->core.cpus,
 					     process, NULL);
 	if (err < 0) {
 		pr_err("Couldn't synthesize thread map.\n");
diff --git a/tools/perf/util/top.c b/tools/perf/util/top.c
index 4c8da8c4435f..5ed6bedc9801 100644
--- a/tools/perf/util/top.c
+++ b/tools/perf/util/top.c
@@ -96,15 +96,15 @@ size_t perf_top__header_snprintf(struct perf_top *top, char *bf, size_t size)
 
 	if (target->cpu_list)
 		ret += SNPRINTF(bf + ret, size - ret, ", CPU%s: %s)",
-				top->evlist->cpus->nr > 1 ? "s" : "",
+				top->evlist->core.cpus->nr > 1 ? "s" : "",
 				target->cpu_list);
 	else {
 		if (target->tid)
 			ret += SNPRINTF(bf + ret, size - ret, ")");
 		else
 			ret += SNPRINTF(bf + ret, size - ret, ", %d CPU%s)",
-					top->evlist->cpus->nr,
-					top->evlist->cpus->nr > 1 ? "s" : "");
+					top->evlist->core.cpus->nr,
+					top->evlist->core.cpus->nr > 1 ? "s" : "");
 	}
 
 	perf_top__reset_sample_counters(top);
