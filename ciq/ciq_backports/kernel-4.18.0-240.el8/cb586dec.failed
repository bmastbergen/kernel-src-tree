xprtrdma: Make sendctx queue lifetime the same as connection lifetime

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Chuck Lever <chuck.lever@oracle.com>
commit cb586decbb88fcd068116af2d4e1e3e2e86978d6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/cb586dec.failed

The size of the sendctx queue depends on the value stored in
ia->ri_max_send_sges. This value is determined by querying the
underlying device.

Eventually, rpcrdma_ia_open() and rpcrdma_ep_create() will be called
in the connect worker rather than at transport set-up time. The
underlying device will not have been chosen device set-up time.

The sendctx queue will thus have to be created after the underlying
device has been chosen via address and route resolution; in other
words, in the connect worker.

	Signed-off-by: Chuck Lever <chuck.lever@oracle.com>
	Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
(cherry picked from commit cb586decbb88fcd068116af2d4e1e3e2e86978d6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sunrpc/xprtrdma/verbs.c
diff --cc net/sunrpc/xprtrdma/verbs.c
index 70a9ee184494,b6aba0c85998..000000000000
--- a/net/sunrpc/xprtrdma/verbs.c
+++ b/net/sunrpc/xprtrdma/verbs.c
@@@ -73,10 -74,14 +73,17 @@@
  /*
   * internal functions
   */
++<<<<<<< HEAD
 +static void rpcrdma_sendctx_put_locked(struct rpcrdma_sendctx *sc);
++=======
+ static int rpcrdma_sendctxs_create(struct rpcrdma_xprt *r_xprt);
+ static void rpcrdma_sendctxs_destroy(struct rpcrdma_xprt *r_xprt);
+ static void rpcrdma_sendctx_put_locked(struct rpcrdma_xprt *r_xprt,
+ 				       struct rpcrdma_sendctx *sc);
++>>>>>>> cb586decbb88 (xprtrdma: Make sendctx queue lifetime the same as connection lifetime)
  static void rpcrdma_reqs_reset(struct rpcrdma_xprt *r_xprt);
 -static void rpcrdma_reps_unmap(struct rpcrdma_xprt *r_xprt);
  static void rpcrdma_mrs_create(struct rpcrdma_xprt *r_xprt);
 -static void rpcrdma_mrs_destroy(struct rpcrdma_xprt *r_xprt);
 +static void rpcrdma_mrs_destroy(struct rpcrdma_buffer *buf);
  static struct rpcrdma_regbuf *
  rpcrdma_regbuf_alloc(size_t size, enum dma_data_direction direction,
  		     gfp_t flags);
@@@ -435,7 -429,8 +442,12 @@@ rpcrdma_ia_remove(struct rpcrdma_ia *ia
  		rpcrdma_regbuf_dma_unmap(req->rl_sendbuf);
  		rpcrdma_regbuf_dma_unmap(req->rl_recvbuf);
  	}
++<<<<<<< HEAD
 +	rpcrdma_mrs_destroy(buf);
++=======
+ 	rpcrdma_mrs_destroy(r_xprt);
+ 	rpcrdma_sendctxs_destroy(r_xprt);
++>>>>>>> cb586decbb88 (xprtrdma: Make sendctx queue lifetime the same as connection lifetime)
  	ib_dealloc_pd(ia->ri_pd);
  	ia->ri_pd = NULL;
  
@@@ -712,8 -705,13 +724,12 @@@ retry
  	ep->rep_connected = 0;
  	xprt_clear_connected(xprt);
  
 -	rpcrdma_reset_cwnd(r_xprt);
  	rpcrdma_post_recvs(r_xprt, true);
  
+ 	rc = rpcrdma_sendctxs_create(r_xprt);
+ 	if (rc)
+ 		goto out;
+ 
  	rc = rdma_connect(ia->ri_id, &ep->rep_remote_cma);
  	if (rc)
  		goto out;
@@@ -765,6 -763,8 +781,11 @@@ rpcrdma_ep_disconnect(struct rpcrdma_e
  
  	rpcrdma_xprt_drain(r_xprt);
  	rpcrdma_reqs_reset(r_xprt);
++<<<<<<< HEAD
++=======
+ 	rpcrdma_mrs_destroy(r_xprt);
+ 	rpcrdma_sendctxs_destroy(r_xprt);
++>>>>>>> cb586decbb88 (xprtrdma: Make sendctx queue lifetime the same as connection lifetime)
  }
  
  /* Fixed-size circular FIFO queue. This implementation is wait-free and
@@@ -1108,13 -1177,8 +1134,9 @@@ int rpcrdma_buffer_create(struct rpcrdm
  		list_add(&req->rl_list, &buf->rb_send_bufs);
  	}
  
 -	init_llist_head(&buf->rb_free_reps);
 +	buf->rb_credits = 1;
 +	INIT_LIST_HEAD(&buf->rb_recv_bufs);
  
- 	rc = rpcrdma_sendctxs_create(r_xprt);
- 	if (rc)
- 		goto out;
- 
  	return 0;
  out:
  	rpcrdma_buffer_destroy(buf);
@@@ -1186,18 -1254,7 +1208,22 @@@ rpcrdma_mrs_destroy(struct rpcrdma_buff
  void
  rpcrdma_buffer_destroy(struct rpcrdma_buffer *buf)
  {
++<<<<<<< HEAD
 +	cancel_delayed_work_sync(&buf->rb_refresh_worker);
 +
 +	rpcrdma_sendctxs_destroy(buf);
 +
 +	while (!list_empty(&buf->rb_recv_bufs)) {
 +		struct rpcrdma_rep *rep;
 +
 +		rep = list_first_entry(&buf->rb_recv_bufs,
 +				       struct rpcrdma_rep, rr_list);
 +		list_del(&rep->rr_list);
 +		rpcrdma_rep_destroy(rep);
 +	}
++=======
+ 	rpcrdma_reps_destroy(buf);
++>>>>>>> cb586decbb88 (xprtrdma: Make sendctx queue lifetime the same as connection lifetime)
  
  	while (!list_empty(&buf->rb_send_bufs)) {
  		struct rpcrdma_req *req;
diff --git a/include/trace/events/rpcrdma.h b/include/trace/events/rpcrdma.h
index cfe761e490ec..cbc8f663578c 100644
--- a/include/trace/events/rpcrdma.h
+++ b/include/trace/events/rpcrdma.h
@@ -592,6 +592,7 @@ TRACE_EVENT(xprtrdma_post_send,
 
 	TP_STRUCT__entry(
 		__field(const void *, req)
+		__field(const void *, sc)
 		__field(unsigned int, task_id)
 		__field(unsigned int, client_id)
 		__field(int, num_sge)
@@ -605,14 +606,15 @@ TRACE_EVENT(xprtrdma_post_send,
 		__entry->task_id = rqst->rq_task->tk_pid;
 		__entry->client_id = rqst->rq_task->tk_client->cl_clid;
 		__entry->req = req;
+		__entry->sc = req->rl_sendctx;
 		__entry->num_sge = req->rl_wr.num_sge;
 		__entry->signaled = req->rl_wr.send_flags & IB_SEND_SIGNALED;
 		__entry->status = status;
 	),
 
-	TP_printk("task:%u@%u req=%p (%d SGE%s) %sstatus=%d",
+	TP_printk("task:%u@%u req=%p sc=%p (%d SGE%s) %sstatus=%d",
 		__entry->task_id, __entry->client_id,
-		__entry->req, __entry->num_sge,
+		__entry->req, __entry->sc, __entry->num_sge,
 		(__entry->num_sge == 1 ? "" : "s"),
 		(__entry->signaled ? "signaled " : ""),
 		__entry->status
@@ -711,6 +713,7 @@ TRACE_EVENT(xprtrdma_wc_send,
 
 	TP_STRUCT__entry(
 		__field(const void *, req)
+		__field(const void *, sc)
 		__field(unsigned int, unmap_count)
 		__field(unsigned int, status)
 		__field(unsigned int, vendor_err)
@@ -718,13 +721,14 @@ TRACE_EVENT(xprtrdma_wc_send,
 
 	TP_fast_assign(
 		__entry->req = sc->sc_req;
+		__entry->sc = sc;
 		__entry->unmap_count = sc->sc_unmap_count;
 		__entry->status = wc->status;
 		__entry->vendor_err = __entry->status ? wc->vendor_err : 0;
 	),
 
-	TP_printk("req=%p, unmapped %u pages: %s (%u/0x%x)",
-		__entry->req, __entry->unmap_count,
+	TP_printk("req=%p sc=%p unmapped=%u: %s (%u/0x%x)",
+		__entry->req, __entry->sc, __entry->unmap_count,
 		rdma_show_wc_status(__entry->status),
 		__entry->status, __entry->vendor_err
 	)
* Unmerged path net/sunrpc/xprtrdma/verbs.c
