net/mlx5: fix kvfree of uninitialized pointer spec

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Colin Ian King <colin.king@canonical.com>
commit 8b3f2eb038d3098b37715afced1e62bbc72da90f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/8b3f2eb0.failed

Currently when a call to  esw_vport_create_legacy_ingress_acl_group
fails the error exit path to label 'out' will cause a kvfree on the
uninitialized pointer spec.  Fix this by ensuring pointer spec is
initialized to NULL to avoid this issue.

Addresses-Coverity: ("Uninitialized pointer read")
Fixes: 10652f39943e ("net/mlx5: Refactor ingress acl configuration")
	Signed-off-by: Colin Ian King <colin.king@canonical.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 8b3f2eb038d3098b37715afced1e62bbc72da90f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index 7ecf89103bc8,48627472a691..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -1072,6 -1070,194 +1072,197 @@@ int esw_vport_enable_ingress_acl(struc
  	struct mlx5_flow_group *g;
  	void *match_criteria;
  	u32 *flow_group_in;
++<<<<<<< HEAD
++=======
+ 	int err;
+ 
+ 	flow_group_in = kvzalloc(inlen, GFP_KERNEL);
+ 	if (!flow_group_in)
+ 		return -ENOMEM;
+ 
+ 	match_criteria = MLX5_ADDR_OF(create_flow_group_in, flow_group_in, match_criteria);
+ 
+ 	MLX5_SET(create_flow_group_in, flow_group_in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_TO_ONES(fte_match_param, match_criteria, outer_headers.cvlan_tag);
+ 	MLX5_SET_TO_ONES(fte_match_param, match_criteria, outer_headers.smac_47_16);
+ 	MLX5_SET_TO_ONES(fte_match_param, match_criteria, outer_headers.smac_15_0);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, start_flow_index, 0);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, end_flow_index, 0);
+ 
+ 	g = mlx5_create_flow_group(vport->ingress.acl, flow_group_in);
+ 	if (IS_ERR(g)) {
+ 		err = PTR_ERR(g);
+ 		esw_warn(dev, "vport[%d] ingress create untagged spoofchk flow group, err(%d)\n",
+ 			 vport->vport, err);
+ 		goto spoof_err;
+ 	}
+ 	vport->ingress.legacy.allow_untagged_spoofchk_grp = g;
+ 
+ 	memset(flow_group_in, 0, inlen);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_TO_ONES(fte_match_param, match_criteria, outer_headers.cvlan_tag);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, start_flow_index, 1);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, end_flow_index, 1);
+ 
+ 	g = mlx5_create_flow_group(vport->ingress.acl, flow_group_in);
+ 	if (IS_ERR(g)) {
+ 		err = PTR_ERR(g);
+ 		esw_warn(dev, "vport[%d] ingress create untagged flow group, err(%d)\n",
+ 			 vport->vport, err);
+ 		goto untagged_err;
+ 	}
+ 	vport->ingress.legacy.allow_untagged_only_grp = g;
+ 
+ 	memset(flow_group_in, 0, inlen);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_TO_ONES(fte_match_param, match_criteria, outer_headers.smac_47_16);
+ 	MLX5_SET_TO_ONES(fte_match_param, match_criteria, outer_headers.smac_15_0);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, start_flow_index, 2);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, end_flow_index, 2);
+ 
+ 	g = mlx5_create_flow_group(vport->ingress.acl, flow_group_in);
+ 	if (IS_ERR(g)) {
+ 		err = PTR_ERR(g);
+ 		esw_warn(dev, "vport[%d] ingress create spoofchk flow group, err(%d)\n",
+ 			 vport->vport, err);
+ 		goto allow_spoof_err;
+ 	}
+ 	vport->ingress.legacy.allow_spoofchk_only_grp = g;
+ 
+ 	memset(flow_group_in, 0, inlen);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, start_flow_index, 3);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, end_flow_index, 3);
+ 
+ 	g = mlx5_create_flow_group(vport->ingress.acl, flow_group_in);
+ 	if (IS_ERR(g)) {
+ 		err = PTR_ERR(g);
+ 		esw_warn(dev, "vport[%d] ingress create drop flow group, err(%d)\n",
+ 			 vport->vport, err);
+ 		goto drop_err;
+ 	}
+ 	vport->ingress.legacy.drop_grp = g;
+ 	kvfree(flow_group_in);
+ 	return 0;
+ 
+ drop_err:
+ 	if (!IS_ERR_OR_NULL(vport->ingress.legacy.allow_spoofchk_only_grp)) {
+ 		mlx5_destroy_flow_group(vport->ingress.legacy.allow_spoofchk_only_grp);
+ 		vport->ingress.legacy.allow_spoofchk_only_grp = NULL;
+ 	}
+ allow_spoof_err:
+ 	if (!IS_ERR_OR_NULL(vport->ingress.legacy.allow_untagged_only_grp)) {
+ 		mlx5_destroy_flow_group(vport->ingress.legacy.allow_untagged_only_grp);
+ 		vport->ingress.legacy.allow_untagged_only_grp = NULL;
+ 	}
+ untagged_err:
+ 	if (!IS_ERR_OR_NULL(vport->ingress.legacy.allow_untagged_spoofchk_grp)) {
+ 		mlx5_destroy_flow_group(vport->ingress.legacy.allow_untagged_spoofchk_grp);
+ 		vport->ingress.legacy.allow_untagged_spoofchk_grp = NULL;
+ 	}
+ spoof_err:
+ 	kvfree(flow_group_in);
+ 	return err;
+ }
+ 
+ int esw_vport_create_ingress_acl_table(struct mlx5_eswitch *esw,
+ 				       struct mlx5_vport *vport, int table_size)
+ {
+ 	struct mlx5_core_dev *dev = esw->dev;
+ 	struct mlx5_flow_namespace *root_ns;
+ 	struct mlx5_flow_table *acl;
+ 	int vport_index;
+ 	int err;
+ 
+ 	if (!MLX5_CAP_ESW_INGRESS_ACL(dev, ft_support))
+ 		return -EOPNOTSUPP;
+ 
+ 	esw_debug(dev, "Create vport[%d] ingress ACL log_max_size(%d)\n",
+ 		  vport->vport, MLX5_CAP_ESW_INGRESS_ACL(dev, log_max_ft_size));
+ 
+ 	vport_index = mlx5_eswitch_vport_num_to_index(esw, vport->vport);
+ 	root_ns = mlx5_get_flow_vport_acl_namespace(dev, MLX5_FLOW_NAMESPACE_ESW_INGRESS,
+ 						    vport_index);
+ 	if (!root_ns) {
+ 		esw_warn(dev, "Failed to get E-Switch ingress flow namespace for vport (%d)\n",
+ 			 vport->vport);
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	acl = mlx5_create_vport_flow_table(root_ns, 0, table_size, 0, vport->vport);
+ 	if (IS_ERR(acl)) {
+ 		err = PTR_ERR(acl);
+ 		esw_warn(dev, "vport[%d] ingress create flow Table, err(%d)\n",
+ 			 vport->vport, err);
+ 		return err;
+ 	}
+ 	vport->ingress.acl = acl;
+ 	return 0;
+ }
+ 
+ void esw_vport_destroy_ingress_acl_table(struct mlx5_vport *vport)
+ {
+ 	if (!vport->ingress.acl)
+ 		return;
+ 
+ 	mlx5_destroy_flow_table(vport->ingress.acl);
+ 	vport->ingress.acl = NULL;
+ }
+ 
+ void esw_vport_cleanup_ingress_rules(struct mlx5_eswitch *esw,
+ 				     struct mlx5_vport *vport)
+ {
+ 	if (vport->ingress.legacy.drop_rule) {
+ 		mlx5_del_flow_rules(vport->ingress.legacy.drop_rule);
+ 		vport->ingress.legacy.drop_rule = NULL;
+ 	}
+ 
+ 	if (vport->ingress.allow_rule) {
+ 		mlx5_del_flow_rules(vport->ingress.allow_rule);
+ 		vport->ingress.allow_rule = NULL;
+ 	}
+ }
+ 
+ static void esw_vport_disable_legacy_ingress_acl(struct mlx5_eswitch *esw,
+ 						 struct mlx5_vport *vport)
+ {
+ 	if (!vport->ingress.acl)
+ 		return;
+ 
+ 	esw_debug(esw->dev, "Destroy vport[%d] E-Switch ingress ACL\n", vport->vport);
+ 
+ 	esw_vport_cleanup_ingress_rules(esw, vport);
+ 	if (vport->ingress.legacy.allow_spoofchk_only_grp) {
+ 		mlx5_destroy_flow_group(vport->ingress.legacy.allow_spoofchk_only_grp);
+ 		vport->ingress.legacy.allow_spoofchk_only_grp = NULL;
+ 	}
+ 	if (vport->ingress.legacy.allow_untagged_only_grp) {
+ 		mlx5_destroy_flow_group(vport->ingress.legacy.allow_untagged_only_grp);
+ 		vport->ingress.legacy.allow_untagged_only_grp = NULL;
+ 	}
+ 	if (vport->ingress.legacy.allow_untagged_spoofchk_grp) {
+ 		mlx5_destroy_flow_group(vport->ingress.legacy.allow_untagged_spoofchk_grp);
+ 		vport->ingress.legacy.allow_untagged_spoofchk_grp = NULL;
+ 	}
+ 	if (vport->ingress.legacy.drop_grp) {
+ 		mlx5_destroy_flow_group(vport->ingress.legacy.drop_grp);
+ 		vport->ingress.legacy.drop_grp = NULL;
+ 	}
+ 	esw_vport_destroy_ingress_acl_table(vport);
+ }
+ 
+ static int esw_vport_ingress_config(struct mlx5_eswitch *esw,
+ 				    struct mlx5_vport *vport)
+ {
+ 	struct mlx5_fc *counter = vport->ingress.legacy.drop_counter;
+ 	struct mlx5_flow_destination drop_ctr_dst = {0};
+ 	struct mlx5_flow_destination *dst = NULL;
+ 	struct mlx5_flow_act flow_act = {0};
+ 	struct mlx5_flow_spec *spec = NULL;
+ 	int dest_num = 0;
+ 	int err = 0;
+ 	u8 *smac_v;
+ 
++>>>>>>> 8b3f2eb038d3 (net/mlx5: fix kvfree of uninitialized pointer spec)
  	/* The ingress acl table contains 4 groups
  	 * (2 active rules at the same time -
  	 *      1 allow rule from one of the first 3 groups.
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
