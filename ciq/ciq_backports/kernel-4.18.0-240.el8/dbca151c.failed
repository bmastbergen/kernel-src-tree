bpf: Update locking comment in hashtab code

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit dbca151cad736c99f4817076daf9fd02ed0c2daa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/dbca151c.failed

The comment where the bucket lock is acquired says:

  /* bpf_map_update_elem() can be called in_irq() */

which is not really helpful and aside of that it does not explain the
subtle details of the hash bucket locks expecially in the context of BPF
and perf, kprobes and tracing.

Add a comment at the top of the file which explains the protection scopes
and the details how potential deadlocks are prevented.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20200224145642.755793061@linutronix.de
(cherry picked from commit dbca151cad736c99f4817076daf9fd02ed0c2daa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/hashtab.c
diff --cc kernel/bpf/hashtab.c
index d92e05d9979b,65711a220fe0..000000000000
--- a/kernel/bpf/hashtab.c
+++ b/kernel/bpf/hashtab.c
@@@ -25,6 -17,36 +25,39 @@@
  	(BPF_F_NO_PREALLOC | BPF_F_NO_COMMON_LRU | BPF_F_NUMA_NODE |	\
  	 BPF_F_ACCESS_MASK | BPF_F_ZERO_SEED)
  
++<<<<<<< HEAD
++=======
+ #define BATCH_OPS(_name)			\
+ 	.map_lookup_batch =			\
+ 	_name##_map_lookup_batch,		\
+ 	.map_lookup_and_delete_batch =		\
+ 	_name##_map_lookup_and_delete_batch,	\
+ 	.map_update_batch =			\
+ 	generic_map_update_batch,		\
+ 	.map_delete_batch =			\
+ 	generic_map_delete_batch
+ 
+ /*
+  * The bucket lock has two protection scopes:
+  *
+  * 1) Serializing concurrent operations from BPF programs on differrent
+  *    CPUs
+  *
+  * 2) Serializing concurrent operations from BPF programs and sys_bpf()
+  *
+  * BPF programs can execute in any context including perf, kprobes and
+  * tracing. As there are almost no limits where perf, kprobes and tracing
+  * can be invoked from the lock operations need to be protected against
+  * deadlocks. Deadlocks can be caused by recursion and by an invocation in
+  * the lock held section when functions which acquire this lock are invoked
+  * from sys_bpf(). BPF recursion is prevented by incrementing the per CPU
+  * variable bpf_prog_active, which prevents BPF programs attached to perf
+  * events, kprobes and tracing to be invoked before the prior invocation
+  * from one of these contexts completed. sys_bpf() uses the same mechanism
+  * by pinning the task to the current CPU and incrementing the recursion
+  * protection accross the map operation.
+  */
++>>>>>>> dbca151cad73 (bpf: Update locking comment in hashtab code)
  struct bucket {
  	struct hlist_nulls_head head;
  	raw_spinlock_t lock;
* Unmerged path kernel/bpf/hashtab.c
