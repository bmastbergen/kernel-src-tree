dma/direct: turn ARCH_ZONE_DMA_BITS into a variable

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Nicolas Saenz Julienne <nsaenzjulienne@suse.de>
commit 8b5369ea580964dbc982781bfb9fb93459fc5e8d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/8b5369ea.failed

Some architectures, notably ARM, are interested in tweaking this
depending on their runtime DMA addressing limitations.

	Acked-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Nicolas Saenz Julienne <nsaenzjulienne@suse.de>
	Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
(cherry picked from commit 8b5369ea580964dbc982781bfb9fb93459fc5e8d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/mm/init.c
#	arch/powerpc/include/asm/page.h
#	arch/powerpc/mm/mem.c
#	include/linux/dma-direct.h
diff --cc arch/arm64/mm/init.c
index 5acf8fbf4557,35f27b839101..000000000000
--- a/arch/arm64/mm/init.c
+++ b/arch/arm64/mm/init.c
@@@ -482,11 -443,15 +485,19 @@@ void __init arm64_memblock_init(void
  
  	early_init_fdt_scan_reserved_mem();
  
++<<<<<<< HEAD
 +	/* 4GB maximum for 32-bit only capable devices */
++=======
+ 	if (IS_ENABLED(CONFIG_ZONE_DMA)) {
+ 		zone_dma_bits = ARM64_ZONE_DMA_BITS;
+ 		arm64_dma_phys_limit = max_zone_phys(ARM64_ZONE_DMA_BITS);
+ 	}
+ 
++>>>>>>> 8b5369ea5809 (dma/direct: turn ARCH_ZONE_DMA_BITS into a variable)
  	if (IS_ENABLED(CONFIG_ZONE_DMA32))
 -		arm64_dma32_phys_limit = max_zone_phys(32);
 +		arm64_dma_phys_limit = max_zone_dma_phys();
  	else
 -		arm64_dma32_phys_limit = PHYS_MASK + 1;
 +		arm64_dma_phys_limit = PHYS_MASK + 1;
  
  	reserve_crashkernel();
  
diff --cc arch/powerpc/include/asm/page.h
index d5568bf09c05,f6c562acc3f8..000000000000
--- a/arch/powerpc/include/asm/page.h
+++ b/arch/powerpc/include/asm/page.h
@@@ -355,6 -329,4 +355,9 @@@ typedef struct page *pgtable_t
  #endif /* __ASSEMBLY__ */
  #include <asm/slice.h>
  
++<<<<<<< HEAD
 +#define ARCH_ZONE_DMA_BITS 31
 +
++=======
++>>>>>>> 8b5369ea5809 (dma/direct: turn ARCH_ZONE_DMA_BITS into a variable)
  #endif /* _ASM_POWERPC_PAGE_H */
diff --cc arch/powerpc/mm/mem.c
index 2c991fdfac6a,c95b7fe9f298..000000000000
--- a/arch/powerpc/mm/mem.c
+++ b/arch/powerpc/mm/mem.c
@@@ -275,15 -238,18 +276,30 @@@ void __init paging_init(void
  	printk(KERN_DEBUG "Memory hole size: %ldMB\n",
  	       (long int)((top_of_ram - total_ram) >> 20));
  
++<<<<<<< HEAD
 +#if defined(CONFIG_ZONE_DMA) && defined(CONFIG_PPC_BOOK3E_64)
 +	max_zone_pfns[ZONE_DMA]	= min(max_low_pfn, 0x7fffffffUL >> PAGE_SHIFT);
 +#endif
 +#if defined(CONFIG_ZONE_DMA) && !defined(CONFIG_PPC_BOOK3E_64)
 +	/*
 +	 * Reduce the window where gfp_allowed_mask isn't out of control of
 +	 * powerpc in between kernel_init_freeable() and free_initmem().
 +	 */
 +	gfp_allowed_mask &= ~(__GFP_DMA|__GFP_DMA32);
++=======
+ 	/*
+ 	 * Allow 30-bit DMA for very limited Broadcom wifi chips on many
+ 	 * powerbooks.
+ 	 */
+ 	if (IS_ENABLED(CONFIG_PPC32))
+ 		zone_dma_bits = 30;
+ 	else
+ 		zone_dma_bits = 31;
+ 
+ #ifdef CONFIG_ZONE_DMA
+ 	max_zone_pfns[ZONE_DMA]	= min(max_low_pfn,
+ 				      1UL << (zone_dma_bits - PAGE_SHIFT));
++>>>>>>> 8b5369ea5809 (dma/direct: turn ARCH_ZONE_DMA_BITS into a variable)
  #endif
  	max_zone_pfns[ZONE_NORMAL] = max_low_pfn;
  #ifdef CONFIG_HIGHMEM
diff --cc include/linux/dma-direct.h
index 6a18a97b76a8,d03af3605460..000000000000
--- a/include/linux/dma-direct.h
+++ b/include/linux/dma-direct.h
@@@ -3,10 -3,9 +3,14 @@@
  #define _LINUX_DMA_DIRECT_H 1
  
  #include <linux/dma-mapping.h>
 +#include <linux/memblock.h> /* for min_low_pfn */
  #include <linux/mem_encrypt.h>
  
++<<<<<<< HEAD
 +static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr);
++=======
+ extern unsigned int zone_dma_bits;
++>>>>>>> 8b5369ea5809 (dma/direct: turn ARCH_ZONE_DMA_BITS into a variable)
  
  #ifdef CONFIG_ARCH_HAS_PHYS_TO_DMA
  #include <asm/dma-direct.h>
* Unmerged path arch/arm64/mm/init.c
* Unmerged path arch/powerpc/include/asm/page.h
* Unmerged path arch/powerpc/mm/mem.c
diff --git a/arch/s390/include/asm/page.h b/arch/s390/include/asm/page.h
index 3f5cb55cde35..85e944f04c70 100644
--- a/arch/s390/include/asm/page.h
+++ b/arch/s390/include/asm/page.h
@@ -179,8 +179,6 @@ static inline int devmem_is_allowed(unsigned long pfn)
 #define VM_DATA_DEFAULT_FLAGS	(VM_READ | VM_WRITE | \
 				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
 
-#define ARCH_ZONE_DMA_BITS	31
-
 #include <asm-generic/memory_model.h>
 #include <asm-generic/getorder.h>
 
diff --git a/arch/s390/mm/init.c b/arch/s390/mm/init.c
index 76f4479d0030..090b4136c997 100644
--- a/arch/s390/mm/init.c
+++ b/arch/s390/mm/init.c
@@ -119,6 +119,7 @@ void __init paging_init(void)
 
 	sparse_memory_present_with_active_regions(MAX_NUMNODES);
 	sparse_init();
+	zone_dma_bits = 31;
 	memset(max_zone_pfns, 0, sizeof(max_zone_pfns));
 	max_zone_pfns[ZONE_DMA] = PFN_DOWN(MAX_DMA_ADDRESS);
 	max_zone_pfns[ZONE_NORMAL] = max_low_pfn;
* Unmerged path include/linux/dma-direct.h
diff --git a/kernel/dma/direct.c b/kernel/dma/direct.c
index 9f38de9d2578..7eef3e5b4c7a 100644
--- a/kernel/dma/direct.c
+++ b/kernel/dma/direct.c
@@ -16,12 +16,11 @@
 #include <linux/swiotlb.h>
 
 /*
- * Most architectures use ZONE_DMA for the first 16 Megabytes, but
- * some use it for entirely different regions:
+ * Most architectures use ZONE_DMA for the first 16 Megabytes, but some use it
+ * it for entirely different regions. In that case the arch code needs to
+ * override the variable below for dma-direct to work properly.
  */
-#ifndef ARCH_ZONE_DMA_BITS
-#define ARCH_ZONE_DMA_BITS 24
-#endif
+unsigned int zone_dma_bits __ro_after_init = 24;
 
 static void report_addr(struct device *dev, dma_addr_t dma_addr, size_t size)
 {
@@ -69,7 +68,7 @@ static gfp_t __dma_direct_optimal_gfp_mask(struct device *dev, u64 dma_mask,
 	 * Note that GFP_DMA32 and GFP_DMA are no ops without the corresponding
 	 * zones.
 	 */
-	if (*phys_mask <= DMA_BIT_MASK(ARCH_ZONE_DMA_BITS))
+	if (*phys_mask <= DMA_BIT_MASK(zone_dma_bits))
 		return GFP_DMA;
 	if (*phys_mask <= DMA_BIT_MASK(32))
 		return GFP_DMA32;
@@ -381,7 +380,7 @@ int dma_direct_supported(struct device *dev, u64 mask)
 	u64 min_mask;
 
 	if (IS_ENABLED(CONFIG_ZONE_DMA))
-		min_mask = DMA_BIT_MASK(ARCH_ZONE_DMA_BITS);
+		min_mask = DMA_BIT_MASK(zone_dma_bits);
 	else
 		min_mask = DMA_BIT_MASK(32);
 
