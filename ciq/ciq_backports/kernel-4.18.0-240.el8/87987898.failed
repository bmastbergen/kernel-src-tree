io_uring: remove REQ_F_IO_DRAINED

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Pavel Begunkov <asml.silence@gmail.com>
commit 87987898a1dbc69b1138f7c10eb9abd655c03396
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/87987898.failed

A request can get into the defer list only once, there is no need for
marking it as drained, so remove it. This probably was left after
extracting __need_defer() for use in timeouts.

	Signed-off-by: Pavel Begunkov <asml.silence@gmail.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 87987898a1dbc69b1138f7c10eb9abd655c03396)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index 28a601d08266,ed1adeda370e..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -331,12 -497,20 +331,11 @@@ struct io_kiocb 
  #define REQ_F_NOWAIT		1	/* must not punt to workers */
  #define REQ_F_IOPOLL_COMPLETED	2	/* polled IO has completed */
  #define REQ_F_FIXED_FILE	4	/* ctx owns file */
 -#define REQ_F_LINK_NEXT		8	/* already grabbed next link */
  #define REQ_F_IO_DRAIN		16	/* drain existing IO first */
- #define REQ_F_IO_DRAINED	32	/* drain done */
  #define REQ_F_LINK		64	/* linked sqes */
 -#define REQ_F_LINK_TIMEOUT	128	/* has linked timeout */
 +#define REQ_F_LINK_DONE		128	/* linked sqes done */
  #define REQ_F_FAIL_LINK		256	/* fail rest of links */
 -#define REQ_F_TIMEOUT		1024	/* timeout request */
 -#define REQ_F_ISREG		2048	/* regular file */
 -#define REQ_F_MUST_PUNT		4096	/* must be punted even for NONBLOCK */
 -#define REQ_F_TIMEOUT_NOSEQ	8192	/* no timeout sequence */
 -#define REQ_F_INFLIGHT		16384	/* on inflight list */
 -#define REQ_F_COMP_LOCKED	32768	/* completion under lock */
 -#define REQ_F_HARDLINK		65536	/* doesn't sever on completion < 0 */
 -#define REQ_F_FORCE_ASYNC	131072	/* IOSQE_ASYNC */
 -#define REQ_F_CUR_POS		262144	/* read/write uses file position */
 +#define REQ_F_SHADOW_DRAIN	512	/* link-drain shadow req */
  	u64			user_data;
  	u32			result;
  	u32			sequence;
@@@ -411,29 -783,43 +410,42 @@@ static struct io_ring_ctx *io_ring_ctx_
  
  	ctx->flags = p->flags;
  	init_waitqueue_head(&ctx->cq_wait);
 -	INIT_LIST_HEAD(&ctx->cq_overflow_list);
 -	init_completion(&ctx->completions[0]);
 -	init_completion(&ctx->completions[1]);
 +	init_completion(&ctx->ctx_done);
 +	init_completion(&ctx->sqo_thread_started);
  	mutex_init(&ctx->uring_lock);
  	init_waitqueue_head(&ctx->wait);
 +	for (i = 0; i < ARRAY_SIZE(ctx->pending_async); i++) {
 +		spin_lock_init(&ctx->pending_async[i].lock);
 +		INIT_LIST_HEAD(&ctx->pending_async[i].list);
 +		atomic_set(&ctx->pending_async[i].cnt, 0);
 +	}
  	spin_lock_init(&ctx->completion_lock);
 -	init_llist_head(&ctx->poll_llist);
  	INIT_LIST_HEAD(&ctx->poll_list);
 +	INIT_LIST_HEAD(&ctx->cancel_list);
  	INIT_LIST_HEAD(&ctx->defer_list);
 -	INIT_LIST_HEAD(&ctx->timeout_list);
 -	init_waitqueue_head(&ctx->inflight_wait);
 -	spin_lock_init(&ctx->inflight_lock);
 -	INIT_LIST_HEAD(&ctx->inflight_list);
  	return ctx;
 -err:
 -	if (ctx->fallback_req)
 -		kmem_cache_free(req_cachep, ctx->fallback_req);
 -	kfree(ctx->completions);
 -	kfree(ctx->cancel_hash);
 -	kfree(ctx);
 -	return NULL;
  }
  
 -static inline bool __req_need_defer(struct io_kiocb *req)
 +static inline bool io_sequence_defer(struct io_ring_ctx *ctx,
 +				     struct io_kiocb *req)
  {
 -	struct io_ring_ctx *ctx = req->ctx;
 +	if ((req->flags & (REQ_F_IO_DRAIN|REQ_F_IO_DRAINED)) != REQ_F_IO_DRAIN)
 +		return false;
  
++<<<<<<< HEAD
 +	return req->sequence != ctx->cached_cq_tail + ctx->sq_ring->dropped;
++=======
+ 	return req->sequence != ctx->cached_cq_tail + ctx->cached_sq_dropped
+ 					+ atomic_read(&ctx->cached_cq_overflow);
+ }
+ 
+ static inline bool req_need_defer(struct io_kiocb *req)
+ {
+ 	if (unlikely(req->flags & REQ_F_IO_DRAIN))
+ 		return __req_need_defer(req);
+ 
+ 	return false;
++>>>>>>> 87987898a1db (io_uring: remove REQ_F_IO_DRAINED)
  }
  
  static struct io_kiocb *io_get_deferred_req(struct io_ring_ctx *ctx)
@@@ -488,17 -933,13 +500,22 @@@ static void io_commit_cqring(struct io_
  {
  	struct io_kiocb *req;
  
 -	while ((req = io_get_timeout_req(ctx)) != NULL)
 -		io_kill_timeout(req);
 -
  	__io_commit_cqring(ctx);
  
++<<<<<<< HEAD
 +	while ((req = io_get_deferred_req(ctx)) != NULL) {
 +		if (req->flags & REQ_F_SHADOW_DRAIN) {
 +			/* Just for drain, free it. */
 +			__io_free_req(req);
 +			continue;
 +		}
 +		req->flags |= REQ_F_IO_DRAINED;
 +		io_queue_async_work(ctx, req);
 +	}
++=======
+ 	while ((req = io_get_deferred_req(ctx)) != NULL)
+ 		io_queue_async_work(req);
++>>>>>>> 87987898a1db (io_uring: remove REQ_F_IO_DRAINED)
  }
  
  static struct io_uring_cqe *io_get_cqring(struct io_ring_ctx *ctx)
* Unmerged path fs/io_uring.c
