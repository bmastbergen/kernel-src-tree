arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE}

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
Rebuild_CHGLOG: - [arm64] Unify WORKAROUND_SPECULATIVE_AT_{NVHE, VHE} (Andrew Jones) [1842468]
Rebuild_FUZZ: 91.30%
commit-author Andrew Scull <ascull@google.com>
commit 02ab1f5018c3ad0b8677e797b5d3333d2e3b7f20
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/02ab1f50.failed

Errata 1165522, 1319367 and 1530923 each allow TLB entries to be
allocated as a result of a speculative AT instruction. In order to
avoid mandating VHE on certain affected CPUs, apply the workaround to
both the nVHE and the VHE case for all affected CPUs.

	Signed-off-by: Andrew Scull <ascull@google.com>
	Acked-by: Will Deacon <will@kernel.org>
CC: Marc Zyngier <maz@kernel.org>
CC: James Morse <james.morse@arm.com>
CC: Suzuki K Poulose <suzuki.poulose@arm.com>
CC: Will Deacon <will@kernel.org>
CC: Steven Price <steven.price@arm.com>
Link: https://lore.kernel.org/r/20200504094858.108917-1-ascull@google.com
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit 02ab1f5018c3ad0b8677e797b5d3333d2e3b7f20)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/Kconfig
#	arch/arm64/include/asm/cpucaps.h
#	arch/arm64/include/asm/kvm_host.h
#	arch/arm64/include/asm/kvm_hyp.h
#	arch/arm64/kernel/cpu_errata.c
#	arch/arm64/kvm/hyp/switch.c
#	arch/arm64/kvm/hyp/sysreg-sr.c
#	arch/arm64/kvm/hyp/tlb.c
diff --cc arch/arm64/Kconfig
index d9a7ce52dbae,c0298e8f1a2d..000000000000
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@@ -510,9 -524,13 +510,19 @@@ config ARM64_ERRATUM_141804
  
  	  If unsure, say Y.
  
++<<<<<<< HEAD
++=======
+ config ARM64_WORKAROUND_SPECULATIVE_AT
+ 	bool
+ 
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  config ARM64_ERRATUM_1165522
- 	bool "Cortex-A76: Speculative AT instruction using out-of-context translation regime could cause subsequent request to generate an incorrect translation"
+ 	bool "Cortex-A76: 1165522: Speculative AT instruction using out-of-context translation regime could cause subsequent request to generate an incorrect translation"
  	default y
++<<<<<<< HEAD
++=======
+ 	select ARM64_WORKAROUND_SPECULATIVE_AT
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  	help
  	  This option adds a workaround for ARM Cortex-A76 erratum 1165522.
  
@@@ -522,6 -540,32 +532,35 @@@
  
  	  If unsure, say Y.
  
++<<<<<<< HEAD
++=======
+ config ARM64_ERRATUM_1319367
+ 	bool "Cortex-A57/A72: 1319537: Speculative AT instruction using out-of-context translation regime could cause subsequent request to generate an incorrect translation"
+ 	default y
+ 	select ARM64_WORKAROUND_SPECULATIVE_AT
+ 	help
+ 	  This option adds work arounds for ARM Cortex-A57 erratum 1319537
+ 	  and A72 erratum 1319367
+ 
+ 	  Cortex-A57 and A72 cores could end-up with corrupted TLBs by
+ 	  speculating an AT instruction during a guest context switch.
+ 
+ 	  If unsure, say Y.
+ 
+ config ARM64_ERRATUM_1530923
+ 	bool "Cortex-A55: 1530923: Speculative AT instruction using out-of-context translation regime could cause subsequent request to generate an incorrect translation"
+ 	default y
+ 	select ARM64_WORKAROUND_SPECULATIVE_AT
+ 	help
+ 	  This option adds a workaround for ARM Cortex-A55 erratum 1530923.
+ 
+ 	  Affected Cortex-A55 cores (r0p0, r0p1, r1p0, r2p0) could end-up with
+ 	  corrupted TLBs by speculating an AT instruction during a guest
+ 	  context switch.
+ 
+ 	  If unsure, say Y.
+ 
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  config ARM64_ERRATUM_1286807
  	bool "Cortex-A76: Modification of the translation table for a virtual address might lead to read-after-read ordering violation"
  	default y
@@@ -538,8 -582,6 +577,11 @@@
  	  invalidated has been observed by other observers. The
  	  workaround repeats the TLBI+DSB operation.
  
++<<<<<<< HEAD
 +	  If unsure, say Y.
 +
++=======
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  config ARM64_ERRATUM_1463225
  	bool "Cortex-A76: Software Step might prevent interrupt recognition"
  	default y
diff --cc arch/arm64/include/asm/cpucaps.h
index 5ca3d91a67b5,dc70883062ba..000000000000
--- a/arch/arm64/include/asm/cpucaps.h
+++ b/arch/arm64/include/asm/cpucaps.h
@@@ -55,16 -44,23 +55,33 @@@
  #define ARM64_SSBS				34
  #define ARM64_WORKAROUND_1418040		35
  #define ARM64_HAS_SB				36
++<<<<<<< HEAD
 +#define ARM64_WORKAROUND_1165522		37
++=======
+ #define ARM64_WORKAROUND_SPECULATIVE_AT	37
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  #define ARM64_HAS_ADDRESS_AUTH_ARCH		38
  #define ARM64_HAS_ADDRESS_AUTH_IMP_DEF		39
  #define ARM64_HAS_GENERIC_AUTH_ARCH		40
  #define ARM64_HAS_GENERIC_AUTH_IMP_DEF		41
 -#define ARM64_HAS_IRQ_PRIO_MASKING		42
 -#define ARM64_HAS_DCPODP			43
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	42
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	43
  #define ARM64_WORKAROUND_1463225		44
++<<<<<<< HEAD
 +#define ARM64_WORKAROUND_1542419		45
 +
 +#define ARM64_NCAPS				46
++=======
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	45
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	46
+ #define ARM64_WORKAROUND_1542419		47
+ #define ARM64_HAS_E0PD				48
+ #define ARM64_HAS_RNG				49
+ #define ARM64_HAS_AMU_EXTN			50
+ #define ARM64_HAS_ADDRESS_AUTH			51
+ #define ARM64_HAS_GENERIC_AUTH			52
+ 
+ #define ARM64_NCAPS				53
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  
  #endif /* __ASM_CPUCAPS_H */
diff --cc arch/arm64/include/asm/kvm_host.h
index 4dd101adad0d,d0e7d7934a1f..000000000000
--- a/arch/arm64/include/asm/kvm_host.h
+++ b/arch/arm64/include/asm/kvm_host.h
@@@ -549,10 -573,6 +549,13 @@@ static inline bool kvm_arch_requires_vh
  	if (system_supports_sve())
  		return true;
  
++<<<<<<< HEAD
 +	/* Some implementations have defects that confine them to VHE */
 +	if (cpus_have_cap(ARM64_WORKAROUND_1165522))
 +		return true;
 +
++=======
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  	return false;
  }
  
diff --cc arch/arm64/include/asm/kvm_hyp.h
index 3e0768d093d1,238d2e049694..000000000000
--- a/arch/arm64/include/asm/kvm_hyp.h
+++ b/arch/arm64/include/asm/kvm_hyp.h
@@@ -109,11 -98,11 +109,15 @@@ static __always_inline void __hyp_text 
  	write_sysreg(kvm_get_vttbr(kvm), vttbr_el2);
  
  	/*
 -	 * ARM errata 1165522 and 1530923 require the actual execution of the
 -	 * above before we can switch to the EL1/EL0 translation regime used by
 +	 * ARM erratum 1165522 requires the actual execution of the above
 +	 * before we can switch to the EL1/EL0 translation regime used by
  	 * the guest.
  	 */
++<<<<<<< HEAD
 +	asm(ALTERNATIVE("nop", "isb", ARM64_WORKAROUND_1165522));
++=======
+ 	asm(ALTERNATIVE("nop", "isb", ARM64_WORKAROUND_SPECULATIVE_AT));
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  }
  
  #endif /* __ARM64_KVM_HYP_H__ */
diff --cc arch/arm64/kernel/cpu_errata.c
index 9de4d99cff30,95006a791026..000000000000
--- a/arch/arm64/kernel/cpu_errata.c
+++ b/arch/arm64/kernel/cpu_errata.c
@@@ -666,9 -635,9 +666,13 @@@ has_neoverse_n1_erratum_1542419(const s
  	return is_midr_in_range(midr, &range) && has_dic;
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_HARDEN_EL2_VECTORS
++=======
+ #if defined(CONFIG_HARDEN_EL2_VECTORS)
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  
 -static const struct midr_range ca57_a72[] = {
 +static const struct midr_range arm64_harden_el2_vectors[] = {
  	MIDR_ALL_VERSIONS(MIDR_CORTEX_A57),
  	MIDR_ALL_VERSIONS(MIDR_CORTEX_A72),
  	{},
@@@ -755,6 -730,51 +759,54 @@@ static const struct midr_range erratum_
  };
  #endif
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_ARM64_ERRATUM_845719
+ static const struct midr_range erratum_845719_list[] = {
+ 	/* Cortex-A53 r0p[01234] */
+ 	MIDR_REV_RANGE(MIDR_CORTEX_A53, 0, 0, 4),
+ 	/* Brahma-B53 r0p[0] */
+ 	MIDR_REV(MIDR_BRAHMA_B53, 0, 0),
+ 	{},
+ };
+ #endif
+ 
+ #ifdef CONFIG_ARM64_ERRATUM_843419
+ static const struct arm64_cpu_capabilities erratum_843419_list[] = {
+ 	{
+ 		/* Cortex-A53 r0p[01234] */
+ 		.matches = is_affected_midr_range,
+ 		ERRATA_MIDR_REV_RANGE(MIDR_CORTEX_A53, 0, 0, 4),
+ 		MIDR_FIXED(0x4, BIT(8)),
+ 	},
+ 	{
+ 		/* Brahma-B53 r0p[0] */
+ 		.matches = is_affected_midr_range,
+ 		ERRATA_MIDR_REV(MIDR_BRAHMA_B53, 0, 0),
+ 	},
+ 	{},
+ };
+ #endif
+ 
+ #ifdef CONFIG_ARM64_WORKAROUND_SPECULATIVE_AT
+ static const struct midr_range erratum_speculative_at_list[] = {
+ #ifdef CONFIG_ARM64_ERRATUM_1165522
+ 	/* Cortex A76 r0p0 to r2p0 */
+ 	MIDR_RANGE(MIDR_CORTEX_A76, 0, 0, 2, 0),
+ #endif
+ #ifdef CONFIG_ARM64_ERRATUM_1319367
+ 	MIDR_ALL_VERSIONS(MIDR_CORTEX_A57),
+ 	MIDR_ALL_VERSIONS(MIDR_CORTEX_A72),
+ #endif
+ #ifdef CONFIG_ARM64_ERRATUM_1530923
+ 	/* Cortex A55 r0p0 to r2p0 */
+ 	MIDR_RANGE(MIDR_CORTEX_A55, 0, 0, 2, 0),
+ #endif
+ 	{},
+ };
+ #endif
+ 
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  const struct arm64_cpu_capabilities arm64_errata[] = {
  #ifdef CONFIG_ARM64_WORKAROUND_CLEAN_CACHE
  	{
@@@ -880,12 -901,19 +932,28 @@@
  		ERRATA_MIDR_RANGE_LIST(erratum_1418040_list),
  	},
  #endif
++<<<<<<< HEAD
 +#ifdef CONFIG_ARM64_ERRATUM_1165522
 +	{
 +		/* Cortex-A76 r0p0 to r2p0 */
 +		.desc = "ARM erratum 1165522",
 +		.capability = ARM64_WORKAROUND_1165522,
 +		ERRATA_MIDR_RANGE(MIDR_CORTEX_A76, 0, 0, 2, 0),
++=======
+ #ifdef CONFIG_ARM64_WORKAROUND_SPECULATIVE_AT
+ 	{
+ 		.desc = "ARM errata 1165522, 1319367, 1530923",
+ 		.capability = ARM64_WORKAROUND_SPECULATIVE_AT,
+ 		ERRATA_MIDR_RANGE_LIST(erratum_speculative_at_list),
+ 	},
+ #endif
+ #ifdef CONFIG_ARM64_ERRATUM_1463225
+ 	{
+ 		.desc = "ARM erratum 1463225",
+ 		.capability = ARM64_WORKAROUND_1463225,
+ 		.type = ARM64_CPUCAP_LOCAL_CPU_ERRATUM,
+ 		.matches = has_cortex_a76_erratum_1463225,
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  	},
  #endif
  #ifdef CONFIG_CAVIUM_TX2_ERRATUM_219
diff --cc arch/arm64/kvm/hyp/switch.c
index b617da7815ad,1336e6f0acdf..000000000000
--- a/arch/arm64/kvm/hyp/switch.c
+++ b/arch/arm64/kvm/hyp/switch.c
@@@ -137,7 -138,7 +137,11 @@@ static void __hyp_text __activate_traps
  
  	write_sysreg(val, cptr_el2);
  
++<<<<<<< HEAD
 +	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
++=======
+ 	if (cpus_have_final_cap(ARM64_WORKAROUND_SPECULATIVE_AT)) {
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  		struct kvm_cpu_context *ctxt = &vcpu->arch.ctxt;
  
  		isb();
@@@ -176,11 -177,11 +180,15 @@@ static void deactivate_traps_vhe(void
  	write_sysreg(HCR_HOST_VHE_FLAGS, hcr_el2);
  
  	/*
 -	 * ARM errata 1165522 and 1530923 require the actual execution of the
 -	 * above before we can switch to the EL2/EL0 translation regime used by
 +	 * ARM erratum 1165522 requires the actual execution of the above
 +	 * before we can switch to the EL2/EL0 translation regime used by
  	 * the host.
  	 */
++<<<<<<< HEAD
 +	asm(ALTERNATIVE("nop", "isb", ARM64_WORKAROUND_1165522));
++=======
+ 	asm(ALTERNATIVE("nop", "isb", ARM64_WORKAROUND_SPECULATIVE_AT));
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  
  	write_sysreg(CPACR_EL1_DEFAULT, cpacr_el1);
  	write_sysreg(vectors, vbar_el1);
@@@ -191,7 -192,7 +199,11 @@@ static void __hyp_text __deactivate_tra
  {
  	u64 mdcr_el2 = read_sysreg(mdcr_el2);
  
++<<<<<<< HEAD
 +	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
++=======
+ 	if (cpus_have_final_cap(ARM64_WORKAROUND_SPECULATIVE_AT)) {
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  		u64 val;
  
  		/*
diff --cc arch/arm64/kvm/hyp/sysreg-sr.c
index d60aa78048e4,3234a9dc149f..000000000000
--- a/arch/arm64/kvm/hyp/sysreg-sr.c
+++ b/arch/arm64/kvm/hyp/sysreg-sr.c
@@@ -118,7 -118,8 +118,12 @@@ static void __hyp_text __sysreg_restore
  	write_sysreg(ctxt->sys_regs[MPIDR_EL1],		vmpidr_el2);
  	write_sysreg(ctxt->sys_regs[CSSELR_EL1],	csselr_el1);
  
++<<<<<<< HEAD
 +	if (!cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
++=======
+ 	if (has_vhe() ||
+ 	    !cpus_have_final_cap(ARM64_WORKAROUND_SPECULATIVE_AT)) {
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  		write_sysreg_el1(ctxt->sys_regs[SCTLR_EL1],	SYS_SCTLR);
  		write_sysreg_el1(ctxt->sys_regs[TCR_EL1],	SYS_TCR);
  	} else	if (!ctxt->__hyp_running_vcpu) {
@@@ -149,7 -150,8 +154,12 @@@
  	write_sysreg(ctxt->sys_regs[PAR_EL1],		par_el1);
  	write_sysreg(ctxt->sys_regs[TPIDR_EL1],		tpidr_el1);
  
++<<<<<<< HEAD
 +	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367) &&
++=======
+ 	if (!has_vhe() &&
+ 	    cpus_have_final_cap(ARM64_WORKAROUND_SPECULATIVE_AT) &&
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  	    ctxt->__hyp_running_vcpu) {
  		/*
  		 * Must only be done for host registers, hence the context
diff --cc arch/arm64/kvm/hyp/tlb.c
index e566bc96cab0,d063a576d511..000000000000
--- a/arch/arm64/kvm/hyp/tlb.c
+++ b/arch/arm64/kvm/hyp/tlb.c
@@@ -34,10 -23,10 +34,14 @@@ static void __hyp_text __tlb_switch_to_
  
  	local_irq_save(cxt->flags);
  
++<<<<<<< HEAD
 +	if (cpus_have_const_cap(ARM64_WORKAROUND_1165522)) {
++=======
+ 	if (cpus_have_final_cap(ARM64_WORKAROUND_SPECULATIVE_AT)) {
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  		/*
 -		 * For CPUs that are affected by ARM errata 1165522 or 1530923,
 -		 * we cannot trust stage-1 to be in a correct state at that
 +		 * For CPUs that are affected by ARM erratum 1165522, we
 +		 * cannot trust stage-1 to be in a correct state at that
  		 * point. Since we do not want to force a full load of the
  		 * vcpu state, we prevent the EL1 page-table walker to
  		 * allocate new TLBs. This is done by setting the EPD bits
@@@ -74,7 -63,7 +78,11 @@@
  static void __hyp_text __tlb_switch_to_guest_nvhe(struct kvm *kvm,
  						  struct tlb_inv_context *cxt)
  {
++<<<<<<< HEAD
 +	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
++=======
+ 	if (cpus_have_final_cap(ARM64_WORKAROUND_SPECULATIVE_AT)) {
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  		u64 val;
  
  		/*
@@@ -114,7 -104,7 +123,11 @@@ static void __hyp_text __tlb_switch_to_
  	write_sysreg(HCR_HOST_VHE_FLAGS, hcr_el2);
  	isb();
  
++<<<<<<< HEAD
 +	if (cpus_have_const_cap(ARM64_WORKAROUND_1165522)) {
++=======
+ 	if (cpus_have_final_cap(ARM64_WORKAROUND_SPECULATIVE_AT)) {
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  		/* Restore the registers to what they were */
  		write_sysreg_el1(cxt->tcr, SYS_TCR);
  		write_sysreg_el1(cxt->sctlr, SYS_SCTLR);
@@@ -128,7 -118,7 +141,11 @@@ static void __hyp_text __tlb_switch_to_
  {
  	write_sysreg(0, vttbr_el2);
  
++<<<<<<< HEAD
 +	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
++=======
+ 	if (cpus_have_final_cap(ARM64_WORKAROUND_SPECULATIVE_AT)) {
++>>>>>>> 02ab1f5018c3 (arm64: Unify WORKAROUND_SPECULATIVE_AT_{NVHE,VHE})
  		/* Ensure write of the host VMID */
  		isb();
  		/* Restore the host's TCR_EL1 */
* Unmerged path arch/arm64/Kconfig
* Unmerged path arch/arm64/include/asm/cpucaps.h
* Unmerged path arch/arm64/include/asm/kvm_host.h
* Unmerged path arch/arm64/include/asm/kvm_hyp.h
* Unmerged path arch/arm64/kernel/cpu_errata.c
* Unmerged path arch/arm64/kvm/hyp/switch.c
* Unmerged path arch/arm64/kvm/hyp/sysreg-sr.c
* Unmerged path arch/arm64/kvm/hyp/tlb.c
