xdp: Fix race in dev_map_hash_update_elem() when replacing element

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Toke Høiland-Jørgensen <toke@redhat.com>
commit af58e7ee6a8d83726ad8a2696e98d86400a7639c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/af58e7ee.failed

syzbot found a crash in dev_map_hash_update_elem(), when replacing an
element with a new one. Jesper correctly identified the cause of the crash
as a race condition between the initial lookup in the map (which is done
before taking the lock), and the removal of the old element.

Rather than just add a second lookup into the hashmap after taking the
lock, fix this by reworking the function logic to take the lock before the
initial lookup.

Fixes: 6f9d451ab1a3 ("xdp: Add devmap_hash map type for looking up devices by hashed index")
Reported-and-tested-by: syzbot+4e7a85b1432052e8d6f8@syzkaller.appspotmail.com
	Signed-off-by: Toke Høiland-Jørgensen <toke@redhat.com>
	Acked-by: Jesper Dangaard Brouer <brouer@redhat.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit af58e7ee6a8d83726ad8a2696e98d86400a7639c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/devmap.c
diff --cc kernel/bpf/devmap.c
index cfc445b29247,d27f3b60ff6d..000000000000
--- a/kernel/bpf/devmap.c
+++ b/kernel/bpf/devmap.c
@@@ -510,6 -642,63 +510,66 @@@ static int dev_map_update_elem(struct b
  				     map, key, value, map_flags);
  }
  
++<<<<<<< HEAD
++=======
+ static int __dev_map_hash_update_elem(struct net *net, struct bpf_map *map,
+ 				     void *key, void *value, u64 map_flags)
+ {
+ 	struct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);
+ 	struct bpf_dtab_netdev *dev, *old_dev;
+ 	u32 ifindex = *(u32 *)value;
+ 	u32 idx = *(u32 *)key;
+ 	unsigned long flags;
+ 	int err = -EEXIST;
+ 
+ 	if (unlikely(map_flags > BPF_EXIST || !ifindex))
+ 		return -EINVAL;
+ 
+ 	spin_lock_irqsave(&dtab->index_lock, flags);
+ 
+ 	old_dev = __dev_map_hash_lookup_elem(map, idx);
+ 	if (old_dev && (map_flags & BPF_NOEXIST))
+ 		goto out_err;
+ 
+ 	dev = __dev_map_alloc_node(net, dtab, ifindex, idx);
+ 	if (IS_ERR(dev)) {
+ 		err = PTR_ERR(dev);
+ 		goto out_err;
+ 	}
+ 
+ 	if (old_dev) {
+ 		hlist_del_rcu(&old_dev->index_hlist);
+ 	} else {
+ 		if (dtab->items >= dtab->map.max_entries) {
+ 			spin_unlock_irqrestore(&dtab->index_lock, flags);
+ 			call_rcu(&dev->rcu, __dev_map_entry_free);
+ 			return -E2BIG;
+ 		}
+ 		dtab->items++;
+ 	}
+ 
+ 	hlist_add_head_rcu(&dev->index_hlist,
+ 			   dev_map_index_hash(dtab, idx));
+ 	spin_unlock_irqrestore(&dtab->index_lock, flags);
+ 
+ 	if (old_dev)
+ 		call_rcu(&old_dev->rcu, __dev_map_entry_free);
+ 
+ 	return 0;
+ 
+ out_err:
+ 	spin_unlock_irqrestore(&dtab->index_lock, flags);
+ 	return err;
+ }
+ 
+ static int dev_map_hash_update_elem(struct bpf_map *map, void *key, void *value,
+ 				   u64 map_flags)
+ {
+ 	return __dev_map_hash_update_elem(current->nsproxy->net_ns,
+ 					 map, key, value, map_flags);
+ }
+ 
++>>>>>>> af58e7ee6a8d (xdp: Fix race in dev_map_hash_update_elem() when replacing element)
  const struct bpf_map_ops dev_map_ops = {
  	.map_alloc = dev_map_alloc,
  	.map_free = dev_map_free,
* Unmerged path kernel/bpf/devmap.c
