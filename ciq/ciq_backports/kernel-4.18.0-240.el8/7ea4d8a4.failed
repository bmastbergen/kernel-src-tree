blk-mq: move more request initialization to blk_mq_rq_ctx_init

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 7ea4d8a4d683298abd346abf89567774de2fa34a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/7ea4d8a4.failed

Don't split request initialization between __blk_mq_alloc_request and
blk_mq_rq_ctx_init.  Also remove the op argument as it can be derived
from the blk_mq_alloc_data structure.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Ming Lei <ming.lei@redhat.com>
	Reviewed-by: Hannes Reinecke <hare@suse.de>
	Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
	Reviewed-by: Bart Van Assche <bvanassche@acm.org>
	Reviewed-by: Daniel Wagner <dwagner@suse.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 7ea4d8a4d683298abd346abf89567774de2fa34a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index f3fc03aa9f37,b20ad88d2d70..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -269,7 -271,7 +269,11 @@@ static inline bool blk_mq_need_time_sta
  }
  
  static struct request *blk_mq_rq_ctx_init(struct blk_mq_alloc_data *data,
++<<<<<<< HEAD
 +		unsigned int tag, unsigned int op)
++=======
+ 		unsigned int tag, u64 alloc_time_ns)
++>>>>>>> 7ea4d8a4d683 (blk-mq: move more request initialization to blk_mq_rq_ctx_init)
  {
  	struct blk_mq_tags *tags = blk_mq_tags_from_data(data);
  	struct request *rq = tags->static_rqs[tag];
@@@ -327,17 -347,18 +346,16 @@@
  	return rq;
  }
  
 -static struct request *__blk_mq_alloc_request(struct blk_mq_alloc_data *data)
 +static struct request *blk_mq_get_request(struct request_queue *q,
 +					  struct bio *bio,
 +					  struct blk_mq_alloc_data *data)
  {
 -	struct request_queue *q = data->q;
  	struct elevator_queue *e = q->elevator;
- 	struct request *rq;
  	unsigned int tag;
  	bool clear_ctx_on_error = false;
 -	u64 alloc_time_ns = 0;
 -
 -	/* alloc_time includes depth and tag waits */
 -	if (blk_queue_rq_alloc_time(q))
 -		alloc_time_ns = ktime_get_ns();
  
 +	blk_queue_enter_live(q);
 +	data->q = q;
  	if (likely(!data->ctx)) {
  		data->ctx = blk_mq_get_ctx(q);
  		clear_ctx_on_error = true;
@@@ -372,19 -392,7 +390,23 @@@
  		return NULL;
  	}
  
++<<<<<<< HEAD
 +	rq = blk_mq_rq_ctx_init(data, tag, data->cmd_flags);
 +	if (!op_is_flush(data->cmd_flags)) {
 +		rq->elv.icq = NULL;
 +		if (e && e->type->ops.prepare_request) {
 +			if (e->type->icq_cache)
 +				blk_mq_sched_assign_ioc(rq);
 +
 +			e->type->ops.prepare_request(rq, bio);
 +			rq->rq_flags |= RQF_ELVPRIV;
 +		}
 +	}
 +	data->hctx->queued++;
 +	return rq;
++=======
+ 	return blk_mq_rq_ctx_init(data, tag, alloc_time_ns);
++>>>>>>> 7ea4d8a4d683 (blk-mq: move more request initialization to blk_mq_rq_ctx_init)
  }
  
  struct request *blk_mq_alloc_request(struct request_queue *q, unsigned int op,
* Unmerged path block/blk-mq.c
