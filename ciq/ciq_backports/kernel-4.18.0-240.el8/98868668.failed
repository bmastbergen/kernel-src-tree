bpf: Abstract away entire bpf_link clean up procedure

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Andrii Nakryiko <andriin@fb.com>
commit 98868668367b24487c0b0b3298d7ca98409baf07
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/98868668.failed

Instead of requiring users to do three steps for cleaning up bpf_link, its
anon_inode file, and unused fd, abstract that away into bpf_link_cleanup()
helper. bpf_link_defunct() is removed, as it shouldn't be needed as an
individual operation anymore.

v1->v2:
- keep bpf_link_cleanup() static for now (Daniel).

	Signed-off-by: Andrii Nakryiko <andriin@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Martin KaFai Lau <kafai@fb.com>
Link: https://lore.kernel.org/bpf/20200313002128.2028680-1-andriin@fb.com
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
(cherry picked from commit 98868668367b24487c0b0b3298d7ca98409baf07)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	kernel/bpf/syscall.c
diff --cc include/linux/bpf.h
index c1c99fdb999a,c2f815e9f7d0..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -734,6 -1066,21 +734,24 @@@ extern int sysctl_unprivileged_bpf_disa
  int bpf_map_new_fd(struct bpf_map *map, int flags);
  int bpf_prog_new_fd(struct bpf_prog *prog);
  
++<<<<<<< HEAD
++=======
+ struct bpf_link;
+ 
+ struct bpf_link_ops {
+ 	void (*release)(struct bpf_link *link);
+ 	void (*dealloc)(struct bpf_link *link);
+ };
+ 
+ void bpf_link_init(struct bpf_link *link, const struct bpf_link_ops *ops,
+ 		   struct bpf_prog *prog);
+ void bpf_link_inc(struct bpf_link *link);
+ void bpf_link_put(struct bpf_link *link);
+ int bpf_link_new_fd(struct bpf_link *link);
+ struct file *bpf_link_new_file(struct bpf_link *link, int *reserved_fd);
+ struct bpf_link *bpf_link_get_from_fd(u32 ufd);
+ 
++>>>>>>> 98868668367b (bpf: Abstract away entire bpf_link clean up procedure)
  int bpf_obj_pin_user(u32 ufd, const char __user *pathname);
  int bpf_obj_get_user(const char __user *pathname, int flags);
  
diff --cc kernel/bpf/syscall.c
index b5b79e59cfd4,85567a6ea5f9..000000000000
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@@ -1855,21 -2173,79 +1855,49 @@@ static int bpf_obj_get(const union bpf_
  				attr->file_flags);
  }
  
 -struct bpf_link {
 -	atomic64_t refcnt;
 -	const struct bpf_link_ops *ops;
 +struct bpf_raw_tracepoint {
 +	struct bpf_raw_event_map *btp;
  	struct bpf_prog *prog;
 -	struct work_struct work;
  };
  
 -void bpf_link_init(struct bpf_link *link, const struct bpf_link_ops *ops,
 -		   struct bpf_prog *prog)
 +static int bpf_raw_tracepoint_release(struct inode *inode, struct file *filp)
  {
 -	atomic64_set(&link->refcnt, 1);
 -	link->ops = ops;
 -	link->prog = prog;
 -}
 +	struct bpf_raw_tracepoint *raw_tp = filp->private_data;
  
++<<<<<<< HEAD
 +	if (raw_tp->prog) {
 +		bpf_probe_unregister(raw_tp->btp, raw_tp->prog);
 +		bpf_prog_put(raw_tp->prog);
++=======
+ /* Clean up bpf_link and corresponding anon_inode file and FD. After
+  * anon_inode is created, bpf_link can't be just kfree()'d due to deferred
+  * anon_inode's release() call. This helper manages marking bpf_link as
+  * defunct, releases anon_inode file and puts reserved FD.
+  */
+ static void bpf_link_cleanup(struct bpf_link *link, struct file *link_file,
+ 			     int link_fd)
+ {
+ 	link->prog = NULL;
+ 	fput(link_file);
+ 	put_unused_fd(link_fd);
+ }
+ 
+ void bpf_link_inc(struct bpf_link *link)
+ {
+ 	atomic64_inc(&link->refcnt);
+ }
+ 
+ /* bpf_link_free is guaranteed to be called from process context */
+ static void bpf_link_free(struct bpf_link *link)
+ {
+ 	if (link->prog) {
+ 		/* detach BPF program, clean up used resources */
+ 		link->ops->release(link);
+ 		bpf_prog_put(link->prog);
++>>>>>>> 98868668367b (bpf: Abstract away entire bpf_link clean up procedure)
  	}
 -	/* free bpf_link and its containing memory */
 -	link->ops->dealloc(link);
 -}
 -
 -static void bpf_link_put_deferred(struct work_struct *work)
 -{
 -	struct bpf_link *link = container_of(work, struct bpf_link, work);
 -
 -	bpf_link_free(link);
 -}
 -
 -/* bpf_link_put can be called from atomic context, but ensures that resources
 - * are freed from process context
 - */
 -void bpf_link_put(struct bpf_link *link)
 -{
 -	if (!atomic64_dec_and_test(&link->refcnt))
 -		return;
 -
 -	if (in_atomic()) {
 -		INIT_WORK(&link->work, bpf_link_put_deferred);
 -		schedule_work(&link->work);
 -	} else {
 -		bpf_link_free(link);
 -	}
 -}
 -
 -static int bpf_link_release(struct inode *inode, struct file *filp)
 -{
 -	struct bpf_link *link = filp->private_data;
 -
 -	bpf_link_put(link);
 +	bpf_put_raw_tracepoint(raw_tp->btp);
 +	kfree(raw_tp);
  	return 0;
  }
  
@@@ -1879,6 -2288,148 +1907,151 @@@ static const struct file_operations bpf
  	.write		= bpf_dummy_write,
  };
  
++<<<<<<< HEAD
++=======
+ int bpf_link_new_fd(struct bpf_link *link)
+ {
+ 	return anon_inode_getfd("bpf-link", &bpf_link_fops, link, O_CLOEXEC);
+ }
+ 
+ /* Similar to bpf_link_new_fd, create anon_inode for given bpf_link, but
+  * instead of immediately installing fd in fdtable, just reserve it and
+  * return. Caller then need to either install it with fd_install(fd, file) or
+  * release with put_unused_fd(fd).
+  * This is useful for cases when bpf_link attachment/detachment are
+  * complicated and expensive operations and should be delayed until all the fd
+  * reservation and anon_inode creation succeeds.
+  */
+ struct file *bpf_link_new_file(struct bpf_link *link, int *reserved_fd)
+ {
+ 	struct file *file;
+ 	int fd;
+ 
+ 	fd = get_unused_fd_flags(O_CLOEXEC);
+ 	if (fd < 0)
+ 		return ERR_PTR(fd);
+ 
+ 	file = anon_inode_getfile("bpf_link", &bpf_link_fops, link, O_CLOEXEC);
+ 	if (IS_ERR(file)) {
+ 		put_unused_fd(fd);
+ 		return file;
+ 	}
+ 
+ 	*reserved_fd = fd;
+ 	return file;
+ }
+ 
+ struct bpf_link *bpf_link_get_from_fd(u32 ufd)
+ {
+ 	struct fd f = fdget(ufd);
+ 	struct bpf_link *link;
+ 
+ 	if (!f.file)
+ 		return ERR_PTR(-EBADF);
+ 	if (f.file->f_op != &bpf_link_fops) {
+ 		fdput(f);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	link = f.file->private_data;
+ 	bpf_link_inc(link);
+ 	fdput(f);
+ 
+ 	return link;
+ }
+ 
+ struct bpf_tracing_link {
+ 	struct bpf_link link;
+ };
+ 
+ static void bpf_tracing_link_release(struct bpf_link *link)
+ {
+ 	WARN_ON_ONCE(bpf_trampoline_unlink_prog(link->prog));
+ }
+ 
+ static void bpf_tracing_link_dealloc(struct bpf_link *link)
+ {
+ 	struct bpf_tracing_link *tr_link =
+ 		container_of(link, struct bpf_tracing_link, link);
+ 
+ 	kfree(tr_link);
+ }
+ 
+ static const struct bpf_link_ops bpf_tracing_link_lops = {
+ 	.release = bpf_tracing_link_release,
+ 	.dealloc = bpf_tracing_link_dealloc,
+ };
+ 
+ static int bpf_tracing_prog_attach(struct bpf_prog *prog)
+ {
+ 	struct bpf_tracing_link *link;
+ 	struct file *link_file;
+ 	int link_fd, err;
+ 
+ 	if (prog->expected_attach_type != BPF_TRACE_FENTRY &&
+ 	    prog->expected_attach_type != BPF_TRACE_FEXIT &&
+ 	    prog->expected_attach_type != BPF_MODIFY_RETURN &&
+ 	    prog->type != BPF_PROG_TYPE_EXT) {
+ 		err = -EINVAL;
+ 		goto out_put_prog;
+ 	}
+ 
+ 	link = kzalloc(sizeof(*link), GFP_USER);
+ 	if (!link) {
+ 		err = -ENOMEM;
+ 		goto out_put_prog;
+ 	}
+ 	bpf_link_init(&link->link, &bpf_tracing_link_lops, prog);
+ 
+ 	link_file = bpf_link_new_file(&link->link, &link_fd);
+ 	if (IS_ERR(link_file)) {
+ 		kfree(link);
+ 		err = PTR_ERR(link_file);
+ 		goto out_put_prog;
+ 	}
+ 
+ 	err = bpf_trampoline_link_prog(prog);
+ 	if (err) {
+ 		bpf_link_cleanup(&link->link, link_file, link_fd);
+ 		goto out_put_prog;
+ 	}
+ 
+ 	fd_install(link_fd, link_file);
+ 	return link_fd;
+ 
+ out_put_prog:
+ 	bpf_prog_put(prog);
+ 	return err;
+ }
+ 
+ struct bpf_raw_tp_link {
+ 	struct bpf_link link;
+ 	struct bpf_raw_event_map *btp;
+ };
+ 
+ static void bpf_raw_tp_link_release(struct bpf_link *link)
+ {
+ 	struct bpf_raw_tp_link *raw_tp =
+ 		container_of(link, struct bpf_raw_tp_link, link);
+ 
+ 	bpf_probe_unregister(raw_tp->btp, raw_tp->link.prog);
+ 	bpf_put_raw_tracepoint(raw_tp->btp);
+ }
+ 
+ static void bpf_raw_tp_link_dealloc(struct bpf_link *link)
+ {
+ 	struct bpf_raw_tp_link *raw_tp =
+ 		container_of(link, struct bpf_raw_tp_link, link);
+ 
+ 	kfree(raw_tp);
+ }
+ 
+ static const struct bpf_link_ops bpf_raw_tp_lops = {
+ 	.release = bpf_raw_tp_link_release,
+ 	.dealloc = bpf_raw_tp_link_dealloc,
+ };
+ 
++>>>>>>> 98868668367b (bpf: Abstract away entire bpf_link clean up procedure)
  #define BPF_RAW_TRACEPOINT_OPEN_LAST_FIELD raw_tracepoint.prog_fd
  
  static int bpf_raw_tracepoint_open(const union bpf_attr *attr)
@@@ -1918,26 -2457,64 +2091,55 @@@
  		goto out_put_prog;
  	}
  
 -	if (prog->type == BPF_PROG_TYPE_TRACING ||
 -	    prog->type == BPF_PROG_TYPE_EXT) {
 -		if (attr->raw_tracepoint.name) {
 -			/* The attach point for this category of programs
 -			 * should be specified via btf_id during program load.
 -			 */
 -			err = -EINVAL;
 -			goto out_put_prog;
 -		}
 -		if (prog->expected_attach_type == BPF_TRACE_RAW_TP)
 -			tp_name = prog->aux->attach_func_name;
 -		else
 -			return bpf_tracing_prog_attach(prog);
 -	} else {
 -		if (strncpy_from_user(buf,
 -				      u64_to_user_ptr(attr->raw_tracepoint.name),
 -				      sizeof(buf) - 1) < 0) {
 -			err = -EFAULT;
 -			goto out_put_prog;
 -		}
 -		buf[sizeof(buf) - 1] = 0;
 -		tp_name = buf;
 -	}
 +	err = bpf_probe_register(raw_tp->btp, prog);
 +	if (err)
 +		goto out_put_prog;
  
 -	btp = bpf_get_raw_tracepoint(tp_name);
 -	if (!btp) {
 -		err = -ENOENT;
 +	raw_tp->prog = prog;
 +	tp_fd = anon_inode_getfd("bpf-raw-tracepoint", &bpf_raw_tp_fops, raw_tp,
 +				 O_CLOEXEC);
 +	if (tp_fd < 0) {
 +		bpf_probe_unregister(raw_tp->btp, prog);
 +		err = tp_fd;
  		goto out_put_prog;
  	}
 +	return tp_fd;
  
++<<<<<<< HEAD
++=======
+ 	link = kzalloc(sizeof(*link), GFP_USER);
+ 	if (!link) {
+ 		err = -ENOMEM;
+ 		goto out_put_btp;
+ 	}
+ 	bpf_link_init(&link->link, &bpf_raw_tp_lops, prog);
+ 	link->btp = btp;
+ 
+ 	link_file = bpf_link_new_file(&link->link, &link_fd);
+ 	if (IS_ERR(link_file)) {
+ 		kfree(link);
+ 		err = PTR_ERR(link_file);
+ 		goto out_put_btp;
+ 	}
+ 
+ 	err = bpf_probe_register(link->btp, prog);
+ 	if (err) {
+ 		bpf_link_cleanup(&link->link, link_file, link_fd);
+ 		goto out_put_btp;
+ 	}
+ 
+ 	fd_install(link_fd, link_file);
+ 	return link_fd;
+ 
+ out_put_btp:
+ 	bpf_put_raw_tracepoint(btp);
++>>>>>>> 98868668367b (bpf: Abstract away entire bpf_link clean up procedure)
  out_put_prog:
  	bpf_prog_put(prog);
 +out_free_tp:
 +	kfree(raw_tp);
 +out_put_btp:
 +	bpf_put_raw_tracepoint(btp);
  	return err;
  }
  
* Unmerged path include/linux/bpf.h
* Unmerged path kernel/bpf/syscall.c
