locking/percpu-rwsem: Extract __percpu_down_read_trylock()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Peter Zijlstra <peterz@infradead.org>
commit 75ff64572e497578e238fefbdff221c96f29067a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/75ff6457.failed

In preparation for removing the embedded rwsem and building a custom
lock, extract the read-trylock primitive.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
	Reviewed-by: Davidlohr Bueso <dbueso@suse.de>
	Acked-by: Will Deacon <will@kernel.org>
	Acked-by: Waiman Long <longman@redhat.com>
	Tested-by: Juri Lelli <juri.lelli@redhat.com>
Link: https://lkml.kernel.org/r/20200131151540.098485539@infradead.org
(cherry picked from commit 75ff64572e497578e238fefbdff221c96f29067a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/locking/percpu-rwsem.c
diff --cc kernel/locking/percpu-rwsem.c
index eb5134b6ac21,b155e8e7ac39..000000000000
--- a/kernel/locking/percpu-rwsem.c
+++ b/kernel/locking/percpu-rwsem.c
@@@ -40,7 -45,7 +40,11 @@@ void percpu_free_rwsem(struct percpu_rw
  }
  EXPORT_SYMBOL_GPL(percpu_free_rwsem);
  
++<<<<<<< HEAD
 +int __percpu_down_read(struct percpu_rw_semaphore *sem, int try)
++=======
+ static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)
++>>>>>>> 75ff64572e49 (locking/percpu-rwsem: Extract __percpu_down_read_trylock())
  {
  	__this_cpu_inc(*sem->read_count);
  
@@@ -66,16 -71,23 +70,23 @@@
  	 * release in percpu_up_write().
  	 */
  	if (likely(!smp_load_acquire(&sem->readers_block)))
 -		return true;
 +		return 1;
  
- 	/*
- 	 * Per the above comment; we still have preemption disabled and
- 	 * will thus decrement on the same CPU as we incremented.
- 	 */
- 	__percpu_up_read(sem);
+ 	__this_cpu_dec(*sem->read_count);
+ 
+ 	/* Prod writer to re-evaluate readers_active_check() */
+ 	rcuwait_wake_up(&sem->writer);
+ 
+ 	return false;
+ }
+ 
+ bool __percpu_down_read(struct percpu_rw_semaphore *sem, bool try)
+ {
+ 	if (__percpu_down_read_trylock(sem))
+ 		return true;
  
  	if (try)
 -		return false;
 +		return 0;
  
  	/*
  	 * We either call schedule() in the wait, or we'll fall through
* Unmerged path kernel/locking/percpu-rwsem.c
