bpf: Implement bpf_link-based cgroup BPF program attachment

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Andrii Nakryiko <andriin@fb.com>
commit af6eea57437a830293eab56246b6025cc7d46ee7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/af6eea57.failed

Implement new sub-command to attach cgroup BPF programs and return FD-based
bpf_link back on success. bpf_link, once attached to cgroup, cannot be
replaced, except by owner having its FD. Cgroup bpf_link supports only
BPF_F_ALLOW_MULTI semantics. Both link-based and prog-based BPF_F_ALLOW_MULTI
attachments can be freely intermixed.

To prevent bpf_cgroup_link from keeping cgroup alive past the point when no
BPF program can be executed, implement auto-detachment of link. When
cgroup_bpf_release() is called, all attached bpf_links are forced to release
cgroup refcounts, but they leave bpf_link otherwise active and allocated, as
well as still owning underlying bpf_prog. This is because user-space might
still have FDs open and active, so bpf_link as a user-referenced object can't
be freed yet. Once last active FD is closed, bpf_link will be freed and
underlying bpf_prog refcount will be dropped. But cgroup refcount won't be
touched, because cgroup is released already.

The inherent race between bpf_cgroup_link release (from closing last FD) and
cgroup_bpf_release() is resolved by both operations taking cgroup_mutex. So
the only additional check required is when bpf_cgroup_link attempts to detach
itself from cgroup. At that time we need to check whether there is still
cgroup associated with that link. And if not, exit with success, because
bpf_cgroup_link was already successfully detached.

	Signed-off-by: Andrii Nakryiko <andriin@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Roman Gushchin <guro@fb.com>
Link: https://lore.kernel.org/bpf/20200330030001.2312810-2-andriin@fb.com
(cherry picked from commit af6eea57437a830293eab56246b6025cc7d46ee7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf-cgroup.h
#	include/linux/bpf.h
#	include/uapi/linux/bpf.h
#	kernel/bpf/cgroup.c
#	kernel/bpf/syscall.c
#	kernel/cgroup/cgroup.c
#	tools/include/uapi/linux/bpf.h
diff --cc include/linux/bpf-cgroup.h
index 63c168a1495a,d2d969669564..000000000000
--- a/include/linux/bpf-cgroup.h
+++ b/include/linux/bpf-cgroup.h
@@@ -116,18 -93,23 +125,32 @@@ struct cgroup_bpf 
  int cgroup_bpf_inherit(struct cgroup *cgrp);
  void cgroup_bpf_offline(struct cgroup *cgrp);
  
++<<<<<<< HEAD
 +int __cgroup_bpf_attach(struct cgroup *cgrp, struct bpf_prog *prog,
++=======
+ int __cgroup_bpf_attach(struct cgroup *cgrp,
+ 			struct bpf_prog *prog, struct bpf_prog *replace_prog,
+ 			struct bpf_cgroup_link *link,
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  			enum bpf_attach_type type, u32 flags);
  int __cgroup_bpf_detach(struct cgroup *cgrp, struct bpf_prog *prog,
+ 			struct bpf_cgroup_link *link,
  			enum bpf_attach_type type);
  int __cgroup_bpf_query(struct cgroup *cgrp, const union bpf_attr *attr,
  		       union bpf_attr __user *uattr);
  
  /* Wrapper for __cgroup_bpf_*() protected by cgroup_mutex */
++<<<<<<< HEAD
 +int cgroup_bpf_attach(struct cgroup *cgrp, struct bpf_prog *prog,
 +		      enum bpf_attach_type type, u32 flags);
++=======
+ int cgroup_bpf_attach(struct cgroup *cgrp,
+ 		      struct bpf_prog *prog, struct bpf_prog *replace_prog,
+ 		      struct bpf_cgroup_link *link, enum bpf_attach_type type,
+ 		      u32 flags);
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  int cgroup_bpf_detach(struct cgroup *cgrp, struct bpf_prog *prog,
- 		      enum bpf_attach_type type, u32 flags);
+ 		      enum bpf_attach_type type);
  int cgroup_bpf_query(struct cgroup *cgrp, const union bpf_attr *attr,
  		     union bpf_attr __user *uattr);
  
diff --cc include/linux/bpf.h
index c1c99fdb999a,56254d880293..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -734,6 -1082,29 +734,32 @@@ extern int sysctl_unprivileged_bpf_disa
  int bpf_map_new_fd(struct bpf_map *map, int flags);
  int bpf_prog_new_fd(struct bpf_prog *prog);
  
++<<<<<<< HEAD
++=======
+ struct bpf_link {
+ 	atomic64_t refcnt;
+ 	const struct bpf_link_ops *ops;
+ 	struct bpf_prog *prog;
+ 	struct work_struct work;
+ };
+ 
+ struct bpf_link_ops {
+ 	void (*release)(struct bpf_link *link);
+ 	void (*dealloc)(struct bpf_link *link);
+ 
+ };
+ 
+ void bpf_link_init(struct bpf_link *link, const struct bpf_link_ops *ops,
+ 		   struct bpf_prog *prog);
+ void bpf_link_cleanup(struct bpf_link *link, struct file *link_file,
+ 		      int link_fd);
+ void bpf_link_inc(struct bpf_link *link);
+ void bpf_link_put(struct bpf_link *link);
+ int bpf_link_new_fd(struct bpf_link *link);
+ struct file *bpf_link_new_file(struct bpf_link *link, int *reserved_fd);
+ struct bpf_link *bpf_link_get_from_fd(u32 ufd);
+ 
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  int bpf_obj_pin_user(u32 ufd, const char __user *pathname);
  int bpf_obj_get_user(const char __user *pathname, int flags);
  
diff --cc include/uapi/linux/bpf.h
index c9871d53e313,37dffe5089a0..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -107,6 -107,11 +107,14 @@@ enum bpf_cmd 
  	BPF_MAP_LOOKUP_AND_DELETE_ELEM,
  	BPF_MAP_FREEZE,
  	BPF_BTF_GET_NEXT_ID,
++<<<<<<< HEAD
++=======
+ 	BPF_MAP_LOOKUP_BATCH,
+ 	BPF_MAP_LOOKUP_AND_DELETE_BATCH,
+ 	BPF_MAP_UPDATE_BATCH,
+ 	BPF_MAP_DELETE_BATCH,
+ 	BPF_LINK_CREATE,
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  };
  
  enum bpf_map_type {
diff --cc kernel/bpf/cgroup.c
index 5b8da1ceafe3,c24029937431..000000000000
--- a/kernel/bpf/cgroup.c
+++ b/kernel/bpf/cgroup.c
@@@ -33,6 -28,69 +33,72 @@@ void cgroup_bpf_offline(struct cgroup *
  	percpu_ref_kill(&cgrp->bpf.refcnt);
  }
  
++<<<<<<< HEAD
++=======
+ static void bpf_cgroup_storages_free(struct bpf_cgroup_storage *storages[])
+ {
+ 	enum bpf_cgroup_storage_type stype;
+ 
+ 	for_each_cgroup_storage_type(stype)
+ 		bpf_cgroup_storage_free(storages[stype]);
+ }
+ 
+ static int bpf_cgroup_storages_alloc(struct bpf_cgroup_storage *storages[],
+ 				     struct bpf_prog *prog)
+ {
+ 	enum bpf_cgroup_storage_type stype;
+ 
+ 	for_each_cgroup_storage_type(stype) {
+ 		storages[stype] = bpf_cgroup_storage_alloc(prog, stype);
+ 		if (IS_ERR(storages[stype])) {
+ 			storages[stype] = NULL;
+ 			bpf_cgroup_storages_free(storages);
+ 			return -ENOMEM;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void bpf_cgroup_storages_assign(struct bpf_cgroup_storage *dst[],
+ 				       struct bpf_cgroup_storage *src[])
+ {
+ 	enum bpf_cgroup_storage_type stype;
+ 
+ 	for_each_cgroup_storage_type(stype)
+ 		dst[stype] = src[stype];
+ }
+ 
+ static void bpf_cgroup_storages_link(struct bpf_cgroup_storage *storages[],
+ 				     struct cgroup* cgrp,
+ 				     enum bpf_attach_type attach_type)
+ {
+ 	enum bpf_cgroup_storage_type stype;
+ 
+ 	for_each_cgroup_storage_type(stype)
+ 		bpf_cgroup_storage_link(storages[stype], cgrp, attach_type);
+ }
+ 
+ static void bpf_cgroup_storages_unlink(struct bpf_cgroup_storage *storages[])
+ {
+ 	enum bpf_cgroup_storage_type stype;
+ 
+ 	for_each_cgroup_storage_type(stype)
+ 		bpf_cgroup_storage_unlink(storages[stype]);
+ }
+ 
+ /* Called when bpf_cgroup_link is auto-detached from dying cgroup.
+  * It drops cgroup and bpf_prog refcounts, and marks bpf_link as defunct. It
+  * doesn't free link memory, which will eventually be done by bpf_link's
+  * release() callback, when its last FD is closed.
+  */
+ static void bpf_cgroup_link_auto_detach(struct bpf_cgroup_link *link)
+ {
+ 	cgroup_put(link->cgroup);
+ 	link->cgroup = NULL;
+ }
+ 
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  /**
   * cgroup_bpf_release() - put references of all bpf programs and
   *                        release all cgroup bpf data
@@@ -54,11 -111,12 +120,20 @@@ static void cgroup_bpf_release(struct w
  
  		list_for_each_entry_safe(pl, tmp, progs, node) {
  			list_del(&pl->node);
++<<<<<<< HEAD
 +			bpf_prog_put(pl->prog);
 +			for_each_cgroup_storage_type(stype) {
 +				bpf_cgroup_storage_unlink(pl->storage[stype]);
 +				bpf_cgroup_storage_free(pl->storage[stype]);
 +			}
++=======
+ 			if (pl->prog)
+ 				bpf_prog_put(pl->prog);
+ 			if (pl->link)
+ 				bpf_cgroup_link_auto_detach(pl->link);
+ 			bpf_cgroup_storages_unlink(pl->storage);
+ 			bpf_cgroup_storages_free(pl->storage);
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  			kfree(pl);
  			static_branch_dec(&cgroup_bpf_enabled_key);
  		}
@@@ -168,13 -238,13 +255,20 @@@ static int compute_effective_progs(stru
  			continue;
  
  		list_for_each_entry(pl, &p->bpf.progs[type], node) {
- 			if (!pl->prog)
+ 			if (!prog_list_prog(pl))
  				continue;
  
++<<<<<<< HEAD
 +			progs->items[cnt].prog = pl->prog;
 +			for_each_cgroup_storage_type(stype)
 +				progs->items[cnt].cgroup_storage[stype] =
 +					pl->storage[stype];
++=======
+ 			item = &progs->items[cnt];
+ 			item->prog = prog_list_prog(pl);
+ 			bpf_cgroup_storages_assign(item->cgroup_storage,
+ 						   pl->storage);
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  			cnt++;
  		}
  	} while ((p = cgroup_parent(p)));
@@@ -297,26 -402,37 +429,50 @@@ static struct bpf_prog_list *find_attac
   *                         propagate the change to descendants
   * @cgrp: The cgroup which descendants to traverse
   * @prog: A program to attach
++<<<<<<< HEAD
++=======
+  * @link: A link to attach
+  * @replace_prog: Previously attached program to replace if BPF_F_REPLACE is set
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
   * @type: Type of attach operation
   * @flags: Option flags
   *
+  * Exactly one of @prog or @link can be non-null.
   * Must be called with cgroup_mutex held.
   */
++<<<<<<< HEAD
 +int __cgroup_bpf_attach(struct cgroup *cgrp, struct bpf_prog *prog,
++=======
+ int __cgroup_bpf_attach(struct cgroup *cgrp,
+ 			struct bpf_prog *prog, struct bpf_prog *replace_prog,
+ 			struct bpf_cgroup_link *link,
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  			enum bpf_attach_type type, u32 flags)
  {
 -	u32 saved_flags = (flags & (BPF_F_ALLOW_OVERRIDE | BPF_F_ALLOW_MULTI));
  	struct list_head *progs = &cgrp->bpf.progs[type];
  	struct bpf_prog *old_prog = NULL;
++<<<<<<< HEAD
 +	struct bpf_cgroup_storage *storage[MAX_BPF_CGROUP_STORAGE_TYPE] = {};
 +	struct bpf_cgroup_storage *old_storage[MAX_BPF_CGROUP_STORAGE_TYPE] = {};
 +	struct bpf_prog_list *pl, *replace_pl = NULL;
 +	enum bpf_cgroup_storage_type stype;
++=======
+ 	struct bpf_cgroup_storage *storage[MAX_BPF_CGROUP_STORAGE_TYPE],
+ 		*old_storage[MAX_BPF_CGROUP_STORAGE_TYPE] = {NULL};
+ 	struct bpf_prog_list *pl;
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  	int err;
  
 -	if (((flags & BPF_F_ALLOW_OVERRIDE) && (flags & BPF_F_ALLOW_MULTI)) ||
 -	    ((flags & BPF_F_REPLACE) && !(flags & BPF_F_ALLOW_MULTI)))
 +	BUILD_BUG_ON(RH_MAX_BPF_ATTACH_TYPE < MAX_BPF_ATTACH_TYPE);
 +	if ((flags & BPF_F_ALLOW_OVERRIDE) && (flags & BPF_F_ALLOW_MULTI))
  		/* invalid combination */
  		return -EINVAL;
+ 	if (link && (prog || replace_prog))
+ 		/* only either link or prog/replace_prog can be specified */
+ 		return -EINVAL;
+ 	if (!!replace_prog != !!(flags & BPF_F_REPLACE))
+ 		/* replace_prog implies BPF_F_REPLACE, and vice versa */
+ 		return -EINVAL;
  
  	if (!hierarchy_allows_attach(cgrp, type))
  		return -EPERM;
@@@ -331,33 -447,18 +487,42 @@@
  	if (prog_list_length(progs) >= BPF_CGROUP_MAX_PROGS)
  		return -E2BIG;
  
++<<<<<<< HEAD
 +	if (flags & BPF_F_ALLOW_MULTI) {
 +		list_for_each_entry(pl, progs, node) {
 +			if (pl->prog == prog)
 +				/* disallow attaching the same prog twice */
 +				return -EINVAL;
 +		}
 +	} else if (!list_empty(progs)) {
 +		replace_pl = list_first_entry(progs, typeof(*pl), node);
 +	}
 +
 +	for_each_cgroup_storage_type(stype) {
 +		storage[stype] = bpf_cgroup_storage_alloc(prog, stype);
 +		if (IS_ERR(storage[stype])) {
 +			storage[stype] = NULL;
 +			for_each_cgroup_storage_type(stype)
 +				bpf_cgroup_storage_free(storage[stype]);
 +			return -ENOMEM;
 +		}
 +	}
++=======
+ 	pl = find_attach_entry(progs, prog, link, replace_prog,
+ 			       flags & BPF_F_ALLOW_MULTI);
+ 	if (IS_ERR(pl))
+ 		return PTR_ERR(pl);
+ 
+ 	if (bpf_cgroup_storages_alloc(storage, prog ? : link->link.prog))
+ 		return -ENOMEM;
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  
- 	if (replace_pl) {
- 		pl = replace_pl;
+ 	if (pl) {
  		old_prog = pl->prog;
 -		bpf_cgroup_storages_unlink(pl->storage);
 -		bpf_cgroup_storages_assign(old_storage, pl->storage);
 +		for_each_cgroup_storage_type(stype) {
 +			old_storage[stype] = pl->storage[stype];
 +			bpf_cgroup_storage_unlink(old_storage[stype]);
 +		}
  	} else {
  		pl = kmalloc(sizeof(*pl), GFP_KERNEL);
  		if (!pl) {
@@@ -369,38 -469,31 +534,64 @@@
  	}
  
  	pl->prog = prog;
++<<<<<<< HEAD
 +	for_each_cgroup_storage_type(stype)
 +		pl->storage[stype] = storage[stype];
 +
 +	cgrp->bpf.flags[type] = flags;
++=======
+ 	pl->link = link;
+ 	bpf_cgroup_storages_assign(pl->storage, storage);
+ 	cgrp->bpf.flags[type] = saved_flags;
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  
  	err = update_effective_progs(cgrp, type);
  	if (err)
  		goto cleanup;
  
++<<<<<<< HEAD
 +	static_branch_inc(&cgroup_bpf_enabled_key);
 +	for_each_cgroup_storage_type(stype) {
 +		if (!old_storage[stype])
 +			continue;
 +		bpf_cgroup_storage_free(old_storage[stype]);
 +	}
 +	if (old_prog) {
 +		bpf_prog_put(old_prog);
 +		static_branch_dec(&cgroup_bpf_enabled_key);
 +	}
 +	for_each_cgroup_storage_type(stype)
 +		bpf_cgroup_storage_link(storage[stype], cgrp, type);
 +	return 0;
 +
 +cleanup:
 +	/* and cleanup the prog list */
 +	pl->prog = old_prog;
 +	for_each_cgroup_storage_type(stype) {
 +		bpf_cgroup_storage_free(pl->storage[stype]);
 +		pl->storage[stype] = old_storage[stype];
 +		bpf_cgroup_storage_link(old_storage[stype], cgrp, type);
 +	}
 +	if (!replace_pl) {
++=======
+ 	bpf_cgroup_storages_free(old_storage);
+ 	if (old_prog)
+ 		bpf_prog_put(old_prog);
+ 	else
+ 		static_branch_inc(&cgroup_bpf_enabled_key);
+ 	bpf_cgroup_storages_link(pl->storage, cgrp, type);
+ 	return 0;
+ 
+ cleanup:
+ 	if (old_prog) {
+ 		pl->prog = old_prog;
+ 		pl->link = NULL;
+ 	}
+ 	bpf_cgroup_storages_free(pl->storage);
+ 	bpf_cgroup_storages_assign(pl->storage, old_storage);
+ 	bpf_cgroup_storages_link(pl->storage, cgrp, type);
+ 	if (!old_prog) {
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  		list_del(&pl->node);
  		kfree(pl);
  	}
@@@ -417,49 -544,26 +642,27 @@@ static struct bpf_prog_list *find_detac
   * Must be called with cgroup_mutex held.
   */
  int __cgroup_bpf_detach(struct cgroup *cgrp, struct bpf_prog *prog,
- 			enum bpf_attach_type type)
+ 			struct bpf_cgroup_link *link, enum bpf_attach_type type)
  {
  	struct list_head *progs = &cgrp->bpf.progs[type];
 +	enum bpf_cgroup_storage_type stype;
  	u32 flags = cgrp->bpf.flags[type];
- 	struct bpf_prog *old_prog = NULL;
  	struct bpf_prog_list *pl;
+ 	struct bpf_prog *old_prog;
  	int err;
  
- 	if (flags & BPF_F_ALLOW_MULTI) {
- 		if (!prog)
- 			/* to detach MULTI prog the user has to specify valid FD
- 			 * of the program to be detached
- 			 */
- 			return -EINVAL;
- 	} else {
- 		if (list_empty(progs))
- 			/* report error when trying to detach and nothing is attached */
- 			return -ENOENT;
- 	}
+ 	if (prog && link)
+ 		/* only one of prog or link can be specified */
+ 		return -EINVAL;
  
- 	if (flags & BPF_F_ALLOW_MULTI) {
- 		/* find the prog and detach it */
- 		list_for_each_entry(pl, progs, node) {
- 			if (pl->prog != prog)
- 				continue;
- 			old_prog = prog;
- 			/* mark it deleted, so it's ignored while
- 			 * recomputing effective
- 			 */
- 			pl->prog = NULL;
- 			break;
- 		}
- 		if (!old_prog)
- 			return -ENOENT;
- 	} else {
- 		/* to maintain backward compatibility NONE and OVERRIDE cgroups
- 		 * allow detaching with invalid FD (prog==NULL)
- 		 */
- 		pl = list_first_entry(progs, typeof(*pl), node);
- 		old_prog = pl->prog;
- 		pl->prog = NULL;
- 	}
+ 	pl = find_detach_entry(progs, prog, link, flags & BPF_F_ALLOW_MULTI);
+ 	if (IS_ERR(pl))
+ 		return PTR_ERR(pl);
+ 
+ 	/* mark it deleted, so it's ignored while recomputing effective */
+ 	old_prog = pl->prog;
+ 	pl->prog = NULL;
+ 	pl->link = NULL;
  
  	err = update_effective_progs(cgrp, type);
  	if (err)
@@@ -545,9 -651,20 +751,26 @@@ int cgroup_bpf_prog_attach(const union 
  	if (IS_ERR(cgrp))
  		return PTR_ERR(cgrp);
  
++<<<<<<< HEAD
 +	rh_mark_used_feature("eBPF/cgroup");
 +	ret = cgroup_bpf_attach(cgrp, prog, attr->attach_type,
 +				attr->attach_flags);
++=======
+ 	if ((attr->attach_flags & BPF_F_ALLOW_MULTI) &&
+ 	    (attr->attach_flags & BPF_F_REPLACE)) {
+ 		replace_prog = bpf_prog_get_type(attr->replace_bpf_fd, ptype);
+ 		if (IS_ERR(replace_prog)) {
+ 			cgroup_put(cgrp);
+ 			return PTR_ERR(replace_prog);
+ 		}
+ 	}
+ 
+ 	ret = cgroup_bpf_attach(cgrp, prog, replace_prog, NULL,
+ 				attr->attach_type, attr->attach_flags);
+ 
+ 	if (replace_prog)
+ 		bpf_prog_put(replace_prog);
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  	cgroup_put(cgrp);
  	return ret;
  }
diff --cc kernel/bpf/syscall.c
index b5b79e59cfd4,97d5c6fb63cd..000000000000
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@@ -1840,43 -2160,290 +1840,117 @@@ free_prog_nouncharge
  static int bpf_obj_pin(const union bpf_attr *attr)
  {
  	if (CHECK_ATTR(BPF_OBJ) || attr->file_flags != 0)
 -		return -EINVAL;
 -
 -	return bpf_obj_pin_user(attr->bpf_fd, u64_to_user_ptr(attr->pathname));
 -}
 -
 -static int bpf_obj_get(const union bpf_attr *attr)
 -{
 -	if (CHECK_ATTR(BPF_OBJ) || attr->bpf_fd != 0 ||
 -	    attr->file_flags & ~BPF_OBJ_FLAG_MASK)
 -		return -EINVAL;
 -
 -	return bpf_obj_get_user(u64_to_user_ptr(attr->pathname),
 -				attr->file_flags);
 -}
 -
 -void bpf_link_init(struct bpf_link *link, const struct bpf_link_ops *ops,
 -		   struct bpf_prog *prog)
 -{
 -	atomic64_set(&link->refcnt, 1);
 -	link->ops = ops;
 -	link->prog = prog;
 -}
 -
 -/* Clean up bpf_link and corresponding anon_inode file and FD. After
 - * anon_inode is created, bpf_link can't be just kfree()'d due to deferred
 - * anon_inode's release() call. This helper manages marking bpf_link as
 - * defunct, releases anon_inode file and puts reserved FD.
 - */
 -void bpf_link_cleanup(struct bpf_link *link, struct file *link_file,
 -		      int link_fd)
 -{
 -	link->prog = NULL;
 -	fput(link_file);
 -	put_unused_fd(link_fd);
 -}
 -
 -void bpf_link_inc(struct bpf_link *link)
 -{
 -	atomic64_inc(&link->refcnt);
 -}
 -
 -/* bpf_link_free is guaranteed to be called from process context */
 -static void bpf_link_free(struct bpf_link *link)
 -{
 -	if (link->prog) {
 -		/* detach BPF program, clean up used resources */
 -		link->ops->release(link);
 -		bpf_prog_put(link->prog);
 -	}
 -	/* free bpf_link and its containing memory */
 -	link->ops->dealloc(link);
 -}
 -
 -static void bpf_link_put_deferred(struct work_struct *work)
 -{
 -	struct bpf_link *link = container_of(work, struct bpf_link, work);
 -
 -	bpf_link_free(link);
 -}
 -
 -/* bpf_link_put can be called from atomic context, but ensures that resources
 - * are freed from process context
 - */
 -void bpf_link_put(struct bpf_link *link)
 -{
 -	if (!atomic64_dec_and_test(&link->refcnt))
 -		return;
 -
 -	if (in_atomic()) {
 -		INIT_WORK(&link->work, bpf_link_put_deferred);
 -		schedule_work(&link->work);
 -	} else {
 -		bpf_link_free(link);
 -	}
 -}
 -
 -static int bpf_link_release(struct inode *inode, struct file *filp)
 -{
 -	struct bpf_link *link = filp->private_data;
 -
 -	bpf_link_put(link);
 -	return 0;
 -}
 -
 -#ifdef CONFIG_PROC_FS
 -static const struct bpf_link_ops bpf_raw_tp_lops;
 -static const struct bpf_link_ops bpf_tracing_link_lops;
 -
 -static void bpf_link_show_fdinfo(struct seq_file *m, struct file *filp)
 -{
 -	const struct bpf_link *link = filp->private_data;
 -	const struct bpf_prog *prog = link->prog;
 -	char prog_tag[sizeof(prog->tag) * 2 + 1] = { };
 -	const char *link_type;
 -
 -	if (link->ops == &bpf_raw_tp_lops)
 -		link_type = "raw_tracepoint";
 -	else if (link->ops == &bpf_tracing_link_lops)
 -		link_type = "tracing";
 -#ifdef CONFIG_CGROUP_BPF
 -	else if (link->ops == &bpf_cgroup_link_lops)
 -		link_type = "cgroup";
 -#endif
 -	else
 -		link_type = "unknown";
 -
 -	bin2hex(prog_tag, prog->tag, sizeof(prog->tag));
 -	seq_printf(m,
 -		   "link_type:\t%s\n"
 -		   "prog_tag:\t%s\n"
 -		   "prog_id:\t%u\n",
 -		   link_type,
 -		   prog_tag,
 -		   prog->aux->id);
 -}
 -#endif
 -
 -const struct file_operations bpf_link_fops = {
 -#ifdef CONFIG_PROC_FS
 -	.show_fdinfo	= bpf_link_show_fdinfo,
 -#endif
 -	.release	= bpf_link_release,
 -	.read		= bpf_dummy_read,
 -	.write		= bpf_dummy_write,
 -};
 -
 -int bpf_link_new_fd(struct bpf_link *link)
 -{
 -	return anon_inode_getfd("bpf-link", &bpf_link_fops, link, O_CLOEXEC);
 -}
 -
 -/* Similar to bpf_link_new_fd, create anon_inode for given bpf_link, but
 - * instead of immediately installing fd in fdtable, just reserve it and
 - * return. Caller then need to either install it with fd_install(fd, file) or
 - * release with put_unused_fd(fd).
 - * This is useful for cases when bpf_link attachment/detachment are
 - * complicated and expensive operations and should be delayed until all the fd
 - * reservation and anon_inode creation succeeds.
 - */
 -struct file *bpf_link_new_file(struct bpf_link *link, int *reserved_fd)
 -{
 -	struct file *file;
 -	int fd;
 -
 -	fd = get_unused_fd_flags(O_CLOEXEC);
 -	if (fd < 0)
 -		return ERR_PTR(fd);
 -
 -	file = anon_inode_getfile("bpf_link", &bpf_link_fops, link, O_CLOEXEC);
 -	if (IS_ERR(file)) {
 -		put_unused_fd(fd);
 -		return file;
 -	}
 -
 -	*reserved_fd = fd;
 -	return file;
 -}
 -
 -struct bpf_link *bpf_link_get_from_fd(u32 ufd)
 -{
 -	struct fd f = fdget(ufd);
 -	struct bpf_link *link;
 -
 -	if (!f.file)
 -		return ERR_PTR(-EBADF);
 -	if (f.file->f_op != &bpf_link_fops) {
 -		fdput(f);
 -		return ERR_PTR(-EINVAL);
 -	}
 -
 -	link = f.file->private_data;
 -	bpf_link_inc(link);
 -	fdput(f);
 -
 -	return link;
 -}
 -
 -struct bpf_tracing_link {
 -	struct bpf_link link;
 -};
 -
 -static void bpf_tracing_link_release(struct bpf_link *link)
 -{
 -	WARN_ON_ONCE(bpf_trampoline_unlink_prog(link->prog));
 -}
 -
 -static void bpf_tracing_link_dealloc(struct bpf_link *link)
 -{
 -	struct bpf_tracing_link *tr_link =
 -		container_of(link, struct bpf_tracing_link, link);
 -
 -	kfree(tr_link);
 -}
 -
 -static const struct bpf_link_ops bpf_tracing_link_lops = {
 -	.release = bpf_tracing_link_release,
 -	.dealloc = bpf_tracing_link_dealloc,
 -};
 -
 -static int bpf_tracing_prog_attach(struct bpf_prog *prog)
 -{
 -	struct bpf_tracing_link *link;
 -	struct file *link_file;
 -	int link_fd, err;
 -
 -	switch (prog->type) {
 -	case BPF_PROG_TYPE_TRACING:
 -		if (prog->expected_attach_type != BPF_TRACE_FENTRY &&
 -		    prog->expected_attach_type != BPF_TRACE_FEXIT &&
 -		    prog->expected_attach_type != BPF_MODIFY_RETURN) {
 -			err = -EINVAL;
 -			goto out_put_prog;
 -		}
 -		break;
 -	case BPF_PROG_TYPE_EXT:
 -		if (prog->expected_attach_type != 0) {
 -			err = -EINVAL;
 -			goto out_put_prog;
 -		}
 -		break;
 -	case BPF_PROG_TYPE_LSM:
 -		if (prog->expected_attach_type != BPF_LSM_MAC) {
 -			err = -EINVAL;
 -			goto out_put_prog;
 -		}
 -		break;
 -	default:
 -		err = -EINVAL;
 -		goto out_put_prog;
 -	}
 -
 -	link = kzalloc(sizeof(*link), GFP_USER);
 -	if (!link) {
 -		err = -ENOMEM;
 -		goto out_put_prog;
 -	}
 -	bpf_link_init(&link->link, &bpf_tracing_link_lops, prog);
 -
 -	link_file = bpf_link_new_file(&link->link, &link_fd);
 -	if (IS_ERR(link_file)) {
 -		kfree(link);
 -		err = PTR_ERR(link_file);
 -		goto out_put_prog;
 -	}
 +		return -EINVAL;
  
 -	err = bpf_trampoline_link_prog(prog);
 -	if (err) {
 -		bpf_link_cleanup(&link->link, link_file, link_fd);
 -		goto out_put_prog;
 -	}
 +	return bpf_obj_pin_user(attr->bpf_fd, u64_to_user_ptr(attr->pathname));
 +}
  
 -	fd_install(link_fd, link_file);
 -	return link_fd;
 +static int bpf_obj_get(const union bpf_attr *attr)
 +{
 +	if (CHECK_ATTR(BPF_OBJ) || attr->bpf_fd != 0 ||
 +	    attr->file_flags & ~BPF_OBJ_FLAG_MASK)
 +		return -EINVAL;
  
 -out_put_prog:
 -	bpf_prog_put(prog);
 -	return err;
 +	return bpf_obj_get_user(u64_to_user_ptr(attr->pathname),
 +				attr->file_flags);
  }
  
 -struct bpf_raw_tp_link {
 -	struct bpf_link link;
++<<<<<<< HEAD
 +struct bpf_raw_tracepoint {
  	struct bpf_raw_event_map *btp;
 +	struct bpf_prog *prog;
  };
  
 -static void bpf_raw_tp_link_release(struct bpf_link *link)
 +static int bpf_raw_tracepoint_release(struct inode *inode, struct file *filp)
++=======
++void bpf_link_init(struct bpf_link *link, const struct bpf_link_ops *ops,
++		   struct bpf_prog *prog)
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  {
 -	struct bpf_raw_tp_link *raw_tp =
 -		container_of(link, struct bpf_raw_tp_link, link);
 +	struct bpf_raw_tracepoint *raw_tp = filp->private_data;
  
 -	bpf_probe_unregister(raw_tp->btp, raw_tp->link.prog);
 -	bpf_put_raw_tracepoint(raw_tp->btp);
++<<<<<<< HEAD
 +	if (raw_tp->prog) {
 +		bpf_probe_unregister(raw_tp->btp, raw_tp->prog);
 +		bpf_prog_put(raw_tp->prog);
++=======
++/* Clean up bpf_link and corresponding anon_inode file and FD. After
++ * anon_inode is created, bpf_link can't be just kfree()'d due to deferred
++ * anon_inode's release() call. This helper manages marking bpf_link as
++ * defunct, releases anon_inode file and puts reserved FD.
++ */
++void bpf_link_cleanup(struct bpf_link *link, struct file *link_file,
++		      int link_fd)
++{
++	link->prog = NULL;
++	fput(link_file);
++	put_unused_fd(link_fd);
+ }
+ 
 -static void bpf_raw_tp_link_dealloc(struct bpf_link *link)
++void bpf_link_inc(struct bpf_link *link)
+ {
 -	struct bpf_raw_tp_link *raw_tp =
 -		container_of(link, struct bpf_raw_tp_link, link);
++	atomic64_inc(&link->refcnt);
++}
+ 
++/* bpf_link_free is guaranteed to be called from process context */
++static void bpf_link_free(struct bpf_link *link)
++{
++	if (link->prog) {
++		/* detach BPF program, clean up used resources */
++		link->ops->release(link);
++		bpf_prog_put(link->prog);
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
 +	}
 +	bpf_put_raw_tracepoint(raw_tp->btp);
  	kfree(raw_tp);
 +	return 0;
 +}
 +
++<<<<<<< HEAD
 +static const struct file_operations bpf_raw_tp_fops = {
 +	.release	= bpf_raw_tracepoint_release,
++=======
++#ifdef CONFIG_PROC_FS
++static const struct bpf_link_ops bpf_raw_tp_lops;
++static const struct bpf_link_ops bpf_tracing_link_lops;
++
++static void bpf_link_show_fdinfo(struct seq_file *m, struct file *filp)
++{
++	const struct bpf_link *link = filp->private_data;
++	const struct bpf_prog *prog = link->prog;
++	char prog_tag[sizeof(prog->tag) * 2 + 1] = { };
++	const char *link_type;
++
++	if (link->ops == &bpf_raw_tp_lops)
++		link_type = "raw_tracepoint";
++	else if (link->ops == &bpf_tracing_link_lops)
++		link_type = "tracing";
++#ifdef CONFIG_CGROUP_BPF
++	else if (link->ops == &bpf_cgroup_link_lops)
++		link_type = "cgroup";
++#endif
++	else
++		link_type = "unknown";
++
++	bin2hex(prog_tag, prog->tag, sizeof(prog->tag));
++	seq_printf(m,
++		   "link_type:\t%s\n"
++		   "prog_tag:\t%s\n"
++		   "prog_id:\t%u\n",
++		   link_type,
++		   prog_tag,
++		   prog->aux->id);
+ }
++#endif
+ 
 -static const struct bpf_link_ops bpf_raw_tp_lops = {
 -	.release = bpf_raw_tp_link_release,
 -	.dealloc = bpf_raw_tp_link_dealloc,
++const struct file_operations bpf_link_fops = {
++#ifdef CONFIG_PROC_FS
++	.show_fdinfo	= bpf_link_show_fdinfo,
++#endif
++	.release	= bpf_link_release,
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
 +	.read		= bpf_dummy_read,
 +	.write		= bpf_dummy_write,
  };
  
  #define BPF_RAW_TRACEPOINT_OPEN_LAST_FIELD raw_tracepoint.prog_fd
@@@ -2908,9 -3495,110 +2982,113 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ #define BPF_MAP_BATCH_LAST_FIELD batch.flags
+ 
+ #define BPF_DO_BATCH(fn)			\
+ 	do {					\
+ 		if (!fn) {			\
+ 			err = -ENOTSUPP;	\
+ 			goto err_put;		\
+ 		}				\
+ 		err = fn(map, attr, uattr);	\
+ 	} while (0)
+ 
+ static int bpf_map_do_batch(const union bpf_attr *attr,
+ 			    union bpf_attr __user *uattr,
+ 			    int cmd)
+ {
+ 	struct bpf_map *map;
+ 	int err, ufd;
+ 	struct fd f;
+ 
+ 	if (CHECK_ATTR(BPF_MAP_BATCH))
+ 		return -EINVAL;
+ 
+ 	ufd = attr->batch.map_fd;
+ 	f = fdget(ufd);
+ 	map = __bpf_map_get(f);
+ 	if (IS_ERR(map))
+ 		return PTR_ERR(map);
+ 
+ 	if ((cmd == BPF_MAP_LOOKUP_BATCH ||
+ 	     cmd == BPF_MAP_LOOKUP_AND_DELETE_BATCH) &&
+ 	    !(map_get_sys_perms(map, f) & FMODE_CAN_READ)) {
+ 		err = -EPERM;
+ 		goto err_put;
+ 	}
+ 
+ 	if (cmd != BPF_MAP_LOOKUP_BATCH &&
+ 	    !(map_get_sys_perms(map, f) & FMODE_CAN_WRITE)) {
+ 		err = -EPERM;
+ 		goto err_put;
+ 	}
+ 
+ 	if (cmd == BPF_MAP_LOOKUP_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_lookup_batch);
+ 	else if (cmd == BPF_MAP_LOOKUP_AND_DELETE_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_lookup_and_delete_batch);
+ 	else if (cmd == BPF_MAP_UPDATE_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_update_batch);
+ 	else
+ 		BPF_DO_BATCH(map->ops->map_delete_batch);
+ 
+ err_put:
+ 	fdput(f);
+ 	return err;
+ }
+ 
+ #define BPF_LINK_CREATE_LAST_FIELD link_create.flags
+ static int link_create(union bpf_attr *attr)
+ {
+ 	enum bpf_prog_type ptype;
+ 	struct bpf_prog *prog;
+ 	int ret;
+ 
+ 	if (!capable(CAP_NET_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (CHECK_ATTR(BPF_LINK_CREATE))
+ 		return -EINVAL;
+ 
+ 	ptype = attach_type_to_prog_type(attr->link_create.attach_type);
+ 	if (ptype == BPF_PROG_TYPE_UNSPEC)
+ 		return -EINVAL;
+ 
+ 	prog = bpf_prog_get_type(attr->link_create.prog_fd, ptype);
+ 	if (IS_ERR(prog))
+ 		return PTR_ERR(prog);
+ 
+ 	ret = bpf_prog_attach_check_attach_type(prog,
+ 						attr->link_create.attach_type);
+ 	if (ret)
+ 		goto err_out;
+ 
+ 	switch (ptype) {
+ 	case BPF_PROG_TYPE_CGROUP_SKB:
+ 	case BPF_PROG_TYPE_CGROUP_SOCK:
+ 	case BPF_PROG_TYPE_CGROUP_SOCK_ADDR:
+ 	case BPF_PROG_TYPE_SOCK_OPS:
+ 	case BPF_PROG_TYPE_CGROUP_DEVICE:
+ 	case BPF_PROG_TYPE_CGROUP_SYSCTL:
+ 	case BPF_PROG_TYPE_CGROUP_SOCKOPT:
+ 		ret = cgroup_bpf_link_attach(attr, prog);
+ 		break;
+ 	default:
+ 		ret = -EINVAL;
+ 	}
+ 
+ err_out:
+ 	if (ret < 0)
+ 		bpf_prog_put(prog);
+ 	return ret;
+ }
+ 
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  SYSCALL_DEFINE3(bpf, int, cmd, union bpf_attr __user *, uattr, unsigned int, size)
  {
 -	union bpf_attr attr = {};
 +	union bpf_attr attr;
  	int err;
  
  	if (sysctl_unprivileged_bpf_disabled && !capable(CAP_SYS_ADMIN))
@@@ -3006,6 -3693,22 +3184,25 @@@
  	case BPF_MAP_LOOKUP_AND_DELETE_ELEM:
  		err = map_lookup_and_delete_elem(&attr);
  		break;
++<<<<<<< HEAD
++=======
+ 	case BPF_MAP_LOOKUP_BATCH:
+ 		err = bpf_map_do_batch(&attr, uattr, BPF_MAP_LOOKUP_BATCH);
+ 		break;
+ 	case BPF_MAP_LOOKUP_AND_DELETE_BATCH:
+ 		err = bpf_map_do_batch(&attr, uattr,
+ 				       BPF_MAP_LOOKUP_AND_DELETE_BATCH);
+ 		break;
+ 	case BPF_MAP_UPDATE_BATCH:
+ 		err = bpf_map_do_batch(&attr, uattr, BPF_MAP_UPDATE_BATCH);
+ 		break;
+ 	case BPF_MAP_DELETE_BATCH:
+ 		err = bpf_map_do_batch(&attr, uattr, BPF_MAP_DELETE_BATCH);
+ 		break;
+ 	case BPF_LINK_CREATE:
+ 		err = link_create(&attr);
+ 		break;
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  	default:
  		err = -EINVAL;
  		break;
diff --cc kernel/cgroup/cgroup.c
index 0ae03b38e5a0,219624fba9ba..000000000000
--- a/kernel/cgroup/cgroup.c
+++ b/kernel/cgroup/cgroup.c
@@@ -6325,13 -6303,16 +6325,25 @@@ void cgroup_sk_free(struct sock_cgroup_
  #endif	/* CONFIG_SOCK_CGROUP_DATA */
  
  #ifdef CONFIG_CGROUP_BPF
++<<<<<<< HEAD
 +int cgroup_bpf_attach(struct cgroup *cgrp, struct bpf_prog *prog,
 +		      enum bpf_attach_type type, u32 flags)
++=======
+ int cgroup_bpf_attach(struct cgroup *cgrp,
+ 		      struct bpf_prog *prog, struct bpf_prog *replace_prog,
+ 		      struct bpf_cgroup_link *link,
+ 		      enum bpf_attach_type type,
+ 		      u32 flags)
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  {
  	int ret;
  
  	mutex_lock(&cgroup_mutex);
++<<<<<<< HEAD
 +	ret = __cgroup_bpf_attach(cgrp, prog, type, flags);
++=======
+ 	ret = __cgroup_bpf_attach(cgrp, prog, replace_prog, link, type, flags);
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  	mutex_unlock(&cgroup_mutex);
  	return ret;
  }
diff --cc tools/include/uapi/linux/bpf.h
index 2bc35095902a,37dffe5089a0..000000000000
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@@ -107,6 -107,11 +107,14 @@@ enum bpf_cmd 
  	BPF_MAP_LOOKUP_AND_DELETE_ELEM,
  	BPF_MAP_FREEZE,
  	BPF_BTF_GET_NEXT_ID,
++<<<<<<< HEAD
++=======
+ 	BPF_MAP_LOOKUP_BATCH,
+ 	BPF_MAP_LOOKUP_AND_DELETE_BATCH,
+ 	BPF_MAP_UPDATE_BATCH,
+ 	BPF_MAP_DELETE_BATCH,
+ 	BPF_LINK_CREATE,
++>>>>>>> af6eea57437a (bpf: Implement bpf_link-based cgroup BPF program attachment)
  };
  
  enum bpf_map_type {
* Unmerged path include/linux/bpf-cgroup.h
* Unmerged path include/linux/bpf.h
* Unmerged path include/uapi/linux/bpf.h
* Unmerged path kernel/bpf/cgroup.c
* Unmerged path kernel/bpf/syscall.c
* Unmerged path kernel/cgroup/cgroup.c
* Unmerged path tools/include/uapi/linux/bpf.h
