bpf: libbpf: Add STRUCT_OPS support

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Martin KaFai Lau <kafai@fb.com>
commit 590a0088825016ca7ec53f1aef7e84e1211778d8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/590a0088.failed

This patch adds BPF STRUCT_OPS support to libbpf.

The only sec_name convention is SEC(".struct_ops") to identify the
struct_ops implemented in BPF,
e.g. To implement a tcp_congestion_ops:

SEC(".struct_ops")
struct tcp_congestion_ops dctcp = {
	.init           = (void *)dctcp_init,  /* <-- a bpf_prog */
	/* ... some more func prts ... */
	.name           = "bpf_dctcp",
};

Each struct_ops is defined as a global variable under SEC(".struct_ops")
as above.  libbpf creates a map for each variable and the variable name
is the map's name.  Multiple struct_ops is supported under
SEC(".struct_ops").

In the bpf_object__open phase, libbpf will look for the SEC(".struct_ops")
section and find out what is the btf-type the struct_ops is
implementing.  Note that the btf-type here is referring to
a type in the bpf_prog.o's btf.  A "struct bpf_map" is added
by bpf_object__add_map() as other maps do.  It will then
collect (through SHT_REL) where are the bpf progs that the
func ptrs are referring to.  No btf_vmlinux is needed in
the open phase.

In the bpf_object__load phase, the map-fields, which depend
on the btf_vmlinux, are initialized (in bpf_map__init_kern_struct_ops()).
It will also set the prog->type, prog->attach_btf_id, and
prog->expected_attach_type.  Thus, the prog's properties do
not rely on its section name.
[ Currently, the bpf_prog's btf-type ==> btf_vmlinux's btf-type matching
  process is as simple as: member-name match + btf-kind match + size match.
  If these matching conditions fail, libbpf will reject.
  The current targeting support is "struct tcp_congestion_ops" which
  most of its members are function pointers.
  The member ordering of the bpf_prog's btf-type can be different from
  the btf_vmlinux's btf-type. ]

Then, all obj->maps are created as usual (in bpf_object__create_maps()).

Once the maps are created and prog's properties are all set,
the libbpf will proceed to load all the progs.

bpf_map__attach_struct_ops() is added to register a struct_ops
map to a kernel subsystem.

	Signed-off-by: Martin KaFai Lau <kafai@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20200109003514.3856730-1-kafai@fb.com
(cherry picked from commit 590a0088825016ca7ec53f1aef7e84e1211778d8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/lib/bpf/bpf.c
#	tools/lib/bpf/libbpf.c
#	tools/lib/bpf/libbpf.h
#	tools/lib/bpf/libbpf.map
#	tools/lib/bpf/libbpf_probes.c
diff --cc tools/lib/bpf/bpf.c
index f9124e381f55,b0ecbe9ef2d4..000000000000
--- a/tools/lib/bpf/bpf.c
+++ b/tools/lib/bpf/bpf.c
@@@ -228,9 -232,15 +232,21 @@@ int bpf_load_program_xattr(const struc
  	memset(&attr, 0, sizeof(attr));
  	attr.prog_type = load_attr->prog_type;
  	attr.expected_attach_type = load_attr->expected_attach_type;
++<<<<<<< HEAD
 +	if (attr.prog_type == BPF_PROG_TYPE_RAW_TRACEPOINT)
 +		/* expected_attach_type is ignored for tracing progs */
 +		attr.attach_btf_id = attr.expected_attach_type;
++=======
+ 	if (attr.prog_type == BPF_PROG_TYPE_STRUCT_OPS) {
+ 		attr.attach_btf_id = load_attr->attach_btf_id;
+ 	} else if (attr.prog_type == BPF_PROG_TYPE_TRACING) {
+ 		attr.attach_btf_id = load_attr->attach_btf_id;
+ 		attr.attach_prog_fd = load_attr->attach_prog_fd;
+ 	} else {
+ 		attr.prog_ifindex = load_attr->prog_ifindex;
+ 		attr.kern_version = load_attr->kern_version;
+ 	}
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  	attr.insn_cnt = (__u32)load_attr->insns_cnt;
  	attr.insns = ptr_to_u64(load_attr->insns);
  	attr.license = ptr_to_u64(load_attr->license);
diff --cc tools/lib/bpf/libbpf.c
index 365ad04b00a7,35a4422ef655..000000000000
--- a/tools/lib/bpf/libbpf.c
+++ b/tools/lib/bpf/libbpf.c
@@@ -231,6 -260,8 +259,11 @@@ struct bpf_struct_ops 
  #define DATA_SEC ".data"
  #define BSS_SEC ".bss"
  #define RODATA_SEC ".rodata"
++<<<<<<< HEAD
++=======
+ #define KCONFIG_SEC ".kconfig"
+ #define STRUCT_OPS_SEC ".struct_ops"
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  
  enum libbpf_map_type {
  	LIBBPF_MAP_UNSPEC,
@@@ -575,6 -993,8 +965,11 @@@ static struct bpf_object *bpf_object__n
  	obj->efile.data_shndx = -1;
  	obj->efile.rodata_shndx = -1;
  	obj->efile.bss_shndx = -1;
++<<<<<<< HEAD
++=======
+ 	obj->efile.st_ops_shndx = -1;
+ 	obj->kconfig_map_idx = -1;
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  
  	obj->kern_version = get_kernel_version();
  	obj->loaded = false;
@@@ -1434,21 -2178,21 +1847,28 @@@ static int bpf_object__init_user_btf_ma
  	return 0;
  }
  
 -static int bpf_object__init_maps(struct bpf_object *obj,
 -				 const struct bpf_object_open_opts *opts)
 +static int bpf_object__init_maps(struct bpf_object *obj, bool relaxed_maps,
 +				 const char *pin_root_path)
  {
 -	const char *pin_root_path;
 -	bool strict;
 +	bool strict = !relaxed_maps;
  	int err;
  
 -	strict = !OPTS_GET(opts, relaxed_maps, false);
 -	pin_root_path = OPTS_GET(opts, pin_root_path, NULL);
 -
  	err = bpf_object__init_user_maps(obj, strict);
++<<<<<<< HEAD
 +	if (err)
 +		return err;
 +
 +	err = bpf_object__init_user_btf_maps(obj, strict, pin_root_path);
 +	if (err)
 +		return err;
 +
 +	err = bpf_object__init_global_data_maps(obj);
++=======
+ 	err = err ?: bpf_object__init_user_btf_maps(obj, strict, pin_root_path);
+ 	err = err ?: bpf_object__init_global_data_maps(obj);
+ 	err = err ?: bpf_object__init_kconfig_map(obj);
+ 	err = err ?: bpf_object__init_struct_ops_maps(obj);
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  	if (err)
  		return err;
  
@@@ -3833,8 -4864,15 +4278,20 @@@ load_program(struct bpf_program *prog, 
  	load_attr.insns = insns;
  	load_attr.insns_cnt = insns_cnt;
  	load_attr.license = license;
++<<<<<<< HEAD
 +	load_attr.kern_version = kern_version;
 +	load_attr.prog_ifindex = prog->prog_ifindex;
++=======
+ 	if (prog->type == BPF_PROG_TYPE_STRUCT_OPS) {
+ 		load_attr.attach_btf_id = prog->attach_btf_id;
+ 	} else if (prog->type == BPF_PROG_TYPE_TRACING) {
+ 		load_attr.attach_prog_fd = prog->attach_prog_fd;
+ 		load_attr.attach_btf_id = prog->attach_btf_id;
+ 	} else {
+ 		load_attr.kern_version = kern_version;
+ 		load_attr.prog_ifindex = prog->prog_ifindex;
+ 	}
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  	/* if .BTF.ext was loaded, kernel supports associated BTF for prog */
  	if (prog->obj->btf_ext)
  		btf_fd = bpf_object__btf_fd(prog->obj);
@@@ -4179,9 -5326,16 +4642,22 @@@ int bpf_object__load_xattr(struct bpf_o
  
  	obj->loaded = true;
  
++<<<<<<< HEAD
 +	CHECK_ERR(bpf_object__create_maps(obj), err, out);
 +	CHECK_ERR(bpf_object__relocate(obj, attr->target_btf_path), err, out);
 +	CHECK_ERR(bpf_object__load_progs(obj, attr->log_level), err, out);
++=======
+ 	err = bpf_object__probe_caps(obj);
+ 	err = err ? : bpf_object__resolve_externs(obj, obj->kconfig);
+ 	err = err ? : bpf_object__sanitize_and_load_btf(obj);
+ 	err = err ? : bpf_object__sanitize_maps(obj);
+ 	err = err ? : bpf_object__init_kern_struct_ops_maps(obj);
+ 	err = err ? : bpf_object__create_maps(obj);
+ 	err = err ? : bpf_object__relocate(obj, attr->target_btf_path);
+ 	err = err ? : bpf_object__load_progs(obj, attr->log_level);
+ 	if (err)
+ 		goto out;
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  
  	return 0;
  out:
@@@ -5022,6 -6192,8 +5505,11 @@@ BPF_PROG_TYPE_FNS(tracepoint, BPF_PROG_
  BPF_PROG_TYPE_FNS(raw_tracepoint, BPF_PROG_TYPE_RAW_TRACEPOINT);
  BPF_PROG_TYPE_FNS(xdp, BPF_PROG_TYPE_XDP);
  BPF_PROG_TYPE_FNS(perf_event, BPF_PROG_TYPE_PERF_EVENT);
++<<<<<<< HEAD
++=======
+ BPF_PROG_TYPE_FNS(tracing, BPF_PROG_TYPE_TRACING);
+ BPF_PROG_TYPE_FNS(struct_ops, BPF_PROG_TYPE_STRUCT_OPS);
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  
  enum bpf_attach_type
  bpf_program__get_expected_attach_type(struct bpf_program *prog)
@@@ -5216,6 -6424,227 +5705,230 @@@ int libbpf_prog_type_by_name(const cha
  	return -ESRCH;
  }
  
++<<<<<<< HEAD
++=======
+ static struct bpf_map *find_struct_ops_map_by_offset(struct bpf_object *obj,
+ 						     size_t offset)
+ {
+ 	struct bpf_map *map;
+ 	size_t i;
+ 
+ 	for (i = 0; i < obj->nr_maps; i++) {
+ 		map = &obj->maps[i];
+ 		if (!bpf_map__is_struct_ops(map))
+ 			continue;
+ 		if (map->sec_offset <= offset &&
+ 		    offset - map->sec_offset < map->def.value_size)
+ 			return map;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ /* Collect the reloc from ELF and populate the st_ops->progs[] */
+ static int bpf_object__collect_struct_ops_map_reloc(struct bpf_object *obj,
+ 						    GElf_Shdr *shdr,
+ 						    Elf_Data *data)
+ {
+ 	const struct btf_member *member;
+ 	struct bpf_struct_ops *st_ops;
+ 	struct bpf_program *prog;
+ 	unsigned int shdr_idx;
+ 	const struct btf *btf;
+ 	struct bpf_map *map;
+ 	Elf_Data *symbols;
+ 	unsigned int moff;
+ 	const char *name;
+ 	u32 member_idx;
+ 	GElf_Sym sym;
+ 	GElf_Rel rel;
+ 	int i, nrels;
+ 
+ 	symbols = obj->efile.symbols;
+ 	btf = obj->btf;
+ 	nrels = shdr->sh_size / shdr->sh_entsize;
+ 	for (i = 0; i < nrels; i++) {
+ 		if (!gelf_getrel(data, i, &rel)) {
+ 			pr_warn("struct_ops reloc: failed to get %d reloc\n", i);
+ 			return -LIBBPF_ERRNO__FORMAT;
+ 		}
+ 
+ 		if (!gelf_getsym(symbols, GELF_R_SYM(rel.r_info), &sym)) {
+ 			pr_warn("struct_ops reloc: symbol %zx not found\n",
+ 				(size_t)GELF_R_SYM(rel.r_info));
+ 			return -LIBBPF_ERRNO__FORMAT;
+ 		}
+ 
+ 		name = elf_strptr(obj->efile.elf, obj->efile.strtabidx,
+ 				  sym.st_name) ? : "<?>";
+ 		map = find_struct_ops_map_by_offset(obj, rel.r_offset);
+ 		if (!map) {
+ 			pr_warn("struct_ops reloc: cannot find map at rel.r_offset %zu\n",
+ 				(size_t)rel.r_offset);
+ 			return -EINVAL;
+ 		}
+ 
+ 		moff = rel.r_offset - map->sec_offset;
+ 		shdr_idx = sym.st_shndx;
+ 		st_ops = map->st_ops;
+ 		pr_debug("struct_ops reloc %s: for %lld value %lld shdr_idx %u rel.r_offset %zu map->sec_offset %zu name %d (\'%s\')\n",
+ 			 map->name,
+ 			 (long long)(rel.r_info >> 32),
+ 			 (long long)sym.st_value,
+ 			 shdr_idx, (size_t)rel.r_offset,
+ 			 map->sec_offset, sym.st_name, name);
+ 
+ 		if (shdr_idx >= SHN_LORESERVE) {
+ 			pr_warn("struct_ops reloc %s: rel.r_offset %zu shdr_idx %u unsupported non-static function\n",
+ 				map->name, (size_t)rel.r_offset, shdr_idx);
+ 			return -LIBBPF_ERRNO__RELOC;
+ 		}
+ 
+ 		member = find_member_by_offset(st_ops->type, moff * 8);
+ 		if (!member) {
+ 			pr_warn("struct_ops reloc %s: cannot find member at moff %u\n",
+ 				map->name, moff);
+ 			return -EINVAL;
+ 		}
+ 		member_idx = member - btf_members(st_ops->type);
+ 		name = btf__name_by_offset(btf, member->name_off);
+ 
+ 		if (!resolve_func_ptr(btf, member->type, NULL)) {
+ 			pr_warn("struct_ops reloc %s: cannot relocate non func ptr %s\n",
+ 				map->name, name);
+ 			return -EINVAL;
+ 		}
+ 
+ 		prog = bpf_object__find_prog_by_idx(obj, shdr_idx);
+ 		if (!prog) {
+ 			pr_warn("struct_ops reloc %s: cannot find prog at shdr_idx %u to relocate func ptr %s\n",
+ 				map->name, shdr_idx, name);
+ 			return -EINVAL;
+ 		}
+ 
+ 		if (prog->type == BPF_PROG_TYPE_UNSPEC) {
+ 			const struct bpf_sec_def *sec_def;
+ 
+ 			sec_def = find_sec_def(prog->section_name);
+ 			if (sec_def &&
+ 			    sec_def->prog_type != BPF_PROG_TYPE_STRUCT_OPS) {
+ 				/* for pr_warn */
+ 				prog->type = sec_def->prog_type;
+ 				goto invalid_prog;
+ 			}
+ 
+ 			prog->type = BPF_PROG_TYPE_STRUCT_OPS;
+ 			prog->attach_btf_id = st_ops->type_id;
+ 			prog->expected_attach_type = member_idx;
+ 		} else if (prog->type != BPF_PROG_TYPE_STRUCT_OPS ||
+ 			   prog->attach_btf_id != st_ops->type_id ||
+ 			   prog->expected_attach_type != member_idx) {
+ 			goto invalid_prog;
+ 		}
+ 		st_ops->progs[member_idx] = prog;
+ 	}
+ 
+ 	return 0;
+ 
+ invalid_prog:
+ 	pr_warn("struct_ops reloc %s: cannot use prog %s in sec %s with type %u attach_btf_id %u expected_attach_type %u for func ptr %s\n",
+ 		map->name, prog->name, prog->section_name, prog->type,
+ 		prog->attach_btf_id, prog->expected_attach_type, name);
+ 	return -EINVAL;
+ }
+ 
+ #define BTF_PREFIX "btf_trace_"
+ int libbpf_find_vmlinux_btf_id(const char *name,
+ 			       enum bpf_attach_type attach_type)
+ {
+ 	struct btf *btf = bpf_find_kernel_btf();
+ 	char raw_tp_btf[128] = BTF_PREFIX;
+ 	char *dst = raw_tp_btf + sizeof(BTF_PREFIX) - 1;
+ 	const char *btf_name;
+ 	int err = -EINVAL;
+ 	__u32 kind;
+ 
+ 	if (IS_ERR(btf)) {
+ 		pr_warn("vmlinux BTF is not found\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (attach_type == BPF_TRACE_RAW_TP) {
+ 		/* prepend "btf_trace_" prefix per kernel convention */
+ 		strncat(dst, name, sizeof(raw_tp_btf) - sizeof(BTF_PREFIX));
+ 		btf_name = raw_tp_btf;
+ 		kind = BTF_KIND_TYPEDEF;
+ 	} else {
+ 		btf_name = name;
+ 		kind = BTF_KIND_FUNC;
+ 	}
+ 	err = btf__find_by_name_kind(btf, btf_name, kind);
+ 	btf__free(btf);
+ 	return err;
+ }
+ 
+ static int libbpf_find_prog_btf_id(const char *name, __u32 attach_prog_fd)
+ {
+ 	struct bpf_prog_info_linear *info_linear;
+ 	struct bpf_prog_info *info;
+ 	struct btf *btf = NULL;
+ 	int err = -EINVAL;
+ 
+ 	info_linear = bpf_program__get_prog_info_linear(attach_prog_fd, 0);
+ 	if (IS_ERR_OR_NULL(info_linear)) {
+ 		pr_warn("failed get_prog_info_linear for FD %d\n",
+ 			attach_prog_fd);
+ 		return -EINVAL;
+ 	}
+ 	info = &info_linear->info;
+ 	if (!info->btf_id) {
+ 		pr_warn("The target program doesn't have BTF\n");
+ 		goto out;
+ 	}
+ 	if (btf__get_from_id(info->btf_id, &btf)) {
+ 		pr_warn("Failed to get BTF of the program\n");
+ 		goto out;
+ 	}
+ 	err = btf__find_by_name_kind(btf, name, BTF_KIND_FUNC);
+ 	btf__free(btf);
+ 	if (err <= 0) {
+ 		pr_warn("%s is not found in prog's BTF\n", name);
+ 		goto out;
+ 	}
+ out:
+ 	free(info_linear);
+ 	return err;
+ }
+ 
+ static int libbpf_find_attach_btf_id(const char *name,
+ 				     enum bpf_attach_type attach_type,
+ 				     __u32 attach_prog_fd)
+ {
+ 	int i, err;
+ 
+ 	if (!name)
+ 		return -EINVAL;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(section_defs); i++) {
+ 		if (!section_defs[i].is_attach_btf)
+ 			continue;
+ 		if (strncmp(name, section_defs[i].sec, section_defs[i].len))
+ 			continue;
+ 		if (attach_prog_fd)
+ 			err = libbpf_find_prog_btf_id(name + section_defs[i].len,
+ 						      attach_prog_fd);
+ 		else
+ 			err = libbpf_find_vmlinux_btf_id(name + section_defs[i].len,
+ 							 attach_type);
+ 		if (err <= 0)
+ 			pr_warn("%s is not found in vmlinux BTF\n", name);
+ 		return err;
+ 	}
+ 	pr_warn("failed to identify btf_id based on ELF section name '%s'\n", name);
+ 	return -ESRCH;
+ }
+ 
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  int libbpf_attach_type_by_name(const char *name,
  			       enum bpf_attach_type *attach_type)
  {
@@@ -5841,6 -7328,114 +6554,117 @@@ struct bpf_link *bpf_program__attach_ra
  	return (struct bpf_link *)link;
  }
  
++<<<<<<< HEAD
++=======
+ static struct bpf_link *attach_raw_tp(const struct bpf_sec_def *sec,
+ 				      struct bpf_program *prog)
+ {
+ 	const char *tp_name = bpf_program__title(prog, false) + sec->len;
+ 
+ 	return bpf_program__attach_raw_tracepoint(prog, tp_name);
+ }
+ 
+ struct bpf_link *bpf_program__attach_trace(struct bpf_program *prog)
+ {
+ 	char errmsg[STRERR_BUFSIZE];
+ 	struct bpf_link_fd *link;
+ 	int prog_fd, pfd;
+ 
+ 	prog_fd = bpf_program__fd(prog);
+ 	if (prog_fd < 0) {
+ 		pr_warn("program '%s': can't attach before loaded\n",
+ 			bpf_program__title(prog, false));
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	link = calloc(1, sizeof(*link));
+ 	if (!link)
+ 		return ERR_PTR(-ENOMEM);
+ 	link->link.detach = &bpf_link__detach_fd;
+ 
+ 	pfd = bpf_raw_tracepoint_open(NULL, prog_fd);
+ 	if (pfd < 0) {
+ 		pfd = -errno;
+ 		free(link);
+ 		pr_warn("program '%s': failed to attach to trace: %s\n",
+ 			bpf_program__title(prog, false),
+ 			libbpf_strerror_r(pfd, errmsg, sizeof(errmsg)));
+ 		return ERR_PTR(pfd);
+ 	}
+ 	link->fd = pfd;
+ 	return (struct bpf_link *)link;
+ }
+ 
+ static struct bpf_link *attach_trace(const struct bpf_sec_def *sec,
+ 				     struct bpf_program *prog)
+ {
+ 	return bpf_program__attach_trace(prog);
+ }
+ 
+ struct bpf_link *bpf_program__attach(struct bpf_program *prog)
+ {
+ 	const struct bpf_sec_def *sec_def;
+ 
+ 	sec_def = find_sec_def(bpf_program__title(prog, false));
+ 	if (!sec_def || !sec_def->attach_fn)
+ 		return ERR_PTR(-ESRCH);
+ 
+ 	return sec_def->attach_fn(sec_def, prog);
+ }
+ 
+ static int bpf_link__detach_struct_ops(struct bpf_link *link)
+ {
+ 	struct bpf_link_fd *l = (void *)link;
+ 	__u32 zero = 0;
+ 
+ 	if (bpf_map_delete_elem(l->fd, &zero))
+ 		return -errno;
+ 
+ 	return 0;
+ }
+ 
+ struct bpf_link *bpf_map__attach_struct_ops(struct bpf_map *map)
+ {
+ 	struct bpf_struct_ops *st_ops;
+ 	struct bpf_link_fd *link;
+ 	__u32 i, zero = 0;
+ 	int err;
+ 
+ 	if (!bpf_map__is_struct_ops(map) || map->fd == -1)
+ 		return ERR_PTR(-EINVAL);
+ 
+ 	link = calloc(1, sizeof(*link));
+ 	if (!link)
+ 		return ERR_PTR(-EINVAL);
+ 
+ 	st_ops = map->st_ops;
+ 	for (i = 0; i < btf_vlen(st_ops->type); i++) {
+ 		struct bpf_program *prog = st_ops->progs[i];
+ 		void *kern_data;
+ 		int prog_fd;
+ 
+ 		if (!prog)
+ 			continue;
+ 
+ 		prog_fd = bpf_program__fd(prog);
+ 		kern_data = st_ops->kern_vdata + st_ops->kern_func_off[i];
+ 		*(unsigned long *)kern_data = prog_fd;
+ 	}
+ 
+ 	err = bpf_map_update_elem(map->fd, &zero, st_ops->kern_vdata, 0);
+ 	if (err) {
+ 		err = -errno;
+ 		free(link);
+ 		return ERR_PTR(err);
+ 	}
+ 
+ 	link->link.detach = bpf_link__detach_struct_ops;
+ 	link->fd = map->fd;
+ 
+ 	return (struct bpf_link *)link;
+ }
+ 
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  enum bpf_perf_event_ret
  bpf_perf_event_read_simple(void *mmap_mem, size_t mmap_size, size_t page_size,
  			   void **copy_mem, size_t *copy_size,
diff --cc tools/lib/bpf/libbpf.h
index e454ceec9fa2,01639f9a1062..000000000000
--- a/tools/lib/bpf/libbpf.h
+++ b/tools/lib/bpf/libbpf.h
@@@ -222,6 -237,10 +222,13 @@@ LIBBPF_API struct bpf_link 
  bpf_program__attach_raw_tracepoint(struct bpf_program *prog,
  				   const char *tp_name);
  
++<<<<<<< HEAD
++=======
+ LIBBPF_API struct bpf_link *
+ bpf_program__attach_trace(struct bpf_program *prog);
+ struct bpf_map;
+ LIBBPF_API struct bpf_link *bpf_map__attach_struct_ops(struct bpf_map *map);
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  struct bpf_insn;
  
  /*
@@@ -297,6 -316,8 +304,11 @@@ LIBBPF_API int bpf_program__set_sched_c
  LIBBPF_API int bpf_program__set_sched_act(struct bpf_program *prog);
  LIBBPF_API int bpf_program__set_xdp(struct bpf_program *prog);
  LIBBPF_API int bpf_program__set_perf_event(struct bpf_program *prog);
++<<<<<<< HEAD
++=======
+ LIBBPF_API int bpf_program__set_tracing(struct bpf_program *prog);
+ LIBBPF_API int bpf_program__set_struct_ops(struct bpf_program *prog);
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  
  LIBBPF_API enum bpf_prog_type bpf_program__get_type(struct bpf_program *prog);
  LIBBPF_API void bpf_program__set_type(struct bpf_program *prog,
@@@ -316,6 -337,8 +328,11 @@@ LIBBPF_API bool bpf_program__is_sched_c
  LIBBPF_API bool bpf_program__is_sched_act(const struct bpf_program *prog);
  LIBBPF_API bool bpf_program__is_xdp(const struct bpf_program *prog);
  LIBBPF_API bool bpf_program__is_perf_event(const struct bpf_program *prog);
++<<<<<<< HEAD
++=======
+ LIBBPF_API bool bpf_program__is_tracing(const struct bpf_program *prog);
+ LIBBPF_API bool bpf_program__is_struct_ops(const struct bpf_program *prog);
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  
  /*
   * No need for __attribute__((packed)), all members of 'bpf_map_def'
diff --cc tools/lib/bpf/libbpf.map
index 3ca7228af37e,a19f04e6e3d9..000000000000
--- a/tools/lib/bpf/libbpf.map
+++ b/tools/lib/bpf/libbpf.map
@@@ -188,9 -197,34 +188,35 @@@ LIBBPF_0.0.4 
  		bpf_map__get_pin_path;
  		bpf_map__is_pinned;
  		bpf_map__set_pin_path;
 -		bpf_object__open_file;
 -		bpf_object__open_mem;
 -		bpf_program__attach_trace;
  		bpf_program__get_expected_attach_type;
  		bpf_program__get_type;
 -		bpf_program__is_tracing;
 -		bpf_program__set_tracing;
 +		bpf_get_link_xdp_info;
  		bpf_program__size;
++<<<<<<< HEAD
 +		bpf_btf_get_next_id;
 +} LIBBPF_0.0.3;
++=======
+ 		btf__find_by_name_kind;
+ 		libbpf_find_vmlinux_btf_id;
+ } LIBBPF_0.0.5;
+ 
+ LIBBPF_0.0.7 {
+ 	global:
+ 		btf_dump__emit_type_decl;
+ 		bpf_link__disconnect;
+ 		bpf_map__attach_struct_ops;
+ 		bpf_object__find_program_by_name;
+ 		bpf_object__attach_skeleton;
+ 		bpf_object__destroy_skeleton;
+ 		bpf_object__detach_skeleton;
+ 		bpf_object__load_skeleton;
+ 		bpf_object__open_skeleton;
+ 		bpf_probe_large_insn_limit;
+ 		bpf_prog_attach_xattr;
+ 		bpf_program__attach;
+ 		bpf_program__name;
+ 		bpf_program__is_struct_ops;
+ 		bpf_program__set_struct_ops;
+ 		btf__align_of;
+ } LIBBPF_0.0.6;
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
diff --cc tools/lib/bpf/libbpf_probes.c
index 4b0b0364f5fc,320697f8e4c7..000000000000
--- a/tools/lib/bpf/libbpf_probes.c
+++ b/tools/lib/bpf/libbpf_probes.c
@@@ -102,6 -102,8 +102,11 @@@ probe_load(enum bpf_prog_type prog_type
  	case BPF_PROG_TYPE_FLOW_DISSECTOR:
  	case BPF_PROG_TYPE_CGROUP_SYSCTL:
  	case BPF_PROG_TYPE_CGROUP_SOCKOPT:
++<<<<<<< HEAD
++=======
+ 	case BPF_PROG_TYPE_TRACING:
+ 	case BPF_PROG_TYPE_STRUCT_OPS:
++>>>>>>> 590a00888250 (bpf: libbpf: Add STRUCT_OPS support)
  	default:
  		break;
  	}
* Unmerged path tools/lib/bpf/bpf.c
diff --git a/tools/lib/bpf/bpf.h b/tools/lib/bpf/bpf.h
index 2848c6333b5e..2dc9fd11bc67 100644
--- a/tools/lib/bpf/bpf.h
+++ b/tools/lib/bpf/bpf.h
@@ -46,7 +46,10 @@ struct bpf_create_map_attr {
 	__u32 btf_key_type_id;
 	__u32 btf_value_type_id;
 	__u32 map_ifindex;
-	__u32 inner_map_fd;
+	union {
+		__u32 inner_map_fd;
+		__u32 btf_vmlinux_value_type_id;
+	};
 };
 
 LIBBPF_API int
* Unmerged path tools/lib/bpf/libbpf.c
* Unmerged path tools/lib/bpf/libbpf.h
* Unmerged path tools/lib/bpf/libbpf.map
* Unmerged path tools/lib/bpf/libbpf_probes.c
