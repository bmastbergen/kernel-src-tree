libperf: Add 'flush' to 'struct perf_mmap'

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jiri Olsa <jolsa@kernel.org>
commit 65aa2e6bae3658cbc84c2e628a5c0ca163686204
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/65aa2e6b.failed

Move 'flush' from tools/perf's mmap to libperf's perf_mmap struct.

	Signed-off-by: Jiri Olsa <jolsa@kernel.org>
	Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
	Cc: Michael Petlan <mpetlan@redhat.com>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
Link: http://lore.kernel.org/lkml/20190913132355.21634-19-jolsa@kernel.org
	Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
(cherry picked from commit 65aa2e6bae3658cbc84c2e628a5c0ca163686204)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/perf/lib/include/internal/mmap.h
#	tools/perf/util/mmap.c
diff --cc tools/perf/util/mmap.c
index 850493205040,4cc3b54b2f73..000000000000
--- a/tools/perf/util/mmap.c
+++ b/tools/perf/util/mmap.c
@@@ -437,25 -440,25 +437,29 @@@ static int overwrite_rb_find_range(voi
  /*
   * Report the start and end of the available data in ringbuffer
   */
 -static int __perf_mmap__read_init(struct mmap *md)
 +static int __perf_mmap__read_init(struct perf_mmap *md)
  {
  	u64 head = perf_mmap__read_head(md);
 -	u64 old = md->core.prev;
 -	unsigned char *data = md->core.base + page_size;
 +	u64 old = md->prev;
 +	unsigned char *data = md->base + page_size;
  	unsigned long size;
  
 -	md->core.start = md->core.overwrite ? head : old;
 -	md->core.end = md->core.overwrite ? old : head;
 +	md->start = md->overwrite ? head : old;
 +	md->end = md->overwrite ? old : head;
  
++<<<<<<< HEAD
 +	if ((md->end - md->start) < md->flush)
++=======
+ 	if ((md->core.end - md->core.start) < md->core.flush)
++>>>>>>> 65aa2e6bae36 (libperf: Add 'flush' to 'struct perf_mmap')
  		return -EAGAIN;
  
 -	size = md->core.end - md->core.start;
 -	if (size > (unsigned long)(md->core.mask) + 1) {
 -		if (!md->core.overwrite) {
 +	size = md->end - md->start;
 +	if (size > (unsigned long)(md->mask) + 1) {
 +		if (!md->overwrite) {
  			WARN_ONCE(1, "failed to keep up with mmap data. (warn only once)\n");
  
 -			md->core.prev = head;
 +			md->prev = head;
  			perf_mmap__consume(md);
  			return -EAGAIN;
  		}
* Unmerged path tools/perf/lib/include/internal/mmap.h
diff --git a/tools/perf/builtin-record.c b/tools/perf/builtin-record.c
index de0619148499..226ba7298a23 100644
--- a/tools/perf/builtin-record.c
+++ b/tools/perf/builtin-record.c
@@ -969,13 +969,13 @@ static int record__mmap_read_evlist(struct record *rec, struct perf_evlist *evli
 		if (map->base) {
 			record__adjust_affinity(rec, map);
 			if (synch) {
-				flush = map->flush;
-				map->flush = 1;
+				flush = map->core.flush;
+				map->core.flush = 1;
 			}
 			if (!record__aio_enabled(rec)) {
 				if (perf_mmap__push(map, rec, record__pushfn) < 0) {
 					if (synch)
-						map->flush = flush;
+						map->core.flush = flush;
 					rc = -1;
 					goto out;
 				}
@@ -983,13 +983,13 @@ static int record__mmap_read_evlist(struct record *rec, struct perf_evlist *evli
 				if (record__aio_push(rec, map, &off) < 0) {
 					record__aio_set_pos(trace_fd, off);
 					if (synch)
-						map->flush = flush;
+						map->core.flush = flush;
 					rc = -1;
 					goto out;
 				}
 			}
 			if (synch)
-				map->flush = flush;
+				map->core.flush = flush;
 		}
 
 		if (map->auxtrace_mmap.base && !rec->opts.auxtrace_snapshot_mode &&
* Unmerged path tools/perf/lib/include/internal/mmap.h
* Unmerged path tools/perf/util/mmap.c
diff --git a/tools/perf/util/mmap.h b/tools/perf/util/mmap.h
index 274ce389cd84..832bfdf1ef62 100644
--- a/tools/perf/util/mmap.h
+++ b/tools/perf/util/mmap.h
@@ -39,7 +39,6 @@ struct perf_mmap {
 	} aio;
 #endif
 	cpu_set_t	affinity_mask;
-	u64		flush;
 	void		*data;
 	int		comp_level;
 };
