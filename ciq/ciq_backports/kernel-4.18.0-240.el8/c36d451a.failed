XArray: Fix xas_pause for large multi-index entries

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Matthew Wilcox (Oracle) <willy@infradead.org>
commit c36d451ad386b34f452fc3c8621ff14b9eaa31a6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/c36d451a.failed

Inspired by the recent Coverity report, I looked for other places where
the offset wasn't being converted to an unsigned long before being
shifted, and I found one in xas_pause() when the entry being paused is
of order >32.

Fixes: b803b42823d0 ("xarray: Add XArray iterators")
	Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
	Cc: stable@vger.kernel.org
(cherry picked from commit c36d451ad386b34f452fc3c8621ff14b9eaa31a6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	lib/test_xarray.c
diff --cc lib/test_xarray.c
index 19225670773b,d4f97925dbd8..000000000000
--- a/lib/test_xarray.c
+++ b/lib/test_xarray.c
@@@ -1061,6 -1101,140 +1061,143 @@@ static noinline void check_find(struct 
  	check_multi_find_3(xa);
  }
  
++<<<<<<< HEAD
++=======
+ /* See find_swap_entry() in mm/shmem.c */
+ static noinline unsigned long xa_find_entry(struct xarray *xa, void *item)
+ {
+ 	XA_STATE(xas, xa, 0);
+ 	unsigned int checked = 0;
+ 	void *entry;
+ 
+ 	rcu_read_lock();
+ 	xas_for_each(&xas, entry, ULONG_MAX) {
+ 		if (xas_retry(&xas, entry))
+ 			continue;
+ 		if (entry == item)
+ 			break;
+ 		checked++;
+ 		if ((checked % 4) != 0)
+ 			continue;
+ 		xas_pause(&xas);
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	return entry ? xas.xa_index : -1;
+ }
+ 
+ static noinline void check_find_entry(struct xarray *xa)
+ {
+ #ifdef CONFIG_XARRAY_MULTI
+ 	unsigned int order;
+ 	unsigned long offset, index;
+ 
+ 	for (order = 0; order < 20; order++) {
+ 		for (offset = 0; offset < (1UL << (order + 3));
+ 		     offset += (1UL << order)) {
+ 			for (index = 0; index < (1UL << (order + 5));
+ 			     index += (1UL << order)) {
+ 				xa_store_order(xa, index, order,
+ 						xa_mk_index(index), GFP_KERNEL);
+ 				XA_BUG_ON(xa, xa_load(xa, index) !=
+ 						xa_mk_index(index));
+ 				XA_BUG_ON(xa, xa_find_entry(xa,
+ 						xa_mk_index(index)) != index);
+ 			}
+ 			XA_BUG_ON(xa, xa_find_entry(xa, xa) != -1);
+ 			xa_destroy(xa);
+ 		}
+ 	}
+ #endif
+ 
+ 	XA_BUG_ON(xa, xa_find_entry(xa, xa) != -1);
+ 	xa_store_index(xa, ULONG_MAX, GFP_KERNEL);
+ 	XA_BUG_ON(xa, xa_find_entry(xa, xa) != -1);
+ 	XA_BUG_ON(xa, xa_find_entry(xa, xa_mk_index(ULONG_MAX)) != -1);
+ 	xa_erase_index(xa, ULONG_MAX);
+ 	XA_BUG_ON(xa, !xa_empty(xa));
+ }
+ 
+ static noinline void check_pause(struct xarray *xa)
+ {
+ 	XA_STATE(xas, xa, 0);
+ 	void *entry;
+ 	unsigned int order;
+ 	unsigned long index = 1;
+ 	unsigned int count = 0;
+ 
+ 	for (order = 0; order < order_limit; order++) {
+ 		XA_BUG_ON(xa, xa_store_order(xa, index, order,
+ 					xa_mk_index(index), GFP_KERNEL));
+ 		index += 1UL << order;
+ 	}
+ 
+ 	rcu_read_lock();
+ 	xas_for_each(&xas, entry, ULONG_MAX) {
+ 		XA_BUG_ON(xa, entry != xa_mk_index(1UL << count));
+ 		count++;
+ 	}
+ 	rcu_read_unlock();
+ 	XA_BUG_ON(xa, count != order_limit);
+ 
+ 	count = 0;
+ 	xas_set(&xas, 0);
+ 	rcu_read_lock();
+ 	xas_for_each(&xas, entry, ULONG_MAX) {
+ 		XA_BUG_ON(xa, entry != xa_mk_index(1UL << count));
+ 		count++;
+ 		xas_pause(&xas);
+ 	}
+ 	rcu_read_unlock();
+ 	XA_BUG_ON(xa, count != order_limit);
+ 
+ 	xa_destroy(xa);
+ }
+ 
+ static noinline void check_move_tiny(struct xarray *xa)
+ {
+ 	XA_STATE(xas, xa, 0);
+ 
+ 	XA_BUG_ON(xa, !xa_empty(xa));
+ 	rcu_read_lock();
+ 	XA_BUG_ON(xa, xas_next(&xas) != NULL);
+ 	XA_BUG_ON(xa, xas_next(&xas) != NULL);
+ 	rcu_read_unlock();
+ 	xa_store_index(xa, 0, GFP_KERNEL);
+ 	rcu_read_lock();
+ 	xas_set(&xas, 0);
+ 	XA_BUG_ON(xa, xas_next(&xas) != xa_mk_index(0));
+ 	XA_BUG_ON(xa, xas_next(&xas) != NULL);
+ 	xas_set(&xas, 0);
+ 	XA_BUG_ON(xa, xas_prev(&xas) != xa_mk_index(0));
+ 	XA_BUG_ON(xa, xas_prev(&xas) != NULL);
+ 	rcu_read_unlock();
+ 	xa_erase_index(xa, 0);
+ 	XA_BUG_ON(xa, !xa_empty(xa));
+ }
+ 
+ static noinline void check_move_max(struct xarray *xa)
+ {
+ 	XA_STATE(xas, xa, 0);
+ 
+ 	xa_store_index(xa, ULONG_MAX, GFP_KERNEL);
+ 	rcu_read_lock();
+ 	XA_BUG_ON(xa, xas_find(&xas, ULONG_MAX) != xa_mk_index(ULONG_MAX));
+ 	XA_BUG_ON(xa, xas_find(&xas, ULONG_MAX) != NULL);
+ 	rcu_read_unlock();
+ 
+ 	xas_set(&xas, 0);
+ 	rcu_read_lock();
+ 	XA_BUG_ON(xa, xas_find(&xas, ULONG_MAX) != xa_mk_index(ULONG_MAX));
+ 	xas_pause(&xas);
+ 	XA_BUG_ON(xa, xas_find(&xas, ULONG_MAX) != NULL);
+ 	rcu_read_unlock();
+ 
+ 	xa_erase_index(xa, ULONG_MAX);
+ 	XA_BUG_ON(xa, !xa_empty(xa));
+ }
+ 
++>>>>>>> c36d451ad386 (XArray: Fix xas_pause for large multi-index entries)
  static noinline void check_move_small(struct xarray *xa, unsigned long idx)
  {
  	XA_STATE(xas, xa, 0);
@@@ -1461,6 -1699,8 +1598,11 @@@ static int xarray_checks(void
  	check_multi_store(&array);
  	check_xa_alloc();
  	check_find(&array);
++<<<<<<< HEAD
++=======
+ 	check_find_entry(&array);
+ 	check_pause(&array);
++>>>>>>> c36d451ad386 (XArray: Fix xas_pause for large multi-index entries)
  	check_account(&array);
  	check_destroy(&array);
  	check_move(&array);
* Unmerged path lib/test_xarray.c
diff --git a/lib/xarray.c b/lib/xarray.c
index 396b1f9a50a6..da435f9d486b 100644
--- a/lib/xarray.c
+++ b/lib/xarray.c
@@ -969,7 +969,7 @@ void xas_pause(struct xa_state *xas)
 		return;
 
 	if (node) {
-		unsigned int offset = xas->xa_offset;
+		unsigned long offset = xas->xa_offset;
 		while (++offset < XA_CHUNK_SIZE) {
 			if (!xa_is_sibling(xa_entry(xas->xa, node, offset)))
 				break;
