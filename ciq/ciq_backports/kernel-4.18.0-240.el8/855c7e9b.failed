KVM: x86: Fix BUILD_BUG() in __cpuid_entry_get_reg() w/ CONFIG_UBSAN=y

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit 855c7e9b9c2c39fb8d108ac70d0eed530f80a2aa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/855c7e9b.failed

Take the target reg in __cpuid_entry_get_reg() instead of a pointer to a
struct cpuid_reg.  When building with -fsanitize=alignment (enabled by
CONFIG_UBSAN=y), some versions of gcc get tripped up on the pointer and
trigger the BUILD_BUG().

	Reported-by: Randy Dunlap <rdunlap@infradead.org>
Fixes: d8577a4c238f8 ("KVM: x86: Do host CPUID at load time to mask KVM cpu caps")
Fixes: 4c61534aaae2a ("KVM: x86: Introduce cpuid_entry_{get,has}() accessors")
	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
Message-Id: <20200325191259.23559-1-sean.j.christopherson@intel.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 855c7e9b9c2c39fb8d108ac70d0eed530f80a2aa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/cpuid.c
diff --cc arch/x86/kvm/cpuid.c
index 78d6db1ce0f2,901cd1fdecd9..000000000000
--- a/arch/x86/kvm/cpuid.c
+++ b/arch/x86/kvm/cpuid.c
@@@ -285,12 -258,173 +285,25 @@@ out
  	return r;
  }
  
 -static __always_inline void kvm_cpu_cap_mask(enum cpuid_leafs leaf, u32 mask)
 +static __always_inline void cpuid_mask(u32 *word, int wordnum)
  {
++<<<<<<< HEAD
 +	reverse_cpuid_check(wordnum);
 +	*word &= boot_cpu_data.x86_capability[wordnum];
++=======
+ 	const struct cpuid_reg cpuid = x86_feature_cpuid(leaf * 32);
+ 	struct kvm_cpuid_entry2 entry;
+ 
+ 	reverse_cpuid_check(leaf);
+ 	kvm_cpu_caps[leaf] &= mask;
+ 
+ 	cpuid_count(cpuid.function, cpuid.index,
+ 		    &entry.eax, &entry.ebx, &entry.ecx, &entry.edx);
+ 
+ 	kvm_cpu_caps[leaf] &= *__cpuid_entry_get_reg(&entry, cpuid.reg);
++>>>>>>> 855c7e9b9c2c (KVM: x86: Fix BUILD_BUG() in __cpuid_entry_get_reg() w/ CONFIG_UBSAN=y)
  }
  
 -void kvm_set_cpu_caps(void)
 -{
 -	unsigned int f_nx = is_efer_nx() ? F(NX) : 0;
 -#ifdef CONFIG_X86_64
 -	unsigned int f_gbpages = F(GBPAGES);
 -	unsigned int f_lm = F(LM);
 -#else
 -	unsigned int f_gbpages = 0;
 -	unsigned int f_lm = 0;
 -#endif
 -
 -	BUILD_BUG_ON(sizeof(kvm_cpu_caps) >
 -		     sizeof(boot_cpu_data.x86_capability));
 -
 -	memcpy(&kvm_cpu_caps, &boot_cpu_data.x86_capability,
 -	       sizeof(kvm_cpu_caps));
 -
 -	kvm_cpu_cap_mask(CPUID_1_ECX,
 -		/*
 -		 * NOTE: MONITOR (and MWAIT) are emulated as NOP, but *not*
 -		 * advertised to guests via CPUID!
 -		 */
 -		F(XMM3) | F(PCLMULQDQ) | 0 /* DTES64, MONITOR */ |
 -		0 /* DS-CPL, VMX, SMX, EST */ |
 -		0 /* TM2 */ | F(SSSE3) | 0 /* CNXT-ID */ | 0 /* Reserved */ |
 -		F(FMA) | F(CX16) | 0 /* xTPR Update, PDCM */ |
 -		F(PCID) | 0 /* Reserved, DCA */ | F(XMM4_1) |
 -		F(XMM4_2) | F(X2APIC) | F(MOVBE) | F(POPCNT) |
 -		0 /* Reserved*/ | F(AES) | F(XSAVE) | 0 /* OSXSAVE */ | F(AVX) |
 -		F(F16C) | F(RDRAND)
 -	);
 -	/* KVM emulates x2apic in software irrespective of host support. */
 -	kvm_cpu_cap_set(X86_FEATURE_X2APIC);
 -
 -	kvm_cpu_cap_mask(CPUID_1_EDX,
 -		F(FPU) | F(VME) | F(DE) | F(PSE) |
 -		F(TSC) | F(MSR) | F(PAE) | F(MCE) |
 -		F(CX8) | F(APIC) | 0 /* Reserved */ | F(SEP) |
 -		F(MTRR) | F(PGE) | F(MCA) | F(CMOV) |
 -		F(PAT) | F(PSE36) | 0 /* PSN */ | F(CLFLUSH) |
 -		0 /* Reserved, DS, ACPI */ | F(MMX) |
 -		F(FXSR) | F(XMM) | F(XMM2) | F(SELFSNOOP) |
 -		0 /* HTT, TM, Reserved, PBE */
 -	);
 -
 -	kvm_cpu_cap_mask(CPUID_7_0_EBX,
 -		F(FSGSBASE) | F(BMI1) | F(HLE) | F(AVX2) | F(SMEP) |
 -		F(BMI2) | F(ERMS) | 0 /*INVPCID*/ | F(RTM) | 0 /*MPX*/ | F(RDSEED) |
 -		F(ADX) | F(SMAP) | F(AVX512IFMA) | F(AVX512F) | F(AVX512PF) |
 -		F(AVX512ER) | F(AVX512CD) | F(CLFLUSHOPT) | F(CLWB) | F(AVX512DQ) |
 -		F(SHA_NI) | F(AVX512BW) | F(AVX512VL) | 0 /*INTEL_PT*/
 -	);
 -
 -	kvm_cpu_cap_mask(CPUID_7_ECX,
 -		F(AVX512VBMI) | F(LA57) | 0 /*PKU*/ | 0 /*OSPKE*/ | F(RDPID) |
 -		F(AVX512_VPOPCNTDQ) | F(UMIP) | F(AVX512_VBMI2) | F(GFNI) |
 -		F(VAES) | F(VPCLMULQDQ) | F(AVX512_VNNI) | F(AVX512_BITALG) |
 -		F(CLDEMOTE) | F(MOVDIRI) | F(MOVDIR64B) | 0 /*WAITPKG*/
 -	);
 -	/* Set LA57 based on hardware capability. */
 -	if (cpuid_ecx(7) & F(LA57))
 -		kvm_cpu_cap_set(X86_FEATURE_LA57);
 -
 -	kvm_cpu_cap_mask(CPUID_7_EDX,
 -		F(AVX512_4VNNIW) | F(AVX512_4FMAPS) | F(SPEC_CTRL) |
 -		F(SPEC_CTRL_SSBD) | F(ARCH_CAPABILITIES) | F(INTEL_STIBP) |
 -		F(MD_CLEAR) | F(AVX512_VP2INTERSECT) | F(FSRM)
 -	);
 -
 -	/* TSC_ADJUST and ARCH_CAPABILITIES are emulated in software. */
 -	kvm_cpu_cap_set(X86_FEATURE_TSC_ADJUST);
 -	kvm_cpu_cap_set(X86_FEATURE_ARCH_CAPABILITIES);
 -
 -	if (boot_cpu_has(X86_FEATURE_IBPB) && boot_cpu_has(X86_FEATURE_IBRS))
 -		kvm_cpu_cap_set(X86_FEATURE_SPEC_CTRL);
 -	if (boot_cpu_has(X86_FEATURE_STIBP))
 -		kvm_cpu_cap_set(X86_FEATURE_INTEL_STIBP);
 -	if (boot_cpu_has(X86_FEATURE_AMD_SSBD))
 -		kvm_cpu_cap_set(X86_FEATURE_SPEC_CTRL_SSBD);
 -
 -	kvm_cpu_cap_mask(CPUID_7_1_EAX,
 -		F(AVX512_BF16)
 -	);
 -
 -	kvm_cpu_cap_mask(CPUID_D_1_EAX,
 -		F(XSAVEOPT) | F(XSAVEC) | F(XGETBV1) | F(XSAVES)
 -	);
 -
 -	kvm_cpu_cap_mask(CPUID_8000_0001_ECX,
 -		F(LAHF_LM) | F(CMP_LEGACY) | 0 /*SVM*/ | 0 /* ExtApicSpace */ |
 -		F(CR8_LEGACY) | F(ABM) | F(SSE4A) | F(MISALIGNSSE) |
 -		F(3DNOWPREFETCH) | F(OSVW) | 0 /* IBS */ | F(XOP) |
 -		0 /* SKINIT, WDT, LWP */ | F(FMA4) | F(TBM) |
 -		F(TOPOEXT) | F(PERFCTR_CORE)
 -	);
 -
 -	kvm_cpu_cap_mask(CPUID_8000_0001_EDX,
 -		F(FPU) | F(VME) | F(DE) | F(PSE) |
 -		F(TSC) | F(MSR) | F(PAE) | F(MCE) |
 -		F(CX8) | F(APIC) | 0 /* Reserved */ | F(SYSCALL) |
 -		F(MTRR) | F(PGE) | F(MCA) | F(CMOV) |
 -		F(PAT) | F(PSE36) | 0 /* Reserved */ |
 -		f_nx | 0 /* Reserved */ | F(MMXEXT) | F(MMX) |
 -		F(FXSR) | F(FXSR_OPT) | f_gbpages | F(RDTSCP) |
 -		0 /* Reserved */ | f_lm | F(3DNOWEXT) | F(3DNOW)
 -	);
 -
 -	if (!tdp_enabled && IS_ENABLED(CONFIG_X86_64))
 -		kvm_cpu_cap_set(X86_FEATURE_GBPAGES);
 -
 -	kvm_cpu_cap_mask(CPUID_8000_0008_EBX,
 -		F(CLZERO) | F(XSAVEERPTR) |
 -		F(WBNOINVD) | F(AMD_IBPB) | F(AMD_IBRS) | F(AMD_SSBD) | F(VIRT_SSBD) |
 -		F(AMD_SSB_NO) | F(AMD_STIBP) | F(AMD_STIBP_ALWAYS_ON)
 -	);
 -
 -	/*
 -	 * AMD has separate bits for each SPEC_CTRL bit.
 -	 * arch/x86/kernel/cpu/bugs.c is kind enough to
 -	 * record that in cpufeatures so use them.
 -	 */
 -	if (boot_cpu_has(X86_FEATURE_IBPB))
 -		kvm_cpu_cap_set(X86_FEATURE_AMD_IBPB);
 -	if (boot_cpu_has(X86_FEATURE_IBRS))
 -		kvm_cpu_cap_set(X86_FEATURE_AMD_IBRS);
 -	if (boot_cpu_has(X86_FEATURE_STIBP))
 -		kvm_cpu_cap_set(X86_FEATURE_AMD_STIBP);
 -	if (boot_cpu_has(X86_FEATURE_SPEC_CTRL_SSBD))
 -		kvm_cpu_cap_set(X86_FEATURE_AMD_SSBD);
 -	if (!boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))
 -		kvm_cpu_cap_set(X86_FEATURE_AMD_SSB_NO);
 -	/*
 -	 * The preference is to use SPEC CTRL MSR instead of the
 -	 * VIRT_SPEC MSR.
 -	 */
 -	if (boot_cpu_has(X86_FEATURE_LS_CFG_SSBD) &&
 -	    !boot_cpu_has(X86_FEATURE_AMD_SSBD))
 -		kvm_cpu_cap_set(X86_FEATURE_VIRT_SSBD);
 -
 -	/*
 -	 * Hide all SVM features by default, SVM will set the cap bits for
 -	 * features it emulates and/or exposes for L1.
 -	 */
 -	kvm_cpu_cap_mask(CPUID_8000_000A_EDX, 0);
 -
 -	kvm_cpu_cap_mask(CPUID_C000_0001_EDX,
 -		F(XSTORE) | F(XSTORE_EN) | F(XCRYPT) | F(XCRYPT_EN) |
 -		F(ACE2) | F(ACE2_EN) | F(PHE) | F(PHE_EN) |
 -		F(PMM) | F(PMM_EN)
 -	);
 -}
 -EXPORT_SYMBOL_GPL(kvm_set_cpu_caps);
 -
  struct kvm_cpuid_array {
  	struct kvm_cpuid_entry2 *entries;
  	const int maxnent;
* Unmerged path arch/x86/kvm/cpuid.c
diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index a2335b92a9a0..9a4239403f83 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -97,9 +97,9 @@ static __always_inline struct cpuid_reg x86_feature_cpuid(unsigned int x86_featu
 }
 
 static __always_inline u32 *__cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry,
-						  const struct cpuid_reg *cpuid)
+						  u32 reg)
 {
-	switch (cpuid->reg) {
+	switch (reg) {
 	case CPUID_EAX:
 		return &entry->eax;
 	case CPUID_EBX:
@@ -119,7 +119,7 @@ static __always_inline u32 *cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry,
 {
 	const struct cpuid_reg cpuid = x86_feature_cpuid(x86_feature);
 
-	return __cpuid_entry_get_reg(entry, &cpuid);
+	return __cpuid_entry_get_reg(entry, cpuid.reg);
 }
 
 static __always_inline u32 cpuid_entry_get(struct kvm_cpuid_entry2 *entry,
@@ -146,7 +146,7 @@ static __always_inline u32 *guest_cpuid_get_register(struct kvm_vcpu *vcpu,
 	if (!entry)
 		return NULL;
 
-	return __cpuid_entry_get_reg(entry, &cpuid);
+	return __cpuid_entry_get_reg(entry, cpuid.reg);
 }
 
 static __always_inline bool guest_cpuid_has(struct kvm_vcpu *vcpu,
