KVM: Move vcpu alloc and init invocation to common code

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit e529ef66e6b53b34f9b8caac55950c8a55c79dac
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/e529ef66.failed

Now that all architectures tightly couple vcpu allocation/free with the
mandatory calls to kvm_{un}init_vcpu(), move the sequences verbatim to
common KVM code.

Move both allocation and initialization in a single patch to eliminate
thrash in arch specific code.  The bisection benefits of moving the two
pieces in separate patches is marginal at best, whereas the odds of
introducing a transient arch specific bug are non-zero.

	Acked-by: Christoffer Dall <christoffer.dall@arm.com>
	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
	Reviewed-by: Cornelia Huck <cohuck@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit e529ef66e6b53b34f9b8caac55950c8a55c79dac)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/mips/kvm/mips.c
#	arch/powerpc/kvm/powerpc.c
#	arch/s390/kvm/kvm-s390.c
#	arch/x86/kvm/x86.c
#	include/linux/kvm_host.h
#	virt/kvm/arm/arm.c
#	virt/kvm/kvm_main.c
diff --cc arch/mips/kvm/mips.c
index 6d4b49925bf8,92c9321b3f95..000000000000
--- a/arch/mips/kvm/mips.c
+++ b/arch/mips/kvm/mips.c
@@@ -280,25 -280,19 +280,39 @@@ static inline void dump_handler(const c
  	pr_debug("\tEND(%s)\n", symbol);
  }
  
++<<<<<<< HEAD
 +struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id)
++=======
+ int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
+ {
+ 	return 0;
+ }
+ 
+ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  {
  	int err, size;
  	void *gebase, *p, *handler, *refill_start, *refill_end;
  	int i;
  
++<<<<<<< HEAD
 +	struct kvm_vcpu *vcpu = kzalloc(sizeof(struct kvm_vcpu), GFP_KERNEL);
 +
 +	if (!vcpu) {
 +		err = -ENOMEM;
 +		goto out;
 +	}
 +
 +	err = kvm_vcpu_init(vcpu, kvm, id);
 +
 +	if (err)
 +		goto out_free_cpu;
 +
 +	kvm_debug("kvm @ %p: create cpu %d at %p\n", kvm, id, vcpu);
++=======
+ 	kvm_debug("kvm @ %p: create cpu %d at %p\n",
+ 		  vcpu->kvm, vcpu->vcpu_id, vcpu);
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  
  	/*
  	 * Allocate space for host mode exception handlers that handle
@@@ -396,18 -390,11 +410,21 @@@
  
  out_free_gebase:
  	kfree(gebase);
++<<<<<<< HEAD
 +
 +out_uninit_cpu:
 +	kvm_vcpu_uninit(vcpu);
 +
 +out_free_cpu:
 +	kfree(vcpu);
 +
++=======
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  out:
- 	return ERR_PTR(err);
+ 	return err;
  }
  
 -void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu)
 +void kvm_arch_vcpu_free(struct kvm_vcpu *vcpu)
  {
  	hrtimer_cancel(&vcpu->arch.comparecount_timer);
  
@@@ -418,12 -403,6 +435,15 @@@
  	kvm_mmu_free_memory_caches(vcpu);
  	kfree(vcpu->arch.guest_ebase);
  	kfree(vcpu->arch.kseg0_commpage);
++<<<<<<< HEAD
 +	kfree(vcpu);
 +}
 +
 +void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu)
 +{
 +	kvm_arch_vcpu_free(vcpu);
++=======
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  }
  
  int kvm_arch_vcpu_ioctl_set_guest_debug(struct kvm_vcpu *vcpu,
diff --cc arch/powerpc/kvm/powerpc.c
index 124aecce15bf,fce1b4776e55..000000000000
--- a/arch/powerpc/kvm/powerpc.c
+++ b/arch/powerpc/kvm/powerpc.c
@@@ -728,18 -720,14 +728,18 @@@ void kvm_arch_flush_shadow_memslot(stru
  	kvmppc_core_flush_memslot(kvm, slot);
  }
  
++<<<<<<< HEAD
 +struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id)
++=======
+ int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
  {
- 	struct kvm_vcpu *vcpu;
- 	int err;
- 
- 	vcpu = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);
- 	if (!vcpu)
- 		return ERR_PTR(-ENOMEM);
+ 	return 0;
+ }
  
- 	err = kvm_vcpu_init(vcpu, kvm, id);
- 	if (err)
- 		goto free_vcpu;
+ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
+ {
+ 	int err;
  
  	err = kvmppc_core_vcpu_create(vcpu);
  	if (err)
diff --cc arch/s390/kvm/kvm-s390.c
index d6b727e2f0a2,9cba1e5d033b..000000000000
--- a/arch/s390/kvm/kvm-s390.c
+++ b/arch/s390/kvm/kvm-s390.c
@@@ -3010,28 -3004,18 +3007,26 @@@ int kvm_arch_vcpu_setup(struct kvm_vcp
  	return rc;
  }
  
++<<<<<<< HEAD
 +struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,
 +				      unsigned int id)
++=======
+ int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
+ {
+ 	if (!kvm_is_ucontrol(kvm) && !sca_can_add_vcpu(kvm, id))
+ 		return -EINVAL;
+ 	return 0;
+ }
+ 
+ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  {
- 	struct kvm_vcpu *vcpu;
  	struct sie_page *sie_page;
 -	int rc;
 +	int rc = -EINVAL;
 +
 +	if (!kvm_is_ucontrol(kvm) && !sca_can_add_vcpu(kvm, id))
 +		goto out;
  
- 	rc = -ENOMEM;
- 
- 	vcpu = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);
- 	if (!vcpu)
- 		goto out;
- 
- 	rc = kvm_vcpu_init(vcpu, kvm, id);
- 	if (rc)
- 		goto out_free_cpu;
- 
- 	rc = -ENOMEM;
- 
  	BUILD_BUG_ON(sizeof(struct sie_page) != 4096);
  	sie_page = (struct sie_page *) get_zeroed_page(GFP_KERNEL);
  	if (!sie_page)
diff --cc arch/x86/kvm/x86.c
index fd0e26bb25de,7bbde6f658bf..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -9148,29 -9170,18 +9148,32 @@@ static void fx_init(struct kvm_vcpu *vc
  	vcpu->arch.cr0 |= X86_CR0_ET;
  }
  
 -int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
 +void kvm_arch_vcpu_free(struct kvm_vcpu *vcpu)
  {
 -	if (kvm_check_tsc_unstable() && atomic_read(&kvm->online_vcpus) != 0)
 -		pr_warn_once("kvm: SMP vm created on host with unstable TSC; "
 -			     "guest TSC will not be reliable\n");
 +	void *wbinvd_dirty_mask = vcpu->arch.wbinvd_dirty_mask;
  
 -	return 0;
 +	kvmclock_reset(vcpu);
 +
 +	kvm_x86_ops->vcpu_free(vcpu);
 +	free_cpumask_var(wbinvd_dirty_mask);
  }
  
- struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,
- 						unsigned int id)
+ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	struct kvm_vcpu *vcpu;
 +
 +	if (kvm_check_tsc_unstable() && atomic_read(&kvm->online_vcpus) != 0)
 +		printk_once(KERN_WARNING
 +		"kvm: SMP vm created on host with unstable TSC; "
 +		"guest TSC will not be reliable\n");
 +
 +	vcpu = kvm_x86_ops->vcpu_create(kvm, id);
 +
 +	return vcpu;
++=======
+ 	return kvm_x86_ops->vcpu_create(vcpu);
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  }
  
  int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)
@@@ -9215,7 -9226,13 +9218,17 @@@ void kvm_arch_vcpu_postcreate(struct kv
  
  void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	kvm_arch_vcpu_free(vcpu);
++=======
+ 	kvmclock_reset(vcpu);
+ 
+ 	kvm_x86_ops->vcpu_free(vcpu);
+ 
+ 	free_cpumask_var(vcpu->arch.wbinvd_dirty_mask);
+ 	kmem_cache_free(x86_fpu_cache, vcpu->arch.user_fpu);
+ 	kmem_cache_free(x86_fpu_cache, vcpu->arch.guest_fpu);
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  }
  
  void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
diff --cc include/linux/kvm_host.h
index 76c481d92694,405ea07068f1..000000000000
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@@ -877,7 -875,8 +877,12 @@@ void kvm_arch_sched_in(struct kvm_vcpu 
  
  void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu);
  void kvm_arch_vcpu_put(struct kvm_vcpu *vcpu);
++<<<<<<< HEAD
 +struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id);
++=======
+ int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id);
+ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu);
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu);
  void kvm_arch_vcpu_postcreate(struct kvm_vcpu *vcpu);
  void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu);
diff --cc virt/kvm/arm/arm.c
index f41a18f358a9,a7d661fc5683..000000000000
--- a/virt/kvm/arm/arm.c
+++ b/virt/kvm/arm/arm.c
@@@ -265,42 -279,20 +265,59 @@@ void kvm_arch_free_vm(struct kvm *kvm
  		vfree(kvm);
  }
  
++<<<<<<< HEAD
 +struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id)
 +{
 +	int err;
 +	struct kvm_vcpu *vcpu;
 +
 +	if (irqchip_in_kernel(kvm) && vgic_initialized(kvm)) {
 +		err = -EBUSY;
 +		goto out;
 +	}
 +
 +	if (id >= kvm->arch.max_vcpus) {
 +		err = -EINVAL;
 +		goto out;
 +	}
 +
 +	vcpu = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);
 +	if (!vcpu) {
 +		err = -ENOMEM;
 +		goto out;
 +	}
 +
 +	err = kvm_vcpu_init(vcpu, kvm, id);
 +	if (err)
 +		goto free_vcpu;
 +
 +	err = create_hyp_mappings(vcpu, vcpu + 1, PAGE_HYP);
 +	if (err)
 +		goto vcpu_uninit;
 +
 +	return vcpu;
 +vcpu_uninit:
 +	kvm_vcpu_uninit(vcpu);
 +free_vcpu:
 +	kmem_cache_free(kvm_vcpu_cache, vcpu);
 +out:
 +	return ERR_PTR(err);
++=======
+ int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
+ {
+ 	if (irqchip_in_kernel(kvm) && vgic_initialized(kvm))
+ 		return -EBUSY;
+ 
+ 	if (id >= kvm->arch.max_vcpus)
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
+ {
+ 	return create_hyp_mappings(vcpu, vcpu + 1, PAGE_HYP);
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  }
  
  void kvm_arch_vcpu_postcreate(struct kvm_vcpu *vcpu)
diff --cc virt/kvm/kvm_main.c
index c6256c9afce6,c84df40518c4..000000000000
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@@ -377,6 -375,15 +377,18 @@@ void kvm_vcpu_uninit(struct kvm_vcpu *v
  }
  EXPORT_SYMBOL_GPL(kvm_vcpu_uninit);
  
++<<<<<<< HEAD
++=======
+ void kvm_vcpu_destroy(struct kvm_vcpu *vcpu)
+ {
+ 	kvm_arch_vcpu_destroy(vcpu);
+ 
+ 	kvm_vcpu_uninit(vcpu);
+ 	kmem_cache_free(kvm_vcpu_cache, vcpu);
+ }
+ EXPORT_SYMBOL_GPL(kvm_vcpu_destroy);
+ 
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  #if defined(CONFIG_MMU_NOTIFIER) && defined(KVM_ARCH_WANT_MMU_NOTIFIER)
  static inline struct kvm *mmu_notifier_to_kvm(struct mmu_notifier *mn)
  {
@@@ -2730,9 -2737,13 +2742,19 @@@ static int kvm_vm_ioctl_create_vcpu(str
  	kvm->created_vcpus++;
  	mutex_unlock(&kvm->lock);
  
++<<<<<<< HEAD
 +	vcpu = kvm_arch_vcpu_create(kvm, id);
 +	if (IS_ERR(vcpu)) {
 +		r = PTR_ERR(vcpu);
++=======
+ 	r = kvm_arch_vcpu_precreate(kvm, id);
+ 	if (r)
+ 		goto vcpu_decrement;
+ 
+ 	vcpu = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);
+ 	if (!vcpu) {
+ 		r = -ENOMEM;
++>>>>>>> e529ef66e6b5 (KVM: Move vcpu alloc and init invocation to common code)
  		goto vcpu_decrement;
  	}
  
* Unmerged path arch/mips/kvm/mips.c
* Unmerged path arch/powerpc/kvm/powerpc.c
* Unmerged path arch/s390/kvm/kvm-s390.c
* Unmerged path arch/x86/kvm/x86.c
* Unmerged path include/linux/kvm_host.h
* Unmerged path virt/kvm/arm/arm.c
* Unmerged path virt/kvm/kvm_main.c
