bpf: Added new helper bpf_get_ns_current_pid_tgid

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Carlos Neira <cneirabustos@gmail.com>
commit b4490c5c4e023f09b7d27c9a9d3e7ad7d09ea6bf
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/b4490c5c.failed

New bpf helper bpf_get_ns_current_pid_tgid,
This helper will return pid and tgid from current task
which namespace matches dev_t and inode number provided,
this will allows us to instrument a process inside a container.

	Signed-off-by: Carlos Neira <cneirabustos@gmail.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Yonghong Song <yhs@fb.com>
Link: https://lore.kernel.org/bpf/20200304204157.58695-3-cneirabustos@gmail.com
(cherry picked from commit b4490c5c4e023f09b7d27c9a9d3e7ad7d09ea6bf)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	include/uapi/linux/bpf.h
#	kernel/bpf/helpers.c
#	kernel/trace/bpf_trace.c
#	tools/include/uapi/linux/bpf.h
diff --cc include/linux/bpf.h
index c1c99fdb999a,4ec835334a1f..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -1098,6 -1496,8 +1098,11 @@@ extern const struct bpf_func_proto bpf_
  extern const struct bpf_func_proto bpf_strtol_proto;
  extern const struct bpf_func_proto bpf_strtoul_proto;
  extern const struct bpf_func_proto bpf_tcp_sock_proto;
++<<<<<<< HEAD
++=======
+ extern const struct bpf_func_proto bpf_jiffies64_proto;
+ extern const struct bpf_func_proto bpf_get_ns_current_pid_tgid_proto;
++>>>>>>> b4490c5c4e02 (bpf: Added new helper bpf_get_ns_current_pid_tgid)
  
  /* Shared helpers among cBPF and eBPF. */
  void bpf_user_rnd_init_once(void);
diff --cc include/uapi/linux/bpf.h
index c9871d53e313,15b239da775b..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -2757,6 -2778,155 +2757,158 @@@ union bpf_attr 
   *		**-EOPNOTSUPP** kernel configuration does not enable SYN cookies
   *
   *		**-EPROTONOSUPPORT** IP packet version is not 4 or 6
++<<<<<<< HEAD
++=======
+  *
+  * int bpf_skb_output(void *ctx, struct bpf_map *map, u64 flags, void *data, u64 size)
+  * 	Description
+  * 		Write raw *data* blob into a special BPF perf event held by
+  * 		*map* of type **BPF_MAP_TYPE_PERF_EVENT_ARRAY**. This perf
+  * 		event must have the following attributes: **PERF_SAMPLE_RAW**
+  * 		as **sample_type**, **PERF_TYPE_SOFTWARE** as **type**, and
+  * 		**PERF_COUNT_SW_BPF_OUTPUT** as **config**.
+  *
+  * 		The *flags* are used to indicate the index in *map* for which
+  * 		the value must be put, masked with **BPF_F_INDEX_MASK**.
+  * 		Alternatively, *flags* can be set to **BPF_F_CURRENT_CPU**
+  * 		to indicate that the index of the current CPU core should be
+  * 		used.
+  *
+  * 		The value to write, of *size*, is passed through eBPF stack and
+  * 		pointed by *data*.
+  *
+  * 		*ctx* is a pointer to in-kernel struct sk_buff.
+  *
+  * 		This helper is similar to **bpf_perf_event_output**\ () but
+  * 		restricted to raw_tracepoint bpf programs.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_probe_read_user(void *dst, u32 size, const void *unsafe_ptr)
+  * 	Description
+  * 		Safely attempt to read *size* bytes from user space address
+  * 		*unsafe_ptr* and store the data in *dst*.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_probe_read_kernel(void *dst, u32 size, const void *unsafe_ptr)
+  * 	Description
+  * 		Safely attempt to read *size* bytes from kernel space address
+  * 		*unsafe_ptr* and store the data in *dst*.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_probe_read_user_str(void *dst, u32 size, const void *unsafe_ptr)
+  * 	Description
+  * 		Copy a NUL terminated string from an unsafe user address
+  * 		*unsafe_ptr* to *dst*. The *size* should include the
+  * 		terminating NUL byte. In case the string length is smaller than
+  * 		*size*, the target is not padded with further NUL bytes. If the
+  * 		string length is larger than *size*, just *size*-1 bytes are
+  * 		copied and the last byte is set to NUL.
+  *
+  * 		On success, the length of the copied string is returned. This
+  * 		makes this helper useful in tracing programs for reading
+  * 		strings, and more importantly to get its length at runtime. See
+  * 		the following snippet:
+  *
+  * 		::
+  *
+  * 			SEC("kprobe/sys_open")
+  * 			void bpf_sys_open(struct pt_regs *ctx)
+  * 			{
+  * 			        char buf[PATHLEN]; // PATHLEN is defined to 256
+  * 			        int res = bpf_probe_read_user_str(buf, sizeof(buf),
+  * 				                                  ctx->di);
+  *
+  * 				// Consume buf, for example push it to
+  * 				// userspace via bpf_perf_event_output(); we
+  * 				// can use res (the string length) as event
+  * 				// size, after checking its boundaries.
+  * 			}
+  *
+  * 		In comparison, using **bpf_probe_read_user()** helper here
+  * 		instead to read the string would require to estimate the length
+  * 		at compile time, and would often result in copying more memory
+  * 		than necessary.
+  *
+  * 		Another useful use case is when parsing individual process
+  * 		arguments or individual environment variables navigating
+  * 		*current*\ **->mm->arg_start** and *current*\
+  * 		**->mm->env_start**: using this helper and the return value,
+  * 		one can quickly iterate at the right offset of the memory area.
+  * 	Return
+  * 		On success, the strictly positive length of the string,
+  * 		including the trailing NUL character. On error, a negative
+  * 		value.
+  *
+  * int bpf_probe_read_kernel_str(void *dst, u32 size, const void *unsafe_ptr)
+  * 	Description
+  * 		Copy a NUL terminated string from an unsafe kernel address *unsafe_ptr*
+  * 		to *dst*. Same semantics as with bpf_probe_read_user_str() apply.
+  * 	Return
+  * 		On success, the strictly positive length of the string,	including
+  * 		the trailing NUL character. On error, a negative value.
+  *
+  * int bpf_tcp_send_ack(void *tp, u32 rcv_nxt)
+  *	Description
+  *		Send out a tcp-ack. *tp* is the in-kernel struct tcp_sock.
+  *		*rcv_nxt* is the ack_seq to be sent out.
+  *	Return
+  *		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_send_signal_thread(u32 sig)
+  *	Description
+  *		Send signal *sig* to the thread corresponding to the current task.
+  *	Return
+  *		0 on success or successfully queued.
+  *
+  *		**-EBUSY** if work queue under nmi is full.
+  *
+  *		**-EINVAL** if *sig* is invalid.
+  *
+  *		**-EPERM** if no permission to send the *sig*.
+  *
+  *		**-EAGAIN** if bpf program can try again.
+  *
+  * u64 bpf_jiffies64(void)
+  *	Description
+  *		Obtain the 64bit jiffies
+  *	Return
+  *		The 64 bit jiffies
+  *
+  * int bpf_read_branch_records(struct bpf_perf_event_data *ctx, void *buf, u32 size, u64 flags)
+  *	Description
+  *		For an eBPF program attached to a perf event, retrieve the
+  *		branch records (struct perf_branch_entry) associated to *ctx*
+  *		and store it in	the buffer pointed by *buf* up to size
+  *		*size* bytes.
+  *	Return
+  *		On success, number of bytes written to *buf*. On error, a
+  *		negative value.
+  *
+  *		The *flags* can be set to **BPF_F_GET_BRANCH_RECORDS_SIZE** to
+  *		instead	return the number of bytes required to store all the
+  *		branch entries. If this flag is set, *buf* may be NULL.
+  *
+  *		**-EINVAL** if arguments invalid or **size** not a multiple
+  *		of sizeof(struct perf_branch_entry).
+  *
+  *		**-ENOENT** if architecture does not support branch records.
+  *
+  * int bpf_get_ns_current_pid_tgid(u64 dev, u64 ino, struct bpf_pidns_info *nsdata, u32 size)
+  *	Description
+  *		Returns 0 on success, values for *pid* and *tgid* as seen from the current
+  *		*namespace* will be returned in *nsdata*.
+  *
+  *		On failure, the returned value is one of the following:
+  *
+  *		**-EINVAL** if dev and inum supplied don't match dev_t and inode number
+  *              with nsfs of current task, or if dev conversion to dev_t lost high bits.
+  *
+  *		**-ENOENT** if pidns does not exists for the current task.
+  *
++>>>>>>> b4490c5c4e02 (bpf: Added new helper bpf_get_ns_current_pid_tgid)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -2869,7 -3039,17 +3021,21 @@@
  	FN(sk_storage_get),		\
  	FN(sk_storage_delete),		\
  	FN(send_signal),		\
++<<<<<<< HEAD
 +	FN(tcp_gen_syncookie),
++=======
+ 	FN(tcp_gen_syncookie),		\
+ 	FN(skb_output),			\
+ 	FN(probe_read_user),		\
+ 	FN(probe_read_kernel),		\
+ 	FN(probe_read_user_str),	\
+ 	FN(probe_read_kernel_str),	\
+ 	FN(tcp_send_ack),		\
+ 	FN(send_signal_thread),		\
+ 	FN(jiffies64),			\
+ 	FN(read_branch_records),	\
+ 	FN(get_ns_current_pid_tgid),
++>>>>>>> b4490c5c4e02 (bpf: Added new helper bpf_get_ns_current_pid_tgid)
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
   * function eBPF program intends to call
diff --cc kernel/bpf/helpers.c
index 4266ffde07ca,01878db15eaf..000000000000
--- a/kernel/bpf/helpers.c
+++ b/kernel/bpf/helpers.c
@@@ -19,6 -11,9 +19,12 @@@
  #include <linux/uidgid.h>
  #include <linux/filter.h>
  #include <linux/ctype.h>
++<<<<<<< HEAD
++=======
+ #include <linux/jiffies.h>
+ #include <linux/pid_namespace.h>
+ #include <linux/proc_ns.h>
++>>>>>>> b4490c5c4e02 (bpf: Added new helper bpf_get_ns_current_pid_tgid)
  
  #include "../../lib/kstrtox.h"
  
diff --cc kernel/trace/bpf_trace.c
index 2425aaf4e9d9,b5071c7e93ca..000000000000
--- a/kernel/trace/bpf_trace.c
+++ b/kernel/trace/bpf_trace.c
@@@ -754,6 -839,12 +754,15 @@@ tracing_func_proto(enum bpf_func_id fun
  #endif
  	case BPF_FUNC_send_signal:
  		return &bpf_send_signal_proto;
++<<<<<<< HEAD
++=======
+ 	case BPF_FUNC_send_signal_thread:
+ 		return &bpf_send_signal_thread_proto;
+ 	case BPF_FUNC_perf_event_read_value:
+ 		return &bpf_perf_event_read_value_proto;
+ 	case BPF_FUNC_get_ns_current_pid_tgid:
+ 		return &bpf_get_ns_current_pid_tgid_proto;
++>>>>>>> b4490c5c4e02 (bpf: Added new helper bpf_get_ns_current_pid_tgid)
  	default:
  		return NULL;
  	}
diff --cc tools/include/uapi/linux/bpf.h
index 2bc35095902a,15b239da775b..000000000000
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@@ -2718,6 -2751,182 +2718,185 @@@ union bpf_attr 
   *		**-EPERM** if no permission to send the *sig*.
   *
   *		**-EAGAIN** if bpf program can try again.
++<<<<<<< HEAD
++=======
+  *
+  * s64 bpf_tcp_gen_syncookie(struct bpf_sock *sk, void *iph, u32 iph_len, struct tcphdr *th, u32 th_len)
+  *	Description
+  *		Try to issue a SYN cookie for the packet with corresponding
+  *		IP/TCP headers, *iph* and *th*, on the listening socket in *sk*.
+  *
+  *		*iph* points to the start of the IPv4 or IPv6 header, while
+  *		*iph_len* contains **sizeof**\ (**struct iphdr**) or
+  *		**sizeof**\ (**struct ip6hdr**).
+  *
+  *		*th* points to the start of the TCP header, while *th_len*
+  *		contains the length of the TCP header.
+  *
+  *	Return
+  *		On success, lower 32 bits hold the generated SYN cookie in
+  *		followed by 16 bits which hold the MSS value for that cookie,
+  *		and the top 16 bits are unused.
+  *
+  *		On failure, the returned value is one of the following:
+  *
+  *		**-EINVAL** SYN cookie cannot be issued due to error
+  *
+  *		**-ENOENT** SYN cookie should not be issued (no SYN flood)
+  *
+  *		**-EOPNOTSUPP** kernel configuration does not enable SYN cookies
+  *
+  *		**-EPROTONOSUPPORT** IP packet version is not 4 or 6
+  *
+  * int bpf_skb_output(void *ctx, struct bpf_map *map, u64 flags, void *data, u64 size)
+  * 	Description
+  * 		Write raw *data* blob into a special BPF perf event held by
+  * 		*map* of type **BPF_MAP_TYPE_PERF_EVENT_ARRAY**. This perf
+  * 		event must have the following attributes: **PERF_SAMPLE_RAW**
+  * 		as **sample_type**, **PERF_TYPE_SOFTWARE** as **type**, and
+  * 		**PERF_COUNT_SW_BPF_OUTPUT** as **config**.
+  *
+  * 		The *flags* are used to indicate the index in *map* for which
+  * 		the value must be put, masked with **BPF_F_INDEX_MASK**.
+  * 		Alternatively, *flags* can be set to **BPF_F_CURRENT_CPU**
+  * 		to indicate that the index of the current CPU core should be
+  * 		used.
+  *
+  * 		The value to write, of *size*, is passed through eBPF stack and
+  * 		pointed by *data*.
+  *
+  * 		*ctx* is a pointer to in-kernel struct sk_buff.
+  *
+  * 		This helper is similar to **bpf_perf_event_output**\ () but
+  * 		restricted to raw_tracepoint bpf programs.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_probe_read_user(void *dst, u32 size, const void *unsafe_ptr)
+  * 	Description
+  * 		Safely attempt to read *size* bytes from user space address
+  * 		*unsafe_ptr* and store the data in *dst*.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_probe_read_kernel(void *dst, u32 size, const void *unsafe_ptr)
+  * 	Description
+  * 		Safely attempt to read *size* bytes from kernel space address
+  * 		*unsafe_ptr* and store the data in *dst*.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_probe_read_user_str(void *dst, u32 size, const void *unsafe_ptr)
+  * 	Description
+  * 		Copy a NUL terminated string from an unsafe user address
+  * 		*unsafe_ptr* to *dst*. The *size* should include the
+  * 		terminating NUL byte. In case the string length is smaller than
+  * 		*size*, the target is not padded with further NUL bytes. If the
+  * 		string length is larger than *size*, just *size*-1 bytes are
+  * 		copied and the last byte is set to NUL.
+  *
+  * 		On success, the length of the copied string is returned. This
+  * 		makes this helper useful in tracing programs for reading
+  * 		strings, and more importantly to get its length at runtime. See
+  * 		the following snippet:
+  *
+  * 		::
+  *
+  * 			SEC("kprobe/sys_open")
+  * 			void bpf_sys_open(struct pt_regs *ctx)
+  * 			{
+  * 			        char buf[PATHLEN]; // PATHLEN is defined to 256
+  * 			        int res = bpf_probe_read_user_str(buf, sizeof(buf),
+  * 				                                  ctx->di);
+  *
+  * 				// Consume buf, for example push it to
+  * 				// userspace via bpf_perf_event_output(); we
+  * 				// can use res (the string length) as event
+  * 				// size, after checking its boundaries.
+  * 			}
+  *
+  * 		In comparison, using **bpf_probe_read_user()** helper here
+  * 		instead to read the string would require to estimate the length
+  * 		at compile time, and would often result in copying more memory
+  * 		than necessary.
+  *
+  * 		Another useful use case is when parsing individual process
+  * 		arguments or individual environment variables navigating
+  * 		*current*\ **->mm->arg_start** and *current*\
+  * 		**->mm->env_start**: using this helper and the return value,
+  * 		one can quickly iterate at the right offset of the memory area.
+  * 	Return
+  * 		On success, the strictly positive length of the string,
+  * 		including the trailing NUL character. On error, a negative
+  * 		value.
+  *
+  * int bpf_probe_read_kernel_str(void *dst, u32 size, const void *unsafe_ptr)
+  * 	Description
+  * 		Copy a NUL terminated string from an unsafe kernel address *unsafe_ptr*
+  * 		to *dst*. Same semantics as with bpf_probe_read_user_str() apply.
+  * 	Return
+  * 		On success, the strictly positive length of the string,	including
+  * 		the trailing NUL character. On error, a negative value.
+  *
+  * int bpf_tcp_send_ack(void *tp, u32 rcv_nxt)
+  *	Description
+  *		Send out a tcp-ack. *tp* is the in-kernel struct tcp_sock.
+  *		*rcv_nxt* is the ack_seq to be sent out.
+  *	Return
+  *		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_send_signal_thread(u32 sig)
+  *	Description
+  *		Send signal *sig* to the thread corresponding to the current task.
+  *	Return
+  *		0 on success or successfully queued.
+  *
+  *		**-EBUSY** if work queue under nmi is full.
+  *
+  *		**-EINVAL** if *sig* is invalid.
+  *
+  *		**-EPERM** if no permission to send the *sig*.
+  *
+  *		**-EAGAIN** if bpf program can try again.
+  *
+  * u64 bpf_jiffies64(void)
+  *	Description
+  *		Obtain the 64bit jiffies
+  *	Return
+  *		The 64 bit jiffies
+  *
+  * int bpf_read_branch_records(struct bpf_perf_event_data *ctx, void *buf, u32 size, u64 flags)
+  *	Description
+  *		For an eBPF program attached to a perf event, retrieve the
+  *		branch records (struct perf_branch_entry) associated to *ctx*
+  *		and store it in	the buffer pointed by *buf* up to size
+  *		*size* bytes.
+  *	Return
+  *		On success, number of bytes written to *buf*. On error, a
+  *		negative value.
+  *
+  *		The *flags* can be set to **BPF_F_GET_BRANCH_RECORDS_SIZE** to
+  *		instead	return the number of bytes required to store all the
+  *		branch entries. If this flag is set, *buf* may be NULL.
+  *
+  *		**-EINVAL** if arguments invalid or **size** not a multiple
+  *		of sizeof(struct perf_branch_entry).
+  *
+  *		**-ENOENT** if architecture does not support branch records.
+  *
+  * int bpf_get_ns_current_pid_tgid(u64 dev, u64 ino, struct bpf_pidns_info *nsdata, u32 size)
+  *	Description
+  *		Returns 0 on success, values for *pid* and *tgid* as seen from the current
+  *		*namespace* will be returned in *nsdata*.
+  *
+  *		On failure, the returned value is one of the following:
+  *
+  *		**-EINVAL** if dev and inum supplied don't match dev_t and inode number
+  *              with nsfs of current task, or if dev conversion to dev_t lost high bits.
+  *
+  *		**-ENOENT** if pidns does not exists for the current task.
+  *
++>>>>>>> b4490c5c4e02 (bpf: Added new helper bpf_get_ns_current_pid_tgid)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -2829,7 -3038,18 +3008,22 @@@
  	FN(strtoul),			\
  	FN(sk_storage_get),		\
  	FN(sk_storage_delete),		\
++<<<<<<< HEAD
 +	FN(send_signal),
++=======
+ 	FN(send_signal),		\
+ 	FN(tcp_gen_syncookie),		\
+ 	FN(skb_output),			\
+ 	FN(probe_read_user),		\
+ 	FN(probe_read_kernel),		\
+ 	FN(probe_read_user_str),	\
+ 	FN(probe_read_kernel_str),	\
+ 	FN(tcp_send_ack),		\
+ 	FN(send_signal_thread),		\
+ 	FN(jiffies64),			\
+ 	FN(read_branch_records),	\
+ 	FN(get_ns_current_pid_tgid),
++>>>>>>> b4490c5c4e02 (bpf: Added new helper bpf_get_ns_current_pid_tgid)
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
   * function eBPF program intends to call
* Unmerged path include/linux/bpf.h
* Unmerged path include/uapi/linux/bpf.h
diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c
index 5381636b23b4..1f09da2cc86b 100644
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@ -2084,6 +2084,7 @@ const struct bpf_func_proto bpf_get_current_uid_gid_proto __weak;
 const struct bpf_func_proto bpf_get_current_comm_proto __weak;
 const struct bpf_func_proto bpf_get_current_cgroup_id_proto __weak;
 const struct bpf_func_proto bpf_get_local_storage_proto __weak;
+const struct bpf_func_proto bpf_get_ns_current_pid_tgid_proto __weak;
 
 const struct bpf_func_proto * __weak bpf_get_trace_printk_proto(void)
 {
* Unmerged path kernel/bpf/helpers.c
* Unmerged path kernel/trace/bpf_trace.c
diff --git a/scripts/bpf_helpers_doc.py b/scripts/bpf_helpers_doc.py
index a34d6bd78d3d..d86db0b5b258 100755
--- a/scripts/bpf_helpers_doc.py
+++ b/scripts/bpf_helpers_doc.py
@@ -437,6 +437,7 @@ class PrinterHelpers(Printer):
             'struct bpf_fib_lookup',
             'struct bpf_perf_event_data',
             'struct bpf_perf_event_value',
+            'struct bpf_pidns_info',
             'struct bpf_sock',
             'struct bpf_sock_addr',
             'struct bpf_sock_ops',
* Unmerged path tools/include/uapi/linux/bpf.h
