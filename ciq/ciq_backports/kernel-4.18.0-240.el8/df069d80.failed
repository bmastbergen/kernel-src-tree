io_uring: spin for sq thread to idle on shutdown

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit df069d80c8e38c19531c392322e9a16617475c44
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/df069d80.failed

As part of io_uring shutdown, we cancel work that is pending and won't
necessarily complete on its own. That includes requests like poll
commands and timeouts.

If we're using SQPOLL for kernel side submission and we shutdown the
ring immediately after queueing such work, we can race with the sqthread
doing the submission. This means we may miss cancelling some work, which
results in the io_uring shutdown hanging forever.

	Cc: stable@vger.kernel.org
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit df069d80c8e38c19531c392322e9a16617475c44)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index ffb8e9d82a6a,87f8655656b5..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -2534,9 -5065,13 +2534,15 @@@ static int io_sq_thread(void *data
  			/*
  			 * We're polling. If we're within the defined idle
  			 * period, then let us spin without work before going
 -			 * to sleep. The exception is if we got EBUSY doing
 -			 * more IO, we should wait for the application to
 -			 * reap events and wake us up.
 +			 * to sleep.
  			 */
++<<<<<<< HEAD
 +			if (inflight || !time_after(jiffies, timeout)) {
++=======
+ 			if (inflight ||
+ 			    (!time_after(jiffies, timeout) && ret != -EBUSY &&
+ 			    !percpu_ref_is_dying(&ctx->refs))) {
++>>>>>>> df069d80c8e3 (io_uring: spin for sq thread to idle on shutdown)
  				cond_resched();
  				continue;
  			}
@@@ -3563,9 -6325,28 +3569,23 @@@ static void io_ring_ctx_wait_and_kill(s
  	percpu_ref_kill(&ctx->refs);
  	mutex_unlock(&ctx->uring_lock);
  
++<<<<<<< HEAD
++=======
+ 	/*
+ 	 * Wait for sq thread to idle, if we have one. It won't spin on new
+ 	 * work after we've killed the ctx ref above. This is important to do
+ 	 * before we cancel existing commands, as the thread could otherwise
+ 	 * be queueing new work post that. If that's work we need to cancel,
+ 	 * it could cause shutdown to hang.
+ 	 */
+ 	while (ctx->sqo_thread && !wq_has_sleeper(&ctx->sqo_wait))
+ 		cpu_relax();
+ 
+ 	io_kill_timeouts(ctx);
++>>>>>>> df069d80c8e3 (io_uring: spin for sq thread to idle on shutdown)
  	io_poll_remove_all(ctx);
 -
 -	if (ctx->io_wq)
 -		io_wq_cancel_all(ctx->io_wq);
 -
  	io_iopoll_reap_events(ctx);
 -	/* if we failed setting up the ctx, we might not have any rings */
 -	if (ctx->rings)
 -		io_cqring_overflow_flush(ctx, true);
 -	idr_for_each(&ctx->personality_idr, io_remove_personalities, ctx);
 -	wait_for_completion(&ctx->completions[0]);
 +	wait_for_completion(&ctx->ctx_done);
  	io_ring_ctx_free(ctx);
  }
  
* Unmerged path fs/io_uring.c
