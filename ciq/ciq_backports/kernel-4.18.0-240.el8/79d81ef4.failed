RDMA/srpt: Fix TPG creation

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Bart Van Assche <bvanassche@acm.org>
commit 79d81ef42c9a8feee2f1df5dffa6ac628b71141d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/79d81ef4.failed

Unlike the iSCSI target driver, for the SRP target driver it is sufficient
if a single TPG can be associated with each RDMA port name. However, users
started associating multiple TPGs with RDMA port names. Support this by
converting the single TPG in struct srpt_port_id into a list. This patch
fixes the following list corruption issue:

 list_add corruption. prev->next should be next (ffffffffc0a080c0), but was ffffa08a994ce6f0. (prev=ffffa08a994ce6f0).
 WARNING: CPU: 2 PID: 2597 at lib/list_debug.c:28 __list_add_valid+0x6a/0x70
 CPU: 2 PID: 2597 Comm: targetcli Not tainted 5.4.0-rc1.3bfa3c9602a7 #1
 RIP: 0010:__list_add_valid+0x6a/0x70
 Call Trace:
  core_tpg_register+0x116/0x200 [target_core_mod]
  srpt_make_tpg+0x3f/0x60 [ib_srpt]
  target_fabric_make_tpg+0x41/0x290 [target_core_mod]
  configfs_mkdir+0x158/0x3e0
  vfs_mkdir+0x108/0x1a0
  do_mkdirat+0x77/0xe0
  do_syscall_64+0x55/0x1d0
  entry_SYSCALL_64_after_hwframe+0x44/0xa9

Link: https://lore.kernel.org/r/20191023204106.23326-1-bvanassche@acm.org
	Reported-by: Honggang LI <honli@redhat.com>
Fixes: a42d985bd5b2 ("ib_srpt: Initial SRP Target merge for v3.3-rc1")
	Signed-off-by: Bart Van Assche <bvanassche@acm.org>
	Acked-by: Honggang Li <honli@redhat.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 79d81ef42c9a8feee2f1df5dffa6ac628b71141d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/ulp/srpt/ib_srpt.c
diff --cc drivers/infiniband/ulp/srpt/ib_srpt.c
index 4bc72a7bf9dc,a278e76b9e02..000000000000
--- a/drivers/infiniband/ulp/srpt/ib_srpt.c
+++ b/drivers/infiniband/ulp/srpt/ib_srpt.c
@@@ -3725,14 -3734,27 +3734,31 @@@ static struct se_portal_group *srpt_mak
  					     const char *name)
  {
  	struct srpt_port *sport = wwn->priv;
- 	struct se_portal_group *tpg = &srpt_wwn_to_sport_id(wwn)->tpg;
- 	int res;
+ 	struct srpt_port_id *sport_id = srpt_wwn_to_sport_id(wwn);
+ 	struct srpt_tpg *stpg;
+ 	int res = -ENOMEM;
  
- 	res = core_tpg_register(wwn, tpg, SCSI_PROTOCOL_SRP);
- 	if (res)
+ 	stpg = kzalloc(sizeof(*stpg), GFP_KERNEL);
+ 	if (!stpg)
  		return ERR_PTR(res);
+ 	stpg->sport_id = sport_id;
+ 	res = core_tpg_register(wwn, &stpg->tpg, SCSI_PROTOCOL_SRP);
+ 	if (res) {
+ 		kfree(stpg);
+ 		return ERR_PTR(res);
+ 	}
+ 
+ 	mutex_lock(&sport_id->mutex);
+ 	list_add_tail(&stpg->entry, &sport_id->tpg_list);
+ 	mutex_unlock(&sport_id->mutex);
  
++<<<<<<< HEAD
 +	return tpg;
++=======
+ 	atomic_inc(&sport->refcount);
+ 
+ 	return &stpg->tpg;
++>>>>>>> 79d81ef42c9a (RDMA/srpt: Fix TPG creation)
  }
  
  /**
@@@ -3741,10 -3763,18 +3767,21 @@@
   */
  static void srpt_drop_tpg(struct se_portal_group *tpg)
  {
+ 	struct srpt_tpg *stpg = container_of(tpg, typeof(*stpg), tpg);
+ 	struct srpt_port_id *sport_id = stpg->sport_id;
  	struct srpt_port *sport = srpt_tpg_to_sport(tpg);
  
+ 	mutex_lock(&sport_id->mutex);
+ 	list_del(&stpg->entry);
+ 	mutex_unlock(&sport_id->mutex);
+ 
  	sport->enabled = false;
  	core_tpg_deregister(tpg);
++<<<<<<< HEAD
++=======
+ 	kfree(stpg);
+ 	srpt_drop_sport_ref(sport);
++>>>>>>> 79d81ef42c9a (RDMA/srpt: Fix TPG creation)
  }
  
  /**
* Unmerged path drivers/infiniband/ulp/srpt/ib_srpt.c
diff --git a/drivers/infiniband/ulp/srpt/ib_srpt.h b/drivers/infiniband/ulp/srpt/ib_srpt.h
index 54b03ab4ab1a..2e1a69840857 100644
--- a/drivers/infiniband/ulp/srpt/ib_srpt.h
+++ b/drivers/infiniband/ulp/srpt/ib_srpt.h
@@ -363,17 +363,34 @@ struct srpt_port_attrib {
 	bool			use_srq;
 };
 
+/**
+ * struct srpt_tpg - information about a single "target portal group"
+ * @entry:	Entry in @sport_id->tpg_list.
+ * @sport_id:	Port name this TPG is associated with.
+ * @tpg:	LIO TPG data structure.
+ *
+ * Zero or more target portal groups are associated with each port name
+ * (srpt_port_id). With each TPG an ACL list is associated.
+ */
+struct srpt_tpg {
+	struct list_head	entry;
+	struct srpt_port_id	*sport_id;
+	struct se_portal_group	tpg;
+};
+
 /**
  * struct srpt_port_id - information about an RDMA port name
- * @tpg: TPG associated with the RDMA port.
- * @wwn: WWN associated with the RDMA port.
- * @name: ASCII representation of the port name.
+ * @mutex:	Protects @tpg_list changes.
+ * @tpg_list:	TPGs associated with the RDMA port name.
+ * @wwn:	WWN associated with the RDMA port name.
+ * @name:	ASCII representation of the port name.
  *
  * Multiple sysfs directories can be associated with a single RDMA port. This
  * data structure represents a single (port, name) pair.
  */
 struct srpt_port_id {
-	struct se_portal_group	tpg;
+	struct mutex		mutex;
+	struct list_head	tpg_list;
 	struct se_wwn		wwn;
 	char			name[64];
 };
