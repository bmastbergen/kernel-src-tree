powerpc/mm/hash64: use _PAGE_PTE when checking for pte_present

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
Rebuild_CHGLOG: - [powerpc] mm/hash64: use _PAGE_PTE when checking for pte_present (Greg Kurz) [1748772]
Rebuild_FUZZ: 93.10%
commit-author Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
commit ec4abf1e70cf6a3fe6e571d640260005c997c6e1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/ec4abf1e.failed

This makes the pte_present check stricter by checking for additional _PAGE_PTE
bit. A level 1 pte pointer (THP pte) can be switched to a pointer to level 0 pte
page table page by following two operations.

1) THP split.
2) madvise(MADV_DONTNEED) in parallel to page fault.

A lockless page table walk need to make sure we can handle such changes
gracefully.

	Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://lore.kernel.org/r/20200505071729.54912-4-aneesh.kumar@linux.ibm.com
(cherry picked from commit ec4abf1e70cf6a3fe6e571d640260005c997c6e1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/book3s/64/pgtable.h
diff --cc arch/powerpc/include/asm/book3s/64/pgtable.h
index 1afb3bf47dee,03521a8b0292..000000000000
--- a/arch/powerpc/include/asm/book3s/64/pgtable.h
+++ b/arch/powerpc/include/asm/book3s/64/pgtable.h
@@@ -584,9 -567,13 +590,16 @@@ static inline int pte_present(pte_t pte
  	 * invalid during ptep_set_access_flags. Hence we look for _PAGE_INVALID
  	 * if we find _PAGE_PRESENT cleared.
  	 */
- 	return !!(pte_raw(pte) & cpu_to_be64(_PAGE_PRESENT | _PAGE_INVALID));
+ 
++<<<<<<< HEAD
++=======
+ 	if (pte_hw_valid(pte))
+ 		return true;
+ 	return (pte_raw(pte) & cpu_to_be64(_PAGE_INVALID | _PAGE_PTE)) ==
+ 		cpu_to_be64(_PAGE_INVALID | _PAGE_PTE);
  }
  
++>>>>>>> ec4abf1e70cf (powerpc/mm/hash64: use _PAGE_PTE when checking for pte_present)
  #ifdef CONFIG_PPC_MEM_KEYS
  extern bool arch_pte_access_permitted(u64 pte, bool write, bool execute);
  #else
* Unmerged path arch/powerpc/include/asm/book3s/64/pgtable.h
diff --git a/arch/powerpc/mm/book3s64/hash_utils.c b/arch/powerpc/mm/book3s64/hash_utils.c
index a638a0fa8666..d911f1725c80 100644
--- a/arch/powerpc/mm/book3s64/hash_utils.c
+++ b/arch/powerpc/mm/book3s64/hash_utils.c
@@ -1320,8 +1320,15 @@ int hash_page_mm(struct mm_struct *mm, unsigned long ea,
 		goto bail;
 	}
 
-	/* Add _PAGE_PRESENT to the required access perm */
-	access |= _PAGE_PRESENT;
+	/*
+	 * Add _PAGE_PRESENT to the required access perm. If there are parallel
+	 * updates to the pte that can possibly clear _PAGE_PTE, catch that too.
+	 *
+	 * We can safely use the return pte address in rest of the function
+	 * because we do set H_PAGE_BUSY which prevents further updates to pte
+	 * from generic code.
+	 */
+	access |= _PAGE_PRESENT | _PAGE_PTE;
 
 	/*
 	 * Pre-check access permissions (will be re-checked atomically
