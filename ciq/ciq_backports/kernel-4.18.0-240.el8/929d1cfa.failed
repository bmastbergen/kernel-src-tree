KVM: MMU: pass arbitrary CR0/CR4/EFER to kvm_init_shadow_mmu

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Paolo Bonzini <pbonzini@redhat.com>
commit 929d1cfaa6926ccee28d8d4220e0b4e2defd9cd1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/929d1cfa.failed

This allows fetching the registers from the hsave area when setting
up the NPT shadow MMU, and is needed for KVM_SET_NESTED_STATE (which
runs long after the CR0, CR4 and EFER values in vcpu have been switched
to hold L2 guest state).

	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 929d1cfaa6926ccee28d8d4220e0b4e2defd9cd1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/mmu.c
#	arch/x86/kvm/svm/nested.c
diff --cc arch/x86/kvm/mmu/mmu.c
index c2e82e8c5c7c,2e62a03410c7..000000000000
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@@ -5124,8 -5043,11 +5124,16 @@@ static void init_kvm_softmmu(struct kvm
  {
  	struct kvm_mmu *context = vcpu->arch.mmu;
  
++<<<<<<< HEAD
 +	kvm_init_shadow_mmu(vcpu);
 +	context->set_cr3           = kvm_x86_ops->set_cr3;
++=======
+ 	kvm_init_shadow_mmu(vcpu,
+ 			    kvm_read_cr0_bits(vcpu, X86_CR0_PG),
+ 			    kvm_read_cr4_bits(vcpu, X86_CR4_PAE),
+ 			    vcpu->arch.efer);
+ 
++>>>>>>> 929d1cfaa692 (KVM: MMU: pass arbitrary CR0/CR4/EFER to kvm_init_shadow_mmu)
  	context->get_guest_pgd     = get_cr3;
  	context->get_pdptr         = kvm_pdptr_read;
  	context->inject_page_fault = kvm_inject_page_fault;
* Unmerged path arch/x86/kvm/svm/nested.c
diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h
index 3165671cd7d6..84d6d7134684 100644
--- a/arch/x86/kvm/mmu.h
+++ b/arch/x86/kvm/mmu.h
@@ -57,7 +57,7 @@ void
 reset_shadow_zero_bits_mask(struct kvm_vcpu *vcpu, struct kvm_mmu *context);
 
 void kvm_init_mmu(struct kvm_vcpu *vcpu, bool reset_roots);
-void kvm_init_shadow_mmu(struct kvm_vcpu *vcpu);
+void kvm_init_shadow_mmu(struct kvm_vcpu *vcpu, u32 cr0, u32 cr4, u32 efer);
 void kvm_init_shadow_ept_mmu(struct kvm_vcpu *vcpu, bool execonly,
 			     bool accessed_dirty, gpa_t new_eptp);
 bool kvm_can_do_async_pf(struct kvm_vcpu *vcpu);
* Unmerged path arch/x86/kvm/mmu/mmu.c
* Unmerged path arch/x86/kvm/svm/nested.c
