libperf: Add threads to struct perf_evlist

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jiri Olsa <jolsa@kernel.org>
commit 03617c22e31f32cbf0e4797e216db898fb898d90
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/03617c22.failed

Move threads from tools/perf's evlist to libperf's perf_evlist struct.

	Signed-off-by: Jiri Olsa <jolsa@kernel.org>
	Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
	Cc: Alexey Budankov <alexey.budankov@linux.intel.com>
	Cc: Andi Kleen <ak@linux.intel.com>
	Cc: Michael Petlan <mpetlan@redhat.com>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
Link: http://lkml.kernel.org/r/20190721112506.12306-56-jolsa@kernel.org
	Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
(cherry picked from commit 03617c22e31f32cbf0e4797e216db898fb898d90)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/perf/builtin-top.c
#	tools/perf/builtin-trace.c
#	tools/perf/lib/include/internal/evlist.h
#	tools/perf/tests/openat-syscall-tp-fields.c
#	tools/perf/util/auxtrace.c
#	tools/perf/util/evlist.c
#	tools/perf/util/evlist.h
diff --cc tools/perf/builtin-top.c
index 6d6fb101231d,c69ddc67c672..000000000000
--- a/tools/perf/builtin-top.c
+++ b/tools/perf/builtin-top.c
@@@ -991,8 -989,8 +991,13 @@@ static int perf_top__start_counters(str
  
  	evlist__for_each_entry(evlist, counter) {
  try_again:
++<<<<<<< HEAD
 +		if (perf_evsel__open(counter, top->evlist->cpus,
 +				     top->evlist->threads) < 0) {
++=======
+ 		if (evsel__open(counter, top->evlist->core.cpus,
+ 				     top->evlist->core.threads) < 0) {
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  
  			/*
  			 * Specially handle overwrite fall back.
diff --cc tools/perf/builtin-trace.c
index 9f9c869e0f26,35f3684f5327..000000000000
--- a/tools/perf/builtin-trace.c
+++ b/tools/perf/builtin-trace.c
@@@ -3409,16 -3409,16 +3409,22 @@@ static int trace__run(struct trace *tra
  
  	if (trace->opts.initial_delay) {
  		usleep(trace->opts.initial_delay * 1000);
 -		evlist__enable(evlist);
 +		perf_evlist__enable(evlist);
  	}
  
++<<<<<<< HEAD
 +	trace->multiple_threads = thread_map__pid(evlist->threads, 0) == -1 ||
 +				  evlist->threads->nr > 1 ||
 +				  perf_evlist__first(evlist)->attr.inherit;
++=======
+ 	trace->multiple_threads = thread_map__pid(evlist->core.threads, 0) == -1 ||
+ 				  evlist->core.threads->nr > 1 ||
+ 				  perf_evlist__first(evlist)->core.attr.inherit;
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  
  	/*
 -	 * Now that we already used evsel->core.attr to ask the kernel to setup the
 -	 * events, lets reuse evsel->core.attr.sample_max_stack as the limit in
 +	 * Now that we already used evsel->attr to ask the kernel to setup the
 +	 * events, lets reuse evsel->attr.sample_max_stack as the limit in
  	 * trace__resolve_callchain(), allowing per-event max-stack settings
  	 * to override an explicitly set --max-stack global setting.
  	 */
diff --cc tools/perf/tests/openat-syscall-tp-fields.c
index 344dc3ac2469,9c06130d37be..000000000000
--- a/tools/perf/tests/openat-syscall-tp-fields.c
+++ b/tools/perf/tests/openat-syscall-tp-fields.c
@@@ -58,9 -58,9 +58,13 @@@ int test__syscall_openat_tp_fields(stru
  
  	perf_evsel__config(evsel, &opts, NULL);
  
++<<<<<<< HEAD
 +	thread_map__set_pid(evlist->threads, 0, getpid());
++=======
+ 	perf_thread_map__set_pid(evlist->core.threads, 0, getpid());
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  
 -	err = evlist__open(evlist);
 +	err = perf_evlist__open(evlist);
  	if (err < 0) {
  		pr_debug("perf_evlist__open: %s\n",
  			 str_error_r(errno, sbuf, sizeof(sbuf)));
diff --cc tools/perf/util/auxtrace.c
index 7479b73720be,65728cdeefb6..000000000000
--- a/tools/perf/util/auxtrace.c
+++ b/tools/perf/util/auxtrace.c
@@@ -139,9 -130,9 +139,15 @@@ void auxtrace_mmap_params__set_idx(stru
  	mp->idx = idx;
  
  	if (per_cpu) {
++<<<<<<< HEAD
 +		mp->cpu = evlist->cpus->map[idx];
 +		if (evlist->threads)
 +			mp->tid = thread_map__pid(evlist->threads, 0);
++=======
+ 		mp->cpu = evlist->core.cpus->map[idx];
+ 		if (evlist->core.threads)
+ 			mp->tid = thread_map__pid(evlist->core.threads, 0);
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  		else
  			mp->tid = -1;
  	} else {
diff --cc tools/perf/util/evlist.c
index 4739b7914374,1a6f877ebb03..000000000000
--- a/tools/perf/util/evlist.c
+++ b/tools/perf/util/evlist.c
@@@ -141,11 -142,11 +141,19 @@@ void perf_evlist__delete(struct perf_ev
  		return;
  
  	perf_evlist__munmap(evlist);
++<<<<<<< HEAD
 +	perf_evlist__close(evlist);
 +	cpu_map__put(evlist->cpus);
 +	thread_map__put(evlist->threads);
 +	evlist->cpus = NULL;
 +	evlist->threads = NULL;
++=======
+ 	evlist__close(evlist);
+ 	perf_cpu_map__put(evlist->core.cpus);
+ 	perf_thread_map__put(evlist->core.threads);
+ 	evlist->core.cpus = NULL;
+ 	evlist->core.threads = NULL;
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  	perf_evlist__purge(evlist);
  	perf_evlist__exit(evlist);
  	free(evlist);
@@@ -158,21 -159,21 +166,26 @@@ static void __perf_evlist__propagate_ma
  	 * We already have cpus for evsel (via PMU sysfs) so
  	 * keep it, if there's no target cpu list defined.
  	 */
 -	if (!evsel->core.own_cpus || evlist->core.has_user_cpus) {
 -		perf_cpu_map__put(evsel->core.cpus);
 -		evsel->core.cpus = perf_cpu_map__get(evlist->core.cpus);
 -	} else if (evsel->core.cpus != evsel->core.own_cpus) {
 -		perf_cpu_map__put(evsel->core.cpus);
 -		evsel->core.cpus = perf_cpu_map__get(evsel->core.own_cpus);
 -	}
 -
 +	if (!evsel->own_cpus || evlist->has_user_cpus) {
 +		cpu_map__put(evsel->cpus);
 +		evsel->cpus = cpu_map__get(evlist->cpus);
 +	} else if (evsel->cpus != evsel->own_cpus) {
 +		cpu_map__put(evsel->cpus);
 +		evsel->cpus = cpu_map__get(evsel->own_cpus);
 +	}
 +
++<<<<<<< HEAD
 +	thread_map__put(evsel->threads);
 +	evsel->threads = thread_map__get(evlist->threads);
++=======
+ 	perf_thread_map__put(evsel->core.threads);
+ 	evsel->core.threads = perf_thread_map__get(evlist->core.threads);
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  }
  
 -static void perf_evlist__propagate_maps(struct evlist *evlist)
 +static void perf_evlist__propagate_maps(struct perf_evlist *evlist)
  {
 -	struct evsel *evsel;
 +	struct perf_evsel *evsel;
  
  	evlist__for_each_entry(evlist, evsel)
  		__perf_evlist__propagate_maps(evlist, evsel);
@@@ -341,12 -342,12 +354,12 @@@ static int perf_evlist__nr_threads(stru
  	if (evsel->system_wide)
  		return 1;
  	else
- 		return thread_map__nr(evlist->threads);
+ 		return thread_map__nr(evlist->core.threads);
  }
  
 -void evlist__disable(struct evlist *evlist)
 +void perf_evlist__disable(struct perf_evlist *evlist)
  {
 -	struct evsel *pos;
 +	struct perf_evsel *pos;
  
  	evlist__for_each_entry(evlist, pos) {
  		if (pos->disabled || !perf_evsel__is_group_leader(pos) || !pos->fd)
@@@ -421,12 -422,12 +434,17 @@@ int perf_evlist__enable_event_idx(struc
  		return perf_evlist__enable_event_thread(evlist, evsel, idx);
  }
  
 -int perf_evlist__alloc_pollfd(struct evlist *evlist)
 +int perf_evlist__alloc_pollfd(struct perf_evlist *evlist)
  {
++<<<<<<< HEAD
 +	int nr_cpus = cpu_map__nr(evlist->cpus);
 +	int nr_threads = thread_map__nr(evlist->threads);
++=======
+ 	int nr_cpus = cpu_map__nr(evlist->core.cpus);
+ 	int nr_threads = thread_map__nr(evlist->core.threads);
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  	int nfds = 0;
 -	struct evsel *evsel;
 +	struct perf_evsel *evsel;
  
  	evlist__for_each_entry(evlist, evsel) {
  		if (evsel->system_wide)
@@@ -551,12 -552,12 +569,12 @@@ static void perf_evlist__set_sid_idx(st
  {
  	struct perf_sample_id *sid = SID(evsel, cpu, thread);
  	sid->idx = idx;
 -	if (evlist->core.cpus && cpu >= 0)
 -		sid->cpu = evlist->core.cpus->map[cpu];
 +	if (evlist->cpus && cpu >= 0)
 +		sid->cpu = evlist->cpus->map[cpu];
  	else
  		sid->cpu = -1;
- 	if (!evsel->system_wide && evlist->threads && thread >= 0)
- 		sid->tid = thread_map__pid(evlist->threads, thread);
+ 	if (!evsel->system_wide && evlist->core.threads && thread >= 0)
+ 		sid->tid = thread_map__pid(evlist->core.threads, thread);
  	else
  		sid->tid = -1;
  }
@@@ -719,9 -720,9 +737,15 @@@ static struct perf_mmap *perf_evlist__a
  	int i;
  	struct perf_mmap *map;
  
++<<<<<<< HEAD
 +	evlist->nr_mmaps = cpu_map__nr(evlist->cpus);
 +	if (cpu_map__empty(evlist->cpus))
 +		evlist->nr_mmaps = thread_map__nr(evlist->threads);
++=======
+ 	evlist->nr_mmaps = cpu_map__nr(evlist->core.cpus);
+ 	if (cpu_map__empty(evlist->core.cpus))
+ 		evlist->nr_mmaps = thread_map__nr(evlist->core.threads);
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  	map = zalloc(evlist->nr_mmaps * sizeof(struct perf_mmap));
  	if (!map)
  		return NULL;
@@@ -834,8 -835,8 +858,13 @@@ static int perf_evlist__mmap_per_cpu(st
  				     struct mmap_params *mp)
  {
  	int cpu, thread;
++<<<<<<< HEAD
 +	int nr_cpus = cpu_map__nr(evlist->cpus);
 +	int nr_threads = thread_map__nr(evlist->threads);
++=======
+ 	int nr_cpus = cpu_map__nr(evlist->core.cpus);
+ 	int nr_threads = thread_map__nr(evlist->core.threads);
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  
  	pr_debug2("perf event ring buffer mmapped per cpu\n");
  	for (cpu = 0; cpu < nr_cpus; cpu++) {
@@@ -1012,9 -1013,9 +1041,15 @@@ int perf_evlist__mmap_ex(struct perf_ev
  			 bool auxtrace_overwrite, int nr_cblocks, int affinity, int flush,
  			 int comp_level)
  {
++<<<<<<< HEAD
 +	struct perf_evsel *evsel;
 +	const struct cpu_map *cpus = evlist->cpus;
 +	const struct thread_map *threads = evlist->threads;
++=======
+ 	struct evsel *evsel;
+ 	const struct perf_cpu_map *cpus = evlist->core.cpus;
+ 	const struct perf_thread_map *threads = evlist->core.threads;
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  	/*
  	 * Delay setting mp.prot: set it before calling perf_mmap__mmap.
  	 * Its value is decided by evsel's write_backward.
@@@ -1115,14 -1116,14 +1150,20 @@@ void perf_evlist__set_maps(struct perf_
  	 * original reference count of 1.  If that is not the case it is up to
  	 * the caller to increase the reference count.
  	 */
 -	if (cpus != evlist->core.cpus) {
 -		perf_cpu_map__put(evlist->core.cpus);
 -		evlist->core.cpus = perf_cpu_map__get(cpus);
 +	if (cpus != evlist->cpus) {
 +		cpu_map__put(evlist->cpus);
 +		evlist->cpus = cpu_map__get(cpus);
  	}
  
++<<<<<<< HEAD
 +	if (threads != evlist->threads) {
 +		thread_map__put(evlist->threads);
 +		evlist->threads = thread_map__get(threads);
++=======
+ 	if (threads != evlist->core.threads) {
+ 		perf_thread_map__put(evlist->core.threads);
+ 		evlist->core.threads = perf_thread_map__get(threads);
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  	}
  
  	perf_evlist__propagate_maps(evlist);
@@@ -1397,7 -1398,7 +1438,11 @@@ int perf_evlist__open(struct perf_evlis
  	 * Default: one fd per CPU, all threads, aka systemwide
  	 * as sys_perf_event_open(cpu = -1, thread = -1) is EINVAL
  	 */
++<<<<<<< HEAD
 +	if (evlist->threads == NULL && evlist->cpus == NULL) {
++=======
+ 	if (evlist->core.threads == NULL && evlist->core.cpus == NULL) {
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  		err = perf_evlist__create_syswide_maps(evlist);
  		if (err < 0)
  			goto out_err;
@@@ -1505,7 -1506,7 +1550,11 @@@ int perf_evlist__prepare_workload(struc
  				__func__, __LINE__);
  			goto out_close_pipes;
  		}
++<<<<<<< HEAD
 +		thread_map__set_pid(evlist->threads, 0, evlist->workload.pid);
++=======
+ 		perf_thread_map__set_pid(evlist->core.threads, 0, evlist->workload.pid);
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  	}
  
  	close(child_ready_pipe[1]);
@@@ -1919,8 -1920,8 +1968,13 @@@ int perf_evlist__start_sb_thread(struc
  		goto out_delete_evlist;
  
  	evlist__for_each_entry(evlist, counter) {
++<<<<<<< HEAD
 +		if (perf_evsel__open(counter, evlist->cpus,
 +				     evlist->threads) < 0)
++=======
+ 		if (evsel__open(counter, evlist->core.cpus,
+ 				     evlist->core.threads) < 0)
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  			goto out_delete_evlist;
  	}
  
diff --cc tools/perf/util/evlist.h
index 49354fe24d5f,de2025d198d4..000000000000
--- a/tools/perf/util/evlist.h
+++ b/tools/perf/util/evlist.h
@@@ -44,12 -43,10 +44,16 @@@ struct perf_evlist 
  	struct fdarray	 pollfd;
  	struct perf_mmap *mmap;
  	struct perf_mmap *overwrite_mmap;
++<<<<<<< HEAD
 +	struct thread_map *threads;
 +	struct cpu_map	  *cpus;
 +	struct perf_evsel *selected;
++=======
+ 	struct evsel *selected;
++>>>>>>> 03617c22e31f (libperf: Add threads to struct perf_evlist)
  	struct events_stats stats;
  	struct perf_env	*env;
 -	void (*trace_event_sample_raw)(struct evlist *evlist,
 +	void (*trace_event_sample_raw)(struct perf_evlist *evlist,
  				       union perf_event *event,
  				       struct perf_sample *sample);
  	u64		first_sample_time;
* Unmerged path tools/perf/lib/include/internal/evlist.h
diff --git a/tools/perf/builtin-ftrace.c b/tools/perf/builtin-ftrace.c
index f0a576403ecd..eedf831280d6 100644
--- a/tools/perf/builtin-ftrace.c
+++ b/tools/perf/builtin-ftrace.c
@@ -157,9 +157,9 @@ static int set_tracing_pid(struct perf_ftrace *ftrace)
 	if (target__has_cpu(&ftrace->target))
 		return 0;
 
-	for (i = 0; i < thread_map__nr(ftrace->evlist->threads); i++) {
+	for (i = 0; i < thread_map__nr(ftrace->evlist->core.threads); i++) {
 		scnprintf(buf, sizeof(buf), "%d",
-			  ftrace->evlist->threads->map[i]);
+			  ftrace->evlist->core.threads->map[i]);
 		if (append_tracing_file("set_ftrace_pid", buf) < 0)
 			return -1;
 	}
diff --git a/tools/perf/builtin-kvm.c b/tools/perf/builtin-kvm.c
index 02e719faa488..1de18567f22e 100644
--- a/tools/perf/builtin-kvm.c
+++ b/tools/perf/builtin-kvm.c
@@ -1451,7 +1451,7 @@ static int kvm_events_live(struct perf_kvm_stat *kvm,
 	perf_session__set_id_hdr_size(kvm->session);
 	ordered_events__set_copy_on_queue(&kvm->session->ordered_events, true);
 	machine__synthesize_threads(&kvm->session->machines.host, &kvm->opts.target,
-				    kvm->evlist->threads, false, 1);
+				    kvm->evlist->core.threads, false, 1);
 	err = kvm_live_open_events(kvm);
 	if (err)
 		goto out;
diff --git a/tools/perf/builtin-record.c b/tools/perf/builtin-record.c
index 6dccaf4058f3..b2133d483962 100644
--- a/tools/perf/builtin-record.c
+++ b/tools/perf/builtin-record.c
@@ -1276,7 +1276,7 @@ static int record__synthesize(struct record *rec, bool tail)
 	if (err)
 		goto out;
 
-	err = perf_event__synthesize_thread_map2(&rec->tool, rec->evlist->threads,
+	err = perf_event__synthesize_thread_map2(&rec->tool, rec->evlist->core.threads,
 						 process_synthesized_event,
 						NULL);
 	if (err < 0) {
@@ -1296,7 +1296,7 @@ static int record__synthesize(struct record *rec, bool tail)
 	if (err < 0)
 		pr_warning("Couldn't synthesize bpf events.\n");
 
-	err = __machine__synthesize_threads(machine, tool, &opts->target, rec->evlist->threads,
+	err = __machine__synthesize_threads(machine, tool, &opts->target, rec->evlist->core.threads,
 					    process_synthesized_event, opts->sample_address,
 					    1);
 out:
diff --git a/tools/perf/builtin-stat.c b/tools/perf/builtin-stat.c
index b71c4390d333..c6b3ef6c4af6 100644
--- a/tools/perf/builtin-stat.c
+++ b/tools/perf/builtin-stat.c
@@ -265,7 +265,7 @@ static int read_single_counter(struct perf_evsel *counter, int cpu,
  */
 static int read_counter(struct perf_evsel *counter, struct timespec *rs)
 {
-	int nthreads = thread_map__nr(evsel_list->threads);
+	int nthreads = thread_map__nr(evsel_list->core.threads);
 	int ncpus, cpu, thread;
 
 	if (target__has_cpu(&target) && !target__has_per_thread(&target))
@@ -487,15 +487,15 @@ static int __run_perf_stat(int argc, const char **argv, int run_idx)
                                         ui__warning("%s\n", msg);
                                 goto try_again;
 			} else if (target__has_per_thread(&target) &&
-				   evsel_list->threads &&
-				   evsel_list->threads->err_thread != -1) {
+				   evsel_list->core.threads &&
+				   evsel_list->core.threads->err_thread != -1) {
 				/*
 				 * For global --per-thread case, skip current
 				 * error thread.
 				 */
-				if (!thread_map__remove(evsel_list->threads,
-							evsel_list->threads->err_thread)) {
-					evsel_list->threads->err_thread = -1;
+				if (!thread_map__remove(evsel_list->core.threads,
+							evsel_list->core.threads->err_thread)) {
+					evsel_list->core.threads->err_thread = -1;
 					goto try_again;
 				}
 			}
@@ -581,7 +581,7 @@ static int __run_perf_stat(int argc, const char **argv, int run_idx)
 		enable_counters();
 		while (!done) {
 			nanosleep(&ts, NULL);
-			if (!is_target_alive(&target, evsel_list->threads))
+			if (!is_target_alive(&target, evsel_list->core.threads))
 				break;
 			if (timeout)
 				break;
@@ -1891,10 +1891,10 @@ int cmd_stat(int argc, const char **argv)
 	 * so we could print it out on output.
 	 */
 	if (stat_config.aggr_mode == AGGR_THREAD) {
-		thread_map__read_comms(evsel_list->threads);
+		thread_map__read_comms(evsel_list->core.threads);
 		if (target.system_wide) {
 			if (runtime_stat_new(&stat_config,
-				thread_map__nr(evsel_list->threads))) {
+				thread_map__nr(evsel_list->core.threads))) {
 				goto out;
 			}
 		}
* Unmerged path tools/perf/builtin-top.c
* Unmerged path tools/perf/builtin-trace.c
* Unmerged path tools/perf/lib/include/internal/evlist.h
* Unmerged path tools/perf/tests/openat-syscall-tp-fields.c
* Unmerged path tools/perf/util/auxtrace.c
* Unmerged path tools/perf/util/evlist.c
* Unmerged path tools/perf/util/evlist.h
diff --git a/tools/perf/util/stat.c b/tools/perf/util/stat.c
index da269d46c09f..1d9189b45917 100644
--- a/tools/perf/util/stat.c
+++ b/tools/perf/util/stat.c
@@ -507,7 +507,7 @@ int perf_stat_synthesize_config(struct perf_stat_config *config,
 	err = perf_event__synthesize_extra_attr(tool, evlist, process,
 						attrs);
 
-	err = perf_event__synthesize_thread_map2(tool, evlist->threads,
+	err = perf_event__synthesize_thread_map2(tool, evlist->core.threads,
 						 process, NULL);
 	if (err < 0) {
 		pr_err("Couldn't synthesize thread map.\n");
