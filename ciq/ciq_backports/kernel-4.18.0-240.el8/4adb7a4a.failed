bpf: Fix leak in LINK_UPDATE and enforce empty old_prog_fd

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Andrii Nakryiko <andriin@fb.com>
commit 4adb7a4a151c65ac7e9c3a1aa462c84190d48385
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/4adb7a4a.failed

Fix bug of not putting bpf_link in LINK_UPDATE command.
Also enforce zeroed old_prog_fd if no BPF_F_REPLACE flag is specified.

	Signed-off-by: Andrii Nakryiko <andriin@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20200424052045.4002963-1-andriin@fb.com
(cherry picked from commit 4adb7a4a151c65ac7e9c3a1aa462c84190d48385)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/syscall.c
diff --cc kernel/bpf/syscall.c
index b5b79e59cfd4,bca58c235ac0..000000000000
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@@ -2908,6 -3503,166 +2908,169 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ #define BPF_MAP_BATCH_LAST_FIELD batch.flags
+ 
+ #define BPF_DO_BATCH(fn)			\
+ 	do {					\
+ 		if (!fn) {			\
+ 			err = -ENOTSUPP;	\
+ 			goto err_put;		\
+ 		}				\
+ 		err = fn(map, attr, uattr);	\
+ 	} while (0)
+ 
+ static int bpf_map_do_batch(const union bpf_attr *attr,
+ 			    union bpf_attr __user *uattr,
+ 			    int cmd)
+ {
+ 	struct bpf_map *map;
+ 	int err, ufd;
+ 	struct fd f;
+ 
+ 	if (CHECK_ATTR(BPF_MAP_BATCH))
+ 		return -EINVAL;
+ 
+ 	ufd = attr->batch.map_fd;
+ 	f = fdget(ufd);
+ 	map = __bpf_map_get(f);
+ 	if (IS_ERR(map))
+ 		return PTR_ERR(map);
+ 
+ 	if ((cmd == BPF_MAP_LOOKUP_BATCH ||
+ 	     cmd == BPF_MAP_LOOKUP_AND_DELETE_BATCH) &&
+ 	    !(map_get_sys_perms(map, f) & FMODE_CAN_READ)) {
+ 		err = -EPERM;
+ 		goto err_put;
+ 	}
+ 
+ 	if (cmd != BPF_MAP_LOOKUP_BATCH &&
+ 	    !(map_get_sys_perms(map, f) & FMODE_CAN_WRITE)) {
+ 		err = -EPERM;
+ 		goto err_put;
+ 	}
+ 
+ 	if (cmd == BPF_MAP_LOOKUP_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_lookup_batch);
+ 	else if (cmd == BPF_MAP_LOOKUP_AND_DELETE_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_lookup_and_delete_batch);
+ 	else if (cmd == BPF_MAP_UPDATE_BATCH)
+ 		BPF_DO_BATCH(map->ops->map_update_batch);
+ 	else
+ 		BPF_DO_BATCH(map->ops->map_delete_batch);
+ 
+ err_put:
+ 	fdput(f);
+ 	return err;
+ }
+ 
+ #define BPF_LINK_CREATE_LAST_FIELD link_create.flags
+ static int link_create(union bpf_attr *attr)
+ {
+ 	enum bpf_prog_type ptype;
+ 	struct bpf_prog *prog;
+ 	int ret;
+ 
+ 	if (!capable(CAP_NET_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (CHECK_ATTR(BPF_LINK_CREATE))
+ 		return -EINVAL;
+ 
+ 	ptype = attach_type_to_prog_type(attr->link_create.attach_type);
+ 	if (ptype == BPF_PROG_TYPE_UNSPEC)
+ 		return -EINVAL;
+ 
+ 	prog = bpf_prog_get_type(attr->link_create.prog_fd, ptype);
+ 	if (IS_ERR(prog))
+ 		return PTR_ERR(prog);
+ 
+ 	ret = bpf_prog_attach_check_attach_type(prog,
+ 						attr->link_create.attach_type);
+ 	if (ret)
+ 		goto err_out;
+ 
+ 	switch (ptype) {
+ 	case BPF_PROG_TYPE_CGROUP_SKB:
+ 	case BPF_PROG_TYPE_CGROUP_SOCK:
+ 	case BPF_PROG_TYPE_CGROUP_SOCK_ADDR:
+ 	case BPF_PROG_TYPE_SOCK_OPS:
+ 	case BPF_PROG_TYPE_CGROUP_DEVICE:
+ 	case BPF_PROG_TYPE_CGROUP_SYSCTL:
+ 	case BPF_PROG_TYPE_CGROUP_SOCKOPT:
+ 		ret = cgroup_bpf_link_attach(attr, prog);
+ 		break;
+ 	default:
+ 		ret = -EINVAL;
+ 	}
+ 
+ err_out:
+ 	if (ret < 0)
+ 		bpf_prog_put(prog);
+ 	return ret;
+ }
+ 
+ #define BPF_LINK_UPDATE_LAST_FIELD link_update.old_prog_fd
+ 
+ static int link_update(union bpf_attr *attr)
+ {
+ 	struct bpf_prog *old_prog = NULL, *new_prog;
+ 	struct bpf_link *link;
+ 	u32 flags;
+ 	int ret;
+ 
+ 	if (!capable(CAP_NET_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (CHECK_ATTR(BPF_LINK_UPDATE))
+ 		return -EINVAL;
+ 
+ 	flags = attr->link_update.flags;
+ 	if (flags & ~BPF_F_REPLACE)
+ 		return -EINVAL;
+ 
+ 	link = bpf_link_get_from_fd(attr->link_update.link_fd);
+ 	if (IS_ERR(link))
+ 		return PTR_ERR(link);
+ 
+ 	new_prog = bpf_prog_get(attr->link_update.new_prog_fd);
+ 	if (IS_ERR(new_prog)) {
+ 		ret = PTR_ERR(new_prog);
+ 		goto out_put_link;
+ 	}
+ 
+ 	if (flags & BPF_F_REPLACE) {
+ 		old_prog = bpf_prog_get(attr->link_update.old_prog_fd);
+ 		if (IS_ERR(old_prog)) {
+ 			ret = PTR_ERR(old_prog);
+ 			old_prog = NULL;
+ 			goto out_put_progs;
+ 		}
+ 	} else if (attr->link_update.old_prog_fd) {
+ 		ret = -EINVAL;
+ 		goto out_put_progs;
+ 	}
+ 
+ #ifdef CONFIG_CGROUP_BPF
+ 	if (link->ops == &bpf_cgroup_link_lops) {
+ 		ret = cgroup_bpf_replace(link, old_prog, new_prog);
+ 		goto out_put_progs;
+ 	}
+ #endif
+ 	ret = -EINVAL;
+ 
+ out_put_progs:
+ 	if (old_prog)
+ 		bpf_prog_put(old_prog);
+ 	if (ret)
+ 		bpf_prog_put(new_prog);
+ out_put_link:
+ 	bpf_link_put(link);
+ 	return ret;
+ }
+ 
++>>>>>>> 4adb7a4a151c (bpf: Fix leak in LINK_UPDATE and enforce empty old_prog_fd)
  SYSCALL_DEFINE3(bpf, int, cmd, union bpf_attr __user *, uattr, unsigned int, size)
  {
  	union bpf_attr attr;
* Unmerged path kernel/bpf/syscall.c
