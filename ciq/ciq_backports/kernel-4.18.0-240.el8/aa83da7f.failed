gfs2: More gfs2_find_jhead fixes

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Andreas Gruenbacher <agruenba@redhat.com>
commit aa83da7f47b26c9587bade6c4bc4736ffa308f0a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/aa83da7f.failed

It turns out that when extending an existing bio, gfs2_find_jhead fails to
check if the block number is consecutive, which leads to incorrect reads for
fragmented journals.

In addition, limit the maximum bio size to an arbitrary value of 2 megabytes:
since commit 07173c3ec276 ("block: enable multipage bvecs"), if we just keep
adding pages until bio_add_page fails, bios will grow much larger than useful,
which pins more memory than necessary with barely any additional performance
gains.

Fixes: f4686c26ecc3 ("gfs2: read journal in large chunks")
	Cc: stable@vger.kernel.org # v5.2+
	Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
	Signed-off-by: Bob Peterson <rpeterso@redhat.com>
(cherry picked from commit aa83da7f47b26c9587bade6c4bc4736ffa308f0a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/gfs2/lops.c
diff --cc fs/gfs2/lops.c
index dfac677e2663,48b54ec1c793..000000000000
--- a/fs/gfs2/lops.c
+++ b/fs/gfs2/lops.c
@@@ -248,33 -247,27 +248,37 @@@ void gfs2_log_flush_bio(struct gfs2_sb
  }
  
  /**
 - * gfs2_log_alloc_bio - Allocate a bio
 - * @sdp: The super block
 - * @blkno: The device block number we want to write to
 - * @end_io: The bi_end_io callback
 + * gfs2_log_alloc_bio - Allocate a new bio for log writing
 + * @sdp: The superblock
 + * @blkno: The next device block number we want to write to
   *
 - * Allocate a new bio, initialize it with the given parameters and return it.
 + * This should never be called when there is a cached bio in the
 + * super block. When it returns, there will be a cached bio in the
 + * super block which will have as many bio_vecs as the device is
 + * happy to handle.
   *
 - * Returns: The newly allocated bio
 + * Returns: Newly allocated bio
   */
  
 -static struct bio *gfs2_log_alloc_bio(struct gfs2_sbd *sdp, u64 blkno,
 -				      bio_end_io_t *end_io)
 +static struct bio *gfs2_log_alloc_bio(struct gfs2_sbd *sdp, u64 blkno)
  {
  	struct super_block *sb = sdp->sd_vfs;
 -	struct bio *bio = bio_alloc(GFP_NOIO, BIO_MAX_PAGES);
 +	struct bio *bio;
 +
++<<<<<<< HEAD
 +	BUG_ON(sdp->sd_log_bio);
  
 +	bio = bio_alloc(GFP_NOIO, BIO_MAX_PAGES);
 +	bio->bi_iter.bi_sector = blkno * (sb->s_blocksize >> 9);
++=======
+ 	bio->bi_iter.bi_sector = blkno << sdp->sd_fsb2bb_shift;
++>>>>>>> aa83da7f47b2 (gfs2: More gfs2_find_jhead fixes)
  	bio_set_dev(bio, sb->s_bdev);
 -	bio->bi_end_io = end_io;
 +	bio->bi_end_io = gfs2_end_log_write;
  	bio->bi_private = sdp;
  
 +	sdp->sd_log_bio = bio;
 +
  	return bio;
  }
  
@@@ -366,8 -371,235 +370,240 @@@ static void gfs2_log_write_bh(struct gf
  void gfs2_log_write_page(struct gfs2_sbd *sdp, struct page *page)
  {
  	struct super_block *sb = sdp->sd_vfs;
++<<<<<<< HEAD
 +	gfs2_log_write(sdp, page, sb->s_blocksize, 0,
 +		       gfs2_log_bmap(sdp));
++=======
+ 	u64 dblock;
+ 
+ 	dblock = gfs2_log_bmap(sdp->sd_jdesc, sdp->sd_log_flush_head);
+ 	gfs2_log_incr_head(sdp);
+ 	gfs2_log_write(sdp, page, sb->s_blocksize, 0, dblock);
+ }
+ 
+ /**
+  * gfs2_end_log_read - end I/O callback for reads from the log
+  * @bio: The bio
+  *
+  * Simply unlock the pages in the bio. The main thread will wait on them and
+  * process them in order as necessary.
+  */
+ 
+ static void gfs2_end_log_read(struct bio *bio)
+ {
+ 	struct page *page;
+ 	struct bio_vec *bvec;
+ 	struct bvec_iter_all iter_all;
+ 
+ 	bio_for_each_segment_all(bvec, bio, iter_all) {
+ 		page = bvec->bv_page;
+ 		if (bio->bi_status) {
+ 			int err = blk_status_to_errno(bio->bi_status);
+ 
+ 			SetPageError(page);
+ 			mapping_set_error(page->mapping, err);
+ 		}
+ 		unlock_page(page);
+ 	}
+ 
+ 	bio_put(bio);
+ }
+ 
+ /**
+  * gfs2_jhead_pg_srch - Look for the journal head in a given page.
+  * @jd: The journal descriptor
+  * @page: The page to look in
+  *
+  * Returns: 1 if found, 0 otherwise.
+  */
+ 
+ static bool gfs2_jhead_pg_srch(struct gfs2_jdesc *jd,
+ 			      struct gfs2_log_header_host *head,
+ 			      struct page *page)
+ {
+ 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
+ 	struct gfs2_log_header_host uninitialized_var(lh);
+ 	void *kaddr = kmap_atomic(page);
+ 	unsigned int offset;
+ 	bool ret = false;
+ 
+ 	for (offset = 0; offset < PAGE_SIZE; offset += sdp->sd_sb.sb_bsize) {
+ 		if (!__get_log_header(sdp, kaddr + offset, 0, &lh)) {
+ 			if (lh.lh_sequence >= head->lh_sequence)
+ 				*head = lh;
+ 			else {
+ 				ret = true;
+ 				break;
+ 			}
+ 		}
+ 	}
+ 	kunmap_atomic(kaddr);
+ 	return ret;
+ }
+ 
+ /**
+  * gfs2_jhead_process_page - Search/cleanup a page
+  * @jd: The journal descriptor
+  * @index: Index of the page to look into
+  * @done: If set, perform only cleanup, else search and set if found.
+  *
+  * Find the page with 'index' in the journal's mapping. Search the page for
+  * the journal head if requested (cleanup == false). Release refs on the
+  * page so the page cache can reclaim it (put_page() twice). We grabbed a
+  * reference on this page two times, first when we did a find_or_create_page()
+  * to obtain the page to add it to the bio and second when we do a
+  * find_get_page() here to get the page to wait on while I/O on it is being
+  * completed.
+  * This function is also used to free up a page we might've grabbed but not
+  * used. Maybe we added it to a bio, but not submitted it for I/O. Or we
+  * submitted the I/O, but we already found the jhead so we only need to drop
+  * our references to the page.
+  */
+ 
+ static void gfs2_jhead_process_page(struct gfs2_jdesc *jd, unsigned long index,
+ 				    struct gfs2_log_header_host *head,
+ 				    bool *done)
+ {
+ 	struct page *page;
+ 
+ 	page = find_get_page(jd->jd_inode->i_mapping, index);
+ 	wait_on_page_locked(page);
+ 
+ 	if (PageError(page))
+ 		*done = true;
+ 
+ 	if (!*done)
+ 		*done = gfs2_jhead_pg_srch(jd, head, page);
+ 
+ 	put_page(page); /* Once for find_get_page */
+ 	put_page(page); /* Once more for find_or_create_page */
+ }
+ 
+ static struct bio *gfs2_chain_bio(struct bio *prev, unsigned int nr_iovecs)
+ {
+ 	struct bio *new;
+ 
+ 	new = bio_alloc(GFP_NOIO, nr_iovecs);
+ 	bio_copy_dev(new, prev);
+ 	new->bi_iter.bi_sector = bio_end_sector(prev);
+ 	new->bi_opf = prev->bi_opf;
+ 	new->bi_write_hint = prev->bi_write_hint;
+ 	bio_chain(new, prev);
+ 	submit_bio(prev);
+ 	return new;
+ }
+ 
+ /**
+  * gfs2_find_jhead - find the head of a log
+  * @jd: The journal descriptor
+  * @head: The log descriptor for the head of the log is returned here
+  *
+  * Do a search of a journal by reading it in large chunks using bios and find
+  * the valid log entry with the highest sequence number.  (i.e. the log head)
+  *
+  * Returns: 0 on success, errno otherwise
+  */
+ int gfs2_find_jhead(struct gfs2_jdesc *jd, struct gfs2_log_header_host *head,
+ 		    bool keep_cache)
+ {
+ 	struct gfs2_sbd *sdp = GFS2_SB(jd->jd_inode);
+ 	struct address_space *mapping = jd->jd_inode->i_mapping;
+ 	unsigned int block = 0, blocks_submitted = 0, blocks_read = 0;
+ 	unsigned int bsize = sdp->sd_sb.sb_bsize, off;
+ 	unsigned int bsize_shift = sdp->sd_sb.sb_bsize_shift;
+ 	unsigned int shift = PAGE_SHIFT - bsize_shift;
+ 	unsigned int max_bio_size = 2 * 1024 * 1024;
+ 	struct gfs2_journal_extent *je;
+ 	int sz, ret = 0;
+ 	struct bio *bio = NULL;
+ 	struct page *page = NULL;
+ 	bool bio_chained = false, done = false;
+ 	errseq_t since;
+ 
+ 	memset(head, 0, sizeof(*head));
+ 	if (list_empty(&jd->extent_list))
+ 		gfs2_map_journal_extents(sdp, jd);
+ 
+ 	since = filemap_sample_wb_err(mapping);
+ 	list_for_each_entry(je, &jd->extent_list, list) {
+ 		u64 dblock = je->dblock;
+ 
+ 		for (; block < je->lblock + je->blocks; block++, dblock++) {
+ 			if (!page) {
+ 				page = find_or_create_page(mapping,
+ 						block >> shift, GFP_NOFS);
+ 				if (!page) {
+ 					ret = -ENOMEM;
+ 					done = true;
+ 					goto out;
+ 				}
+ 				off = 0;
+ 			}
+ 
+ 			if (!bio || (bio_chained && !off) ||
+ 			    bio->bi_iter.bi_size >= max_bio_size) {
+ 				/* start new bio */
+ 			} else {
+ 				sector_t sector = dblock << sdp->sd_fsb2bb_shift;
+ 
+ 				if (bio_end_sector(bio) == sector) {
+ 					sz = bio_add_page(bio, page, bsize, off);
+ 					if (sz == bsize)
+ 						goto block_added;
+ 				}
+ 				if (off) {
+ 					unsigned int blocks =
+ 						(PAGE_SIZE - off) >> bsize_shift;
+ 
+ 					bio = gfs2_chain_bio(bio, blocks);
+ 					bio_chained = true;
+ 					goto add_block_to_new_bio;
+ 				}
+ 			}
+ 
+ 			if (bio) {
+ 				blocks_submitted = block + 1;
+ 				submit_bio(bio);
+ 			}
+ 
+ 			bio = gfs2_log_alloc_bio(sdp, dblock, gfs2_end_log_read);
+ 			bio->bi_opf = REQ_OP_READ;
+ 			bio_chained = false;
+ add_block_to_new_bio:
+ 			sz = bio_add_page(bio, page, bsize, off);
+ 			BUG_ON(sz != bsize);
+ block_added:
+ 			off += bsize;
+ 			if (off == PAGE_SIZE)
+ 				page = NULL;
+ 			if (blocks_submitted < 2 * max_bio_size >> bsize_shift) {
+ 				/* Keep at least one bio in flight */
+ 				continue;
+ 			}
+ 
+ 			gfs2_jhead_process_page(jd, blocks_read >> shift, head, &done);
+ 			blocks_read += PAGE_SIZE >> bsize_shift;
+ 			if (done)
+ 				goto out;  /* found */
+ 		}
+ 	}
+ 
+ out:
+ 	if (bio)
+ 		submit_bio(bio);
+ 	while (blocks_read < block) {
+ 		gfs2_jhead_process_page(jd, blocks_read >> shift, head, &done);
+ 		blocks_read += PAGE_SIZE >> bsize_shift;
+ 	}
+ 
+ 	if (!ret)
+ 		ret = filemap_check_wb_err(mapping, since);
+ 
+ 	if (!keep_cache)
+ 		truncate_inode_pages(mapping, 0);
+ 
+ 	return ret;
++>>>>>>> aa83da7f47b2 (gfs2: More gfs2_find_jhead fixes)
  }
  
  static struct page *gfs2_get_log_desc(struct gfs2_sbd *sdp, u32 ld_type,
* Unmerged path fs/gfs2/lops.c
