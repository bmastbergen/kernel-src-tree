drm/amd/display: Split program front end part that occur outside lock

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Anthony Koo <Anthony.Koo@amd.com>
commit bbf5f6c3f83bedd71006473849138a446ad4d9a3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/bbf5f6c3.failed

[Why]
Eventually want to lock at a higher level in stack.
To do this, we need to be able to isolate the parts that need to be done
after pipe unlock.

[How]
Split out programming that is done post unlock.

	Signed-off-by: Anthony Koo <Anthony.Koo@amd.com>
	Reviewed-by: Aric Cyr <Aric.Cyr@amd.com>
	Acked-by: Bhawanpreet Lakha <Bhawanpreet.Lakha@amd.com>
	Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
(cherry picked from commit bbf5f6c3f83bedd71006473849138a446ad4d9a3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/amd/display/dc/core/dc.c
#	drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c
#	drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.h
#	drivers/gpu/drm/amd/display/dc/dcn10/dcn10_init.c
#	drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
#	drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.h
#	drivers/gpu/drm/amd/display/dc/dcn20/dcn20_init.c
#	drivers/gpu/drm/amd/display/dc/dcn21/dcn21_init.c
#	drivers/gpu/drm/amd/display/dc/inc/hw_sequencer.h
diff --cc drivers/gpu/drm/amd/display/dc/core/dc.c
index d8c0d01bb191,738ba91220df..000000000000
--- a/drivers/gpu/drm/amd/display/dc/core/dc.c
+++ b/drivers/gpu/drm/amd/display/dc/core/dc.c
@@@ -745,10 -785,15 +745,21 @@@ static void disable_dangling_plane(stru
  		}
  		if (should_disable && old_stream) {
  			dc_rem_all_planes_for_stream(dc, old_stream, dangling_context);
 +#if defined(CONFIG_DRM_AMD_DC_DCN2_0)
  			disable_all_writeback_pipes_for_stream(dc, old_stream, dangling_context);
++<<<<<<< HEAD
 +#endif
 +			dc->hwss.apply_ctx_for_surface(dc, old_stream, 0, dangling_context);
++=======
+ 			if (dc->hwss.apply_ctx_for_surface) {
+ 				dc->hwss.apply_ctx_for_surface(dc, old_stream, 0, dangling_context);
+ 				dc->hwss.post_unlock_program_front_end(dc, dangling_context);
+ 			}
+ 			if (dc->hwss.program_front_end_for_ctx) {
+ 				dc->hwss.program_front_end_for_ctx(dc, dangling_context);
+ 				dc->hwss.post_unlock_program_front_end(dc, dangling_context);
+ 			}
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  		}
  	}
  
@@@ -1050,15 -1214,17 +1061,24 @@@ static enum dc_status dc_commit_state_n
  	/* re-program planes for existing stream, in case we need to
  	 * free up plane resource for later use
  	 */
 -	if (dc->hwss.apply_ctx_for_surface)
 -		for (i = 0; i < context->stream_count; i++) {
 -			if (context->streams[i]->mode_changed)
 -				continue;
 +	for (i = 0; i < context->stream_count; i++) {
 +		if (context->streams[i]->mode_changed)
 +			continue;
  
++<<<<<<< HEAD
 +		dc->hwss.apply_ctx_for_surface(
 +			dc, context->streams[i],
 +			context->stream_status[i].plane_count,
 +			context); /* use new pipe config in new context */
 +	}
++=======
+ 			dc->hwss.apply_ctx_for_surface(
+ 				dc, context->streams[i],
+ 				context->stream_status[i].plane_count,
+ 				context); /* use new pipe config in new context */
+ 			dc->hwss.post_unlock_program_front_end(dc, context);
+ 		}
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  
  	/* Program hardware */
  	for (i = 0; i < dc->res_pool->pipe_count; i++) {
@@@ -1077,16 -1243,24 +1097,34 @@@
  	}
  
  	/* Program all planes within new context*/
++<<<<<<< HEAD
++=======
+ 	if (dc->hwss.program_front_end_for_ctx) {
+ 		dc->hwss.program_front_end_for_ctx(dc, context);
+ 		dc->hwss.post_unlock_program_front_end(dc, context);
+ 	}
+ 
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  	for (i = 0; i < context->stream_count; i++) {
  		const struct dc_link *link = context->streams[i]->link;
  
  		if (!context->streams[i]->mode_changed)
  			continue;
  
++<<<<<<< HEAD
 +		dc->hwss.apply_ctx_for_surface(
 +				dc, context->streams[i],
 +				context->stream_status[i].plane_count,
 +				context);
++=======
+ 		if (dc->hwss.apply_ctx_for_surface) {
+ 			dc->hwss.apply_ctx_for_surface(
+ 					dc, context->streams[i],
+ 					context->stream_status[i].plane_count,
+ 					context);
+ 			dc->hwss.post_unlock_program_front_end(dc, context);
+ 		}
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  
  		/*
  		 * enable stereo
@@@ -1909,7 -2188,12 +1947,16 @@@ static void commit_planes_for_stream(st
  		 * In case of turning off screen, no need to program front end a second time.
  		 * just return after program blank.
  		 */
++<<<<<<< HEAD
 +		dc->hwss.apply_ctx_for_surface(dc, stream, 0, context);
++=======
+ 		if (dc->hwss.apply_ctx_for_surface)
+ 			dc->hwss.apply_ctx_for_surface(dc, stream, 0, context);
+ 		if (dc->hwss.program_front_end_for_ctx)
+ 			dc->hwss.program_front_end_for_ctx(dc, context);
+ 
+ 		dc->hwss.post_unlock_program_front_end(dc, context);
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  		return;
  	}
  
diff --cc drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c
index 2118ea21d7e9,a9a5a13d5edf..000000000000
--- a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c
@@@ -2403,10 -2511,10 +2403,9 @@@ static void dcn10_apply_ctx_for_surface
  	int i;
  	struct timing_generator *tg;
  	uint32_t underflow_check_delay_us;
- 	bool removed_pipe[4] = { false };
  	bool interdependent_update = false;
  	struct pipe_ctx *top_pipe_to_program =
 -			dcn10_find_top_pipe_for_stream(dc, context, stream);
 +			find_top_pipe_for_stream(dc, context, stream);
  	DC_LOGGER_INIT(dc->ctx->logger);
  
  	if (!top_pipe_to_program)
@@@ -2461,8 -2572,8 +2463,13 @@@
  		    old_pipe_ctx->plane_state &&
  		    old_pipe_ctx->stream_res.tg == tg) {
  
++<<<<<<< HEAD
 +			dc->hwss.plane_atomic_disconnect(dc, old_pipe_ctx);
 +			removed_pipe[i] = true;
++=======
+ 			hws->funcs.plane_atomic_disconnect(dc, old_pipe_ctx);
+ 			pipe_ctx->update_flags.bits.disable = 1;
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  
  			DC_LOG_DC("Reset mpcc for pipe %d\n",
  					old_pipe_ctx->pipe_idx);
@@@ -2492,19 -2601,44 +2499,49 @@@
  		}
  
  	if (interdependent_update)
 -		dcn10_lock_all_pipes(dc, context, false);
 +		lock_all_pipes(dc, context, false);
  	else
  		dcn10_pipe_control_lock(dc, top_pipe_to_program, false);
+ }
+ 
+ void dcn10_post_unlock_program_front_end(
+ 		struct dc *dc,
+ 		struct dc_state *context)
+ {
+ 	int i, j;
+ 
+ 	DC_LOGGER_INIT(dc->ctx->logger);
  
- 	if (num_planes == 0)
- 		false_optc_underflow_wa(dc, stream, tg);
+ 	for (i = 0; i < dc->res_pool->pipe_count; i++) {
+ 		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
+ 
+ 		if (!pipe_ctx->top_pipe &&
+ 			!pipe_ctx->prev_odm_pipe &&
+ 			pipe_ctx->stream) {
+ 			struct dc_stream_status *stream_status = NULL;
+ 			struct timing_generator *tg = pipe_ctx->stream_res.tg;
+ 
+ 			for (j = 0; j < context->stream_count; j++) {
+ 				if (pipe_ctx->stream == context->streams[j])
+ 					stream_status = &context->stream_status[j];
+ 			}
+ 
+ 			if (context->stream_status[i].plane_count == 0)
+ 				false_optc_underflow_wa(dc, pipe_ctx->stream, tg);
+ 		}
+ 	}
  
  	for (i = 0; i < dc->res_pool->pipe_count; i++)
++<<<<<<< HEAD
 +		if (removed_pipe[i])
 +			dcn10_disable_plane(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
++=======
+ 		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable)
+ 			dc->hwss.disable_plane(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  
  	for (i = 0; i < dc->res_pool->pipe_count; i++)
- 		if (removed_pipe[i]) {
+ 		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable) {
  			dc->hwss.optimize_bandwidth(dc, context);
  			break;
  		}
diff --cc drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.h
index d3616b1948cc,b523f0b8dc23..000000000000
--- a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.h
+++ b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.h
@@@ -31,16 -32,66 +31,78 @@@
  struct dc;
  
  void dcn10_hw_sequencer_construct(struct dc *dc);
 +extern void fill_display_configs(
 +	const struct dc_state *context,
 +	struct dm_pp_display_configuration *pp_display_cfg);
  
 +bool is_rgb_cspace(enum dc_color_space output_color_space);
 +
 +void hwss1_plane_atomic_disconnect(struct dc *dc, struct pipe_ctx *pipe_ctx);
 +
 +void dcn10_verify_allow_pstate_change_high(struct dc *dc);
 +
++<<<<<<< HEAD
++=======
+ int dcn10_get_vupdate_offset_from_vsync(struct pipe_ctx *pipe_ctx);
+ void dcn10_setup_vupdate_interrupt(struct dc *dc, struct pipe_ctx *pipe_ctx);
+ enum dc_status dcn10_enable_stream_timing(
+ 		struct pipe_ctx *pipe_ctx,
+ 		struct dc_state *context,
+ 		struct dc *dc);
+ void dcn10_optimize_bandwidth(
+ 		struct dc *dc,
+ 		struct dc_state *context);
+ void dcn10_prepare_bandwidth(
+ 		struct dc *dc,
+ 		struct dc_state *context);
+ void dcn10_pipe_control_lock(
+ 	struct dc *dc,
+ 	struct pipe_ctx *pipe,
+ 	bool lock);
+ void dcn10_blank_pixel_data(
+ 		struct dc *dc,
+ 		struct pipe_ctx *pipe_ctx,
+ 		bool blank);
+ void dcn10_unblank_stream(struct pipe_ctx *pipe_ctx,
+ 		struct dc_link_settings *link_settings);
+ void dcn10_program_output_csc(struct dc *dc,
+ 		struct pipe_ctx *pipe_ctx,
+ 		enum dc_color_space colorspace,
+ 		uint16_t *matrix,
+ 		int opp_id);
+ bool dcn10_set_output_transfer_func(struct dc *dc, struct pipe_ctx *pipe_ctx,
+ 				const struct dc_stream_state *stream);
+ bool dcn10_set_input_transfer_func(struct dc *dc, struct pipe_ctx *pipe_ctx,
+ 			const struct dc_plane_state *plane_state);
+ void dcn10_update_plane_addr(const struct dc *dc, struct pipe_ctx *pipe_ctx);
+ void dcn10_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx);
+ void dcn10_reset_hw_ctx_wrap(
+ 		struct dc *dc,
+ 		struct dc_state *context);
+ void dcn10_disable_plane(struct dc *dc, struct pipe_ctx *pipe_ctx);
+ void dcn10_apply_ctx_for_surface(
+ 		struct dc *dc,
+ 		const struct dc_stream_state *stream,
+ 		int num_planes,
+ 		struct dc_state *context);
+ void dcn10_post_unlock_program_front_end(
+ 		struct dc *dc,
+ 		struct dc_state *context);
+ void dcn10_hubp_pg_control(
+ 		struct dce_hwseq *hws,
+ 		unsigned int hubp_inst,
+ 		bool power_on);
+ void dcn10_dpp_pg_control(
+ 		struct dce_hwseq *hws,
+ 		unsigned int dpp_inst,
+ 		bool power_on);
+ void dcn10_enable_power_gating_plane(
+ 	struct dce_hwseq *hws,
+ 	bool enable);
+ void dcn10_plane_atomic_disable(struct dc *dc, struct pipe_ctx *pipe_ctx);
+ void dcn10_disable_vga(
+ 	struct dce_hwseq *hws);
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  void dcn10_program_pipe(
  		struct dc *dc,
  		struct pipe_ctx *pipe_ctx,
diff --cc drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
index fbbf9758dc66,f36c4d1b7c30..000000000000
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
@@@ -1312,112 -1167,501 +1312,201 @@@ void dcn20_pipe_control_lock
  	}
  }
  
 -static void dcn20_detect_pipe_changes(struct pipe_ctx *old_pipe, struct pipe_ctx *new_pipe)
 -{
 -	new_pipe->update_flags.raw = 0;
 -
 -	/* Exit on unchanged, unused pipe */
 -	if (!old_pipe->plane_state && !new_pipe->plane_state)
 -		return;
 -	/* Detect pipe enable/disable */
 -	if (!old_pipe->plane_state && new_pipe->plane_state) {
 -		new_pipe->update_flags.bits.enable = 1;
 -		new_pipe->update_flags.bits.mpcc = 1;
 -		new_pipe->update_flags.bits.dppclk = 1;
 -		new_pipe->update_flags.bits.hubp_interdependent = 1;
 -		new_pipe->update_flags.bits.hubp_rq_dlg_ttu = 1;
 -		new_pipe->update_flags.bits.gamut_remap = 1;
 -		new_pipe->update_flags.bits.scaler = 1;
 -		new_pipe->update_flags.bits.viewport = 1;
 -		if (!new_pipe->top_pipe && !new_pipe->prev_odm_pipe) {
 -			new_pipe->update_flags.bits.odm = 1;
 -			new_pipe->update_flags.bits.global_sync = 1;
 -		}
 -		return;
 -	}
 -	if (old_pipe->plane_state && !new_pipe->plane_state) {
 -		new_pipe->update_flags.bits.disable = 1;
 -		return;
 -	}
 -
 -	/* Detect top pipe only changes */
 -	if (!new_pipe->top_pipe && !new_pipe->prev_odm_pipe) {
 -		/* Detect odm changes */
 -		if ((old_pipe->next_odm_pipe && new_pipe->next_odm_pipe
 -			&& old_pipe->next_odm_pipe->pipe_idx != new_pipe->next_odm_pipe->pipe_idx)
 -				|| (!old_pipe->next_odm_pipe && new_pipe->next_odm_pipe)
 -				|| (old_pipe->next_odm_pipe && !new_pipe->next_odm_pipe)
 -				|| old_pipe->stream_res.opp != new_pipe->stream_res.opp)
 -			new_pipe->update_flags.bits.odm = 1;
 -
 -		/* Detect global sync changes */
 -		if (old_pipe->pipe_dlg_param.vready_offset != new_pipe->pipe_dlg_param.vready_offset
 -				|| old_pipe->pipe_dlg_param.vstartup_start != new_pipe->pipe_dlg_param.vstartup_start
 -				|| old_pipe->pipe_dlg_param.vupdate_offset != new_pipe->pipe_dlg_param.vupdate_offset
 -				|| old_pipe->pipe_dlg_param.vupdate_width != new_pipe->pipe_dlg_param.vupdate_width)
 -			new_pipe->update_flags.bits.global_sync = 1;
 -	}
 -
 -	/*
 -	 * Detect opp / tg change, only set on change, not on enable
 -	 * Assume mpcc inst = pipe index, if not this code needs to be updated
 -	 * since mpcc is what is affected by these. In fact all of our sequence
 -	 * makes this assumption at the moment with how hubp reset is matched to
 -	 * same index mpcc reset.
 -	 */
 -	if (old_pipe->stream_res.opp != new_pipe->stream_res.opp)
 -		new_pipe->update_flags.bits.opp_changed = 1;
 -	if (old_pipe->stream_res.tg != new_pipe->stream_res.tg)
 -		new_pipe->update_flags.bits.tg_changed = 1;
 -
 -	/* Detect mpcc blending changes, only dpp inst and bot matter here */
 -	if (old_pipe->plane_res.dpp != new_pipe->plane_res.dpp
 -			|| old_pipe->stream_res.opp != new_pipe->stream_res.opp
 -			|| (!old_pipe->bottom_pipe && new_pipe->bottom_pipe)
 -			|| (old_pipe->bottom_pipe && !new_pipe->bottom_pipe)
 -			|| (old_pipe->bottom_pipe && new_pipe->bottom_pipe
 -				&& old_pipe->bottom_pipe->plane_res.mpcc_inst
 -					!= new_pipe->bottom_pipe->plane_res.mpcc_inst))
 -		new_pipe->update_flags.bits.mpcc = 1;
 -
 -	/* Detect dppclk change */
 -	if (old_pipe->plane_res.bw.dppclk_khz != new_pipe->plane_res.bw.dppclk_khz)
 -		new_pipe->update_flags.bits.dppclk = 1;
 -
 -	/* Check for scl update */
 -	if (memcmp(&old_pipe->plane_res.scl_data, &new_pipe->plane_res.scl_data, sizeof(struct scaler_data)))
 -			new_pipe->update_flags.bits.scaler = 1;
 -	/* Check for vp update */
 -	if (memcmp(&old_pipe->plane_res.scl_data.viewport, &new_pipe->plane_res.scl_data.viewport, sizeof(struct rect))
 -			|| memcmp(&old_pipe->plane_res.scl_data.viewport_c,
 -				&new_pipe->plane_res.scl_data.viewport_c, sizeof(struct rect)))
 -		new_pipe->update_flags.bits.viewport = 1;
 -
 -	/* Detect dlg/ttu/rq updates */
 -	{
 -		struct _vcs_dpi_display_dlg_regs_st old_dlg_attr = old_pipe->dlg_regs;
 -		struct _vcs_dpi_display_ttu_regs_st old_ttu_attr = old_pipe->ttu_regs;
 -		struct _vcs_dpi_display_dlg_regs_st *new_dlg_attr = &new_pipe->dlg_regs;
 -		struct _vcs_dpi_display_ttu_regs_st *new_ttu_attr = &new_pipe->ttu_regs;
 -
 -		/* Detect pipe interdependent updates */
 -		if (old_dlg_attr.dst_y_prefetch != new_dlg_attr->dst_y_prefetch ||
 -				old_dlg_attr.vratio_prefetch != new_dlg_attr->vratio_prefetch ||
 -				old_dlg_attr.vratio_prefetch_c != new_dlg_attr->vratio_prefetch_c ||
 -				old_dlg_attr.dst_y_per_vm_vblank != new_dlg_attr->dst_y_per_vm_vblank ||
 -				old_dlg_attr.dst_y_per_row_vblank != new_dlg_attr->dst_y_per_row_vblank ||
 -				old_dlg_attr.dst_y_per_vm_flip != new_dlg_attr->dst_y_per_vm_flip ||
 -				old_dlg_attr.dst_y_per_row_flip != new_dlg_attr->dst_y_per_row_flip ||
 -				old_dlg_attr.refcyc_per_meta_chunk_vblank_l != new_dlg_attr->refcyc_per_meta_chunk_vblank_l ||
 -				old_dlg_attr.refcyc_per_meta_chunk_vblank_c != new_dlg_attr->refcyc_per_meta_chunk_vblank_c ||
 -				old_dlg_attr.refcyc_per_meta_chunk_flip_l != new_dlg_attr->refcyc_per_meta_chunk_flip_l ||
 -				old_dlg_attr.refcyc_per_line_delivery_pre_l != new_dlg_attr->refcyc_per_line_delivery_pre_l ||
 -				old_dlg_attr.refcyc_per_line_delivery_pre_c != new_dlg_attr->refcyc_per_line_delivery_pre_c ||
 -				old_ttu_attr.refcyc_per_req_delivery_pre_l != new_ttu_attr->refcyc_per_req_delivery_pre_l ||
 -				old_ttu_attr.refcyc_per_req_delivery_pre_c != new_ttu_attr->refcyc_per_req_delivery_pre_c ||
 -				old_ttu_attr.refcyc_per_req_delivery_pre_cur0 != new_ttu_attr->refcyc_per_req_delivery_pre_cur0 ||
 -				old_ttu_attr.refcyc_per_req_delivery_pre_cur1 != new_ttu_attr->refcyc_per_req_delivery_pre_cur1 ||
 -				old_ttu_attr.min_ttu_vblank != new_ttu_attr->min_ttu_vblank ||
 -				old_ttu_attr.qos_level_flip != new_ttu_attr->qos_level_flip) {
 -			old_dlg_attr.dst_y_prefetch = new_dlg_attr->dst_y_prefetch;
 -			old_dlg_attr.vratio_prefetch = new_dlg_attr->vratio_prefetch;
 -			old_dlg_attr.vratio_prefetch_c = new_dlg_attr->vratio_prefetch_c;
 -			old_dlg_attr.dst_y_per_vm_vblank = new_dlg_attr->dst_y_per_vm_vblank;
 -			old_dlg_attr.dst_y_per_row_vblank = new_dlg_attr->dst_y_per_row_vblank;
 -			old_dlg_attr.dst_y_per_vm_flip = new_dlg_attr->dst_y_per_vm_flip;
 -			old_dlg_attr.dst_y_per_row_flip = new_dlg_attr->dst_y_per_row_flip;
 -			old_dlg_attr.refcyc_per_meta_chunk_vblank_l = new_dlg_attr->refcyc_per_meta_chunk_vblank_l;
 -			old_dlg_attr.refcyc_per_meta_chunk_vblank_c = new_dlg_attr->refcyc_per_meta_chunk_vblank_c;
 -			old_dlg_attr.refcyc_per_meta_chunk_flip_l = new_dlg_attr->refcyc_per_meta_chunk_flip_l;
 -			old_dlg_attr.refcyc_per_line_delivery_pre_l = new_dlg_attr->refcyc_per_line_delivery_pre_l;
 -			old_dlg_attr.refcyc_per_line_delivery_pre_c = new_dlg_attr->refcyc_per_line_delivery_pre_c;
 -			old_ttu_attr.refcyc_per_req_delivery_pre_l = new_ttu_attr->refcyc_per_req_delivery_pre_l;
 -			old_ttu_attr.refcyc_per_req_delivery_pre_c = new_ttu_attr->refcyc_per_req_delivery_pre_c;
 -			old_ttu_attr.refcyc_per_req_delivery_pre_cur0 = new_ttu_attr->refcyc_per_req_delivery_pre_cur0;
 -			old_ttu_attr.refcyc_per_req_delivery_pre_cur1 = new_ttu_attr->refcyc_per_req_delivery_pre_cur1;
 -			old_ttu_attr.min_ttu_vblank = new_ttu_attr->min_ttu_vblank;
 -			old_ttu_attr.qos_level_flip = new_ttu_attr->qos_level_flip;
 -			new_pipe->update_flags.bits.hubp_interdependent = 1;
 -		}
 -		/* Detect any other updates to ttu/rq/dlg */
 -		if (memcmp(&old_dlg_attr, &new_pipe->dlg_regs, sizeof(old_dlg_attr)) ||
 -				memcmp(&old_ttu_attr, &new_pipe->ttu_regs, sizeof(old_ttu_attr)) ||
 -				memcmp(&old_pipe->rq_regs, &new_pipe->rq_regs, sizeof(old_pipe->rq_regs)))
 -			new_pipe->update_flags.bits.hubp_rq_dlg_ttu = 1;
 -	}
 -}
 -
 -static void dcn20_update_dchubp_dpp(
 -	struct dc *dc,
 -	struct pipe_ctx *pipe_ctx,
 -	struct dc_state *context)
 -{
 -	struct dce_hwseq *hws = dc->hwseq;
 -	struct hubp *hubp = pipe_ctx->plane_res.hubp;
 -	struct dpp *dpp = pipe_ctx->plane_res.dpp;
 -	struct dc_plane_state *plane_state = pipe_ctx->plane_state;
 -	bool viewport_changed = false;
 -
 -	if (pipe_ctx->update_flags.bits.dppclk)
 -		dpp->funcs->dpp_dppclk_control(dpp, false, true);
 -
 -	/* TODO: Need input parameter to tell current DCHUB pipe tie to which OTG
 -	 * VTG is within DCHUBBUB which is commond block share by each pipe HUBP.
 -	 * VTG is 1:1 mapping with OTG. Each pipe HUBP will select which VTG
 -	 */
 -	if (pipe_ctx->update_flags.bits.hubp_rq_dlg_ttu) {
 -		hubp->funcs->hubp_vtg_sel(hubp, pipe_ctx->stream_res.tg->inst);
 -
 -		hubp->funcs->hubp_setup(
 -			hubp,
 -			&pipe_ctx->dlg_regs,
 -			&pipe_ctx->ttu_regs,
 -			&pipe_ctx->rq_regs,
 -			&pipe_ctx->pipe_dlg_param);
 -	}
 -	if (pipe_ctx->update_flags.bits.hubp_interdependent)
 -		hubp->funcs->hubp_setup_interdependent(
 -			hubp,
 -			&pipe_ctx->dlg_regs,
 -			&pipe_ctx->ttu_regs);
 -
 -	if (pipe_ctx->update_flags.bits.enable ||
 -			plane_state->update_flags.bits.bpp_change ||
 -			plane_state->update_flags.bits.input_csc_change ||
 -			plane_state->update_flags.bits.color_space_change ||
 -			plane_state->update_flags.bits.coeff_reduction_change) {
 -		struct dc_bias_and_scale bns_params = {0};
 -
 -		// program the input csc
 -		dpp->funcs->dpp_setup(dpp,
 -				plane_state->format,
 -				EXPANSION_MODE_ZERO,
 -				plane_state->input_csc_color_matrix,
 -				plane_state->color_space,
 -				NULL);
 -
 -		if (dpp->funcs->dpp_program_bias_and_scale) {
 -			//TODO :for CNVC set scale and bias registers if necessary
 -			build_prescale_params(&bns_params, plane_state);
 -			dpp->funcs->dpp_program_bias_and_scale(dpp, &bns_params);
 -		}
 -	}
 -
 -	if (pipe_ctx->update_flags.bits.mpcc
 -			|| plane_state->update_flags.bits.global_alpha_change
 -			|| plane_state->update_flags.bits.per_pixel_alpha_change) {
 -		// MPCC inst is equal to pipe index in practice
 -		int mpcc_inst = hubp->inst;
 -		int opp_inst;
 -		int opp_count = dc->res_pool->pipe_count;
 -
 -		for (opp_inst = 0; opp_inst < opp_count; opp_inst++) {
 -			if (dc->res_pool->opps[opp_inst]->mpcc_disconnect_pending[mpcc_inst]) {
 -				dc->res_pool->mpc->funcs->wait_for_idle(dc->res_pool->mpc, mpcc_inst);
 -				dc->res_pool->opps[opp_inst]->mpcc_disconnect_pending[mpcc_inst] = false;
 -				break;
 -			}
 -		}
 -		hws->funcs.update_mpcc(dc, pipe_ctx);
 -	}
 -
 -	if (pipe_ctx->update_flags.bits.scaler ||
 -			plane_state->update_flags.bits.scaling_change ||
 -			plane_state->update_flags.bits.position_change ||
 -			plane_state->update_flags.bits.per_pixel_alpha_change ||
 -			pipe_ctx->stream->update_flags.bits.scaling) {
 -		pipe_ctx->plane_res.scl_data.lb_params.alpha_en = pipe_ctx->plane_state->per_pixel_alpha;
 -		ASSERT(pipe_ctx->plane_res.scl_data.lb_params.depth == LB_PIXEL_DEPTH_30BPP);
 -		/* scaler configuration */
 -		pipe_ctx->plane_res.dpp->funcs->dpp_set_scaler(
 -				pipe_ctx->plane_res.dpp, &pipe_ctx->plane_res.scl_data);
 -	}
 -
 -	if (pipe_ctx->update_flags.bits.viewport ||
 -			(context == dc->current_state && plane_state->update_flags.bits.scaling_change) ||
 -			(context == dc->current_state && pipe_ctx->stream->update_flags.bits.scaling)) {
 -
 -		hubp->funcs->mem_program_viewport(
 -			hubp,
 -			&pipe_ctx->plane_res.scl_data.viewport,
 -			&pipe_ctx->plane_res.scl_data.viewport_c);
 -		viewport_changed = true;
 -	}
 -
 -	/* Any updates are handled in dc interface, just need to apply existing for plane enable */
 -	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->update_flags.bits.opp_changed ||
 -			pipe_ctx->update_flags.bits.scaler || pipe_ctx->update_flags.bits.viewport)
 -			&& pipe_ctx->stream->cursor_attributes.address.quad_part != 0) {
 -		dc->hwss.set_cursor_position(pipe_ctx);
 -		dc->hwss.set_cursor_attribute(pipe_ctx);
 -
 -		if (dc->hwss.set_cursor_sdr_white_level)
 -			dc->hwss.set_cursor_sdr_white_level(pipe_ctx);
 -	}
 -
 -	/* Any updates are handled in dc interface, just need
 -	 * to apply existing for plane enable / opp change */
 -	if (pipe_ctx->update_flags.bits.enable || pipe_ctx->update_flags.bits.opp_changed
 -			|| pipe_ctx->stream->update_flags.bits.gamut_remap
 -			|| pipe_ctx->stream->update_flags.bits.out_csc) {
 -			/* dpp/cm gamut remap*/
 -			dc->hwss.program_gamut_remap(pipe_ctx);
 -
 -		/*call the dcn2 method which uses mpc csc*/
 -		dc->hwss.program_output_csc(dc,
 -				pipe_ctx,
 -				pipe_ctx->stream->output_color_space,
 -				pipe_ctx->stream->csc_color_matrix.matrix,
 -				hubp->opp_id);
 -	}
 -
 -	if (pipe_ctx->update_flags.bits.enable ||
 -			pipe_ctx->update_flags.bits.opp_changed ||
 -			plane_state->update_flags.bits.pixel_format_change ||
 -			plane_state->update_flags.bits.horizontal_mirror_change ||
 -			plane_state->update_flags.bits.rotation_change ||
 -			plane_state->update_flags.bits.swizzle_change ||
 -			plane_state->update_flags.bits.dcc_change ||
 -			plane_state->update_flags.bits.bpp_change ||
 -			plane_state->update_flags.bits.scaling_change ||
 -			plane_state->update_flags.bits.plane_size_change) {
 -		struct plane_size size = plane_state->plane_size;
 -
 -		size.surface_size = pipe_ctx->plane_res.scl_data.viewport;
 -		hubp->funcs->hubp_program_surface_config(
 -			hubp,
 -			plane_state->format,
 -			&plane_state->tiling_info,
 -			&size,
 -			plane_state->rotation,
 -			&plane_state->dcc,
 -			plane_state->horizontal_mirror,
 -			0);
 -		hubp->power_gated = false;
 -	}
 -
 -	if (hubp->funcs->apply_PLAT_54186_wa && viewport_changed)
 -		hubp->funcs->apply_PLAT_54186_wa(hubp, &plane_state->address);
 -
 -	if (pipe_ctx->update_flags.bits.enable || plane_state->update_flags.bits.addr_update)
 -		hws->funcs.update_plane_addr(dc, pipe_ctx);
 -
 -
 -
 -	if (pipe_ctx->update_flags.bits.enable)
 -		hubp->funcs->set_blank(hubp, false);
 -}
 -
 -
 -static void dcn20_program_pipe(
 +static void dcn20_apply_ctx_for_surface(
  		struct dc *dc,
 -		struct pipe_ctx *pipe_ctx,
 +		const struct dc_stream_state *stream,
 +		int num_planes,
  		struct dc_state *context)
  {
 -	struct dce_hwseq *hws = dc->hwseq;
 -	/* Only need to unblank on top pipe */
 -	if ((pipe_ctx->update_flags.bits.enable || pipe_ctx->stream->update_flags.bits.abm_level)
 -			&& !pipe_ctx->top_pipe && !pipe_ctx->prev_odm_pipe)
 -		hws->funcs.blank_pixel_data(dc, pipe_ctx, !pipe_ctx->plane_state->visible);
  
++<<<<<<< HEAD
++=======
+ 	if (pipe_ctx->update_flags.bits.global_sync) {
+ 		pipe_ctx->stream_res.tg->funcs->program_global_sync(
+ 				pipe_ctx->stream_res.tg,
+ 				pipe_ctx->pipe_dlg_param.vready_offset,
+ 				pipe_ctx->pipe_dlg_param.vstartup_start,
+ 				pipe_ctx->pipe_dlg_param.vupdate_offset,
+ 				pipe_ctx->pipe_dlg_param.vupdate_width);
+ 
+ 		pipe_ctx->stream_res.tg->funcs->set_vtg_params(
+ 				pipe_ctx->stream_res.tg, &pipe_ctx->stream->timing);
+ 
+ 		if (hws->funcs.setup_vupdate_interrupt)
+ 			hws->funcs.setup_vupdate_interrupt(dc, pipe_ctx);
+ 	}
+ 
+ 	if (pipe_ctx->update_flags.bits.odm)
+ 		hws->funcs.update_odm(dc, context, pipe_ctx);
+ 
+ 	if (pipe_ctx->update_flags.bits.enable)
+ 		dcn20_enable_plane(dc, pipe_ctx, context);
+ 
+ 	if (pipe_ctx->update_flags.raw || pipe_ctx->plane_state->update_flags.raw || pipe_ctx->stream->update_flags.raw)
+ 		dcn20_update_dchubp_dpp(dc, pipe_ctx, context);
+ 
+ 	if (pipe_ctx->update_flags.bits.enable
+ 			|| pipe_ctx->plane_state->update_flags.bits.hdr_mult)
+ 		hws->funcs.set_hdr_multiplier(pipe_ctx);
+ 
+ 	if (pipe_ctx->update_flags.bits.enable ||
+ 			pipe_ctx->plane_state->update_flags.bits.in_transfer_func_change ||
+ 			pipe_ctx->plane_state->update_flags.bits.gamma_change)
+ 		hws->funcs.set_input_transfer_func(dc, pipe_ctx, pipe_ctx->plane_state);
+ 
+ 	/* dcn10_translate_regamma_to_hw_format takes 750us to finish
+ 	 * only do gamma programming for powering on, internal memcmp to avoid
+ 	 * updating on slave planes
+ 	 */
+ 	if (pipe_ctx->update_flags.bits.enable || pipe_ctx->stream->update_flags.bits.out_tf)
+ 		hws->funcs.set_output_transfer_func(dc, pipe_ctx, pipe_ctx->stream);
+ 
+ 	/* If the pipe has been enabled or has a different opp, we
+ 	 * should reprogram the fmt. This deals with cases where
+ 	 * interation between mpc and odm combine on different streams
+ 	 * causes a different pipe to be chosen to odm combine with.
+ 	 */
+ 	if (pipe_ctx->update_flags.bits.enable
+ 	    || pipe_ctx->update_flags.bits.opp_changed) {
+ 
+ 		pipe_ctx->stream_res.opp->funcs->opp_set_dyn_expansion(
+ 			pipe_ctx->stream_res.opp,
+ 			COLOR_SPACE_YCBCR601,
+ 			pipe_ctx->stream->timing.display_color_depth,
+ 			pipe_ctx->stream->signal);
+ 
+ 		pipe_ctx->stream_res.opp->funcs->opp_program_fmt(
+ 			pipe_ctx->stream_res.opp,
+ 			&pipe_ctx->stream->bit_depth_params,
+ 			&pipe_ctx->stream->clamping);
+ 	}
+ }
+ 
+ static bool does_pipe_need_lock(struct pipe_ctx *pipe)
+ {
+ 	if ((pipe->plane_state && pipe->plane_state->update_flags.raw)
+ 			|| pipe->update_flags.raw)
+ 		return true;
+ 	if (pipe->bottom_pipe)
+ 		return does_pipe_need_lock(pipe->bottom_pipe);
+ 
+ 	return false;
+ }
+ 
+ void dcn20_program_front_end_for_ctx(
+ 		struct dc *dc,
+ 		struct dc_state *context)
+ {
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  	int i;
 -	struct dce_hwseq *hws = dc->hwseq;
 -	bool pipe_locked[MAX_PIPES] = {false};
 +	struct timing_generator *tg;
 +	bool removed_pipe[6] = { false };
 +	bool interdependent_update = false;
 +	struct pipe_ctx *top_pipe_to_program =
 +			find_top_pipe_for_stream(dc, context, stream);
  	DC_LOGGER_INIT(dc->ctx->logger);
  
 +	if (!top_pipe_to_program)
 +		return;
 +
  	/* Carry over GSL groups in case the context is changing. */
 -	for (i = 0; i < dc->res_pool->pipe_count; i++)
 -		if (context->res_ctx.pipe_ctx[i].stream == dc->current_state->res_ctx.pipe_ctx[i].stream)
 -			context->res_ctx.pipe_ctx[i].stream_res.gsl_group =
 -				dc->current_state->res_ctx.pipe_ctx[i].stream_res.gsl_group;
 +	for (i = 0; i < dc->res_pool->pipe_count; i++) {
 +		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
 +		struct pipe_ctx *old_pipe_ctx =
 +			&dc->current_state->res_ctx.pipe_ctx[i];
  
 -	/* Set pipe update flags and lock pipes */
 -	for (i = 0; i < dc->res_pool->pipe_count; i++)
 -		dcn20_detect_pipe_changes(&dc->current_state->res_ctx.pipe_ctx[i],
 -				&context->res_ctx.pipe_ctx[i]);
 -	for (i = 0; i < dc->res_pool->pipe_count; i++)
 -		if (!context->res_ctx.pipe_ctx[i].top_pipe &&
 -				does_pipe_need_lock(&context->res_ctx.pipe_ctx[i])) {
 -			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
 +		if (pipe_ctx->stream == stream &&
 +		    pipe_ctx->stream == old_pipe_ctx->stream)
 +			pipe_ctx->stream_res.gsl_group =
 +				old_pipe_ctx->stream_res.gsl_group;
 +	}
  
 -			if (pipe_ctx->update_flags.bits.tg_changed || pipe_ctx->update_flags.bits.enable)
 -				dc->hwss.pipe_control_lock(dc, pipe_ctx, true);
 -			if (!pipe_ctx->update_flags.bits.enable)
 -				dc->hwss.pipe_control_lock(dc, &dc->current_state->res_ctx.pipe_ctx[i], true);
 -			pipe_locked[i] = true;
 -		}
 +	tg = top_pipe_to_program->stream_res.tg;
  
 -	/* OTG blank before disabling all front ends */
 -	for (i = 0; i < dc->res_pool->pipe_count; i++)
 -		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable
 -				&& !context->res_ctx.pipe_ctx[i].top_pipe
 -				&& !context->res_ctx.pipe_ctx[i].prev_odm_pipe
 -				&& context->res_ctx.pipe_ctx[i].stream)
 -			hws->funcs.blank_pixel_data(dc, &context->res_ctx.pipe_ctx[i], true);
 +	interdependent_update = top_pipe_to_program->plane_state &&
 +		top_pipe_to_program->plane_state->update_flags.bits.full_update;
  
 -	/* Disconnect mpcc */
 -	for (i = 0; i < dc->res_pool->pipe_count; i++)
 -		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable
 -				|| context->res_ctx.pipe_ctx[i].update_flags.bits.opp_changed) {
 -			hws->funcs.plane_atomic_disconnect(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
 -			DC_LOG_DC("Reset mpcc for pipe %d\n", dc->current_state->res_ctx.pipe_ctx[i].pipe_idx);
 -		}
 +	if (interdependent_update)
 +		lock_all_pipes(dc, context, true);
 +	else
 +		dcn20_pipe_control_lock(dc, top_pipe_to_program, true);
  
 -	/*
 -	 * Program all updated pipes, order matters for mpcc setup. Start with
 -	 * top pipe and program all pipes that follow in order
 -	 */
 +	if (num_planes == 0) {
 +		/* OTG blank before remove all front end */
 +		dc->hwss.blank_pixel_data(dc, top_pipe_to_program, true);
 +	}
 +
 +	/* Disconnect unused mpcc */
  	for (i = 0; i < dc->res_pool->pipe_count; i++) {
 -		struct pipe_ctx *pipe = &context->res_ctx.pipe_ctx[i];
 +		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
 +		struct pipe_ctx *old_pipe_ctx =
 +				&dc->current_state->res_ctx.pipe_ctx[i];
 +		/*
 +		 * Powergate reused pipes that are not powergated
 +		 * fairly hacky right now, using opp_id as indicator
 +		 * TODO: After move dc_post to dc_update, this will
 +		 * be removed.
 +		 */
 +		if (pipe_ctx->plane_state && !old_pipe_ctx->plane_state) {
 +			if (old_pipe_ctx->stream_res.tg == tg &&
 +			    old_pipe_ctx->plane_res.hubp &&
 +			    old_pipe_ctx->plane_res.hubp->opp_id != OPP_ID_INVALID)
 +				dcn20_disable_plane(dc, old_pipe_ctx);
 +		}
  
 -		if (pipe->plane_state && !pipe->top_pipe) {
 -			while (pipe) {
 -				dcn20_program_pipe(dc, pipe, context);
 -				pipe = pipe->bottom_pipe;
 -			}
 -			/* Program secondary blending tree and writeback pipes */
 -			pipe = &context->res_ctx.pipe_ctx[i];
 -			if (!pipe->prev_odm_pipe && pipe->stream->num_wb_info > 0
 -					&& (pipe->update_flags.raw || pipe->plane_state->update_flags.raw || pipe->stream->update_flags.raw)
 -					&& hws->funcs.program_all_writeback_pipes_in_tree)
 -				hws->funcs.program_all_writeback_pipes_in_tree(dc, pipe->stream, context);
 +		if ((!pipe_ctx->plane_state ||
 +		     pipe_ctx->stream_res.tg != old_pipe_ctx->stream_res.tg) &&
 +		     old_pipe_ctx->plane_state &&
 +		     old_pipe_ctx->stream_res.tg == tg) {
 +
 +			dc->hwss.plane_atomic_disconnect(dc, old_pipe_ctx);
 +			removed_pipe[i] = true;
 +
 +			DC_LOG_DC("Reset mpcc for pipe %d\n",
 +					old_pipe_ctx->pipe_idx);
  		}
  	}
  
 -	/* Unlock all locked pipes */
 -	for (i = 0; i < dc->res_pool->pipe_count; i++)
 -		if (pipe_locked[i]) {
 +	if (num_planes > 0)
 +		dcn20_program_all_pipe_in_tree(dc, top_pipe_to_program, context);
 +
 +	/* Program secondary blending tree and writeback pipes */
 +	if ((stream->num_wb_info > 0) && (dc->hwss.program_all_writeback_pipes_in_tree))
 +		dc->hwss.program_all_writeback_pipes_in_tree(dc, stream, context);
 +
 +	if (interdependent_update)
 +		for (i = 0; i < dc->res_pool->pipe_count; i++) {
  			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
  
 -			if (pipe_ctx->update_flags.bits.tg_changed || pipe_ctx->update_flags.bits.enable)
 -				dc->hwss.pipe_control_lock(dc, pipe_ctx, false);
 -			if (!pipe_ctx->update_flags.bits.enable)
 -				dc->hwss.pipe_control_lock(dc, &dc->current_state->res_ctx.pipe_ctx[i], false);
 +			/* Skip inactive pipes and ones already updated */
 +			if (!pipe_ctx->stream || pipe_ctx->stream == stream ||
 +			    !pipe_ctx->plane_state || !tg->funcs->is_tg_enabled(tg))
 +				continue;
 +
 +			pipe_ctx->plane_res.hubp->funcs->hubp_setup_interdependent(
 +				pipe_ctx->plane_res.hubp,
 +				&pipe_ctx->dlg_regs,
 +				&pipe_ctx->ttu_regs);
  		}
+ }
+ 
+ void dcn20_post_unlock_program_front_end(
+ 		struct dc *dc,
 -		struct dc_state *context)
 -{
 -	int i;
 -	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
 -
 -	DC_LOGGER_INIT(dc->ctx->logger);
 -
 -	for (i = 0; i < dc->res_pool->pipe_count; i++)
 -		if (context->res_ctx.pipe_ctx[i].update_flags.bits.disable)
 -			dc->hwss.disable_plane(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
 -
 -	/*
 -	 * If we are enabling a pipe, we need to wait for pending clear as this is a critical
 -	 * part of the enable operation otherwise, DM may request an immediate flip which
 -	 * will cause HW to perform an "immediate enable" (as opposed to "vsync enable") which
 -	 * is unsupported on DCN.
 -	 */
 -	for (i = 0; i < dc->res_pool->pipe_count; i++) {
 -		struct pipe_ctx *pipe = &context->res_ctx.pipe_ctx[i];
++		struct dc_state *context)
++{
++	int i;
++	const unsigned int TIMEOUT_FOR_PIPE_ENABLE_MS = 100;
+ 
 -		if (pipe->plane_state && !pipe->top_pipe && pipe->update_flags.bits.enable) {
 -			struct hubp *hubp = pipe->plane_res.hubp;
 -			int j = 0;
++	DC_LOGGER_INIT(dc->ctx->logger);
  
 -			for (j = 0; j < TIMEOUT_FOR_PIPE_ENABLE_MS*1000
 -					&& hubp->funcs->hubp_is_flip_pending(hubp); j++)
 -				mdelay(1);
 -		}
 -	}
 +	if (interdependent_update)
 +		lock_all_pipes(dc, context, false);
 +	else
 +		dcn20_pipe_control_lock(dc, top_pipe_to_program, false);
  
 -	/* WA to apply WM setting*/
 -	if (dc->hwseq->wa.DEGVIDCN21)
 -		dc->res_pool->hubbub->funcs->apply_DEDCN21_147_wa(dc->res_pool->hubbub);
 +	for (i = 0; i < dc->res_pool->pipe_count; i++)
 +		if (removed_pipe[i])
 +			dcn20_disable_plane(dc, &dc->current_state->res_ctx.pipe_ctx[i]);
  }
  
  
diff --cc drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.h
index 2b0409454073,80f192b8b3a2..000000000000
--- a/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.h
+++ b/drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.h
@@@ -26,20 -26,24 +26,33 @@@
  #ifndef __DC_HWSS_DCN20_H__
  #define __DC_HWSS_DCN20_H__
  
 -#include "hw_sequencer_private.h"
 +struct dc;
  
 -bool dcn20_set_blend_lut(
 -	struct pipe_ctx *pipe_ctx, const struct dc_plane_state *plane_state);
 -bool dcn20_set_shaper_3dlut(
 -	struct pipe_ctx *pipe_ctx, const struct dc_plane_state *plane_state);
 -void dcn20_program_front_end_for_ctx(
 +void dcn20_hw_sequencer_construct(struct dc *dc);
 +
 +enum dc_status dcn20_enable_stream_timing(
 +		struct pipe_ctx *pipe_ctx,
 +		struct dc_state *context,
 +		struct dc *dc);
 +
 +void dcn20_blank_pixel_data(
  		struct dc *dc,
++<<<<<<< HEAD
 +		struct pipe_ctx *pipe_ctx,
 +		bool blank);
 +
++=======
+ 		struct dc_state *context);
+ void dcn20_post_unlock_program_front_end(
+ 		struct dc *dc,
+ 		struct dc_state *context);
+ void dcn20_update_plane_addr(const struct dc *dc, struct pipe_ctx *pipe_ctx);
+ void dcn20_update_mpcc(struct dc *dc, struct pipe_ctx *pipe_ctx);
+ bool dcn20_set_input_transfer_func(struct dc *dc, struct pipe_ctx *pipe_ctx,
+ 			const struct dc_plane_state *plane_state);
+ bool dcn20_set_output_transfer_func(struct dc *dc, struct pipe_ctx *pipe_ctx,
+ 			const struct dc_stream_state *stream);
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  void dcn20_program_output_csc(struct dc *dc,
  		struct pipe_ctx *pipe_ctx,
  		enum dc_color_space colorspace,
diff --cc drivers/gpu/drm/amd/display/dc/inc/hw_sequencer.h
index c6fd0f92eb43,63919866ba38..000000000000
--- a/drivers/gpu/drm/amd/display/dc/inc/hw_sequencer.h
+++ b/drivers/gpu/drm/amd/display/dc/inc/hw_sequencer.h
@@@ -43,160 -37,79 +43,175 @@@ enum vline_select 
  	VLINE1
  };
  
 +struct dce_hwseq_wa {
 +	bool blnd_crtc_trigger;
 +	bool DEGVIDCN10_253;
 +	bool false_optc_underflow;
 +	bool DEGVIDCN10_254;
 +};
 +
 +struct hwseq_wa_state {
 +	bool DEGVIDCN10_253_applied;
 +};
 +
 +struct dce_hwseq {
 +	struct dc_context *ctx;
 +	const struct dce_hwseq_registers *regs;
 +	const struct dce_hwseq_shift *shifts;
 +	const struct dce_hwseq_mask *masks;
 +	struct dce_hwseq_wa wa;
 +	struct hwseq_wa_state wa_state;
 +};
 +
  struct pipe_ctx;
  struct dc_state;
 +#if defined(CONFIG_DRM_AMD_DC_DCN2_0)
  struct dc_stream_status;
  struct dc_writeback_info;
 +#endif
  struct dchub_init_data;
 -struct dc_static_screen_params;
 +struct dc_static_screen_events;
  struct resource_pool;
 +struct resource_context;
 +struct stream_resource;
 +#ifdef CONFIG_DRM_AMD_DC_DCN2_0
  struct dc_phy_addr_space_config;
  struct dc_virtual_addr_space_config;
 -struct dpp;
 -struct dce_hwseq;
 +#endif
  
  struct hw_sequencer_funcs {
 -	/* Embedded Display Related */
 -	void (*edp_power_control)(struct dc_link *link, bool enable);
 -	void (*edp_wait_for_hpd_ready)(struct dc_link *link, bool power_up);
  
 -	/* Pipe Programming Related */
 +	void (*disable_stream_gating)(struct dc *dc, struct pipe_ctx *pipe_ctx);
 +
 +	void (*enable_stream_gating)(struct dc *dc, struct pipe_ctx *pipe_ctx);
 +
  	void (*init_hw)(struct dc *dc);
 -	void (*enable_accelerated_mode)(struct dc *dc,
 -			struct dc_state *context);
 -	enum dc_status (*apply_ctx_to_hw)(struct dc *dc,
 -			struct dc_state *context);
 -	void (*disable_plane)(struct dc *dc, struct pipe_ctx *pipe_ctx);
 -	void (*apply_ctx_for_surface)(struct dc *dc,
 +
 +	void (*init_pipes)(struct dc *dc, struct dc_state *context);
 +
 +	enum dc_status (*apply_ctx_to_hw)(
 +			struct dc *dc, struct dc_state *context);
 +
 +	void (*reset_hw_ctx_wrap)(
 +			struct dc *dc, struct dc_state *context);
 +
 +	void (*apply_ctx_for_surface)(
 +			struct dc *dc,
  			const struct dc_stream_state *stream,
 -			int num_planes, struct dc_state *context);
 -	void (*program_front_end_for_ctx)(struct dc *dc,
 +			int num_planes,
  			struct dc_state *context);
++<<<<<<< HEAD
++=======
+ 	void (*post_unlock_program_front_end)(struct dc *dc,
+ 			struct dc_state *context);
+ 	void (*update_plane_addr)(const struct dc *dc,
+ 			struct pipe_ctx *pipe_ctx);
+ 	void (*update_dchub)(struct dce_hwseq *hws,
+ 			struct dchub_init_data *dh_data);
+ 	void (*wait_for_mpcc_disconnect)(struct dc *dc,
+ 			struct resource_pool *res_pool,
+ 			struct pipe_ctx *pipe_ctx);
+ 	void (*program_triplebuffer)(const struct dc *dc,
+ 		struct pipe_ctx *pipe_ctx, bool enableTripleBuffer);
+ 	void (*update_pending_status)(struct pipe_ctx *pipe_ctx);
++>>>>>>> bbf5f6c3f83b (drm/amd/display: Split program front end part that occur outside lock)
  
 -	/* Pipe Lock Related */
 -	void (*pipe_control_lock_global)(struct dc *dc,
 -			struct pipe_ctx *pipe, bool lock);
 -	void (*pipe_control_lock)(struct dc *dc,
 -			struct pipe_ctx *pipe, bool lock);
 -	void (*set_flip_control_gsl)(struct pipe_ctx *pipe_ctx,
 -			bool flip_immediate);
 +	void (*program_gamut_remap)(
 +			struct pipe_ctx *pipe_ctx);
  
 -	/* Timing Related */
 -	void (*get_position)(struct pipe_ctx **pipe_ctx, int num_pipes,
 -			struct crtc_position *position);
 -	int (*get_vupdate_offset_from_vsync)(struct pipe_ctx *pipe_ctx);
 -	void (*enable_per_frame_crtc_position_reset)(struct dc *dc,
 -			int group_size, struct pipe_ctx *grouped_pipes[]);
 -	void (*enable_timing_synchronization)(struct dc *dc,
 -			int group_index, int group_size,
 -			struct pipe_ctx *grouped_pipes[]);
 -	void (*setup_periodic_interrupt)(struct dc *dc,
 +	void (*program_output_csc)(struct dc *dc,
  			struct pipe_ctx *pipe_ctx,
 -			enum vline_select vline);
 -	void (*set_drr)(struct pipe_ctx **pipe_ctx, int num_pipes,
 -			unsigned int vmin, unsigned int vmax,
 -			unsigned int vmid, unsigned int vmid_frame_number);
 -	void (*set_static_screen_control)(struct pipe_ctx **pipe_ctx,
 -			int num_pipes,
 -			const struct dc_static_screen_params *events);
 +			enum dc_color_space colorspace,
 +			uint16_t *matrix,
 +			int opp_id);
 +
 +#if defined(CONFIG_DRM_AMD_DC_DCN2_0)
 +	void (*program_triplebuffer)(
 +		const struct dc *dc,
 +		struct pipe_ctx *pipe_ctx,
 +		bool enableTripleBuffer);
 +	void (*set_flip_control_gsl)(
 +		struct pipe_ctx *pipe_ctx,
 +		bool flip_immediate);
 +#endif
 +
 +	void (*update_plane_addr)(
 +		const struct dc *dc,
 +		struct pipe_ctx *pipe_ctx);
 +
 +	void (*plane_atomic_disconnect)(
 +		struct dc *dc,
 +		struct pipe_ctx *pipe_ctx);
 +
 +	void (*update_dchub)(
 +		struct dce_hwseq *hws,
 +		struct dchub_init_data *dh_data);
 +
 +#ifdef CONFIG_DRM_AMD_DC_DCN2_0
 +	int (*init_sys_ctx)(
 +			struct dce_hwseq *hws,
 +			struct dc *dc,
 +			struct dc_phy_addr_space_config *pa_config);
 +	void (*init_vm_ctx)(
 +			struct dce_hwseq *hws,
 +			struct dc *dc,
 +			struct dc_virtual_addr_space_config *va_config,
 +			int vmid);
 +#endif
 +	void (*update_mpcc)(
 +		struct dc *dc,
 +		struct pipe_ctx *pipe_ctx);
 +
 +	void (*update_pending_status)(
 +			struct pipe_ctx *pipe_ctx);
 +
 +	bool (*set_input_transfer_func)(
 +				struct pipe_ctx *pipe_ctx,
 +				const struct dc_plane_state *plane_state);
 +
 +	bool (*set_output_transfer_func)(
 +				struct pipe_ctx *pipe_ctx,
 +				const struct dc_stream_state *stream);
 +
 +	void (*power_down)(struct dc *dc);
 +
 +	void (*enable_accelerated_mode)(struct dc *dc, struct dc_state *context);
 +
 +	void (*enable_timing_synchronization)(
 +			struct dc *dc,
 +			int group_index,
 +			int group_size,
 +			struct pipe_ctx *grouped_pipes[]);
 +
 +	void (*enable_per_frame_crtc_position_reset)(
 +			struct dc *dc,
 +			int group_size,
 +			struct pipe_ctx *grouped_pipes[]);
 +
 +	void (*enable_display_pipe_clock_gating)(
 +					struct dc_context *ctx,
 +					bool clock_gating);
 +
 +	bool (*enable_display_power_gating)(
 +					struct dc *dc,
 +					uint8_t controller_id,
 +					struct dc_bios *dcb,
 +					enum pipe_gating_control power_gating);
 +
 +	void (*disable_plane)(struct dc *dc, struct pipe_ctx *pipe_ctx);
 +
 +	void (*update_info_frame)(struct pipe_ctx *pipe_ctx);
 +
 +	void (*send_immediate_sdp_message)(
 +				struct pipe_ctx *pipe_ctx,
 +				const uint8_t *custom_sdp_message,
 +				unsigned int sdp_message_size);
  
 -	/* Stream Related */
  	void (*enable_stream)(struct pipe_ctx *pipe_ctx);
 -	void (*disable_stream)(struct pipe_ctx *pipe_ctx);
 -	void (*blank_stream)(struct pipe_ctx *pipe_ctx);
 +
 +	void (*disable_stream)(struct pipe_ctx *pipe_ctx,
 +			int option);
 +
  	void (*unblank_stream)(struct pipe_ctx *pipe_ctx,
  			struct dc_link_settings *link_settings);
  
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn10/dcn10_init.c
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn20/dcn20_init.c
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn21/dcn21_init.c
* Unmerged path drivers/gpu/drm/amd/display/dc/core/dc.c
diff --git a/drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c b/drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c
index fafb4b470140..5567eddd5764 100644
--- a/drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c
+++ b/drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c
@@ -2645,6 +2645,11 @@ static void dce110_apply_ctx_for_surface(
 		enable_fbc(dc, context);
 }
 
+static void dce110_post_unlock_program_front_end(
+		struct dc *dc,
+		struct dc_state *context)
+{
+}
 static void dce110_power_down_fe(struct dc *dc, struct pipe_ctx *pipe_ctx)
 {
 	int fe_idx = pipe_ctx->plane_res.mi ?
@@ -2746,6 +2751,7 @@ static const struct hw_sequencer_funcs dce110_funcs = {
 	.init_pipes = init_pipes,
 	.apply_ctx_to_hw = dce110_apply_ctx_to_hw,
 	.apply_ctx_for_surface = dce110_apply_ctx_for_surface,
+	.post_unlock_program_front_end = dce110_post_unlock_program_front_end,
 	.update_plane_addr = update_plane_addr,
 	.update_pending_status = dce110_update_pending_status,
 	.set_input_transfer_func = dce110_set_input_transfer_func,
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.h
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn10/dcn10_init.c
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.c
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn20/dcn20_hwseq.h
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn20/dcn20_init.c
* Unmerged path drivers/gpu/drm/amd/display/dc/dcn21/dcn21_init.c
* Unmerged path drivers/gpu/drm/amd/display/dc/inc/hw_sequencer.h
