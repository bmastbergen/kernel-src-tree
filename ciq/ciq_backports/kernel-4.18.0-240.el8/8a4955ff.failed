io_uring: sqthread should grab ctx->uring_lock for submissions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit 8a4955ff1cca7d4da480774034a16e7c28bafec8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/8a4955ff.failed

We use the mutex to guard against registered file updates, for instance.
Ensure we're safe in accessing that state against concurrent updates.

	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 8a4955ff1cca7d4da480774034a16e7c28bafec8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index 7e2b8c92aeeb,366fc351869d..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -1939,12 -2996,7 +1939,16 @@@ static int __io_submit_sqe(struct io_ri
  		if (req->result == -EAGAIN)
  			return -EAGAIN;
  
++<<<<<<< HEAD
 +		/* workqueue context doesn't hold uring_lock, grab it now */
 +		if (s->needs_lock)
 +			mutex_lock(&ctx->uring_lock);
 +		io_iopoll_req_issued(req);
 +		if (s->needs_lock)
 +			mutex_unlock(&ctx->uring_lock);
++=======
+ 		io_iopoll_req_issued(req);
++>>>>>>> 8a4955ff1cca (io_uring: sqthread should grab ctx->uring_lock for submissions)
  	}
  
  	return 0;
@@@ -2580,34 -3646,15 +2584,43 @@@ static int io_sq_thread(void *data
  			}
  			finish_wait(&ctx->sqo_wait, &wait);
  
 -			ctx->rings->sq_flags &= ~IORING_SQ_NEED_WAKEUP;
 +			ctx->sq_ring->flags &= ~IORING_SQ_NEED_WAKEUP;
 +		}
 +
++<<<<<<< HEAD
 +		i = 0;
 +		all_fixed = true;
 +		do {
 +			if (all_fixed && io_sqe_needs_user(sqes[i].sqe))
 +				all_fixed = false;
 +
 +			i++;
 +			if (i == ARRAY_SIZE(sqes))
 +				break;
 +		} while (io_get_sqring(ctx, &sqes[i]));
 +
 +		/* Unless all new commands are FIXED regions, grab mm */
 +		if (!all_fixed && !cur_mm) {
 +			mm_fault = !mmget_not_zero(ctx->sqo_mm);
 +			if (!mm_fault) {
 +				use_mm(ctx->sqo_mm);
 +				cur_mm = ctx->sqo_mm;
 +			}
  		}
  
 +		inflight += io_submit_sqes(ctx, sqes, i, cur_mm != NULL,
 +						mm_fault);
 +
 +		/* Commit SQ ring head once we've consumed all SQEs */
 +		io_commit_sqring(ctx);
++=======
+ 		to_submit = min(to_submit, ctx->sq_entries);
+ 		mutex_lock(&ctx->uring_lock);
+ 		ret = io_submit_sqes(ctx, to_submit, NULL, -1, &cur_mm, true);
+ 		mutex_unlock(&ctx->uring_lock);
+ 		if (ret > 0)
+ 			inflight += ret;
++>>>>>>> 8a4955ff1cca (io_uring: sqthread should grab ctx->uring_lock for submissions)
  	}
  
  	set_fs(old_fs);
* Unmerged path fs/io_uring.c
