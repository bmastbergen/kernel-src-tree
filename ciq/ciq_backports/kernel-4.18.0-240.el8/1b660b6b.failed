KVM: VMX: Split out architectural interrupt/NMI blocking checks

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit 1b660b6baaafd8b9056740b83decd7fc74023627
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/1b660b6b.failed

Move the architectural (non-KVM specific) interrupt/NMI blocking checks
to a separate helper so that they can be used in a future patch by
vmx_check_nested_events().

No functional change intended.

	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
Message-Id: <20200423022550.15113-8-sean.j.christopherson@intel.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 1b660b6baaafd8b9056740b83decd7fc74023627)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx/vmx.c
diff --cc arch/x86/kvm/vmx/vmx.c
index 906cd31684bd,a5140ed7dbf9..000000000000
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@@ -4584,24 -4510,38 +4584,48 @@@ void vmx_set_nmi_mask(struct kvm_vcpu *
  	}
  }
  
++<<<<<<< HEAD
 +static int vmx_nmi_allowed(struct kvm_vcpu *vcpu)
++=======
+ bool vmx_nmi_blocked(struct kvm_vcpu *vcpu)
+ {
+ 	if (is_guest_mode(vcpu) && nested_exit_on_nmi(vcpu))
+ 		return false;
+ 
+ 	if (!enable_vnmi && to_vmx(vcpu)->loaded_vmcs->soft_vnmi_blocked)
+ 		return true;
+ 
+ 	return (vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &
+ 		(GUEST_INTR_STATE_MOV_SS | GUEST_INTR_STATE_STI |
+ 		 GUEST_INTR_STATE_NMI));
+ }
+ 
+ static bool vmx_nmi_allowed(struct kvm_vcpu *vcpu)
++>>>>>>> 1b660b6baaaf (KVM: VMX: Split out architectural interrupt/NMI blocking checks)
  {
  	if (to_vmx(vcpu)->nested.nested_run_pending)
 -		return false;
 +		return 0;
  
- 	if (is_guest_mode(vcpu) && nested_exit_on_nmi(vcpu))
- 		return true;
+ 	return !vmx_nmi_blocked(vcpu);
+ }
  
++<<<<<<< HEAD
 +	if (!enable_vnmi &&
 +	    to_vmx(vcpu)->loaded_vmcs->soft_vnmi_blocked)
 +		return 0;
++=======
+ bool vmx_interrupt_blocked(struct kvm_vcpu *vcpu)
+ {
+ 	if (is_guest_mode(vcpu) && nested_exit_on_intr(vcpu))
+ 		return false;
++>>>>>>> 1b660b6baaaf (KVM: VMX: Split out architectural interrupt/NMI blocking checks)
  
- 	return	!(vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &
- 		  (GUEST_INTR_STATE_MOV_SS | GUEST_INTR_STATE_STI
- 		   | GUEST_INTR_STATE_NMI));
+ 	return !(vmcs_readl(GUEST_RFLAGS) & X86_EFLAGS_IF) ||
+ 	       (vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &
+ 		(GUEST_INTR_STATE_STI | GUEST_INTR_STATE_MOV_SS));
  }
  
 -static bool vmx_interrupt_allowed(struct kvm_vcpu *vcpu)
 +static int vmx_interrupt_allowed(struct kvm_vcpu *vcpu)
  {
  	if (to_vmx(vcpu)->nested.nested_run_pending)
  		return false;
* Unmerged path arch/x86/kvm/vmx/vmx.c
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index 2860db4335ad..2f764479cad9 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -345,6 +345,8 @@ void vmx_set_segment(struct kvm_vcpu *vcpu, struct kvm_segment *var, int seg);
 u64 construct_eptp(struct kvm_vcpu *vcpu, unsigned long root_hpa);
 void update_exception_bitmap(struct kvm_vcpu *vcpu);
 void vmx_update_msr_bitmap(struct kvm_vcpu *vcpu);
+bool vmx_nmi_blocked(struct kvm_vcpu *vcpu);
+bool vmx_interrupt_blocked(struct kvm_vcpu *vcpu);
 bool vmx_get_nmi_mask(struct kvm_vcpu *vcpu);
 void vmx_set_nmi_mask(struct kvm_vcpu *vcpu, bool masked);
 void vmx_set_virtual_apic_mode(struct kvm_vcpu *vcpu);
