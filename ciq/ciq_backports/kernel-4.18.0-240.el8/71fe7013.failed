KVM: x86/mmu: Add module param to force TLB flush on root reuse

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit 71fe70130d88729abc0e658d3202618c340d2e71
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/71fe7013.failed

Add a module param, flush_on_reuse, to override skip_tlb_flush and
skip_mmu_sync when performing a so called "fast cr3 switch", i.e. when
reusing a cached root.  The primary motiviation for the control is to
provide a fallback mechanism in the event that TLB flushing and/or MMU
sync bugs are exposed/introduced by upcoming changes to stop
unconditionally flushing on nested VMX transitions.

	Suggested-by: Jim Mattson <jmattson@google.com>
	Suggested-by: Junaid Shahid <junaids@google.com>
	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
Message-Id: <20200320212833.3507-33-sean.j.christopherson@intel.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 71fe70130d88729abc0e658d3202618c340d2e71)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/mmu.c
diff --cc arch/x86/kvm/mmu/mmu.c
index dbd97923dc2c,c98948459414..000000000000
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@@ -4396,17 -4306,42 +4399,47 @@@ static bool fast_cr3_switch(struct kvm_
  
  static void __kvm_mmu_new_cr3(struct kvm_vcpu *vcpu, gpa_t new_cr3,
  			      union kvm_mmu_page_role new_role,
 -			      bool skip_tlb_flush, bool skip_mmu_sync)
 +			      bool skip_tlb_flush)
  {
++<<<<<<< HEAD
 +	if (!fast_cr3_switch(vcpu, new_cr3, new_role, skip_tlb_flush))
 +		kvm_mmu_free_roots(vcpu, vcpu->arch.mmu,
 +				   KVM_MMU_ROOT_CURRENT);
++=======
+ 	if (!fast_cr3_switch(vcpu, new_cr3, new_role)) {
+ 		kvm_mmu_free_roots(vcpu, vcpu->arch.mmu, KVM_MMU_ROOT_CURRENT);
+ 		return;
+ 	}
+ 
+ 	/*
+ 	 * It's possible that the cached previous root page is obsolete because
+ 	 * of a change in the MMU generation number. However, changing the
+ 	 * generation number is accompanied by KVM_REQ_MMU_RELOAD, which will
+ 	 * free the root set here and allocate a new one.
+ 	 */
+ 	kvm_make_request(KVM_REQ_LOAD_MMU_PGD, vcpu);
+ 
+ 	if (!skip_mmu_sync || force_flush_and_sync_on_reuse)
+ 		kvm_make_request(KVM_REQ_MMU_SYNC, vcpu);
+ 	if (!skip_tlb_flush || force_flush_and_sync_on_reuse)
+ 		kvm_make_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu);
+ 
+ 	/*
+ 	 * The last MMIO access's GVA and GPA are cached in the VCPU. When
+ 	 * switching to a new CR3, that GVA->GPA mapping may no longer be
+ 	 * valid. So clear any cached MMIO info even when we don't need to sync
+ 	 * the shadow page tables.
+ 	 */
+ 	vcpu_clear_mmio_info(vcpu, MMIO_GVA_ANY);
+ 
+ 	__clear_sp_write_flooding_count(page_header(vcpu->arch.mmu->root_hpa));
++>>>>>>> 71fe70130d88 (KVM: x86/mmu: Add module param to force TLB flush on root reuse)
  }
  
 -void kvm_mmu_new_cr3(struct kvm_vcpu *vcpu, gpa_t new_cr3, bool skip_tlb_flush,
 -		     bool skip_mmu_sync)
 +void kvm_mmu_new_cr3(struct kvm_vcpu *vcpu, gpa_t new_cr3, bool skip_tlb_flush)
  {
  	__kvm_mmu_new_cr3(vcpu, new_cr3, kvm_mmu_calc_root_page_role(vcpu),
 -			  skip_tlb_flush, skip_mmu_sync);
 +			  skip_tlb_flush);
  }
  EXPORT_SYMBOL_GPL(kvm_mmu_new_cr3);
  
* Unmerged path arch/x86/kvm/mmu/mmu.c
