bpf: Fix bug in mmap() implementation for BPF array map

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Andrii Nakryiko <andriin@fb.com>
commit 333291ce5055f2039afc907badaf5b66bc1adfdc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/333291ce.failed

mmap() subsystem allows user-space application to memory-map region with
initial page offset. This wasn't taken into account in initial implementation
of BPF array memory-mapping. This would result in wrong pages, not taking into
account requested page shift, being memory-mmaped into user-space. This patch
fixes this gap and adds a test for such scenario.

Fixes: fc9702273e2e ("bpf: Add mmap() support for BPF_MAP_TYPE_ARRAY")
	Signed-off-by: Andrii Nakryiko <andriin@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Yonghong Song <yhs@fb.com>
Link: https://lore.kernel.org/bpf/20200512235925.3817805-1-andriin@fb.com
(cherry picked from commit 333291ce5055f2039afc907badaf5b66bc1adfdc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/arraymap.c
#	tools/testing/selftests/bpf/prog_tests/mmap.c
diff --cc kernel/bpf/arraymap.c
index 2e73e2ac0f7e,1d6120fd5ba6..000000000000
--- a/kernel/bpf/arraymap.c
+++ b/kernel/bpf/arraymap.c
@@@ -452,6 -478,22 +452,25 @@@ static int array_map_check_btf(const st
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int array_map_mmap(struct bpf_map *map, struct vm_area_struct *vma)
+ {
+ 	struct bpf_array *array = container_of(map, struct bpf_array, map);
+ 	pgoff_t pgoff = PAGE_ALIGN(sizeof(*array)) >> PAGE_SHIFT;
+ 
+ 	if (!(map->map_flags & BPF_F_MMAPABLE))
+ 		return -EINVAL;
+ 
+ 	if (vma->vm_pgoff * PAGE_SIZE + (vma->vm_end - vma->vm_start) >
+ 	    PAGE_ALIGN((u64)array->map.max_entries * array->elem_size))
+ 		return -EINVAL;
+ 
+ 	return remap_vmalloc_range(vma, array_map_vmalloc_addr(array),
+ 				   vma->vm_pgoff + pgoff);
+ }
+ 
++>>>>>>> 333291ce5055 (bpf: Fix bug in mmap() implementation for BPF array map)
  const struct bpf_map_ops array_map_ops = {
  	.map_alloc_check = array_map_alloc_check,
  	.map_alloc = array_map_alloc,
diff --cc tools/testing/selftests/bpf/prog_tests/mmap.c
index 051a6d48762c,6b9dce431d41..000000000000
--- a/tools/testing/selftests/bpf/prog_tests/mmap.c
+++ b/tools/testing/selftests/bpf/prog_tests/mmap.c
@@@ -209,6 -216,53 +209,56 @@@ void test_mmap(void
  	CHECK_FAIL(map_data->val[far] != 3 * 321);
  
  	munmap(tmp2, 4 * page_size);
++<<<<<<< HEAD
++=======
+ 
+ 	/* map all 4 pages, but with pg_off=1 page, should fail */
+ 	tmp1 = mmap(NULL, 4 * page_size, PROT_READ, MAP_SHARED | MAP_FIXED,
+ 		    data_map_fd, page_size /* initial page shift */);
+ 	if (CHECK(tmp1 != MAP_FAILED, "adv_mmap7", "unexpected success")) {
+ 		munmap(tmp1, 4 * page_size);
+ 		goto cleanup;
+ 	}
+ 
+ 	tmp1 = mmap(NULL, map_sz, PROT_READ, MAP_SHARED, data_map_fd, 0);
+ 	if (CHECK(tmp1 == MAP_FAILED, "last_mmap", "failed %d\n", errno))
+ 		goto cleanup;
+ 
+ 	test_mmap__destroy(skel);
+ 	skel = NULL;
+ 	CHECK_FAIL(munmap(bss_mmaped, bss_sz));
+ 	bss_mmaped = NULL;
+ 	CHECK_FAIL(munmap(map_mmaped, map_sz));
+ 	map_mmaped = NULL;
+ 
+ 	/* map should be still held by active mmap */
+ 	tmp_fd = bpf_map_get_fd_by_id(data_map_id);
+ 	if (CHECK(tmp_fd < 0, "get_map_by_id", "failed %d\n", errno)) {
+ 		munmap(tmp1, map_sz);
+ 		goto cleanup;
+ 	}
+ 	close(tmp_fd);
+ 
+ 	/* this should release data map finally */
+ 	munmap(tmp1, map_sz);
+ 
+ 	/* we need to wait for RCU grace period */
+ 	for (i = 0; i < 10000; i++) {
+ 		__u32 id = data_map_id - 1;
+ 		if (bpf_map_get_next_id(id, &id) || id > data_map_id)
+ 			break;
+ 		usleep(1);
+ 	}
+ 
+ 	/* should fail to get map FD by non-existing ID */
+ 	tmp_fd = bpf_map_get_fd_by_id(data_map_id);
+ 	if (CHECK(tmp_fd >= 0, "get_map_by_id_after",
+ 		  "unexpectedly succeeded %d\n", tmp_fd)) {
+ 		close(tmp_fd);
+ 		goto cleanup;
+ 	}
+ 
++>>>>>>> 333291ce5055 (bpf: Fix bug in mmap() implementation for BPF array map)
  cleanup:
  	if (bss_mmaped)
  		CHECK_FAIL(munmap(bss_mmaped, bss_sz));
* Unmerged path kernel/bpf/arraymap.c
* Unmerged path tools/testing/selftests/bpf/prog_tests/mmap.c
