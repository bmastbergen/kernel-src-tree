bpf: Fix pointer arithmetic mask tightening under state pruning

jira LE-1907
cve CVE-2021-29155
Rebuild_History Non-Buildable kernel-4.18.0-338.el8
commit-author Daniel Borkmann <daniel@iogearbox.net>
commit e042aa532c84d18ff13291d00620502ce7a38dda
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-338.el8/e042aa53.failed

In 7fedb63a8307 ("bpf: Tighten speculative pointer arithmetic mask") we
narrowed the offset mask for unprivileged pointer arithmetic in order to
mitigate a corner case where in the speculative domain it is possible to
advance, for example, the map value pointer by up to value_size-1 out-of-
bounds in order to leak kernel memory via side-channel to user space.

The verifier's state pruning for scalars leaves one corner case open
where in the first verification path R_x holds an unknown scalar with an
aux->alu_limit of e.g. 7, and in a second verification path that same
register R_x, here denoted as R_x', holds an unknown scalar which has
tighter bounds and would thus satisfy range_within(R_x, R_x') as well as
tnum_in(R_x, R_x') for state pruning, yielding an aux->alu_limit of 3:
Given the second path fits the register constraints for pruning, the final
generated mask from aux->alu_limit will remain at 7. While technically
not wrong for the non-speculative domain, it would however be possible
to craft similar cases where the mask would be too wide as in 7fedb63a8307.

One way to fix it is to detect the presence of unknown scalar map pointer
arithmetic and force a deeper search on unknown scalars to ensure that
we do not run into a masking mismatch.

	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Acked-by: Alexei Starovoitov <ast@kernel.org>
(cherry picked from commit e042aa532c84d18ff13291d00620502ce7a38dda)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/verifier.c
diff --cc kernel/bpf/verifier.c
index e65c8ec142c6,657062cb4d85..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -5882,6 -6550,25 +5882,28 @@@ static int sanitize_ptr_alu(struct bpf_
  	if (err < 0)
  		return err;
  
++<<<<<<< HEAD
++=======
+ 	if (commit_window) {
+ 		/* In commit phase we narrow the masking window based on
+ 		 * the observed pointer move after the simulated operation.
+ 		 */
+ 		alu_state = info->aux.alu_state;
+ 		alu_limit = abs(info->aux.alu_limit - alu_limit);
+ 	} else {
+ 		alu_state  = off_is_neg ? BPF_ALU_NEG_VALUE : 0;
+ 		alu_state |= off_is_imm ? BPF_ALU_IMMEDIATE : 0;
+ 		alu_state |= ptr_is_dst_reg ?
+ 			     BPF_ALU_SANITIZE_SRC : BPF_ALU_SANITIZE_DST;
+ 
+ 		/* Limit pruning on unknown scalars to enable deep search for
+ 		 * potential masking differences from other program paths.
+ 		 */
+ 		if (!off_is_imm)
+ 			env->explore_alu_limits = true;
+ 	}
+ 
++>>>>>>> e042aa532c84 (bpf: Fix pointer arithmetic mask tightening under state pruning)
  	err = update_alu_sanitation_state(aux, alu_state, alu_limit);
  	if (err < 0)
  		return err;
diff --git a/include/linux/bpf_verifier.h b/include/linux/bpf_verifier.h
index 4f9a6cb270fe..a2176e7305c0 100644
--- a/include/linux/bpf_verifier.h
+++ b/include/linux/bpf_verifier.h
@@ -410,6 +410,7 @@ struct bpf_verifier_env {
 	u32 used_map_cnt;		/* number of used maps */
 	u32 used_btf_cnt;		/* number of used BTF objects */
 	u32 id_gen;			/* used to generate unique reg IDs */
+	bool explore_alu_limits;
 	bool allow_ptr_leaks;
 	bool allow_uninit_stack;
 	bool allow_ptr_to_map_access;
* Unmerged path kernel/bpf/verifier.c
