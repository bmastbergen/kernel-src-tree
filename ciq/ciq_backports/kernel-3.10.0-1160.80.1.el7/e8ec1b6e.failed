x86/bugs: Enable STIBP for JMP2RET

jira LE-1907
cve CVE-2022-29901
cve CVE-2022-29900
cve CVE-2022-23825
cve CVE-2022-23816
Rebuild_History Non-Buildable kernel-3.10.0-1160.80.1.el7
commit-author Kim Phillips <kim.phillips@amd.com>
commit e8ec1b6e08a2102d8755ccb06fa26d540f26a2fa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.80.1.el7/e8ec1b6e.failed

For untrained return thunks to be fully effective, STIBP must be enabled
or SMT disabled.

Co-developed-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Signed-off-by: Kim Phillips <kim.phillips@amd.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Borislav Petkov <bp@suse.de>
(cherry picked from commit e8ec1b6e08a2102d8755ccb06fa26d540f26a2fa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/admin-guide/kernel-parameters.txt
#	arch/x86/kernel/cpu/bugs.c
diff --cc arch/x86/kernel/cpu/bugs.c
index a7e93ef81745,fb249b2c1eb0..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -650,9 -760,175 +650,125 @@@ static int __init nospectre_v1_cmdline(
  early_param("nospectre_v1", nospectre_v1_cmdline);
  
  #undef pr_fmt
++<<<<<<< HEAD
++=======
+ #define pr_fmt(fmt)     "RETBleed: " fmt
+ 
+ enum retbleed_mitigation {
+ 	RETBLEED_MITIGATION_NONE,
+ 	RETBLEED_MITIGATION_UNRET,
+ };
+ 
+ enum retbleed_mitigation_cmd {
+ 	RETBLEED_CMD_OFF,
+ 	RETBLEED_CMD_AUTO,
+ 	RETBLEED_CMD_UNRET,
+ };
+ 
+ const char * const retbleed_strings[] = {
+ 	[RETBLEED_MITIGATION_NONE]	= "Vulnerable",
+ 	[RETBLEED_MITIGATION_UNRET]	= "Mitigation: untrained return thunk",
+ };
+ 
+ static enum retbleed_mitigation retbleed_mitigation __ro_after_init =
+ 	RETBLEED_MITIGATION_NONE;
+ static enum retbleed_mitigation_cmd retbleed_cmd __ro_after_init =
+ 	RETBLEED_CMD_AUTO;
+ 
+ static int __ro_after_init retbleed_nosmt = false;
+ 
+ static int __init retbleed_parse_cmdline(char *str)
+ {
+ 	if (!str)
+ 		return -EINVAL;
+ 
+ 	while (str) {
+ 		char *next = strchr(str, ',');
+ 		if (next) {
+ 			*next = 0;
+ 			next++;
+ 		}
+ 
+ 		if (!strcmp(str, "off")) {
+ 			retbleed_cmd = RETBLEED_CMD_OFF;
+ 		} else if (!strcmp(str, "auto")) {
+ 			retbleed_cmd = RETBLEED_CMD_AUTO;
+ 		} else if (!strcmp(str, "unret")) {
+ 			retbleed_cmd = RETBLEED_CMD_UNRET;
+ 		} else if (!strcmp(str, "nosmt")) {
+ 			retbleed_nosmt = true;
+ 		} else {
+ 			pr_err("Ignoring unknown retbleed option (%s).", str);
+ 		}
+ 
+ 		str = next;
+ 	}
+ 
+ 	return 0;
+ }
+ early_param("retbleed", retbleed_parse_cmdline);
+ 
+ #define RETBLEED_UNTRAIN_MSG "WARNING: BTB untrained return thunk mitigation is only effective on AMD/Hygon!\n"
+ #define RETBLEED_COMPILER_MSG "WARNING: kernel not compiled with RETPOLINE or -mfunction-return capable compiler!\n"
+ 
+ static void __init retbleed_select_mitigation(void)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_RETBLEED) || cpu_mitigations_off())
+ 		return;
+ 
+ 	switch (retbleed_cmd) {
+ 	case RETBLEED_CMD_OFF:
+ 		return;
+ 
+ 	case RETBLEED_CMD_UNRET:
+ 		retbleed_mitigation = RETBLEED_MITIGATION_UNRET;
+ 		break;
+ 
+ 	case RETBLEED_CMD_AUTO:
+ 	default:
+ 		if (!boot_cpu_has_bug(X86_BUG_RETBLEED))
+ 			break;
+ 
+ 		if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD ||
+ 		    boot_cpu_data.x86_vendor == X86_VENDOR_HYGON)
+ 			retbleed_mitigation = RETBLEED_MITIGATION_UNRET;
+ 		break;
+ 	}
+ 
+ 	switch (retbleed_mitigation) {
+ 	case RETBLEED_MITIGATION_UNRET:
+ 
+ 		if (!IS_ENABLED(CONFIG_RETPOLINE) ||
+ 		    !IS_ENABLED(CONFIG_CC_HAS_RETURN_THUNK)) {
+ 			pr_err(RETBLEED_COMPILER_MSG);
+ 			retbleed_mitigation = RETBLEED_MITIGATION_NONE;
+ 			break;
+ 		}
+ 
+ 		setup_force_cpu_cap(X86_FEATURE_RETHUNK);
+ 		setup_force_cpu_cap(X86_FEATURE_UNRET);
+ 
+ 		if (!boot_cpu_has(X86_FEATURE_STIBP) &&
+ 		    (retbleed_nosmt || cpu_mitigations_auto_nosmt()))
+ 			cpu_smt_disable(false);
+ 
+ 		if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD &&
+ 		    boot_cpu_data.x86_vendor != X86_VENDOR_HYGON)
+ 			pr_err(RETBLEED_UNTRAIN_MSG);
+ 		break;
+ 
+ 	default:
+ 		break;
+ 	}
+ 
+ 	pr_info("%s\n", retbleed_strings[retbleed_mitigation]);
+ }
+ 
+ #undef pr_fmt
++>>>>>>> e8ec1b6e08a2 (x86/bugs: Enable STIBP for JMP2RET)
  #define pr_fmt(fmt)     "Spectre V2 : " fmt
  
 -static enum spectre_v2_mitigation spectre_v2_enabled __ro_after_init =
 -	SPECTRE_V2_NONE;
 -
 -static enum spectre_v2_user_mitigation spectre_v2_user_stibp __ro_after_init =
 -	SPECTRE_V2_USER_NONE;
 -static enum spectre_v2_user_mitigation spectre_v2_user_ibpb __ro_after_init =
 -	SPECTRE_V2_USER_NONE;
 -
 -#ifdef CONFIG_RETPOLINE
 -static bool spectre_v2_bad_module;
 -
 -bool retpoline_module_ok(bool has_retpoline)
 -{
 -	if (spectre_v2_enabled == SPECTRE_V2_NONE || has_retpoline)
 -		return true;
 -
 -	pr_err("System may be vulnerable to spectre v2\n");
 -	spectre_v2_bad_module = true;
 -	return false;
 -}
 -
 -static inline const char *spectre_v2_module_string(void)
 -{
 -	return spectre_v2_bad_module ? " - vulnerable module loaded" : "";
 -}
 -#else
 -static inline const char *spectre_v2_module_string(void) { return ""; }
 -#endif
 -
 -#define SPECTRE_V2_LFENCE_MSG "WARNING: LFENCE mitigation is not recommended for this CPU, data leaks possible!\n"
 -#define SPECTRE_V2_EIBRS_EBPF_MSG "WARNING: Unprivileged eBPF is enabled with eIBRS on, data leaks possible via Spectre v2 BHB attacks!\n"
 -#define SPECTRE_V2_EIBRS_LFENCE_EBPF_SMT_MSG "WARNING: Unprivileged eBPF is enabled with eIBRS+LFENCE mitigation and SMT, data leaks possible via Spectre v2 BHB attacks!\n"
 -
 -#ifdef CONFIG_BPF_SYSCALL
 -void unpriv_ebpf_notify(int new_state)
 -{
 -	if (new_state)
 -		return;
 -
 -	/* Unprivileged eBPF is enabled */
 -
 -	switch (spectre_v2_enabled) {
 -	case SPECTRE_V2_EIBRS:
 -		pr_err(SPECTRE_V2_EIBRS_EBPF_MSG);
 -		break;
 -	case SPECTRE_V2_EIBRS_LFENCE:
 -		if (sched_smt_active())
 -			pr_err(SPECTRE_V2_EIBRS_LFENCE_EBPF_SMT_MSG);
 -		break;
 -	default:
 -		break;
 -	}
 -}
 -#endif
 +enum spectre_v2_mitigation spectre_v2_enabled = SPECTRE_V2_NONE;
  
  static inline bool match_option(const char *arg, int arglen, const char *opt)
  {
@@@ -661,6 -937,197 +777,200 @@@
  	return len == arglen && !strncmp(arg, opt, len);
  }
  
++<<<<<<< HEAD
++=======
+ /* The kernel command line selection for spectre v2 */
+ enum spectre_v2_mitigation_cmd {
+ 	SPECTRE_V2_CMD_NONE,
+ 	SPECTRE_V2_CMD_AUTO,
+ 	SPECTRE_V2_CMD_FORCE,
+ 	SPECTRE_V2_CMD_RETPOLINE,
+ 	SPECTRE_V2_CMD_RETPOLINE_GENERIC,
+ 	SPECTRE_V2_CMD_RETPOLINE_LFENCE,
+ 	SPECTRE_V2_CMD_EIBRS,
+ 	SPECTRE_V2_CMD_EIBRS_RETPOLINE,
+ 	SPECTRE_V2_CMD_EIBRS_LFENCE,
+ };
+ 
+ enum spectre_v2_user_cmd {
+ 	SPECTRE_V2_USER_CMD_NONE,
+ 	SPECTRE_V2_USER_CMD_AUTO,
+ 	SPECTRE_V2_USER_CMD_FORCE,
+ 	SPECTRE_V2_USER_CMD_PRCTL,
+ 	SPECTRE_V2_USER_CMD_PRCTL_IBPB,
+ 	SPECTRE_V2_USER_CMD_SECCOMP,
+ 	SPECTRE_V2_USER_CMD_SECCOMP_IBPB,
+ };
+ 
+ static const char * const spectre_v2_user_strings[] = {
+ 	[SPECTRE_V2_USER_NONE]			= "User space: Vulnerable",
+ 	[SPECTRE_V2_USER_STRICT]		= "User space: Mitigation: STIBP protection",
+ 	[SPECTRE_V2_USER_STRICT_PREFERRED]	= "User space: Mitigation: STIBP always-on protection",
+ 	[SPECTRE_V2_USER_PRCTL]			= "User space: Mitigation: STIBP via prctl",
+ 	[SPECTRE_V2_USER_SECCOMP]		= "User space: Mitigation: STIBP via seccomp and prctl",
+ };
+ 
+ static const struct {
+ 	const char			*option;
+ 	enum spectre_v2_user_cmd	cmd;
+ 	bool				secure;
+ } v2_user_options[] __initconst = {
+ 	{ "auto",		SPECTRE_V2_USER_CMD_AUTO,		false },
+ 	{ "off",		SPECTRE_V2_USER_CMD_NONE,		false },
+ 	{ "on",			SPECTRE_V2_USER_CMD_FORCE,		true  },
+ 	{ "prctl",		SPECTRE_V2_USER_CMD_PRCTL,		false },
+ 	{ "prctl,ibpb",		SPECTRE_V2_USER_CMD_PRCTL_IBPB,		false },
+ 	{ "seccomp",		SPECTRE_V2_USER_CMD_SECCOMP,		false },
+ 	{ "seccomp,ibpb",	SPECTRE_V2_USER_CMD_SECCOMP_IBPB,	false },
+ };
+ 
+ static void __init spec_v2_user_print_cond(const char *reason, bool secure)
+ {
+ 	if (boot_cpu_has_bug(X86_BUG_SPECTRE_V2) != secure)
+ 		pr_info("spectre_v2_user=%s forced on command line.\n", reason);
+ }
+ 
+ static enum spectre_v2_user_cmd __init
+ spectre_v2_parse_user_cmdline(enum spectre_v2_mitigation_cmd v2_cmd)
+ {
+ 	char arg[20];
+ 	int ret, i;
+ 
+ 	switch (v2_cmd) {
+ 	case SPECTRE_V2_CMD_NONE:
+ 		return SPECTRE_V2_USER_CMD_NONE;
+ 	case SPECTRE_V2_CMD_FORCE:
+ 		return SPECTRE_V2_USER_CMD_FORCE;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	ret = cmdline_find_option(boot_command_line, "spectre_v2_user",
+ 				  arg, sizeof(arg));
+ 	if (ret < 0)
+ 		return SPECTRE_V2_USER_CMD_AUTO;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(v2_user_options); i++) {
+ 		if (match_option(arg, ret, v2_user_options[i].option)) {
+ 			spec_v2_user_print_cond(v2_user_options[i].option,
+ 						v2_user_options[i].secure);
+ 			return v2_user_options[i].cmd;
+ 		}
+ 	}
+ 
+ 	pr_err("Unknown user space protection option (%s). Switching to AUTO select\n", arg);
+ 	return SPECTRE_V2_USER_CMD_AUTO;
+ }
+ 
+ static inline bool spectre_v2_in_eibrs_mode(enum spectre_v2_mitigation mode)
+ {
+ 	return (mode == SPECTRE_V2_EIBRS ||
+ 		mode == SPECTRE_V2_EIBRS_RETPOLINE ||
+ 		mode == SPECTRE_V2_EIBRS_LFENCE);
+ }
+ 
+ static void __init
+ spectre_v2_user_select_mitigation(enum spectre_v2_mitigation_cmd v2_cmd)
+ {
+ 	enum spectre_v2_user_mitigation mode = SPECTRE_V2_USER_NONE;
+ 	bool smt_possible = IS_ENABLED(CONFIG_SMP);
+ 	enum spectre_v2_user_cmd cmd;
+ 
+ 	if (!boot_cpu_has(X86_FEATURE_IBPB) && !boot_cpu_has(X86_FEATURE_STIBP))
+ 		return;
+ 
+ 	if (cpu_smt_control == CPU_SMT_FORCE_DISABLED ||
+ 	    cpu_smt_control == CPU_SMT_NOT_SUPPORTED)
+ 		smt_possible = false;
+ 
+ 	cmd = spectre_v2_parse_user_cmdline(v2_cmd);
+ 	switch (cmd) {
+ 	case SPECTRE_V2_USER_CMD_NONE:
+ 		goto set_mode;
+ 	case SPECTRE_V2_USER_CMD_FORCE:
+ 		mode = SPECTRE_V2_USER_STRICT;
+ 		break;
+ 	case SPECTRE_V2_USER_CMD_AUTO:
+ 	case SPECTRE_V2_USER_CMD_PRCTL:
+ 	case SPECTRE_V2_USER_CMD_PRCTL_IBPB:
+ 		mode = SPECTRE_V2_USER_PRCTL;
+ 		break;
+ 	case SPECTRE_V2_USER_CMD_SECCOMP:
+ 	case SPECTRE_V2_USER_CMD_SECCOMP_IBPB:
+ 		if (IS_ENABLED(CONFIG_SECCOMP))
+ 			mode = SPECTRE_V2_USER_SECCOMP;
+ 		else
+ 			mode = SPECTRE_V2_USER_PRCTL;
+ 		break;
+ 	}
+ 
+ 	/* Initialize Indirect Branch Prediction Barrier */
+ 	if (boot_cpu_has(X86_FEATURE_IBPB)) {
+ 		setup_force_cpu_cap(X86_FEATURE_USE_IBPB);
+ 
+ 		spectre_v2_user_ibpb = mode;
+ 		switch (cmd) {
+ 		case SPECTRE_V2_USER_CMD_FORCE:
+ 		case SPECTRE_V2_USER_CMD_PRCTL_IBPB:
+ 		case SPECTRE_V2_USER_CMD_SECCOMP_IBPB:
+ 			static_branch_enable(&switch_mm_always_ibpb);
+ 			spectre_v2_user_ibpb = SPECTRE_V2_USER_STRICT;
+ 			break;
+ 		case SPECTRE_V2_USER_CMD_PRCTL:
+ 		case SPECTRE_V2_USER_CMD_AUTO:
+ 		case SPECTRE_V2_USER_CMD_SECCOMP:
+ 			static_branch_enable(&switch_mm_cond_ibpb);
+ 			break;
+ 		default:
+ 			break;
+ 		}
+ 
+ 		pr_info("mitigation: Enabling %s Indirect Branch Prediction Barrier\n",
+ 			static_key_enabled(&switch_mm_always_ibpb) ?
+ 			"always-on" : "conditional");
+ 	}
+ 
+ 	/*
+ 	 * If no STIBP, enhanced IBRS is enabled or SMT impossible, STIBP is not
+ 	 * required.
+ 	 */
+ 	if (!boot_cpu_has(X86_FEATURE_STIBP) ||
+ 	    !smt_possible ||
+ 	    spectre_v2_in_eibrs_mode(spectre_v2_enabled))
+ 		return;
+ 
+ 	/*
+ 	 * At this point, an STIBP mode other than "off" has been set.
+ 	 * If STIBP support is not being forced, check if STIBP always-on
+ 	 * is preferred.
+ 	 */
+ 	if (mode != SPECTRE_V2_USER_STRICT &&
+ 	    boot_cpu_has(X86_FEATURE_AMD_STIBP_ALWAYS_ON))
+ 		mode = SPECTRE_V2_USER_STRICT_PREFERRED;
+ 
+ 	if (retbleed_mitigation == RETBLEED_MITIGATION_UNRET) {
+ 		if (mode != SPECTRE_V2_USER_STRICT &&
+ 		    mode != SPECTRE_V2_USER_STRICT_PREFERRED)
+ 			pr_info("Selecting STIBP always-on mode to complement retbleed mitigation'\n");
+ 		mode = SPECTRE_V2_USER_STRICT_PREFERRED;
+ 	}
+ 
+ 	spectre_v2_user_stibp = mode;
+ 
+ set_mode:
+ 	pr_info("%s\n", spectre_v2_user_strings[mode]);
+ }
+ 
+ static const char * const spectre_v2_strings[] = {
+ 	[SPECTRE_V2_NONE]			= "Vulnerable",
+ 	[SPECTRE_V2_RETPOLINE]			= "Mitigation: Retpolines",
+ 	[SPECTRE_V2_LFENCE]			= "Mitigation: LFENCE",
+ 	[SPECTRE_V2_EIBRS]			= "Mitigation: Enhanced IBRS",
+ 	[SPECTRE_V2_EIBRS_LFENCE]		= "Mitigation: Enhanced IBRS + LFENCE",
+ 	[SPECTRE_V2_EIBRS_RETPOLINE]		= "Mitigation: Enhanced IBRS + Retpolines",
+ };
+ 
++>>>>>>> e8ec1b6e08a2 (x86/bugs: Enable STIBP for JMP2RET)
  static const struct {
  	const char *option;
  	enum spectre_v2_mitigation_cmd cmd;
@@@ -1393,8 -2121,26 +1703,29 @@@ static ssize_t srbds_show_state(char *b
  	return sprintf(buf, "%s\n", srbds_strings[srbds_mitigation]);
  }
  
++<<<<<<< HEAD
++=======
+ static ssize_t retbleed_show_state(char *buf)
+ {
+ 	if (retbleed_mitigation == RETBLEED_MITIGATION_UNRET) {
+ 	    if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD &&
+ 		boot_cpu_data.x86_vendor != X86_VENDOR_HYGON)
+ 		    return sprintf(buf, "Vulnerable: untrained return thunk on non-Zen uarch\n");
+ 
+ 	    return sprintf(buf, "%s; SMT %s\n",
+ 			   retbleed_strings[retbleed_mitigation],
+ 			   !sched_smt_active() ? "disabled" :
+ 			   spectre_v2_user_stibp == SPECTRE_V2_USER_STRICT ||
+ 			   spectre_v2_user_stibp == SPECTRE_V2_USER_STRICT_PREFERRED ?
+ 			   "enabled with STIBP protection" : "vulnerable");
+ 	}
+ 
+ 	return sprintf(buf, "%s\n", retbleed_strings[retbleed_mitigation]);
+ }
+ 
++>>>>>>> e8ec1b6e08a2 (x86/bugs: Enable STIBP for JMP2RET)
  static ssize_t cpu_show_common(struct device *dev, struct device_attribute *attr,
 -			       char *buf, unsigned int bug)
 +			char *buf, unsigned int bug)
  {
  	if (!boot_cpu_has_bug(bug))
  		return sprintf(buf, "Not affected\n");
* Unmerged path Documentation/admin-guide/kernel-parameters.txt
* Unmerged path Documentation/admin-guide/kernel-parameters.txt
* Unmerged path arch/x86/kernel/cpu/bugs.c
