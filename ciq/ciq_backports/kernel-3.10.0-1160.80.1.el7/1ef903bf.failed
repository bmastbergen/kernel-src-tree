net/mlx5: Free IRQs in shutdown path

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1160.80.1.el7
commit-author Daniel Jurgens <danielj@mellanox.com>
commit 1ef903bf795be01c91c10c93a0f9d9d6f2f7921b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.80.1.el7/1ef903bf.failed

Some platforms require IRQs to be free'd in the shutdown path. Otherwise
they will fail to be reallocated after a kexec.

Fixes: 8812c24d28f4 ("net/mlx5: Add fast unload support in shutdown flow")
	Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 1ef903bf795be01c91c10c93a0f9d9d6f2f7921b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/main.c
#	drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/main.c
index b83bea6e48e5,e2c465b0b3f8..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@@ -1325,6 -1558,46 +1325,49 @@@ static const struct pci_error_handlers 
  	.resume		= mlx5_pci_resume
  };
  
++<<<<<<< HEAD
++=======
+ static int mlx5_try_fast_unload(struct mlx5_core_dev *dev)
+ {
+ 	int ret;
+ 
+ 	if (!MLX5_CAP_GEN(dev, force_teardown)) {
+ 		mlx5_core_dbg(dev, "force teardown is not supported in the firmware\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	if (dev->state == MLX5_DEVICE_STATE_INTERNAL_ERROR) {
+ 		mlx5_core_dbg(dev, "Device in internal error state, giving up\n");
+ 		return -EAGAIN;
+ 	}
+ 
+ 	/* Panic tear down fw command will stop the PCI bus communication
+ 	 * with the HCA, so the health polll is no longer needed.
+ 	 */
+ 	mlx5_drain_health_wq(dev);
+ 	mlx5_stop_health_poll(dev);
+ 
+ 	ret = mlx5_cmd_force_teardown_hca(dev);
+ 	if (ret) {
+ 		mlx5_core_dbg(dev, "Firmware couldn't do fast unload error: %d\n", ret);
+ 		mlx5_start_health_poll(dev);
+ 		return ret;
+ 	}
+ 
+ 	mlx5_enter_error_state(dev, true);
+ 
+ 	/* Some platforms requiring freeing the IRQ's in the shutdown
+ 	 * flow. If they aren't freed they can't be allocated after
+ 	 * kexec. There is no need to cleanup the mlx5_core software
+ 	 * contexts.
+ 	 */
+ 	mlx5_irq_clear_affinity_hints(dev);
+ 	mlx5_core_eq_free_irqs(dev);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 1ef903bf795b (net/mlx5: Free IRQs in shutdown path)
  static void shutdown(struct pci_dev *pdev)
  {
  	struct mlx5_core_dev *dev  = pci_get_drvdata(pdev);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
index 72c4903ec42b,023882d9a22e..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
@@@ -121,10 -114,30 +121,30 @@@ int mlx5_modify_scheduling_element_cmd(
  int mlx5_destroy_scheduling_element_cmd(struct mlx5_core_dev *dev, u8 hierarchy,
  					u32 element_id);
  int mlx5_wait_for_vf_pages(struct mlx5_core_dev *dev);
 -u64 mlx5_read_internal_timer(struct mlx5_core_dev *dev);
 +u64 mlx5_read_internal_timer(struct mlx5_core_dev *dev,
 +			     struct ptp_system_timestamp *sts);
  
++<<<<<<< HEAD
++=======
+ int mlx5_eq_init(struct mlx5_core_dev *dev);
+ void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
+ int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
+ 		       int nent, u64 mask, const char *name,
+ 		       enum mlx5_eq_type type);
+ int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+ int mlx5_eq_add_cq(struct mlx5_eq *eq, struct mlx5_core_cq *cq);
+ int mlx5_eq_del_cq(struct mlx5_eq *eq, struct mlx5_core_cq *cq);
+ int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
+ 		       u32 *out, int outlen);
+ int mlx5_start_eqs(struct mlx5_core_dev *dev);
+ void mlx5_stop_eqs(struct mlx5_core_dev *dev);
+ /* This function should only be called after mlx5_cmd_force_teardown_hca */
+ void mlx5_core_eq_free_irqs(struct mlx5_core_dev *dev);
+ struct mlx5_eq *mlx5_eqn2eq(struct mlx5_core_dev *dev, int eqn);
+ u32 mlx5_eq_poll_irq_disabled(struct mlx5_eq *eq);
+ void mlx5_cq_tasklet_cb(unsigned long data);
++>>>>>>> 1ef903bf795b (net/mlx5: Free IRQs in shutdown path)
  void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced);
 -int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 -void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
 -int mlx5_eq_debugfs_init(struct mlx5_core_dev *dev);
 -void mlx5_eq_debugfs_cleanup(struct mlx5_core_dev *dev);
  int mlx5_cq_debugfs_init(struct mlx5_core_dev *dev);
  void mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev);
  
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eq.c b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
index fa1793021209..a450b0e8a37e 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@ -1174,3 +1174,28 @@ void mlx5_eq_table_destroy(struct mlx5_core_dev *dev)
 	destroy_async_eqs(dev);
 	free_irq_vectors(dev);
 }
+
+/* This function should only be called after mlx5_cmd_force_teardown_hca */
+void mlx5_core_eq_free_irqs(struct mlx5_core_dev *dev)
+{
+	struct mlx5_eq_table *table = &dev->priv.eq_table;
+	struct mlx5_eq *eq;
+
+#ifdef CONFIG_RFS_ACCEL
+	if (dev->rmap) {
+		free_irq_cpu_rmap(dev->rmap);
+		dev->rmap = NULL;
+	}
+#endif
+	list_for_each_entry(eq, &table->comp_eqs_list, list)
+		free_irq(eq->irqn, eq);
+
+	free_irq(table->pages_eq.irqn, &table->pages_eq);
+	free_irq(table->async_eq.irqn, &table->async_eq);
+	free_irq(table->cmd_eq.irqn, &table->cmd_eq);
+#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+	if (MLX5_CAP_GEN(dev, pg))
+		free_irq(table->pfault_eq.irqn, &table->pfault_eq);
+#endif
+	pci_free_irq_vectors(dev->pdev);
+}
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
