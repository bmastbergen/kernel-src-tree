x86/kexec: Disable RET on kexec

jira LE-1907
cve CVE-2022-29901
cve CVE-2022-29900
cve CVE-2022-23825
cve CVE-2022-23816
Rebuild_History Non-Buildable kernel-3.10.0-1160.80.1.el7
commit-author Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
commit 697977d8415d61f3acbc4ee6d564c9dcf0309507
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.80.1.el7/697977d8.failed

All the invocations unroll to __x86_return_thunk and this file
must be PIC independent.

This fixes kexec on 64-bit AMD boxes.

  [ bp: Fix 32-bit build. ]

	Reported-by: Edward Tran <edward.tran@oracle.com>
	Reported-by: Awais Tanveer <awais.tanveer@oracle.com>
	Suggested-by: Ankur Arora <ankur.a.arora@oracle.com>
	Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
	Signed-off-by: Alexandre Chartre <alexandre.chartre@oracle.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
(cherry picked from commit 697977d8415d61f3acbc4ee6d564c9dcf0309507)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/relocate_kernel_32.S
#	arch/x86/kernel/relocate_kernel_64.S
diff --cc arch/x86/kernel/relocate_kernel_32.S
index 36818f8ec2be,c7c4b1917336..000000000000
--- a/arch/x86/kernel/relocate_kernel_32.S
+++ b/arch/x86/kernel/relocate_kernel_32.S
@@@ -94,9 -93,12 +96,16 @@@ relocate_kernel
  	movl    %edi, %eax
  	addl    $(identity_mapped - relocate_kernel), %eax
  	pushl   %eax
++<<<<<<< HEAD
 +	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
+ 	ret
+ 	int3
+ SYM_CODE_END(relocate_kernel)
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
 -SYM_CODE_START_LOCAL_NOALIGN(identity_mapped)
 +identity_mapped:
  	/* set return address to 0 if not preserving context */
  	pushl	$0
  	/* store the start address on the stack */
@@@ -161,7 -163,9 +170,13 @@@
  	xorl    %edx, %edx
  	xorl    %esi, %esi
  	xorl    %ebp, %ebp
++<<<<<<< HEAD
++	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
  	ret
+ 	int3
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  1:
  	popl	%edx
  	movl	CP_PA_SWAP_PAGE(%edi), %esp
@@@ -192,9 -197,12 +208,16 @@@
  	movl	%edi, %eax
  	addl	$(virtual_mapped - relocate_kernel), %eax
  	pushl	%eax
++<<<<<<< HEAD
++	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
  	ret
+ 	int3
+ SYM_CODE_END(identity_mapped)
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
 -SYM_CODE_START_LOCAL_NOALIGN(virtual_mapped)
 +virtual_mapped:
  	movl	CR4(%edi), %eax
  	movl	%eax, %cr4
  	movl	CR3(%edi), %eax
@@@ -209,10 -217,13 +232,17 @@@
  	popl	%edi
  	popl	%esi
  	popl	%ebx
++<<<<<<< HEAD
 +	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
+ 	ret
+ 	int3
+ SYM_CODE_END(virtual_mapped)
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
  	/* Do the copies */
 -SYM_CODE_START_LOCAL_NOALIGN(swap_pages)
 +swap_pages:
  	movl	8(%esp), %edx
  	movl	4(%esp), %ecx
  	pushl	%ebp
@@@ -271,7 -282,10 +301,14 @@@
  	popl	%edi
  	popl	%ebx
  	popl	%ebp
++<<<<<<< HEAD
++	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
  	ret
+ 	int3
+ SYM_CODE_END(swap_pages)
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
  	.globl kexec_control_code_size
  .set kexec_control_code_size, . - relocate_kernel
diff --cc arch/x86/kernel/relocate_kernel_64.S
index a59dd47921a2,4809c0dc4eb0..000000000000
--- a/arch/x86/kernel/relocate_kernel_64.S
+++ b/arch/x86/kernel/relocate_kernel_64.S
@@@ -11,9 -9,12 +11,10 @@@
  #include <asm/kexec.h>
  #include <asm/processor-flags.h>
  #include <asm/pgtable_types.h>
 -#include <asm/nospec-branch.h>
 -#include <asm/unwind_hints.h>
  
  /*
-  * Must be relocatable PIC code callable as a C function
+  * Must be relocatable PIC code callable as a C function, in particular
+  * there must be a plain RET and not jump to return thunk.
   */
  
  #define PTR(x) (x << 3)
@@@ -101,9 -106,13 +102,16 @@@ relocate_kernel
  	/* jump to identity mapped page */
  	addq	$(identity_mapped - relocate_kernel), %r8
  	pushq	%r8
++<<<<<<< HEAD
 +	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
+ 	ret
+ 	int3
+ SYM_CODE_END(relocate_kernel)
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
 -SYM_CODE_START_LOCAL_NOALIGN(identity_mapped)
 -	UNWIND_HINT_EMPTY
 +identity_mapped:
  	/* set return address to 0 if not preserving context */
  	pushq	$0
  	/* store the start address on the stack */
@@@ -165,23 -187,25 +173,29 @@@
  
  	testq	%r11, %r11
  	jnz 1f
 -	xorl	%eax, %eax
 -	xorl	%ebx, %ebx
 -	xorl    %ecx, %ecx
 -	xorl    %edx, %edx
 -	xorl    %esi, %esi
 -	xorl    %edi, %edi
 -	xorl    %ebp, %ebp
 -	xorl	%r8d, %r8d
 -	xorl	%r9d, %r9d
 -	xorl	%r10d, %r10d
 -	xorl	%r11d, %r11d
 -	xorl	%r12d, %r12d
 -	xorl	%r13d, %r13d
 -	xorl	%r14d, %r14d
 -	xorl	%r15d, %r15d
 -
 +	xorq	%rax, %rax
 +	xorq	%rbx, %rbx
 +	xorq    %rcx, %rcx
 +	xorq    %rdx, %rdx
 +	xorq    %rsi, %rsi
 +	xorq    %rdi, %rdi
 +	xorq    %rbp, %rbp
 +	xorq	%r8,  %r8
 +	xorq	%r9,  %r9
 +	xorq	%r10, %r10
 +	xorq	%r11, %r11
 +	xorq	%r12, %r12
 +	xorq	%r13, %r13
 +	xorq	%r14, %r14
 +	xorq	%r15, %r15
 +
++<<<<<<< HEAD
++	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
  	ret
+ 	int3
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
  1:
  	popq	%rdx
@@@ -202,9 -224,14 +216,16 @@@
  	call	swap_pages
  	movq	$virtual_mapped, %rax
  	pushq	%rax
++<<<<<<< HEAD
++	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
  	ret
+ 	int3
+ SYM_CODE_END(identity_mapped)
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
 -SYM_CODE_START_LOCAL_NOALIGN(virtual_mapped)
 -	UNWIND_HINT_EMPTY
 -	ANNOTATE_NOENDBR // RET target, above
 +virtual_mapped:
  	movq	RSP(%r8), %rsp
  	movq	CR4(%r8), %rax
  	movq	%rax, %cr4
@@@ -221,13 -248,17 +242,20 @@@
  	popq	%r12
  	popq	%rbp
  	popq	%rbx
++<<<<<<< HEAD
 +	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
+ 	ret
+ 	int3
+ SYM_CODE_END(virtual_mapped)
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
  	/* Do the copies */
 -SYM_CODE_START_LOCAL_NOALIGN(swap_pages)
 -	UNWIND_HINT_EMPTY
 +swap_pages:
  	movq	%rdi, %rcx 	/* Put the page_list in %rcx */
 -	xorl	%edi, %edi
 -	xorl	%esi, %esi
 +	xorq	%rdi, %rdi
 +	xorq	%rsi, %rsi
  	jmp	1f
  
  0:	/* top, read another word for the indirection page */
@@@ -276,7 -307,10 +304,14 @@@
  	lea	PAGE_SIZE(%rax), %rsi
  	jmp	0b
  3:
++<<<<<<< HEAD
++	ret
++=======
+ 	ANNOTATE_UNRET_SAFE
  	ret
+ 	int3
+ SYM_CODE_END(swap_pages)
++>>>>>>> 697977d8415d (x86/kexec: Disable RET on kexec)
  
  	.globl kexec_control_code_size
  .set kexec_control_code_size, . - relocate_kernel
* Unmerged path arch/x86/kernel/relocate_kernel_32.S
* Unmerged path arch/x86/kernel/relocate_kernel_64.S
