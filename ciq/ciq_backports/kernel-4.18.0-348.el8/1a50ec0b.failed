arm64: Implement archrandom.h for ARMv8.5-RNG

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-348.el8
commit-author Richard Henderson <richard.henderson@linaro.org>
commit 1a50ec0b3b2e9a83f1b1245ea37a853aac2f741c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-348.el8/1a50ec0b.failed

Expose the ID_AA64ISAR0.RNDR field to userspace, as the RNG system
registers are always available at EL0.

Implement arch_get_random_seed_long using RNDR.  Given that the
TRNG is likely to be a shared resource between cores, and VMs,
do not explicitly force re-seeding with RNDRRS.  In order to avoid
code complexity and potential issues with hetrogenous systems only
provide values after cpufeature has finalized the system capabilities.

	Signed-off-by: Richard Henderson <richard.henderson@linaro.org>
[Modified to only function after cpufeature has finalized the system
capabilities and move all the code into the header -- broonie]
	Signed-off-by: Mark Brown <broonie@kernel.org>
	Reviewed-by: Mark Rutland <mark.rutland@arm.com>
	Reviewed-by: Ard Biesheuvel <ardb@kernel.org>
[will: Advertise HWCAP via /proc/cpuinfo]
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit 1a50ec0b3b2e9a83f1b1245ea37a853aac2f741c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/arm64/cpu-feature-registers.txt
#	Documentation/arm64/elf_hwcaps.txt
#	arch/arm64/include/asm/cpucaps.h
#	arch/arm64/include/asm/hwcap.h
#	arch/arm64/include/asm/sysreg.h
#	arch/arm64/include/uapi/asm/hwcap.h
#	arch/arm64/kernel/cpufeature.c
#	arch/arm64/kernel/cpuinfo.c
diff --cc Documentation/arm64/cpu-feature-registers.txt
index d4b4dd1fe786,ce320785fb0c..000000000000
--- a/Documentation/arm64/cpu-feature-registers.txt
+++ b/Documentation/arm64/cpu-feature-registers.txt
@@@ -107,33 -113,36 +107,39 @@@ infrastructure
  -------------------------------------------
  
    1) ID_AA64ISAR0_EL1 - Instruction Set Attribute Register 0
 -
 -     +------------------------------+---------+---------+
 +     x--------------------------------------------------x
       | Name                         |  bits   | visible |
++<<<<<<< HEAD:Documentation/arm64/cpu-feature-registers.txt
 +     |--------------------------------------------------|
++=======
+      +------------------------------+---------+---------+
+      | RNDR                         | [63-60] |    y    |
+      +------------------------------+---------+---------+
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG):Documentation/arm64/cpu-feature-registers.rst
       | TS                           | [55-52] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | FHM                          | [51-48] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | DP                           | [47-44] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | SM4                          | [43-40] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | SM3                          | [39-36] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | SHA3                         | [35-32] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | RDM                          | [31-28] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | ATOMICS                      | [23-20] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | CRC32                        | [19-16] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | SHA2                         | [15-12] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | SHA1                         | [11-8]  |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | AES                          | [7-4]   |    y    |
 -     +------------------------------+---------+---------+
 +     x--------------------------------------------------x
  
  
    2) ID_AA64PFR0_EL1 - Processor Feature Register 0
diff --cc Documentation/arm64/elf_hwcaps.txt
index 16c8d3bd1bd3,276a33414b22..000000000000
--- a/Documentation/arm64/elf_hwcaps.txt
+++ b/Documentation/arm64/elf_hwcaps.txt
@@@ -187,13 -159,58 +187,64 @@@ HWCAP_S
      Functionality implied by ID_AA64ISAR1_EL1.SB == 0b0001.
  
  HWCAP_PACA
 +
      Functionality implied by ID_AA64ISAR1_EL1.APA == 0b0001 or
      ID_AA64ISAR1_EL1.API == 0b0001, as described by
 -    Documentation/arm64/pointer-authentication.rst.
 +    Documentation/arm64/pointer-authentication.txt.
  
  HWCAP_PACG
 +
      Functionality implied by ID_AA64ISAR1_EL1.GPA == 0b0001 or
      ID_AA64ISAR1_EL1.GPI == 0b0001, as described by
++<<<<<<< HEAD:Documentation/arm64/elf_hwcaps.txt
 +    Documentation/arm64/pointer-authentication.txt.
++=======
+     Documentation/arm64/pointer-authentication.rst.
+ 
+ HWCAP2_DCPODP
+ 
+     Functionality implied by ID_AA64ISAR1_EL1.DPB == 0b0010.
+ 
+ HWCAP2_SVE2
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.SVEVer == 0b0001.
+ 
+ HWCAP2_SVEAES
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.AES == 0b0001.
+ 
+ HWCAP2_SVEPMULL
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.AES == 0b0010.
+ 
+ HWCAP2_SVEBITPERM
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.BitPerm == 0b0001.
+ 
+ HWCAP2_SVESHA3
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.SHA3 == 0b0001.
+ 
+ HWCAP2_SVESM4
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.SM4 == 0b0001.
+ 
+ HWCAP2_FLAGM2
+ 
+     Functionality implied by ID_AA64ISAR0_EL1.TS == 0b0010.
+ 
+ HWCAP2_FRINT
+ 
+     Functionality implied by ID_AA64ISAR1_EL1.FRINTTS == 0b0001.
+ 
+ HWCAP2_RNG
+ 
+     Functionality implied by ID_AA64ISAR0_EL1.RNDR == 0b0001.
+ 
+ 
+ 4. Unused AT_HWCAP bits
+ -----------------------
+ 
+ For interoperation with userspace, the kernel guarantees that bits 62
+ and 63 of AT_HWCAP will always be returned as 0.
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG):Documentation/arm64/elf_hwcaps.rst
diff --cc arch/arm64/include/asm/cpucaps.h
index 73140a10296f,515f4fbcbf91..000000000000
--- a/arch/arm64/include/asm/cpucaps.h
+++ b/arch/arm64/include/asm/cpucaps.h
@@@ -61,15 -50,14 +61,27 @@@
  #define ARM64_HAS_GENERIC_AUTH_ARCH		40
  #define ARM64_HAS_GENERIC_AUTH_IMP_DEF		41
  #define ARM64_HAS_IRQ_PRIO_MASKING		42
++<<<<<<< HEAD
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	43
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	44
 +#define ARM64_WORKAROUND_1463225		45
 +#define ARM64_WORKAROUND_1542419		46
 +#define ARM64_HAS_32BIT_EL1			47
 +#define ARM64_WORKAROUND_NVIDIA_CARMEL_CNP	48
 +#define ARM64_HAS_ARMv8_4_TTL			49
 +#define ARM64_HAS_TLB_RANGE			50
 +
 +#define ARM64_NCAPS				51
++=======
+ #define ARM64_HAS_DCPODP			43
+ #define ARM64_WORKAROUND_1463225		44
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	45
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	46
+ #define ARM64_WORKAROUND_1542419		47
+ #define ARM64_WORKAROUND_1319367		48
+ #define ARM64_HAS_RNG				49
+ 
+ #define ARM64_NCAPS				50
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG)
  
  #endif /* __ASM_CPUCAPS_H */
diff --cc arch/arm64/include/asm/hwcap.h
index 400b80b49595,fa186480e805..000000000000
--- a/arch/arm64/include/asm/hwcap.h
+++ b/arch/arm64/include/asm/hwcap.h
@@@ -40,6 -30,64 +40,67 @@@
  #define COMPAT_HWCAP2_CRC32	(1 << 4)
  
  #ifndef __ASSEMBLY__
++<<<<<<< HEAD
++=======
+ #include <linux/log2.h>
+ 
+ /*
+  * For userspace we represent hwcaps as a collection of HWCAP{,2}_x bitfields
+  * as described in uapi/asm/hwcap.h. For the kernel we represent hwcaps as
+  * natural numbers (in a single range of size MAX_CPU_FEATURES) defined here
+  * with prefix KERNEL_HWCAP_ mapped to their HWCAP{,2}_x counterpart.
+  *
+  * Hwcaps should be set and tested within the kernel via the
+  * cpu_{set,have}_named_feature(feature) where feature is the unique suffix
+  * of KERNEL_HWCAP_{feature}.
+  */
+ #define __khwcap_feature(x)		const_ilog2(HWCAP_ ## x)
+ #define KERNEL_HWCAP_FP			__khwcap_feature(FP)
+ #define KERNEL_HWCAP_ASIMD		__khwcap_feature(ASIMD)
+ #define KERNEL_HWCAP_EVTSTRM		__khwcap_feature(EVTSTRM)
+ #define KERNEL_HWCAP_AES		__khwcap_feature(AES)
+ #define KERNEL_HWCAP_PMULL		__khwcap_feature(PMULL)
+ #define KERNEL_HWCAP_SHA1		__khwcap_feature(SHA1)
+ #define KERNEL_HWCAP_SHA2		__khwcap_feature(SHA2)
+ #define KERNEL_HWCAP_CRC32		__khwcap_feature(CRC32)
+ #define KERNEL_HWCAP_ATOMICS		__khwcap_feature(ATOMICS)
+ #define KERNEL_HWCAP_FPHP		__khwcap_feature(FPHP)
+ #define KERNEL_HWCAP_ASIMDHP		__khwcap_feature(ASIMDHP)
+ #define KERNEL_HWCAP_CPUID		__khwcap_feature(CPUID)
+ #define KERNEL_HWCAP_ASIMDRDM		__khwcap_feature(ASIMDRDM)
+ #define KERNEL_HWCAP_JSCVT		__khwcap_feature(JSCVT)
+ #define KERNEL_HWCAP_FCMA		__khwcap_feature(FCMA)
+ #define KERNEL_HWCAP_LRCPC		__khwcap_feature(LRCPC)
+ #define KERNEL_HWCAP_DCPOP		__khwcap_feature(DCPOP)
+ #define KERNEL_HWCAP_SHA3		__khwcap_feature(SHA3)
+ #define KERNEL_HWCAP_SM3		__khwcap_feature(SM3)
+ #define KERNEL_HWCAP_SM4		__khwcap_feature(SM4)
+ #define KERNEL_HWCAP_ASIMDDP		__khwcap_feature(ASIMDDP)
+ #define KERNEL_HWCAP_SHA512		__khwcap_feature(SHA512)
+ #define KERNEL_HWCAP_SVE		__khwcap_feature(SVE)
+ #define KERNEL_HWCAP_ASIMDFHM		__khwcap_feature(ASIMDFHM)
+ #define KERNEL_HWCAP_DIT		__khwcap_feature(DIT)
+ #define KERNEL_HWCAP_USCAT		__khwcap_feature(USCAT)
+ #define KERNEL_HWCAP_ILRCPC		__khwcap_feature(ILRCPC)
+ #define KERNEL_HWCAP_FLAGM		__khwcap_feature(FLAGM)
+ #define KERNEL_HWCAP_SSBS		__khwcap_feature(SSBS)
+ #define KERNEL_HWCAP_SB			__khwcap_feature(SB)
+ #define KERNEL_HWCAP_PACA		__khwcap_feature(PACA)
+ #define KERNEL_HWCAP_PACG		__khwcap_feature(PACG)
+ 
+ #define __khwcap2_feature(x)		(const_ilog2(HWCAP2_ ## x) + 32)
+ #define KERNEL_HWCAP_DCPODP		__khwcap2_feature(DCPODP)
+ #define KERNEL_HWCAP_SVE2		__khwcap2_feature(SVE2)
+ #define KERNEL_HWCAP_SVEAES		__khwcap2_feature(SVEAES)
+ #define KERNEL_HWCAP_SVEPMULL		__khwcap2_feature(SVEPMULL)
+ #define KERNEL_HWCAP_SVEBITPERM		__khwcap2_feature(SVEBITPERM)
+ #define KERNEL_HWCAP_SVESHA3		__khwcap2_feature(SVESHA3)
+ #define KERNEL_HWCAP_SVESM4		__khwcap2_feature(SVESM4)
+ #define KERNEL_HWCAP_FLAGM2		__khwcap2_feature(FLAGM2)
+ #define KERNEL_HWCAP_FRINT		__khwcap2_feature(FRINT)
+ #define KERNEL_HWCAP_RNG		__khwcap2_feature(RNG)
+ 
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG)
  /*
   * This yields a mask that user programs can use to figure out what
   * instruction set this cpu supports.
diff --cc arch/arm64/include/asm/sysreg.h
index cca1edca6ca9,5e718f279469..000000000000
--- a/arch/arm64/include/asm/sysreg.h
+++ b/arch/arm64/include/asm/sysreg.h
@@@ -598,19 -537,12 +601,23 @@@
  
  #define SCTLR_EL1_SET	(SCTLR_ELx_M    | SCTLR_ELx_C    | SCTLR_ELx_SA   |\
  			 SCTLR_EL1_SA0  | SCTLR_EL1_SED  | SCTLR_ELx_I    |\
 -			 SCTLR_EL1_DZE  | SCTLR_EL1_UCT                   |\
 +			 SCTLR_EL1_DZE  | SCTLR_EL1_UCT  | SCTLR_EL1_NTWI |\
  			 SCTLR_EL1_NTWE | SCTLR_ELx_IESB | SCTLR_EL1_SPAN |\
  			 ENDIAN_SET_EL1 | SCTLR_EL1_UCI  | SCTLR_EL1_RES1)
 +#define SCTLR_EL1_CLEAR	(SCTLR_ELx_A   | SCTLR_EL1_CP15BEN | SCTLR_EL1_ITD    |\
 +			 SCTLR_EL1_UMA | SCTLR_ELx_WXN     | ENDIAN_CLEAR_EL1 |\
 +			 SCTLR_ELx_DSSBS | SCTLR_EL1_RES0)
 +
 +#if (SCTLR_EL1_SET ^ SCTLR_EL1_CLEAR) != 0xffffffffffffffff
 +#error "Inconsistent SCTLR_EL1 set/clear bits"
 +#endif
  
  /* id_aa64isar0 */
++<<<<<<< HEAD
 +#define ID_AA64ISAR0_TLB_SHIFT		56
++=======
+ #define ID_AA64ISAR0_RNDR_SHIFT		60
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG)
  #define ID_AA64ISAR0_TS_SHIFT		52
  #define ID_AA64ISAR0_FHM_SHIFT		48
  #define ID_AA64ISAR0_DP_SHIFT		44
diff --cc arch/arm64/include/uapi/asm/hwcap.h
index 5f0750c2199c,f192ac33fc76..000000000000
--- a/arch/arm64/include/uapi/asm/hwcap.h
+++ b/arch/arm64/include/uapi/asm/hwcap.h
@@@ -53,4 -53,18 +53,21 @@@
  #define HWCAP_PACA		(1 << 30)
  #define HWCAP_PACG		(1UL << 31)
  
++<<<<<<< HEAD
++=======
+ /*
+  * HWCAP2 flags - for AT_HWCAP2
+  */
+ #define HWCAP2_DCPODP		(1 << 0)
+ #define HWCAP2_SVE2		(1 << 1)
+ #define HWCAP2_SVEAES		(1 << 2)
+ #define HWCAP2_SVEPMULL		(1 << 3)
+ #define HWCAP2_SVEBITPERM	(1 << 4)
+ #define HWCAP2_SVESHA3		(1 << 5)
+ #define HWCAP2_SVESM4		(1 << 6)
+ #define HWCAP2_FLAGM2		(1 << 7)
+ #define HWCAP2_FRINT		(1 << 8)
+ #define HWCAP2_RNG		(1 << 9)
+ 
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG)
  #endif /* _UAPI__ASM_HWCAP_H */
diff --cc arch/arm64/kernel/cpufeature.c
index 2fd906bc1b63,3b94e8047c9e..000000000000
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@@ -133,7 -119,7 +133,11 @@@ static void cpu_enable_cnp(struct arm64
   * sync with the documentation of the CPU feature register ABI.
   */
  static const struct arm64_ftr_bits ftr_id_aa64isar0[] = {
++<<<<<<< HEAD
 +	ARM64_FTR_BITS(FTR_HIDDEN, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ISAR0_TLB_SHIFT, 4, 0),
++=======
+ 	ARM64_FTR_BITS(FTR_VISIBLE, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ISAR0_RNDR_SHIFT, 4, 0),
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG)
  	ARM64_FTR_BITS(FTR_VISIBLE, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ISAR0_TS_SHIFT, 4, 0),
  	ARM64_FTR_BITS(FTR_VISIBLE, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ISAR0_FHM_SHIFT, 4, 0),
  	ARM64_FTR_BITS(FTR_VISIBLE, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ISAR0_DP_SHIFT, 4, 0),
@@@ -1721,39 -1636,49 +1737,72 @@@ static const struct arm64_cpu_capabilit
  #endif
  
  static const struct arm64_cpu_capabilities arm64_elf_hwcaps[] = {
++<<<<<<< HEAD
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_AES_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, HWCAP_PMULL),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_AES_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_AES),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA1_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SHA1),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA2_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SHA2),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA2_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, HWCAP_SHA512),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_CRC32_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_CRC32),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_ATOMICS_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, HWCAP_ATOMICS),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_RDM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_ASIMDRDM),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA3_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SHA3),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SM3_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SM3),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SM4_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SM4),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_DP_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_ASIMDDP),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_FHM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_ASIMDFHM),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_TS_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_FLAGM),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_FP_SHIFT, FTR_SIGNED, 0, CAP_HWCAP, HWCAP_FP),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_FP_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, HWCAP_FPHP),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_ASIMD_SHIFT, FTR_SIGNED, 0, CAP_HWCAP, HWCAP_ASIMD),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_ASIMD_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, HWCAP_ASIMDHP),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_DIT_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, HWCAP_DIT),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_DPB_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_DCPOP),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_JSCVT_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_JSCVT),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_FCMA_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_FCMA),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_LRCPC_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_LRCPC),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_LRCPC_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, HWCAP_ILRCPC),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_SB_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SB),
 +	HWCAP_CAP(SYS_ID_AA64MMFR2_EL1, ID_AA64MMFR2_AT_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_USCAT),
++=======
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_AES_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_PMULL),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_AES_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_AES),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA1_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SHA1),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA2_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SHA2),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA2_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_SHA512),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_CRC32_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_CRC32),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_ATOMICS_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_ATOMICS),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_RDM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_ASIMDRDM),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA3_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SHA3),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SM3_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SM3),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SM4_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SM4),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_DP_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_ASIMDDP),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_FHM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_ASIMDFHM),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_TS_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_FLAGM),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_TS_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_FLAGM2),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_RNDR_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_RNG),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_FP_SHIFT, FTR_SIGNED, 0, CAP_HWCAP, KERNEL_HWCAP_FP),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_FP_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_FPHP),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_ASIMD_SHIFT, FTR_SIGNED, 0, CAP_HWCAP, KERNEL_HWCAP_ASIMD),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_ASIMD_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_ASIMDHP),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_DIT_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_DIT),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_DPB_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_DCPOP),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_DPB_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_DCPODP),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_JSCVT_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_JSCVT),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_FCMA_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_FCMA),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_LRCPC_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_LRCPC),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_LRCPC_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_ILRCPC),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_FRINTTS_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_FRINT),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_SB_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SB),
+ 	HWCAP_CAP(SYS_ID_AA64MMFR2_EL1, ID_AA64MMFR2_AT_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_USCAT),
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG)
  #ifdef CONFIG_ARM64_SVE
 -	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_SVE_SHIFT, FTR_UNSIGNED, ID_AA64PFR0_SVE, CAP_HWCAP, KERNEL_HWCAP_SVE),
 -	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_SVEVER_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_SVEVER_SVE2, CAP_HWCAP, KERNEL_HWCAP_SVE2),
 -	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_AES_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_AES, CAP_HWCAP, KERNEL_HWCAP_SVEAES),
 -	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_AES_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_AES_PMULL, CAP_HWCAP, KERNEL_HWCAP_SVEPMULL),
 -	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_BITPERM_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_BITPERM, CAP_HWCAP, KERNEL_HWCAP_SVEBITPERM),
 -	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_SHA3_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_SHA3, CAP_HWCAP, KERNEL_HWCAP_SVESHA3),
 -	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_SM4_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_SM4, CAP_HWCAP, KERNEL_HWCAP_SVESM4),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_SVE_SHIFT, FTR_UNSIGNED, ID_AA64PFR0_SVE, CAP_HWCAP, HWCAP_SVE),
  #endif
 -	HWCAP_CAP(SYS_ID_AA64PFR1_EL1, ID_AA64PFR1_SSBS_SHIFT, FTR_UNSIGNED, ID_AA64PFR1_SSBS_PSTATE_INSNS, CAP_HWCAP, KERNEL_HWCAP_SSBS),
 +	HWCAP_CAP(SYS_ID_AA64PFR1_EL1, ID_AA64PFR1_SSBS_SHIFT, FTR_UNSIGNED, ID_AA64PFR1_SSBS_PSTATE_INSNS, CAP_HWCAP, HWCAP_SSBS),
  #ifdef CONFIG_ARM64_PTR_AUTH
 -	HWCAP_MULTI_CAP(ptr_auth_hwcap_addr_matches, CAP_HWCAP, KERNEL_HWCAP_PACA),
 -	HWCAP_MULTI_CAP(ptr_auth_hwcap_gen_matches, CAP_HWCAP, KERNEL_HWCAP_PACG),
 +	HWCAP_MULTI_CAP(ptr_auth_hwcap_addr_matches, CAP_HWCAP, HWCAP_PACA),
 +	HWCAP_MULTI_CAP(ptr_auth_hwcap_gen_matches, CAP_HWCAP, HWCAP_PACG),
  #endif
  	{},
  };
diff --cc arch/arm64/kernel/cpuinfo.c
index 8d646abd3fbe,3000dd27816f..000000000000
--- a/arch/arm64/kernel/cpuinfo.c
+++ b/arch/arm64/kernel/cpuinfo.c
@@@ -85,6 -75,16 +85,19 @@@ static const char *const hwcap_str[] = 
  	"sb",
  	"paca",
  	"pacg",
++<<<<<<< HEAD
++=======
+ 	"dcpodp",
+ 	"sve2",
+ 	"sveaes",
+ 	"svepmull",
+ 	"svebitperm",
+ 	"svesha3",
+ 	"svesm4",
+ 	"flagm2",
+ 	"frint",
+ 	"rng",
++>>>>>>> 1a50ec0b3b2e (arm64: Implement archrandom.h for ARMv8.5-RNG)
  	NULL
  };
  
* Unmerged path Documentation/arm64/cpu-feature-registers.txt
* Unmerged path Documentation/arm64/elf_hwcaps.txt
diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig
index 8ef565a5b888..de42bb59a686 100644
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@ -1415,6 +1415,18 @@ config ARM64_TLB_RANGE
 
 endmenu
 
+menu "ARMv8.5 architectural features"
+
+config ARCH_RANDOM
+	bool "Enable support for random number generation"
+	default y
+	help
+	  Random number generation (part of the ARMv8.5 Extensions)
+	  provides a high bandwidth, cryptographically secure
+	  hardware random number generator.
+
+endmenu
+
 config ARM64_SVE
 	bool "ARM Scalable Vector Extension support"
 	default y
diff --git a/arch/arm64/include/asm/archrandom.h b/arch/arm64/include/asm/archrandom.h
new file mode 100644
index 000000000000..5ea5a1ce5a5f
--- /dev/null
+++ b/arch/arm64/include/asm/archrandom.h
@@ -0,0 +1,67 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _ASM_ARCHRANDOM_H
+#define _ASM_ARCHRANDOM_H
+
+#ifdef CONFIG_ARCH_RANDOM
+
+#include <linux/random.h>
+#include <asm/cpufeature.h>
+
+static inline bool __arm64_rndr(unsigned long *v)
+{
+	bool ok;
+
+	/*
+	 * Reads of RNDR set PSTATE.NZCV to 0b0000 on success,
+	 * and set PSTATE.NZCV to 0b0100 otherwise.
+	 */
+	asm volatile(
+		__mrs_s("%0", SYS_RNDR_EL0) "\n"
+	"	cset %w1, ne\n"
+	: "=r" (*v), "=r" (ok)
+	:
+	: "cc");
+
+	return ok;
+}
+
+static inline bool __must_check arch_get_random_long(unsigned long *v)
+{
+	return false;
+}
+
+static inline bool __must_check arch_get_random_int(unsigned int *v)
+{
+	return false;
+}
+
+static inline bool __must_check arch_get_random_seed_long(unsigned long *v)
+{
+	/*
+	 * Only support the generic interface after we have detected
+	 * the system wide capability, avoiding complexity with the
+	 * cpufeature code and with potential scheduling between CPUs
+	 * with and without the feature.
+	 */
+	if (!cpus_have_const_cap(ARM64_HAS_RNG))
+		return false;
+
+	return __arm64_rndr(v);
+}
+
+
+static inline bool __must_check arch_get_random_seed_int(unsigned int *v)
+{
+	unsigned long val;
+	bool ok = arch_get_random_seed_long(&val);
+
+	*v = val;
+	return ok;
+}
+
+#else
+
+static inline bool __arm64_rndr(unsigned long *v) { return false; }
+
+#endif /* CONFIG_ARCH_RANDOM */
+#endif /* _ASM_ARCHRANDOM_H */
* Unmerged path arch/arm64/include/asm/cpucaps.h
* Unmerged path arch/arm64/include/asm/hwcap.h
* Unmerged path arch/arm64/include/asm/sysreg.h
* Unmerged path arch/arm64/include/uapi/asm/hwcap.h
* Unmerged path arch/arm64/kernel/cpufeature.c
* Unmerged path arch/arm64/kernel/cpuinfo.c
