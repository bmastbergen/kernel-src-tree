arm64: cpufeature: Export matrix and other features to userspace

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-348.el8
commit-author Steven Price <steven.price@arm.com>
commit d4209d8b717311d114b5d47ba7f8249fd44e97c2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-348.el8/d4209d8b.failed

Export the features introduced as part of ARMv8.6 exposed in the
ID_AA64ISAR1_EL1 and ID_AA64ZFR0_EL1 registers. This introduces the
Matrix features (ARMv8.2-I8MM, ARMv8.2-F64MM and ARMv8.2-F32MM) along
with BFloat16 (Armv8.2-BF16), speculation invalidation (SPECRES) and
Data Gathering Hint (ARMv8.0-DGH).

	Signed-off-by: Julien Grall <julien.grall@arm.com>
[Added other features in those registers]
	Signed-off-by: Steven Price <steven.price@arm.com>
[will: Don't advertise SPECRES to userspace]
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit d4209d8b717311d114b5d47ba7f8249fd44e97c2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/arm64/cpu-feature-registers.txt
#	Documentation/arm64/elf_hwcaps.txt
#	arch/arm64/include/asm/hwcap.h
#	arch/arm64/include/asm/sysreg.h
#	arch/arm64/include/uapi/asm/hwcap.h
#	arch/arm64/kernel/cpufeature.c
#	arch/arm64/kernel/cpuinfo.c
diff --cc Documentation/arm64/cpu-feature-registers.txt
index d4b4dd1fe786,27877d25dd9b..000000000000
--- a/Documentation/arm64/cpu-feature-registers.txt
+++ b/Documentation/arm64/cpu-feature-registers.txt
@@@ -179,69 -195,105 +179,111 @@@ infrastructure
     as available on the CPU where it is fetched and is not a system
     wide safe value.
  
 -  5) ID_AA64ISAR1_EL1 - Instruction set attribute register 1
 +  4) ID_AA64ISAR1_EL1 - Instruction set attribute register 1
  
 -     +------------------------------+---------+---------+
 +     x--------------------------------------------------x
       | Name                         |  bits   | visible |
-      |--------------------------------------------------|
++<<<<<<< HEAD:Documentation/arm64/cpu-feature-registers.txt
++     |--------------------------------------------------|
++=======
+      +------------------------------+---------+---------+
+      | I8MM                         | [55-52] |    y    |
+      +------------------------------+---------+---------+
+      | DGH                          | [51-48] |    y    |
+      +------------------------------+---------+---------+
+      | BF16                         | [47-44] |    y    |
+      +------------------------------+---------+---------+
+      | SB                           | [39-36] |    y    |
+      +------------------------------+---------+---------+
+      | FRINTTS                      | [35-32] |    y    |
+      +------------------------------+---------+---------+
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace):Documentation/arm64/cpu-feature-registers.rst
       | GPI                          | [31-28] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | GPA                          | [27-24] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | LRCPC                        | [23-20] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | FCMA                         | [19-16] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | JSCVT                        | [15-12] |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | API                          | [11-8]  |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | APA                          | [7-4]   |    y    |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | DPB                          | [3-0]   |    y    |
 -     +------------------------------+---------+---------+
 +     x--------------------------------------------------x
  
 -  6) ID_AA64MMFR2_EL1 - Memory model feature register 2
 +  5) ID_AA64MMFR2_EL1 - Memory model feature register 2
  
 -     +------------------------------+---------+---------+
 +     x--------------------------------------------------x
       | Name                         |  bits   | visible |
 -     +------------------------------+---------+---------+
 +     |--------------------------------------------------|
       | AT                           | [35-32] |    y    |
++<<<<<<< HEAD:Documentation/arm64/cpu-feature-registers.txt
 +     x--------------------------------------------------x
++=======
+      +------------------------------+---------+---------+
+ 
+   7) ID_AA64ZFR0_EL1 - SVE feature ID register 0
+ 
+      +------------------------------+---------+---------+
+      | Name                         |  bits   | visible |
+      +------------------------------+---------+---------+
+      | F64MM                        | [59-56] |    y    |
+      +------------------------------+---------+---------+
+      | F32MM                        | [55-52] |    y    |
+      +------------------------------+---------+---------+
+      | I8MM                         | [47-44] |    y    |
+      +------------------------------+---------+---------+
+      | SM4                          | [43-40] |    y    |
+      +------------------------------+---------+---------+
+      | SHA3                         | [35-32] |    y    |
+      +------------------------------+---------+---------+
+      | BF16                         | [23-20] |    y    |
+      +------------------------------+---------+---------+
+      | BitPerm                      | [19-16] |    y    |
+      +------------------------------+---------+---------+
+      | AES                          | [7-4]   |    y    |
+      +------------------------------+---------+---------+
+      | SVEVer                       | [3-0]   |    y    |
+      +------------------------------+---------+---------+
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace):Documentation/arm64/cpu-feature-registers.rst
  
  Appendix I: Example
 --------------------
 -
 -::
 -
 -  /*
 -   * Sample program to demonstrate the MRS emulation ABI.
 -   *
 -   * Copyright (C) 2015-2016, ARM Ltd
 -   *
 -   * Author: Suzuki K Poulose <suzuki.poulose@arm.com>
 -   *
 -   * This program is free software; you can redistribute it and/or modify
 -   * it under the terms of the GNU General Public License version 2 as
 -   * published by the Free Software Foundation.
 -   *
 -   * This program is distributed in the hope that it will be useful,
 -   * but WITHOUT ANY WARRANTY; without even the implied warranty of
 -   * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 -   * GNU General Public License for more details.
 -   * This program is free software; you can redistribute it and/or modify
 -   * it under the terms of the GNU General Public License version 2 as
 -   * published by the Free Software Foundation.
 -   *
 -   * This program is distributed in the hope that it will be useful,
 -   * but WITHOUT ANY WARRANTY; without even the implied warranty of
 -   * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 -   * GNU General Public License for more details.
 -   */
 -
 -  #include <asm/hwcap.h>
 -  #include <stdio.h>
 -  #include <sys/auxv.h>
 -
 -  #define get_cpu_ftr(id) ({					\
 +---------------------------
 +
 +/*
 + * Sample program to demonstrate the MRS emulation ABI.
 + *
 + * Copyright (C) 2015-2016, ARM Ltd
 + *
 + * Author: Suzuki K Poulose <suzuki.poulose@arm.com>
 + *
 + * This program is free software; you can redistribute it and/or modify
 + * it under the terms of the GNU General Public License version 2 as
 + * published by the Free Software Foundation.
 + *
 + * This program is distributed in the hope that it will be useful,
 + * but WITHOUT ANY WARRANTY; without even the implied warranty of
 + * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 + * GNU General Public License for more details.
 + * This program is free software; you can redistribute it and/or modify
 + * it under the terms of the GNU General Public License version 2 as
 + * published by the Free Software Foundation.
 + *
 + * This program is distributed in the hope that it will be useful,
 + * but WITHOUT ANY WARRANTY; without even the implied warranty of
 + * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 + * GNU General Public License for more details.
 + */
 +
 +#include <asm/hwcap.h>
 +#include <stdio.h>
 +#include <sys/auxv.h>
 +
 +#define get_cpu_ftr(id) ({					\
  		unsigned long __val;				\
  		asm("mrs %0, "#id : "=r" (__val));		\
  		printf("%-20s: 0x%016lx\n", #id, __val);	\
diff --cc Documentation/arm64/elf_hwcaps.txt
index 16c8d3bd1bd3,4fafc57d8e73..000000000000
--- a/Documentation/arm64/elf_hwcaps.txt
+++ b/Documentation/arm64/elf_hwcaps.txt
@@@ -187,13 -159,81 +187,87 @@@ HWCAP_S
      Functionality implied by ID_AA64ISAR1_EL1.SB == 0b0001.
  
  HWCAP_PACA
 +
      Functionality implied by ID_AA64ISAR1_EL1.APA == 0b0001 or
      ID_AA64ISAR1_EL1.API == 0b0001, as described by
 -    Documentation/arm64/pointer-authentication.rst.
 +    Documentation/arm64/pointer-authentication.txt.
  
  HWCAP_PACG
 +
      Functionality implied by ID_AA64ISAR1_EL1.GPA == 0b0001 or
      ID_AA64ISAR1_EL1.GPI == 0b0001, as described by
++<<<<<<< HEAD:Documentation/arm64/elf_hwcaps.txt
 +    Documentation/arm64/pointer-authentication.txt.
++=======
+     Documentation/arm64/pointer-authentication.rst.
+ 
+ HWCAP2_DCPODP
+ 
+     Functionality implied by ID_AA64ISAR1_EL1.DPB == 0b0010.
+ 
+ HWCAP2_SVE2
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.SVEVer == 0b0001.
+ 
+ HWCAP2_SVEAES
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.AES == 0b0001.
+ 
+ HWCAP2_SVEPMULL
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.AES == 0b0010.
+ 
+ HWCAP2_SVEBITPERM
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.BitPerm == 0b0001.
+ 
+ HWCAP2_SVESHA3
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.SHA3 == 0b0001.
+ 
+ HWCAP2_SVESM4
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.SM4 == 0b0001.
+ 
+ HWCAP2_FLAGM2
+ 
+     Functionality implied by ID_AA64ISAR0_EL1.TS == 0b0010.
+ 
+ HWCAP2_FRINT
+ 
+     Functionality implied by ID_AA64ISAR1_EL1.FRINTTS == 0b0001.
+ 
+ HWCAP2_SVEI8MM
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.I8MM == 0b0001.
+ 
+ HWCAP2_SVEF32MM
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.F32MM == 0b0001.
+ 
+ HWCAP2_SVEF64MM
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.F64MM == 0b0001.
+ 
+ HWCAP2_SVEBF16
+ 
+     Functionality implied by ID_AA64ZFR0_EL1.BF16 == 0b0001.
+ 
+ HWCAP2_I8MM
+ 
+     Functionality implied by ID_AA64ISAR1_EL1.I8MM == 0b0001.
+ 
+ HWCAP2_BF16
+ 
+     Functionality implied by ID_AA64ISAR1_EL1.BF16 == 0b0001.
+ 
+ HWCAP2_DGH
+ 
+     Functionality implied by ID_AA64ISAR1_EL1.DGH == 0b0001.
+ 
+ 4. Unused AT_HWCAP bits
+ -----------------------
+ 
+ For interoperation with userspace, the kernel guarantees that bits 62
+ and 63 of AT_HWCAP will always be returned as 0.
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace):Documentation/arm64/elf_hwcaps.rst
diff --cc arch/arm64/include/asm/hwcap.h
index 400b80b49595,fcb390ea29ea..000000000000
--- a/arch/arm64/include/asm/hwcap.h
+++ b/arch/arm64/include/asm/hwcap.h
@@@ -40,6 -30,70 +40,73 @@@
  #define COMPAT_HWCAP2_CRC32	(1 << 4)
  
  #ifndef __ASSEMBLY__
++<<<<<<< HEAD
++=======
+ #include <linux/log2.h>
+ 
+ /*
+  * For userspace we represent hwcaps as a collection of HWCAP{,2}_x bitfields
+  * as described in uapi/asm/hwcap.h. For the kernel we represent hwcaps as
+  * natural numbers (in a single range of size MAX_CPU_FEATURES) defined here
+  * with prefix KERNEL_HWCAP_ mapped to their HWCAP{,2}_x counterpart.
+  *
+  * Hwcaps should be set and tested within the kernel via the
+  * cpu_{set,have}_named_feature(feature) where feature is the unique suffix
+  * of KERNEL_HWCAP_{feature}.
+  */
+ #define __khwcap_feature(x)		const_ilog2(HWCAP_ ## x)
+ #define KERNEL_HWCAP_FP			__khwcap_feature(FP)
+ #define KERNEL_HWCAP_ASIMD		__khwcap_feature(ASIMD)
+ #define KERNEL_HWCAP_EVTSTRM		__khwcap_feature(EVTSTRM)
+ #define KERNEL_HWCAP_AES		__khwcap_feature(AES)
+ #define KERNEL_HWCAP_PMULL		__khwcap_feature(PMULL)
+ #define KERNEL_HWCAP_SHA1		__khwcap_feature(SHA1)
+ #define KERNEL_HWCAP_SHA2		__khwcap_feature(SHA2)
+ #define KERNEL_HWCAP_CRC32		__khwcap_feature(CRC32)
+ #define KERNEL_HWCAP_ATOMICS		__khwcap_feature(ATOMICS)
+ #define KERNEL_HWCAP_FPHP		__khwcap_feature(FPHP)
+ #define KERNEL_HWCAP_ASIMDHP		__khwcap_feature(ASIMDHP)
+ #define KERNEL_HWCAP_CPUID		__khwcap_feature(CPUID)
+ #define KERNEL_HWCAP_ASIMDRDM		__khwcap_feature(ASIMDRDM)
+ #define KERNEL_HWCAP_JSCVT		__khwcap_feature(JSCVT)
+ #define KERNEL_HWCAP_FCMA		__khwcap_feature(FCMA)
+ #define KERNEL_HWCAP_LRCPC		__khwcap_feature(LRCPC)
+ #define KERNEL_HWCAP_DCPOP		__khwcap_feature(DCPOP)
+ #define KERNEL_HWCAP_SHA3		__khwcap_feature(SHA3)
+ #define KERNEL_HWCAP_SM3		__khwcap_feature(SM3)
+ #define KERNEL_HWCAP_SM4		__khwcap_feature(SM4)
+ #define KERNEL_HWCAP_ASIMDDP		__khwcap_feature(ASIMDDP)
+ #define KERNEL_HWCAP_SHA512		__khwcap_feature(SHA512)
+ #define KERNEL_HWCAP_SVE		__khwcap_feature(SVE)
+ #define KERNEL_HWCAP_ASIMDFHM		__khwcap_feature(ASIMDFHM)
+ #define KERNEL_HWCAP_DIT		__khwcap_feature(DIT)
+ #define KERNEL_HWCAP_USCAT		__khwcap_feature(USCAT)
+ #define KERNEL_HWCAP_ILRCPC		__khwcap_feature(ILRCPC)
+ #define KERNEL_HWCAP_FLAGM		__khwcap_feature(FLAGM)
+ #define KERNEL_HWCAP_SSBS		__khwcap_feature(SSBS)
+ #define KERNEL_HWCAP_SB			__khwcap_feature(SB)
+ #define KERNEL_HWCAP_PACA		__khwcap_feature(PACA)
+ #define KERNEL_HWCAP_PACG		__khwcap_feature(PACG)
+ 
+ #define __khwcap2_feature(x)		(const_ilog2(HWCAP2_ ## x) + 32)
+ #define KERNEL_HWCAP_DCPODP		__khwcap2_feature(DCPODP)
+ #define KERNEL_HWCAP_SVE2		__khwcap2_feature(SVE2)
+ #define KERNEL_HWCAP_SVEAES		__khwcap2_feature(SVEAES)
+ #define KERNEL_HWCAP_SVEPMULL		__khwcap2_feature(SVEPMULL)
+ #define KERNEL_HWCAP_SVEBITPERM		__khwcap2_feature(SVEBITPERM)
+ #define KERNEL_HWCAP_SVESHA3		__khwcap2_feature(SVESHA3)
+ #define KERNEL_HWCAP_SVESM4		__khwcap2_feature(SVESM4)
+ #define KERNEL_HWCAP_FLAGM2		__khwcap2_feature(FLAGM2)
+ #define KERNEL_HWCAP_FRINT		__khwcap2_feature(FRINT)
+ #define KERNEL_HWCAP_SVEI8MM		__khwcap2_feature(SVEI8MM)
+ #define KERNEL_HWCAP_SVEF32MM		__khwcap2_feature(SVEF32MM)
+ #define KERNEL_HWCAP_SVEF64MM		__khwcap2_feature(SVEF64MM)
+ #define KERNEL_HWCAP_SVEBF16		__khwcap2_feature(SVEBF16)
+ #define KERNEL_HWCAP_I8MM		__khwcap2_feature(I8MM)
+ #define KERNEL_HWCAP_DGH		__khwcap2_feature(DGH)
+ #define KERNEL_HWCAP_BF16		__khwcap2_feature(BF16)
+ 
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace)
  /*
   * This yields a mask that user programs can use to figure out what
   * instruction set this cpu supports.
diff --cc arch/arm64/include/asm/sysreg.h
index cca1edca6ca9,f56c4a02a127..000000000000
--- a/arch/arm64/include/asm/sysreg.h
+++ b/arch/arm64/include/asm/sysreg.h
@@@ -624,11 -552,13 +624,15 @@@
  #define ID_AA64ISAR0_SHA1_SHIFT		8
  #define ID_AA64ISAR0_AES_SHIFT		4
  
 +#define ID_AA64ISAR0_TLB_RANGE_NI	0x0
 +#define ID_AA64ISAR0_TLB_RANGE		0x2
 +
  /* id_aa64isar1 */
+ #define ID_AA64ISAR1_I8MM_SHIFT		52
+ #define ID_AA64ISAR1_DGH_SHIFT		48
+ #define ID_AA64ISAR1_BF16_SHIFT		44
+ #define ID_AA64ISAR1_SPECRES_SHIFT	40
  #define ID_AA64ISAR1_SB_SHIFT		36
 -#define ID_AA64ISAR1_FRINTTS_SHIFT	32
  #define ID_AA64ISAR1_GPI_SHIFT		28
  #define ID_AA64ISAR1_GPA_SHIFT		24
  #define ID_AA64ISAR1_LRCPC_SHIFT	20
@@@ -680,10 -608,29 +684,35 @@@
  #define ID_AA64PFR1_SSBS_PSTATE_ONLY	1
  #define ID_AA64PFR1_SSBS_PSTATE_INSNS	2
  
++<<<<<<< HEAD
++=======
+ /* id_aa64zfr0 */
+ #define ID_AA64ZFR0_F64MM_SHIFT		56
+ #define ID_AA64ZFR0_F32MM_SHIFT		52
+ #define ID_AA64ZFR0_I8MM_SHIFT		44
+ #define ID_AA64ZFR0_SM4_SHIFT		40
+ #define ID_AA64ZFR0_SHA3_SHIFT		32
+ #define ID_AA64ZFR0_BF16_SHIFT		20
+ #define ID_AA64ZFR0_BITPERM_SHIFT	16
+ #define ID_AA64ZFR0_AES_SHIFT		4
+ #define ID_AA64ZFR0_SVEVER_SHIFT	0
+ 
+ #define ID_AA64ZFR0_F64MM		0x1
+ #define ID_AA64ZFR0_F32MM		0x1
+ #define ID_AA64ZFR0_I8MM		0x1
+ #define ID_AA64ZFR0_BF16		0x1
+ #define ID_AA64ZFR0_SM4			0x1
+ #define ID_AA64ZFR0_SHA3		0x1
+ #define ID_AA64ZFR0_BITPERM		0x1
+ #define ID_AA64ZFR0_AES			0x1
+ #define ID_AA64ZFR0_AES_PMULL		0x2
+ #define ID_AA64ZFR0_SVEVER_SVE2		0x1
+ 
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace)
  /* id_aa64mmfr0 */
 +#define ID_AA64MMFR0_TGRAN4_2_SHIFT	40
 +#define ID_AA64MMFR0_TGRAN64_2_SHIFT	36
 +#define ID_AA64MMFR0_TGRAN16_2_SHIFT	32
  #define ID_AA64MMFR0_TGRAN4_SHIFT	28
  #define ID_AA64MMFR0_TGRAN64_SHIFT	24
  #define ID_AA64MMFR0_TGRAN16_SHIFT	20
diff --cc arch/arm64/include/uapi/asm/hwcap.h
index 5f0750c2199c,e6dad5924703..000000000000
--- a/arch/arm64/include/uapi/asm/hwcap.h
+++ b/arch/arm64/include/uapi/asm/hwcap.h
@@@ -53,4 -53,24 +53,27 @@@
  #define HWCAP_PACA		(1 << 30)
  #define HWCAP_PACG		(1UL << 31)
  
++<<<<<<< HEAD
++=======
+ /*
+  * HWCAP2 flags - for AT_HWCAP2
+  */
+ #define HWCAP2_DCPODP		(1 << 0)
+ #define HWCAP2_SVE2		(1 << 1)
+ #define HWCAP2_SVEAES		(1 << 2)
+ #define HWCAP2_SVEPMULL		(1 << 3)
+ #define HWCAP2_SVEBITPERM	(1 << 4)
+ #define HWCAP2_SVESHA3		(1 << 5)
+ #define HWCAP2_SVESM4		(1 << 6)
+ #define HWCAP2_FLAGM2		(1 << 7)
+ #define HWCAP2_FRINT		(1 << 8)
+ #define HWCAP2_SVEI8MM		(1 << 9)
+ #define HWCAP2_SVEF32MM		(1 << 10)
+ #define HWCAP2_SVEF64MM		(1 << 11)
+ #define HWCAP2_SVEBF16		(1 << 12)
+ #define HWCAP2_I8MM		(1 << 13)
+ #define HWCAP2_BF16		(1 << 14)
+ #define HWCAP2_DGH		(1 << 15)
+ 
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace)
  #endif /* _UAPI__ASM_HWCAP_H */
diff --cc arch/arm64/kernel/cpufeature.c
index 5c98a0b235b2,6e63cad1eda4..000000000000
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@@ -187,25 -179,29 +191,50 @@@ static const struct arm64_ftr_bits ftr_
  	ARM64_FTR_END,
  };
  
++<<<<<<< HEAD
++=======
+ static const struct arm64_ftr_bits ftr_id_aa64zfr0[] = {
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_F64MM_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_F32MM_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_I8MM_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_SM4_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_SHA3_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_BF16_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_BITPERM_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_AES_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_SVE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64ZFR0_SVEVER_SHIFT, 4, 0),
+ 	ARM64_FTR_END,
+ };
+ 
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace)
  static const struct arm64_ftr_bits ftr_id_aa64mmfr0[] = {
 +	/*
 +	 * Page size not being supported at Stage-2 is not fatal. You
 +	 * just give up KVM if PAGE_SIZE isn't supported there. Go fix
 +	 * your favourite nesting hypervisor.
 +	 *
 +	 * There is a small corner case where the hypervisor explicitly
 +	 * advertises a given granule size at Stage-2 (value 2) on some
 +	 * vCPUs, and uses the fallback to Stage-1 (value 0) for other
 +	 * vCPUs. Although this is not forbidden by the architecture, it
 +	 * indicates that the hypervisor is being silly (or buggy).
 +	 *
 +	 * We make no effort to cope with this and pretend that if these
 +	 * fields are inconsistent across vCPUs, then it isn't worth
 +	 * trying to bring KVM up.
 +	 */
 +	ARM64_FTR_BITS(FTR_HIDDEN, FTR_NONSTRICT, FTR_EXACT, ID_AA64MMFR0_TGRAN4_2_SHIFT, 4, 1),
 +	ARM64_FTR_BITS(FTR_HIDDEN, FTR_NONSTRICT, FTR_EXACT, ID_AA64MMFR0_TGRAN64_2_SHIFT, 4, 1),
 +	ARM64_FTR_BITS(FTR_HIDDEN, FTR_NONSTRICT, FTR_EXACT, ID_AA64MMFR0_TGRAN16_2_SHIFT, 4, 1),
  	/*
  	 * We already refuse to boot CPUs that don't support our configured
  	 * page size, so we can only detect mismatches for a page size other
@@@ -1679,39 -1635,55 +1708,86 @@@ static const struct arm64_cpu_capabilit
  #endif
  
  static const struct arm64_cpu_capabilities arm64_elf_hwcaps[] = {
++<<<<<<< HEAD
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_AES_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, HWCAP_PMULL),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_AES_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_AES),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA1_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SHA1),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA2_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SHA2),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA2_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, HWCAP_SHA512),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_CRC32_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_CRC32),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_ATOMICS_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, HWCAP_ATOMICS),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_RDM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_ASIMDRDM),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA3_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SHA3),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SM3_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SM3),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SM4_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SM4),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_DP_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_ASIMDDP),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_FHM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_ASIMDFHM),
 +	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_TS_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_FLAGM),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_FP_SHIFT, FTR_SIGNED, 0, CAP_HWCAP, HWCAP_FP),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_FP_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, HWCAP_FPHP),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_ASIMD_SHIFT, FTR_SIGNED, 0, CAP_HWCAP, HWCAP_ASIMD),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_ASIMD_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, HWCAP_ASIMDHP),
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_DIT_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, HWCAP_DIT),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_DPB_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_DCPOP),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_JSCVT_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_JSCVT),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_FCMA_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_FCMA),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_LRCPC_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_LRCPC),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_LRCPC_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, HWCAP_ILRCPC),
 +	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_SB_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_SB),
 +	HWCAP_CAP(SYS_ID_AA64MMFR2_EL1, ID_AA64MMFR2_AT_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, HWCAP_USCAT),
 +#ifdef CONFIG_ARM64_SVE
 +	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_SVE_SHIFT, FTR_UNSIGNED, ID_AA64PFR0_SVE, CAP_HWCAP, HWCAP_SVE),
++=======
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_AES_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_PMULL),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_AES_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_AES),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA1_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SHA1),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA2_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SHA2),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA2_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_SHA512),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_CRC32_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_CRC32),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_ATOMICS_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_ATOMICS),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_RDM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_ASIMDRDM),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SHA3_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SHA3),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SM3_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SM3),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_SM4_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SM4),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_DP_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_ASIMDDP),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_FHM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_ASIMDFHM),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_TS_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_FLAGM),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR0_EL1, ID_AA64ISAR0_TS_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_FLAGM2),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_FP_SHIFT, FTR_SIGNED, 0, CAP_HWCAP, KERNEL_HWCAP_FP),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_FP_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_FPHP),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_ASIMD_SHIFT, FTR_SIGNED, 0, CAP_HWCAP, KERNEL_HWCAP_ASIMD),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_ASIMD_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_ASIMDHP),
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_DIT_SHIFT, FTR_SIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_DIT),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_DPB_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_DCPOP),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_DPB_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_DCPODP),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_JSCVT_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_JSCVT),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_FCMA_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_FCMA),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_LRCPC_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_LRCPC),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_LRCPC_SHIFT, FTR_UNSIGNED, 2, CAP_HWCAP, KERNEL_HWCAP_ILRCPC),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_FRINTTS_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_FRINT),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_SB_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_SB),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_BF16_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_BF16),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_DGH_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_DGH),
+ 	HWCAP_CAP(SYS_ID_AA64ISAR1_EL1, ID_AA64ISAR1_I8MM_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_I8MM),
+ 	HWCAP_CAP(SYS_ID_AA64MMFR2_EL1, ID_AA64MMFR2_AT_SHIFT, FTR_UNSIGNED, 1, CAP_HWCAP, KERNEL_HWCAP_USCAT),
+ #ifdef CONFIG_ARM64_SVE
+ 	HWCAP_CAP(SYS_ID_AA64PFR0_EL1, ID_AA64PFR0_SVE_SHIFT, FTR_UNSIGNED, ID_AA64PFR0_SVE, CAP_HWCAP, KERNEL_HWCAP_SVE),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_SVEVER_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_SVEVER_SVE2, CAP_HWCAP, KERNEL_HWCAP_SVE2),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_AES_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_AES, CAP_HWCAP, KERNEL_HWCAP_SVEAES),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_AES_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_AES_PMULL, CAP_HWCAP, KERNEL_HWCAP_SVEPMULL),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_BITPERM_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_BITPERM, CAP_HWCAP, KERNEL_HWCAP_SVEBITPERM),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_BF16_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_BF16, CAP_HWCAP, KERNEL_HWCAP_SVEBF16),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_SHA3_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_SHA3, CAP_HWCAP, KERNEL_HWCAP_SVESHA3),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_SM4_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_SM4, CAP_HWCAP, KERNEL_HWCAP_SVESM4),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_I8MM_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_I8MM, CAP_HWCAP, KERNEL_HWCAP_SVEI8MM),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_F32MM_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_F32MM, CAP_HWCAP, KERNEL_HWCAP_SVEF32MM),
+ 	HWCAP_CAP(SYS_ID_AA64ZFR0_EL1, ID_AA64ZFR0_F64MM_SHIFT, FTR_UNSIGNED, ID_AA64ZFR0_F64MM, CAP_HWCAP, KERNEL_HWCAP_SVEF64MM),
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace)
  #endif
 -	HWCAP_CAP(SYS_ID_AA64PFR1_EL1, ID_AA64PFR1_SSBS_SHIFT, FTR_UNSIGNED, ID_AA64PFR1_SSBS_PSTATE_INSNS, CAP_HWCAP, KERNEL_HWCAP_SSBS),
 +	HWCAP_CAP(SYS_ID_AA64PFR1_EL1, ID_AA64PFR1_SSBS_SHIFT, FTR_UNSIGNED, ID_AA64PFR1_SSBS_PSTATE_INSNS, CAP_HWCAP, HWCAP_SSBS),
  #ifdef CONFIG_ARM64_PTR_AUTH
 -	HWCAP_MULTI_CAP(ptr_auth_hwcap_addr_matches, CAP_HWCAP, KERNEL_HWCAP_PACA),
 -	HWCAP_MULTI_CAP(ptr_auth_hwcap_gen_matches, CAP_HWCAP, KERNEL_HWCAP_PACG),
 +	HWCAP_MULTI_CAP(ptr_auth_hwcap_addr_matches, CAP_HWCAP, HWCAP_PACA),
 +	HWCAP_MULTI_CAP(ptr_auth_hwcap_gen_matches, CAP_HWCAP, HWCAP_PACG),
  #endif
  	{},
  };
diff --cc arch/arm64/kernel/cpuinfo.c
index 8d646abd3fbe,63f5dec1c730..000000000000
--- a/arch/arm64/kernel/cpuinfo.c
+++ b/arch/arm64/kernel/cpuinfo.c
@@@ -85,6 -75,22 +85,25 @@@ static const char *const hwcap_str[] = 
  	"sb",
  	"paca",
  	"pacg",
++<<<<<<< HEAD
++=======
+ 	"dcpodp",
+ 	"sve2",
+ 	"sveaes",
+ 	"svepmull",
+ 	"svebitperm",
+ 	"svesha3",
+ 	"svesm4",
+ 	"flagm2",
+ 	"frint",
+ 	"svei8mm",
+ 	"svef32mm",
+ 	"svef64mm",
+ 	"svebf16",
+ 	"i8mm",
+ 	"bf16",
+ 	"dgh",
++>>>>>>> d4209d8b7173 (arm64: cpufeature: Export matrix and other features to userspace)
  	NULL
  };
  
* Unmerged path Documentation/arm64/cpu-feature-registers.txt
* Unmerged path Documentation/arm64/elf_hwcaps.txt
* Unmerged path arch/arm64/include/asm/hwcap.h
* Unmerged path arch/arm64/include/asm/sysreg.h
* Unmerged path arch/arm64/include/uapi/asm/hwcap.h
* Unmerged path arch/arm64/kernel/cpufeature.c
* Unmerged path arch/arm64/kernel/cpuinfo.c
