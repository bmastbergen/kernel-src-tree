arm64: HWCAP: encapsulate elf_hwcap

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-348.el8
commit-author Andrew Murray <andrew.murray@arm.com>
commit aec0bff757c937489d003ab7b36c52e77e4b096a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-348.el8/aec0bff7.failed

The introduction of AT_HWCAP2 introduced accessors which ensure that
hwcap features are set and tested appropriately.

Let's now mandate access to elf_hwcap via these accessors by making
elf_hwcap static within cpufeature.c.

	Signed-off-by: Andrew Murray <andrew.murray@arm.com>
	Reviewed-by: Dave Martin <Dave.Martin@arm.com>
	Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
	Signed-off-by: Will Deacon <will.deacon@arm.com>
(cherry picked from commit aec0bff757c937489d003ab7b36c52e77e4b096a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/cpufeature.h
#	arch/arm64/include/asm/hwcap.h
diff --cc arch/arm64/include/asm/cpufeature.h
index 7dd74bdb252c,a3f028f82def..000000000000
--- a/arch/arm64/include/asm/cpufeature.h
+++ b/arch/arm64/include/asm/cpufeature.h
@@@ -399,22 -392,22 +399,31 @@@ extern DECLARE_BITMAP(boot_capabilities
  	for_each_set_bit(cap, cpu_hwcaps, ARM64_NCAPS)
  
  bool this_cpu_has_cap(unsigned int cap);
+ void cpu_set_feature(unsigned int num);
+ bool cpu_have_feature(unsigned int num);
+ unsigned long cpu_get_elf_hwcap(void);
+ unsigned long cpu_get_elf_hwcap2(void);
  
++<<<<<<< HEAD
 +static inline bool cpu_have_feature(unsigned int num)
 +{
 +	return elf_hwcap & (1UL << num);
 +}
++=======
+ #define cpu_set_named_feature(name) cpu_set_feature(cpu_feature(name))
+ #define cpu_have_named_feature(name) cpu_have_feature(cpu_feature(name))
++>>>>>>> aec0bff757c9 (arm64: HWCAP: encapsulate elf_hwcap)
  
 -/* System capability check for constant caps */
 -static inline bool __cpus_have_const_cap(int num)
 +static __always_inline bool system_capabilities_finalized(void)
  {
 -	if (num >= ARM64_NCAPS)
 -		return false;
 -	return static_branch_unlikely(&cpu_hwcap_keys[num]);
 +	return static_branch_likely(&arm64_const_caps_ready);
  }
  
 +/*
 + * Test for a capability with a runtime check.
 + *
 + * Before the capability is detected, this returns false.
 + */
  static inline bool cpus_have_cap(unsigned int num)
  {
  	if (num >= ARM64_NCAPS)
diff --cc arch/arm64/include/asm/hwcap.h
index 400b80b49595,a843b6efce5b..000000000000
--- a/arch/arm64/include/asm/hwcap.h
+++ b/arch/arm64/include/asm/hwcap.h
@@@ -40,11 -41,60 +41,67 @@@
  #define COMPAT_HWCAP2_CRC32	(1 << 4)
  
  #ifndef __ASSEMBLY__
++<<<<<<< HEAD
++=======
+ #include <linux/log2.h>
+ 
+ /*
+  * For userspace we represent hwcaps as a collection of HWCAP{,2}_x bitfields
+  * as described in uapi/asm/hwcap.h. For the kernel we represent hwcaps as
+  * natural numbers (in a single range of size MAX_CPU_FEATURES) defined here
+  * with prefix KERNEL_HWCAP_ mapped to their HWCAP{,2}_x counterpart.
+  *
+  * Hwcaps should be set and tested within the kernel via the
+  * cpu_{set,have}_named_feature(feature) where feature is the unique suffix
+  * of KERNEL_HWCAP_{feature}.
+  */
+ #define __khwcap_feature(x)		const_ilog2(HWCAP_ ## x)
+ #define KERNEL_HWCAP_FP			__khwcap_feature(FP)
+ #define KERNEL_HWCAP_ASIMD		__khwcap_feature(ASIMD)
+ #define KERNEL_HWCAP_EVTSTRM		__khwcap_feature(EVTSTRM)
+ #define KERNEL_HWCAP_AES		__khwcap_feature(AES)
+ #define KERNEL_HWCAP_PMULL		__khwcap_feature(PMULL)
+ #define KERNEL_HWCAP_SHA1		__khwcap_feature(SHA1)
+ #define KERNEL_HWCAP_SHA2		__khwcap_feature(SHA2)
+ #define KERNEL_HWCAP_CRC32		__khwcap_feature(CRC32)
+ #define KERNEL_HWCAP_ATOMICS		__khwcap_feature(ATOMICS)
+ #define KERNEL_HWCAP_FPHP		__khwcap_feature(FPHP)
+ #define KERNEL_HWCAP_ASIMDHP		__khwcap_feature(ASIMDHP)
+ #define KERNEL_HWCAP_CPUID		__khwcap_feature(CPUID)
+ #define KERNEL_HWCAP_ASIMDRDM		__khwcap_feature(ASIMDRDM)
+ #define KERNEL_HWCAP_JSCVT		__khwcap_feature(JSCVT)
+ #define KERNEL_HWCAP_FCMA		__khwcap_feature(FCMA)
+ #define KERNEL_HWCAP_LRCPC		__khwcap_feature(LRCPC)
+ #define KERNEL_HWCAP_DCPOP		__khwcap_feature(DCPOP)
+ #define KERNEL_HWCAP_SHA3		__khwcap_feature(SHA3)
+ #define KERNEL_HWCAP_SM3		__khwcap_feature(SM3)
+ #define KERNEL_HWCAP_SM4		__khwcap_feature(SM4)
+ #define KERNEL_HWCAP_ASIMDDP		__khwcap_feature(ASIMDDP)
+ #define KERNEL_HWCAP_SHA512		__khwcap_feature(SHA512)
+ #define KERNEL_HWCAP_SVE		__khwcap_feature(SVE)
+ #define KERNEL_HWCAP_ASIMDFHM		__khwcap_feature(ASIMDFHM)
+ #define KERNEL_HWCAP_DIT		__khwcap_feature(DIT)
+ #define KERNEL_HWCAP_USCAT		__khwcap_feature(USCAT)
+ #define KERNEL_HWCAP_ILRCPC		__khwcap_feature(ILRCPC)
+ #define KERNEL_HWCAP_FLAGM		__khwcap_feature(FLAGM)
+ #define KERNEL_HWCAP_SSBS		__khwcap_feature(SSBS)
+ #define KERNEL_HWCAP_SB			__khwcap_feature(SB)
+ #define KERNEL_HWCAP_PACA		__khwcap_feature(PACA)
+ #define KERNEL_HWCAP_PACG		__khwcap_feature(PACG)
+ 
+ #define __khwcap2_feature(x)		(const_ilog2(HWCAP2_ ## x) + 32)
+ 
++>>>>>>> aec0bff757c9 (arm64: HWCAP: encapsulate elf_hwcap)
  /*
   * This yields a mask that user programs can use to figure out what
   * instruction set this cpu supports.
   */
++<<<<<<< HEAD
 +#define ELF_HWCAP		(elf_hwcap)
++=======
+ #define ELF_HWCAP		cpu_get_elf_hwcap()
+ #define ELF_HWCAP2		cpu_get_elf_hwcap2()
++>>>>>>> aec0bff757c9 (arm64: HWCAP: encapsulate elf_hwcap)
  
  #ifdef CONFIG_COMPAT
  #define COMPAT_ELF_HWCAP	(compat_elf_hwcap)
* Unmerged path arch/arm64/include/asm/cpufeature.h
* Unmerged path arch/arm64/include/asm/hwcap.h
diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c
index cce641fc4a8a..8c600f072002 100644
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@ -36,8 +36,8 @@
 #include <asm/traps.h>
 #include <asm/virt.h>
 
-unsigned long elf_hwcap __read_mostly;
-EXPORT_SYMBOL_GPL(elf_hwcap);
+/* Kernel representation of AT_HWCAP and AT_HWCAP2 */
+static unsigned long elf_hwcap __read_mostly;
 
 #ifdef CONFIG_COMPAT
 #define COMPAT_ELF_HWCAP_DEFAULT	\
@@ -2081,6 +2081,35 @@ bool this_cpu_has_cap(unsigned int n)
 	return false;
 }
 
+void cpu_set_feature(unsigned int num)
+{
+	WARN_ON(num >= MAX_CPU_FEATURES);
+	elf_hwcap |= BIT(num);
+}
+EXPORT_SYMBOL_GPL(cpu_set_feature);
+
+bool cpu_have_feature(unsigned int num)
+{
+	WARN_ON(num >= MAX_CPU_FEATURES);
+	return elf_hwcap & BIT(num);
+}
+EXPORT_SYMBOL_GPL(cpu_have_feature);
+
+unsigned long cpu_get_elf_hwcap(void)
+{
+	/*
+	 * We currently only populate the first 32 bits of AT_HWCAP. Please
+	 * note that for userspace compatibility we guarantee that bits 62
+	 * and 63 will always be returned as 0.
+	 */
+	return lower_32_bits(elf_hwcap);
+}
+
+unsigned long cpu_get_elf_hwcap2(void)
+{
+	return upper_32_bits(elf_hwcap);
+}
+
 static void __init setup_system_capabilities(void)
 {
 	/*
