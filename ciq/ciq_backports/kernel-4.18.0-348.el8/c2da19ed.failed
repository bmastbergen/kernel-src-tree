blk-mq: fix kernel panic during iterating over flush request

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-348.el8
commit-author Ming Lei <ming.lei@redhat.com>
commit c2da19ed50554ce52ecbad3655c98371fe58599f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-348.el8/c2da19ed.failed

For fixing use-after-free during iterating over requests, we grabbed
request's refcount before calling ->fn in commit 2e315dc07df0 ("blk-mq:
grab rq->refcount before calling ->fn in blk_mq_tagset_busy_iter").
Turns out this way may cause kernel panic when iterating over one flush
request:

1) old flush request's tag is just released, and this tag is reused by
one new request, but ->rqs[] isn't updated yet

2) the flush request can be re-used for submitting one new flush command,
so blk_rq_init() is called at the same time

3) meantime blk_mq_queue_tag_busy_iter() is called, and old flush request
is retrieved from ->rqs[tag]; when blk_mq_put_rq_ref() is called,
flush_rq->end_io may not be updated yet, so NULL pointer dereference
is triggered in blk_mq_put_rq_ref().

Fix the issue by calling refcount_set(&flush_rq->ref, 1) after
flush_rq->end_io is set. So far the only other caller of blk_rq_init() is
scsi_ioctl_reset() in which the request doesn't enter block IO stack and
the request reference count isn't used, so the change is safe.

Fixes: 2e315dc07df0 ("blk-mq: grab rq->refcount before calling ->fn in blk_mq_tagset_busy_iter")
	Reported-by: "Blank-Burian, Markus, Dr." <blankburian@uni-muenster.de>
	Tested-by: "Blank-Burian, Markus, Dr." <blankburian@uni-muenster.de>
	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: John Garry <john.garry@huawei.com>
Link: https://lore.kernel.org/r/20210811142624.618598-1-ming.lei@redhat.com
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit c2da19ed50554ce52ecbad3655c98371fe58599f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-core.c
diff --cc block/blk-core.c
index 864131b945b7,4f8449b29b21..000000000000
--- a/block/blk-core.c
+++ b/block/blk-core.c
@@@ -116,7 -122,7 +116,11 @@@ void blk_rq_init(struct request_queue *
  	rq->internal_tag = BLK_MQ_NO_TAG;
  	rq->start_time_ns = ktime_get_ns();
  	rq->part = NULL;
++<<<<<<< HEAD
 +	refcount_set(&rq->ref, 1);
++=======
+ 	blk_crypto_rq_set_defaults(rq);
++>>>>>>> c2da19ed5055 (blk-mq: fix kernel panic during iterating over flush request)
  }
  EXPORT_SYMBOL(blk_rq_init);
  
* Unmerged path block/blk-core.c
diff --git a/block/blk-flush.c b/block/blk-flush.c
index 6accc15d79b4..1bb1e823b380 100644
--- a/block/blk-flush.c
+++ b/block/blk-flush.c
@@ -318,6 +318,14 @@ static void blk_kick_flush(struct request_queue *q, struct blk_flush_queue *fq,
 	flush_rq->rq_flags |= RQF_FLUSH_SEQ;
 	flush_rq->rq_disk = first_rq->rq_disk;
 	flush_rq->end_io = flush_end_io;
+	/*
+	 * Order WRITE ->end_io and WRITE rq->ref, and its pair is the one
+	 * implied in refcount_inc_not_zero() called from
+	 * blk_mq_find_and_get_req(), which orders WRITE/READ flush_rq->ref
+	 * and READ flush_rq->end_io
+	 */
+	smp_wmb();
+	refcount_set(&flush_rq->ref, 1);
 
 	blk_flush_queue_rq(flush_rq, false);
 }
