arm64: Add initial support for E0PD

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-348.el8
commit-author Mark Brown <broonie@kernel.org>
commit 3e6c69a058deaa50d33c3dac36cde80b4ce590e8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-348.el8/3e6c69a0.failed

Kernel Page Table Isolation (KPTI) is used to mitigate some speculation
based security issues by ensuring that the kernel is not mapped when
userspace is running but this approach is expensive and is incompatible
with SPE.  E0PD, introduced in the ARMv8.5 extensions, provides an
alternative to this which ensures that accesses from userspace to the
kernel's half of the memory map to always fault with constant time,
preventing timing attacks without requiring constant unmapping and
remapping or preventing legitimate accesses.

Currently this feature will only be enabled if all CPUs in the system
support E0PD, if some CPUs do not support the feature at boot time then
the feature will not be enabled and in the unlikely event that a late
CPU is the first CPU to lack the feature then we will reject that CPU.

This initial patch does not yet integrate with KPTI, this will be dealt
with in followup patches.  Ideally we could ensure that by default we
don't use KPTI on CPUs where E0PD is present.

	Signed-off-by: Mark Brown <broonie@kernel.org>
	Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
[will: Fixed typo in Kconfig text]
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit 3e6c69a058deaa50d33c3dac36cde80b4ce590e8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/cpucaps.h
#	arch/arm64/include/asm/sysreg.h
#	arch/arm64/kernel/cpufeature.c
diff --cc arch/arm64/include/asm/cpucaps.h
index 73140a10296f,33ff25c1ab1b..000000000000
--- a/arch/arm64/include/asm/cpucaps.h
+++ b/arch/arm64/include/asm/cpucaps.h
@@@ -61,15 -50,14 +61,27 @@@
  #define ARM64_HAS_GENERIC_AUTH_ARCH		40
  #define ARM64_HAS_GENERIC_AUTH_IMP_DEF		41
  #define ARM64_HAS_IRQ_PRIO_MASKING		42
++<<<<<<< HEAD
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	43
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	44
 +#define ARM64_WORKAROUND_1463225		45
 +#define ARM64_WORKAROUND_1542419		46
 +#define ARM64_HAS_32BIT_EL1			47
 +#define ARM64_WORKAROUND_NVIDIA_CARMEL_CNP	48
 +#define ARM64_HAS_ARMv8_4_TTL			49
 +#define ARM64_HAS_TLB_RANGE			50
 +
 +#define ARM64_NCAPS				51
++=======
+ #define ARM64_HAS_DCPODP			43
+ #define ARM64_WORKAROUND_1463225		44
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	45
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	46
+ #define ARM64_WORKAROUND_1542419		47
+ #define ARM64_WORKAROUND_1319367		48
+ #define ARM64_HAS_E0PD				49
+ 
+ #define ARM64_NCAPS				50
++>>>>>>> 3e6c69a058de (arm64: Add initial support for E0PD)
  
  #endif /* __ASM_CPUCAPS_H */
diff --cc arch/arm64/include/asm/sysreg.h
index cca1edca6ca9,b085258cfe4e..000000000000
--- a/arch/arm64/include/asm/sysreg.h
+++ b/arch/arm64/include/asm/sysreg.h
@@@ -720,7 -655,7 +720,11 @@@
  #define ID_AA64MMFR1_VMIDBITS_16	2
  
  /* id_aa64mmfr2 */
++<<<<<<< HEAD
 +#define ID_AA64MMFR2_TTL_SHIFT		48
++=======
+ #define ID_AA64MMFR2_E0PD_SHIFT		60
++>>>>>>> 3e6c69a058de (arm64: Add initial support for E0PD)
  #define ID_AA64MMFR2_FWB_SHIFT		40
  #define ID_AA64MMFR2_AT_SHIFT		32
  #define ID_AA64MMFR2_LVA_SHIFT		16
diff --cc arch/arm64/kernel/cpufeature.c
index 5c98a0b235b2,9d578e720168..000000000000
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@@ -241,7 -225,7 +241,11 @@@ static const struct arm64_ftr_bits ftr_
  };
  
  static const struct arm64_ftr_bits ftr_id_aa64mmfr2[] = {
++<<<<<<< HEAD
 +	ARM64_FTR_BITS(FTR_HIDDEN, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64MMFR2_TTL_SHIFT, 4, 0),
++=======
+ 	ARM64_FTR_BITS(FTR_HIDDEN, FTR_NONSTRICT, FTR_LOWER_SAFE, ID_AA64MMFR2_E0PD_SHIFT, 4, 0),
++>>>>>>> 3e6c69a058de (arm64: Add initial support for E0PD)
  	ARM64_FTR_BITS(FTR_HIDDEN, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64MMFR2_FWB_SHIFT, 4, 0),
  	ARM64_FTR_BITS(FTR_VISIBLE, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64MMFR2_AT_SHIFT, 4, 0),
  	ARM64_FTR_BITS(FTR_HIDDEN, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64MMFR2_LVA_SHIFT, 4, 0),
diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig
index 8ef565a5b888..000443a15b42 100644
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@ -1415,6 +1415,22 @@ config ARM64_TLB_RANGE
 
 endmenu
 
+menu "ARMv8.5 architectural features"
+
+config ARM64_E0PD
+	bool "Enable support for E0PD"
+	default y
+	help
+	   E0PD (part of the ARMv8.5 extensions) allows us to ensure
+	   that EL0 accesses made via TTBR1 always fault in constant time,
+	   providing similar benefits to KASLR as those provided by KPTI, but
+	   with lower overhead and without disrupting legitimate access to
+	   kernel memory such as SPE.
+
+	   This option enables E0PD for TTBR1 where available.
+
+endmenu
+
 config ARM64_SVE
 	bool "ARM Scalable Vector Extension support"
 	default y
* Unmerged path arch/arm64/include/asm/cpucaps.h
diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h
index a69259cc1f16..4b18fc45ccfc 100644
--- a/arch/arm64/include/asm/pgtable-hwdef.h
+++ b/arch/arm64/include/asm/pgtable-hwdef.h
@@ -304,6 +304,8 @@
 #define TCR_HD			(UL(1) << 40)
 #define TCR_NFD0		(UL(1) << 53)
 #define TCR_NFD1		(UL(1) << 54)
+#define TCR_E0PD0		(UL(1) << 55)
+#define TCR_E0PD1		(UL(1) << 56)
 
 /*
  * TTBR.
* Unmerged path arch/arm64/include/asm/sysreg.h
* Unmerged path arch/arm64/kernel/cpufeature.c
