percpu: unify allocation of schunk and dchunk

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Dennis Zhou (Facebook) <dennisszhou@gmail.com>
commit 10edf5b0b6e238f9102c88df8b92ba7ce8fdcc46
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/10edf5b0.failed

Create a common allocator for first chunk initialization,
pcpu_alloc_first_chunk. Comments for this function will be added in a
later patch once the bitmap allocator is added.

	Signed-off-by: Dennis Zhou <dennisszhou@gmail.com>
	Reviewed-by: Josef Bacik <jbacik@fb.com>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 10edf5b0b6e238f9102c88df8b92ba7ce8fdcc46)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/percpu.c
diff --cc mm/percpu.c
index 3c1f6f694380,2e785a77ce14..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -1671,50 -1709,20 +1702,67 @@@ int __init pcpu_setup_first_chunk(cons
  	 * covers static area + reserved area (mostly used for module
  	 * static percpu allocation).
  	 */
++<<<<<<< HEAD
 +	schunk = memblock_virt_alloc(pcpu_chunk_struct_size, 0);
 +	INIT_LIST_HEAD(&schunk->list);
 +	INIT_LIST_HEAD(&schunk->map_extend_list);
 +	schunk->base_addr = base_addr;
 +	schunk->map = smap;
 +	schunk->map_alloc = ARRAY_SIZE(smap);
 +	schunk->immutable = true;
 +	bitmap_fill(schunk->populated, pcpu_unit_pages);
 +	schunk->nr_populated = pcpu_unit_pages;
 +
 +	if (ai->reserved_size) {
 +		schunk->free_size = ai->reserved_size;
 +		pcpu_reserved_chunk = schunk;
 +		pcpu_reserved_chunk_limit = ai->static_size + ai->reserved_size;
 +	} else {
 +		schunk->free_size = dyn_size;
 +		dyn_size = 0;			/* dynamic area covered */
 +	}
 +	schunk->contig_hint = schunk->free_size;
 +
 +	schunk->map[0] = 1;
 +	schunk->map[1] = ai->static_size;
 +	schunk->map_used = 1;
 +	if (schunk->free_size)
 +		schunk->map[++schunk->map_used] = ai->static_size + schunk->free_size;
 +	schunk->map[schunk->map_used] |= 1;
 +
 +	/* init dynamic chunk if necessary */
 +	if (dyn_size) {
 +		dchunk = memblock_virt_alloc(pcpu_chunk_struct_size, 0);
 +		INIT_LIST_HEAD(&dchunk->list);
 +		INIT_LIST_HEAD(&dchunk->map_extend_list);
 +		dchunk->base_addr = base_addr;
 +		dchunk->map = dmap;
 +		dchunk->map_alloc = ARRAY_SIZE(dmap);
 +		dchunk->immutable = true;
 +		bitmap_fill(dchunk->populated, pcpu_unit_pages);
 +		dchunk->nr_populated = pcpu_unit_pages;
 +
 +		dchunk->contig_hint = dchunk->free_size = dyn_size;
 +		dchunk->map[0] = 1;
 +		dchunk->map[1] = pcpu_reserved_chunk_limit;
 +		dchunk->map[2] = (pcpu_reserved_chunk_limit + dchunk->free_size) | 1;
 +		dchunk->map_used = 2;
++=======
+ 	start_offset = ai->static_size;
+ 	map_size = ai->reserved_size ?: ai->dyn_size;
+ 	schunk = pcpu_alloc_first_chunk(base_addr, start_offset, map_size,
+ 					smap, ARRAY_SIZE(smap));
+ 
+ 	/* init dynamic chunk if necessary */
+ 	if (ai->reserved_size) {
+ 		pcpu_reserved_chunk = schunk;
+ 
+ 		start_offset = ai->static_size + ai->reserved_size;
+ 		map_size = ai->dyn_size;
+ 		dchunk = pcpu_alloc_first_chunk(base_addr, start_offset,
+ 						map_size, dmap,
+ 						ARRAY_SIZE(dmap));
++>>>>>>> 10edf5b0b6e2 (percpu: unify allocation of schunk and dchunk)
  	}
  
  	/* link the first chunk in */
* Unmerged path mm/percpu.c
