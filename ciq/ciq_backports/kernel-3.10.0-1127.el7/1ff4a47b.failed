perf/x86/intel/uncore: Support multi-die/package

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Kan Liang <kan.liang@linux.intel.com>
commit 1ff4a47b2d0c13b755b2eeeb0e23be6c056d5dd9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/1ff4a47b.failed

Uncore becomes die-scope on Xeon Cascade Lake-AP. Uncore driver needs to
support die-scope uncore units.

Use topology_logical_die_id() to replace topology_logical_package_id().
For previous platforms which doesn't have multi-die,
topology_logical_die_id() is identical as topology_logical_package_id().

In pci_probe()/remove(), the group id reads from PCI BUS is logical die id
for multi-die systems.

Use topology_die_cpumask() to replace topology_core_cpumask().
For previous platforms which doesn't have multi-die,
topology_die_cpumask() is identical as topology_core_cpumask().

There is no functional change for previous platforms.

	Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
	Signed-off-by: Len Brown <len.brown@intel.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Ingo Molnar <mingo@kernel.org>
	Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lkml.kernel.org/r/a25bba4a5b480aa4e9f8190005d7f5f53e29c8da.1557769318.git.len.brown@intel.com

(cherry picked from commit 1ff4a47b2d0c13b755b2eeeb0e23be6c056d5dd9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/events/intel/uncore.c
diff --cc arch/x86/events/intel/uncore.c
index ff23e9faa5b1,aeb5eae83750..000000000000
--- a/arch/x86/events/intel/uncore.c
+++ b/arch/x86/events/intel/uncore.c
@@@ -98,7 -100,13 +98,17 @@@ ssize_t uncore_event_show(struct kobjec
  
  struct intel_uncore_box *uncore_pmu_to_box(struct intel_uncore_pmu *pmu, int cpu)
  {
++<<<<<<< HEAD
 +	return pmu->boxes[topology_logical_package_id(cpu)];
++=======
+ 	unsigned int pkgid = topology_logical_die_id(cpu);
+ 
+ 	/*
+ 	 * The unsigned check also catches the '-1' return value for non
+ 	 * existent mappings in the topology map.
+ 	 */
+ 	return pkgid < max_packages ? pmu->boxes[pkgid] : NULL;
++>>>>>>> 1ff4a47b2d0c (perf/x86/intel/uncore: Support multi-die/package)
  }
  
  u64 uncore_msr_read_counter(struct intel_uncore_box *box, struct perf_event *event)
@@@ -1244,10 -1151,9 +1256,10 @@@ static void uncore_event_exit_cpu(int c
  
  	/* Check if exiting cpu is used for collecting uncore events */
  	if (!cpumask_test_and_clear_cpu(cpu, &uncore_cpu_mask))
 -		goto unref;
 +		return;
 +
  	/* Find a new cpu to collect uncore events */
- 	target = cpumask_any_but(topology_core_cpumask(cpu), cpu);
+ 	target = cpumask_any_but(topology_die_cpumask(cpu), cpu);
  
  	/* Migrate uncore events to the new target */
  	if (target < nr_cpu_ids)
@@@ -1257,19 -1163,90 +1269,96 @@@
  
  	uncore_change_context(uncore_msr_uncores, cpu, target);
  	uncore_change_context(uncore_pci_uncores, cpu, target);
++<<<<<<< HEAD
++=======
+ 
+ unref:
+ 	/* Clear the references */
+ 	pkg = topology_logical_die_id(cpu);
+ 	for (; *types; types++) {
+ 		type = *types;
+ 		pmu = type->pmus;
+ 		for (i = 0; i < type->num_boxes; i++, pmu++) {
+ 			box = pmu->boxes[pkg];
+ 			if (box && atomic_dec_return(&box->refcnt) == 0)
+ 				uncore_box_exit(box);
+ 		}
+ 	}
+ 	return 0;
++>>>>>>> 1ff4a47b2d0c (perf/x86/intel/uncore: Support multi-die/package)
  }
  
 -static int allocate_boxes(struct intel_uncore_type **types,
 -			 unsigned int pkg, unsigned int cpu)
 +static void uncore_event_init_cpu(int cpu)
  {
++<<<<<<< HEAD
 +	int target;
++=======
+ 	struct intel_uncore_box *box, *tmp;
+ 	struct intel_uncore_type *type;
+ 	struct intel_uncore_pmu *pmu;
+ 	LIST_HEAD(allocated);
+ 	int i;
+ 
+ 	/* Try to allocate all required boxes */
+ 	for (; *types; types++) {
+ 		type = *types;
+ 		pmu = type->pmus;
+ 		for (i = 0; i < type->num_boxes; i++, pmu++) {
+ 			if (pmu->boxes[pkg])
+ 				continue;
+ 			box = uncore_alloc_box(type, cpu_to_node(cpu));
+ 			if (!box)
+ 				goto cleanup;
+ 			box->pmu = pmu;
+ 			box->pkgid = pkg;
+ 			list_add(&box->active_list, &allocated);
+ 		}
+ 	}
+ 	/* Install them in the pmus */
+ 	list_for_each_entry_safe(box, tmp, &allocated, active_list) {
+ 		list_del_init(&box->active_list);
+ 		box->pmu->boxes[pkg] = box;
+ 	}
+ 	return 0;
+ 
+ cleanup:
+ 	list_for_each_entry_safe(box, tmp, &allocated, active_list) {
+ 		list_del_init(&box->active_list);
+ 		kfree(box);
+ 	}
+ 	return -ENOMEM;
+ }
+ 
+ static int uncore_event_cpu_online(unsigned int cpu)
+ {
+ 	struct intel_uncore_type *type, **types = uncore_msr_uncores;
+ 	struct intel_uncore_pmu *pmu;
+ 	struct intel_uncore_box *box;
+ 	int i, ret, pkg, target;
+ 
+ 	pkg = topology_logical_die_id(cpu);
+ 	ret = allocate_boxes(types, pkg, cpu);
+ 	if (ret)
+ 		return ret;
+ 
+ 	for (; *types; types++) {
+ 		type = *types;
+ 		pmu = type->pmus;
+ 		for (i = 0; i < type->num_boxes; i++, pmu++) {
+ 			box = pmu->boxes[pkg];
+ 			if (box && atomic_inc_return(&box->refcnt) == 1)
+ 				uncore_box_init(box);
+ 		}
+ 	}
++>>>>>>> 1ff4a47b2d0c (perf/x86/intel/uncore: Support multi-die/package)
  
  	/*
  	 * Check if there is an online cpu in the package
  	 * which collects uncore events already.
  	 */
- 	target = cpumask_any_and(&uncore_cpu_mask, topology_core_cpumask(cpu));
+ 	target = cpumask_any_and(&uncore_cpu_mask, topology_die_cpumask(cpu));
  	if (target < nr_cpu_ids)
 -		return 0;
 +		return;
  
  	cpumask_set_cpu(cpu, &uncore_cpu_mask);
  
@@@ -1503,10 -1416,10 +1592,10 @@@ static int __init intel_uncore_init(voi
  	if (!id)
  		return -ENODEV;
  
 -	if (boot_cpu_has(X86_FEATURE_HYPERVISOR))
 +	if (cpu_has_hypervisor)
  		return -ENODEV;
  
- 	max_packages = topology_max_packages();
+ 	max_packages = topology_max_packages() * topology_max_die_per_package();
  
  	uncore_init = (struct intel_uncore_init_fun *)id->driver_data;
  	if (uncore_init->pci_init) {
* Unmerged path arch/x86/events/intel/uncore.c
