mm: cleanup add_to_page_cache_locked()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
commit 66a0c8ee3dce78362d59f00a8efbd752fbeddfb1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/66a0c8ee.failed

Make add_to_page_cache_locked() cleaner:

 - unindent most code of the function by inverting one condition;
 - streamline code no-error path;
 - move insert error path outside normal code path;
 - call radix_tree_preload_end() earlier;

No functional changes.

	Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Acked-by: Dave Hansen <dave.hansen@linux.intel.com>
	Cc: Andrea Arcangeli <aarcange@redhat.com>
	Cc: Al Viro <viro@zeniv.linux.org.uk>
	Cc: Hugh Dickins <hughd@google.com>
	Cc: Wu Fengguang <fengguang.wu@intel.com>
	Cc: Jan Kara <jack@suse.cz>
	Cc: Mel Gorman <mgorman@suse.de>
	Cc: Andi Kleen <ak@linux.intel.com>
	Cc: Matthew Wilcox <willy@linux.intel.com>
	Cc: Hillf Danton <dhillf@gmail.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 66a0c8ee3dce78362d59f00a8efbd752fbeddfb1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/filemap.c
diff --cc mm/filemap.c
index 4ee01a45ccd4,1e6aec4a2d2e..000000000000
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@@ -596,50 -467,36 +596,76 @@@ static int __add_to_page_cache_locked(s
  	error = mem_cgroup_cache_charge(page, current->mm,
  					gfp_mask & GFP_RECLAIM_MASK);
  	if (error)
- 		goto out;
+ 		return error;
  
  	error = radix_tree_maybe_preload(gfp_mask & ~__GFP_HIGHMEM);
++<<<<<<< HEAD
 +	if (error == 0) {
 +		page_cache_get(page);
 +		page->mapping = mapping;
 +		page->index = offset;
 +
 +		spin_lock_irq(&mapping->tree_lock);
 +		error = page_cache_tree_insert(mapping, page, shadowp);
 +		if (likely(!error)) {
 +			__inc_zone_page_state(page, NR_FILE_PAGES);
 +			spin_unlock_irq(&mapping->tree_lock);
 +			trace_mm_filemap_add_to_page_cache(page);
 +		} else {
 +			page->mapping = NULL;
 +			/* Leave page->index set: truncation relies upon it */
 +			spin_unlock_irq(&mapping->tree_lock);
 +			mem_cgroup_uncharge_cache_page(page);
 +			page_cache_release(page);
 +		}
 +		radix_tree_preload_end();
 +	} else
++=======
+ 	if (error) {
++>>>>>>> 66a0c8ee3dce (mm: cleanup add_to_page_cache_locked())
  		mem_cgroup_uncharge_cache_page(page);
- out:
+ 		return error;
+ 	}
+ 
+ 	page_cache_get(page);
+ 	page->mapping = mapping;
+ 	page->index = offset;
+ 
+ 	spin_lock_irq(&mapping->tree_lock);
+ 	error = radix_tree_insert(&mapping->page_tree, offset, page);
+ 	radix_tree_preload_end();
+ 	if (unlikely(error))
+ 		goto err_insert;
+ 	mapping->nrpages++;
+ 	__inc_zone_page_state(page, NR_FILE_PAGES);
+ 	spin_unlock_irq(&mapping->tree_lock);
+ 	trace_mm_filemap_add_to_page_cache(page);
+ 	return 0;
+ err_insert:
+ 	page->mapping = NULL;
+ 	/* Leave page->index set: truncation relies upon it */
+ 	spin_unlock_irq(&mapping->tree_lock);
+ 	mem_cgroup_uncharge_cache_page(page);
+ 	page_cache_release(page);
  	return error;
  }
 +
 +/**
 + * add_to_page_cache_locked - add a locked page to the pagecache
 + * @page:	page to add
 + * @mapping:	the page's address_space
 + * @offset:	page index
 + * @gfp_mask:	page allocation mode
 + *
 + * This function is used to add a page to the pagecache. It must be locked.
 + * This function does not add the page to the LRU.  The caller must do that.
 + */
 +int add_to_page_cache_locked(struct page *page, struct address_space *mapping,
 +		pgoff_t offset, gfp_t gfp_mask)
 +{
 +	return __add_to_page_cache_locked(page, mapping, offset,
 +					  gfp_mask, NULL);
 +}
  EXPORT_SYMBOL(add_to_page_cache_locked);
  
  int add_to_page_cache_lru(struct page *page, struct address_space *mapping,
* Unmerged path mm/filemap.c
