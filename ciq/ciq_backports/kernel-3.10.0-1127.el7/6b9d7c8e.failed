percpu: end chunk area maps page aligned for the populated bitmap

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Dennis Zhou (Facebook) <dennisszhou@gmail.com>
commit 6b9d7c8e8ecf35dc9ba6763a45d81e54ee3ffcde
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/6b9d7c8e.failed

The area map allocator manages the first chunk area by hiding all but
the region it is responsible for serving in the area map. To align this
with the populated page bitmap, end_offset is introduced to keep track
of the delta to end page aligned. The area map is appended with the
page aligned end when necessary to be in line with how the bitmap
allocator requires the ending to be aligned with the LCM of PAGE_SIZE
and the size of each bitmap block. percpu_stats is updated to ignore
this region when present.

	Signed-off-by: Dennis Zhou <dennisszhou@gmail.com>
	Reviewed-by: Josef Bacik <jbacik@fb.com>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 6b9d7c8e8ecf35dc9ba6763a45d81e54ee3ffcde)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/percpu-internal.h
#	mm/percpu-stats.c
#	mm/percpu.c
diff --cc mm/percpu.c
index 3c1f6f694380,1d2c980fde3f..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -720,6 -708,45 +720,48 @@@ static void pcpu_free_area(struct pcpu_
  	pcpu_chunk_relocate(chunk, oslot);
  }
  
++<<<<<<< HEAD
++=======
+ static struct pcpu_chunk * __init pcpu_alloc_first_chunk(void *base_addr,
+ 							 int start_offset,
+ 							 int map_size,
+ 							 int *map,
+ 							 int init_map_size)
+ {
+ 	struct pcpu_chunk *chunk;
+ 	int region_size;
+ 
+ 	region_size = PFN_ALIGN(start_offset + map_size);
+ 
+ 	chunk = memblock_virt_alloc(pcpu_chunk_struct_size, 0);
+ 	INIT_LIST_HEAD(&chunk->list);
+ 	INIT_LIST_HEAD(&chunk->map_extend_list);
+ 	chunk->base_addr = base_addr;
+ 	chunk->start_offset = start_offset;
+ 	chunk->end_offset = region_size - chunk->start_offset - map_size;
+ 	chunk->map = map;
+ 	chunk->map_alloc = init_map_size;
+ 
+ 	/* manage populated page bitmap */
+ 	chunk->immutable = true;
+ 	bitmap_fill(chunk->populated, pcpu_unit_pages);
+ 	chunk->nr_populated = pcpu_unit_pages;
+ 
+ 	chunk->contig_hint = chunk->free_size = map_size;
+ 	chunk->map[0] = 1;
+ 	chunk->map[1] = chunk->start_offset;
+ 	chunk->map[2] = (chunk->start_offset + chunk->free_size) | 1;
+ 	chunk->map_used = 2;
+ 
+ 	if (chunk->end_offset) {
+ 		/* hide the end of the bitmap */
+ 		chunk->map[++chunk->map_used] = region_size | 1;
+ 	}
+ 
+ 	return chunk;
+ }
+ 
++>>>>>>> 6b9d7c8e8ecf (percpu: end chunk area maps page aligned for the populated bitmap)
  static struct pcpu_chunk *pcpu_alloc_chunk(void)
  {
  	struct pcpu_chunk *chunk;
* Unmerged path mm/percpu-internal.h
* Unmerged path mm/percpu-stats.c
* Unmerged path mm/percpu-internal.h
* Unmerged path mm/percpu-stats.c
* Unmerged path mm/percpu.c
