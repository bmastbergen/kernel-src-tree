mm/percpu.c: fix potential memory leakage for pcpu_embed_first_chunk()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author zijun_hu <zijun_hu@htc.com>
commit 9b7396624a7b503220d85428654634b60762f2b0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/9b739662.failed

in order to ensure the percpu group areas within a chunk aren't
distributed too sparsely, pcpu_embed_first_chunk() goes to error handling
path when a chunk spans over 3/4 VMALLOC area, however, during the error
handling, it forget to free the memory allocated for all percpu groups by
going to label @out_free other than @out_free_areas.

it will cause memory leakage issue if the rare scene really happens, in
order to fix the issue, we check chunk spanned area immediately after
completing memory allocation for all percpu groups, we go to label
@out_free_areas to free the memory then return if the checking is failed.

in order to verify the approach, we dump all memory allocated then
enforce the jump then dump all memory freed, the result is okay after
checking whether we free all memory we allocate in this function.

BTW, The approach is chosen after thinking over the below scenes
 - we don't go to label @out_free directly to fix this issue since we
   maybe free several allocated memory blocks twice
 - the aim of jumping after pcpu_setup_first_chunk() is bypassing free
   usable memory other than handling error, moreover, the function does
   not return error code in any case, it either panics due to BUG_ON()
   or return 0.

	Signed-off-by: zijun_hu <zijun_hu@htc.com>
	Tested-by: zijun_hu <zijun_hu@htc.com>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 9b7396624a7b503220d85428654634b60762f2b0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/percpu.c
diff --cc mm/percpu.c
index 895c2996b902,255714302394..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -1972,8 -1961,9 +1972,14 @@@ int __init pcpu_embed_first_chunk(size_
  	void *base = (void *)ULONG_MAX;
  	void **areas = NULL;
  	struct pcpu_alloc_info *ai;
++<<<<<<< HEAD
 +	size_t size_sum, areas_size, max_distance;
 +	int group, i, rc;
++=======
+ 	size_t size_sum, areas_size;
+ 	unsigned long max_distance;
+ 	int group, i, highest_group, rc;
++>>>>>>> 9b7396624a7b (mm/percpu.c: fix potential memory leakage for pcpu_embed_first_chunk())
  
  	ai = pcpu_build_alloc_info(reserved_size, dyn_size, atom_size,
  				   cpu_distance_fn);
@@@ -2034,27 -2040,11 +2056,32 @@@
  	}
  
  	/* base address is now known, determine group base offsets */
++<<<<<<< HEAD
 +	max_distance = 0;
 +	for (group = 0; group < ai->nr_groups; group++) {
 +		ai->groups[group].base_offset = areas[group] - base;
 +		max_distance = max_t(size_t, max_distance,
 +				     ai->groups[group].base_offset);
 +	}
 +	max_distance += ai->unit_size;
 +
 +	/* warn if maximum distance is further than 75% of vmalloc space */
 +	if (max_distance > VMALLOC_TOTAL * 3 / 4) {
 +		pr_warning("PERCPU: max_distance=0x%zx too large for vmalloc "
 +			   "space 0x%lx\n", max_distance,
 +			   VMALLOC_TOTAL);
 +#ifdef CONFIG_NEED_PER_CPU_PAGE_FIRST_CHUNK
 +		/* and fail if we have fallback */
 +		rc = -EINVAL;
 +		goto out_free;
 +#endif
++=======
+ 	for (group = 0; group < ai->nr_groups; group++) {
+ 		ai->groups[group].base_offset = areas[group] - base;
++>>>>>>> 9b7396624a7b (mm/percpu.c: fix potential memory leakage for pcpu_embed_first_chunk())
  	}
  
 -	pr_info("Embedded %zu pages/cpu @%p s%zu r%zu d%zu u%zu\n",
 +	pr_info("PERCPU: Embedded %zu pages/cpu @%p s%zu r%zu d%zu u%zu\n",
  		PFN_DOWN(size_sum), base, ai->static_size, ai->reserved_size,
  		ai->dyn_size, ai->unit_size);
  
* Unmerged path mm/percpu.c
