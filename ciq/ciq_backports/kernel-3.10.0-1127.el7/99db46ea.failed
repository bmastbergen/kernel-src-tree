ipc: do cyclic id allocation for the ipc object.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
Rebuild_CHGLOG: - [ipc] do cyclic id allocation for the ipc object (Waiman Long) [1373519]
Rebuild_FUZZ: 93.33%
commit-author Manfred Spraul <manfred@colorfullife.com>
commit 99db46ea292780cd978d56932d9445b1e8bdafe8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/99db46ea.failed

For ipcmni_extend mode, the sequence number space is only 7 bits.  So
the chance of id reuse is relatively high compared with the non-extended
mode.

To alleviate this id reuse problem, this patch enables cyclic allocation
for the index to the radix tree (idx).  The disadvantage is that this
can cause a slight slow-down of the fast path, as the radix tree could
be higher than necessary.

To limit the radix tree height, I have chosen the following limits:
 1) The cycling is done over in_use*1.5.
 2) At least, the cycling is done over
   "normal" ipcnmi mode: RADIX_TREE_MAP_SIZE elements
   "ipcmni_extended": 4096 elements

Result:
- for normal mode:
	No change for <= 42 active ipc elements. With more than 42
	active ipc elements, a 2nd level would be added to the radix
	tree.
	Without cyclic allocation, a 2nd level would be added only with
	more than 63 active elements.

- for extended mode:
	Cycling creates always at least a 2-level radix tree.
	With more than 2730 active objects, a 3rd level would be
	added, instead of > 4095 active objects until the 3rd level
	is added without cyclic allocation.

For a 2-level radix tree compared to a 1-level radix tree, I have
observed < 1% performance impact.

Notes:
1) Normal "x=semget();y=semget();" is unaffected: Then the idx
  is e.g. a and a+1, regardless if idr_alloc() or idr_alloc_cyclic()
  is used.

2) The -1% happens in a microbenchmark after this situation:
	x=semget();
	for(i=0;i<4000;i++) {t=semget();semctl(t,0,IPC_RMID);}
	y=semget();
	Now perform semget calls on x and y that do not sleep.

3) The worst-case reuse cycle time is unfortunately unaffected:
   If you have 2^24-1 ipc objects allocated, and get/remove the last
   possible element in a loop, then the id is reused after 128
   get/remove pairs.

Performance check:
A microbenchmark that performes no-op semop() randomly on two IDs,
with only these two IDs allocated.
The IDs were set using /proc/sys/kernel/sem_next_id.
The test was run 5 times, averages are shown.

1 & 2: Base (6.22 seconds for 10.000.000 semops)
1 & 40: -0.2%
1 & 3348: - 0.8%
1 & 27348: - 1.6%
1 & 15777204: - 3.2%

Or: ~12.6 cpu cycles per additional radix tree level.
The cpu is an Intel I3-5010U. ~1300 cpu cycles/syscall is slower
than what I remember (spectre impact?).

V2 of the patch:
- use "min" and "max"
- use RADIX_TREE_MAP_SIZE * RADIX_TREE_MAP_SIZE instead of
	(2<<12).

[akpm@linux-foundation.org: fix max() warning]
Link: http://lkml.kernel.org/r/20190329204930.21620-3-longman@redhat.com
	Signed-off-by: Manfred Spraul <manfred@colorfullife.com>
	Acked-by: Waiman Long <longman@redhat.com>
	Cc: "Luis R. Rodriguez" <mcgrof@kernel.org>
	Cc: Kees Cook <keescook@chromium.org>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Al Viro <viro@zeniv.linux.org.uk>
	Cc: Matthew Wilcox <willy@infradead.org>
	Cc: "Eric W . Biederman" <ebiederm@xmission.com>
	Cc: Takashi Iwai <tiwai@suse.de>
	Cc: Davidlohr Bueso <dbueso@suse.de>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 99db46ea292780cd978d56932d9445b1e8bdafe8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	ipc/ipc_sysctl.c
#	ipc/util.c
#	ipc/util.h
diff --cc ipc/ipc_sysctl.c
index 68c60de19527,bfaae457810c..000000000000
--- a/ipc/ipc_sysctl.c
+++ b/ipc/ipc_sysctl.c
@@@ -158,7 -120,9 +158,13 @@@ static int proc_ipcauto_dointvec_minmax
  static int zero;
  static int one = 1;
  static int int_max = INT_MAX;
++<<<<<<< HEAD
 +static int ipc_mni = IPCMNI;
++=======
+ int ipc_mni = IPCMNI;
+ int ipc_mni_shift = IPCMNI_SHIFT;
+ int ipc_min_cycle = RADIX_TREE_MAP_SIZE;
++>>>>>>> 99db46ea2927 (ipc: do cyclic id allocation for the ipc object.)
  
  static struct ctl_table ipc_kern_table[] = {
  	{
@@@ -284,3 -248,13 +290,16 @@@ static int __init ipc_sysctl_init(void
  }
  
  device_initcall(ipc_sysctl_init);
++<<<<<<< HEAD
++=======
+ 
+ static int __init ipc_mni_extend(char *str)
+ {
+ 	ipc_mni = IPCMNI_EXTEND;
+ 	ipc_mni_shift = IPCMNI_EXTEND_SHIFT;
+ 	ipc_min_cycle = IPCMNI_EXTEND_MIN_CYCLE;
+ 	pr_info("IPCMNI extended to %d.\n", ipc_mni);
+ 	return 0;
+ }
+ early_param("ipcmni_extend", ipc_mni_extend);
++>>>>>>> 99db46ea2927 (ipc: do cyclic id allocation for the ipc object.)
diff --cc ipc/util.c
index 1df75a61612b,d126d156efc6..000000000000
--- a/ipc/util.c
+++ b/ipc/util.c
@@@ -191,39 -159,104 +191,108 @@@ void __init ipc_init_proc_interface(con
  #endif
  
  /**
 - * ipc_findkey	- find a key in an ipc identifier set
 - * @ids: ipc identifier set
 - * @key: key to find
 - *
 - * Returns the locked pointer to the ipc structure if found or NULL
 - * otherwise. If key is found ipc points to the owning ipc structure
 - *
 - * Called with writer ipc_ids.rwsem held.
 + *	ipc_findkey	-	find a key in an ipc identifier set	
 + *	@ids: Identifier set
 + *	@key: The key to find
 + *	
 + *	Requires ipc_ids.rwsem locked.
 + *	Returns the LOCKED pointer to the ipc structure if found or NULL
 + *	if not.
 + *	If key is found ipc points to the owning ipc structure
   */
 + 
  static struct kern_ipc_perm *ipc_findkey(struct ipc_ids *ids, key_t key)
  {
 -	struct kern_ipc_perm *ipcp;
 +	struct kern_ipc_perm *ipc;
 +	int next_id;
 +	int total;
  
 -	ipcp = rhashtable_lookup_fast(&ids->key_ht, &key,
 -					      ipc_kht_params);
 -	if (!ipcp)
 -		return NULL;
 +	for (total = 0, next_id = 0; total < ids->in_use; next_id++) {
 +		ipc = idr_find(&ids->ipcs_idr, next_id);
  
 -	rcu_read_lock();
 -	ipc_lock_object(ipcp);
 -	return ipcp;
 -}
 +		if (ipc == NULL)
 +			continue;
  
++<<<<<<< HEAD
 +		if (ipc->key != key) {
 +			total++;
 +			continue;
++=======
+ /*
+  * Insert new IPC object into idr tree, and set sequence number and id
+  * in the correct order.
+  * Especially:
+  * - the sequence number must be set before inserting the object into the idr,
+  *   because the sequence number is accessed without a lock.
+  * - the id can/must be set after inserting the object into the idr.
+  *   All accesses must be done after getting kern_ipc_perm.lock.
+  *
+  * The caller must own kern_ipc_perm.lock.of the new object.
+  * On error, the function returns a (negative) error code.
+  *
+  * To conserve sequence number space, especially with extended ipc_mni,
+  * the sequence number is incremented only when the returned ID is less than
+  * the last one.
+  */
+ static inline int ipc_idr_alloc(struct ipc_ids *ids, struct kern_ipc_perm *new)
+ {
+ 	int idx, next_id = -1;
+ 
+ #ifdef CONFIG_CHECKPOINT_RESTORE
+ 	next_id = ids->next_id;
+ 	ids->next_id = -1;
+ #endif
+ 
+ 	/*
+ 	 * As soon as a new object is inserted into the idr,
+ 	 * ipc_obtain_object_idr() or ipc_obtain_object_check() can find it,
+ 	 * and the lockless preparations for ipc operations can start.
+ 	 * This means especially: permission checks, audit calls, allocation
+ 	 * of undo structures, ...
+ 	 *
+ 	 * Thus the object must be fully initialized, and if something fails,
+ 	 * then the full tear-down sequence must be followed.
+ 	 * (i.e.: set new->deleted, reduce refcount, call_rcu())
+ 	 */
+ 
+ 	if (next_id < 0) { /* !CHECKPOINT_RESTORE or next_id is unset */
+ 		int max_idx;
+ 
+ 		max_idx = max(ids->in_use*3/2, ipc_min_cycle);
+ 		max_idx = min(max_idx, ipc_mni);
+ 
+ 		/* allocate the idx, with a NULL struct kern_ipc_perm */
+ 		idx = idr_alloc_cyclic(&ids->ipcs_idr, NULL, 0, max_idx,
+ 					GFP_NOWAIT);
+ 
+ 		if (idx >= 0) {
+ 			/*
+ 			 * idx got allocated successfully.
+ 			 * Now calculate the sequence number and set the
+ 			 * pointer for real.
+ 			 */
+ 			if (idx <= ids->last_idx) {
+ 				ids->seq++;
+ 				if (ids->seq >= ipcid_seq_max())
+ 					ids->seq = 0;
+ 			}
+ 			ids->last_idx = idx;
+ 
+ 			new->seq = ids->seq;
+ 			/* no need for smp_wmb(), this is done
+ 			 * inside idr_replace, as part of
+ 			 * rcu_assign_pointer
+ 			 */
+ 			idr_replace(&ids->ipcs_idr, new, idx);
++>>>>>>> 99db46ea2927 (ipc: do cyclic id allocation for the ipc object.)
  		}
 -	} else {
 -		new->seq = ipcid_to_seqx(next_id);
 -		idx = idr_alloc(&ids->ipcs_idr, new, ipcid_to_idx(next_id),
 -				0, GFP_NOWAIT);
 +
 +		rcu_read_lock();
 +		ipc_lock_object(ipc);
 +		return ipc;
  	}
 -	if (idx >= 0)
 -		new->id = (new->seq << ipcmni_seq_shift()) + idx;
 -	return idx;
 +
 +	return NULL;
  }
  
  /**
diff --cc ipc/util.h
index 778c12c8c204,0fcf8e719b76..000000000000
--- a/ipc/util.h
+++ b/ipc/util.h
@@@ -12,15 -13,46 +12,53 @@@
  
  #include <linux/unistd.h>
  #include <linux/err.h>
 -#include <linux/ipc_namespace.h>
  
++<<<<<<< HEAD
 +#define IPCMNI 32768  /* <= MAX_INT limit for ipc arrays (including sysctl changes) */
 +#define SEQ_MULTIPLIER	(IPCMNI)
 +
 +void sem_init (void);
 +void msg_init (void);
 +void shm_init (void);
++=======
+ /*
+  * The IPC ID contains 2 separate numbers - index and sequence number.
+  * By default,
+  *   bits  0-14: index (32k, 15 bits)
+  *   bits 15-30: sequence number (64k, 16 bits)
+  *
+  * When IPCMNI extension mode is turned on, the composition changes:
+  *   bits  0-23: index (16M, 24 bits)
+  *   bits 24-30: sequence number (128, 7 bits)
+  */
+ #define IPCMNI_SHIFT		15
+ #define IPCMNI_EXTEND_SHIFT	24
+ #define IPCMNI_EXTEND_MIN_CYCLE	(RADIX_TREE_MAP_SIZE * RADIX_TREE_MAP_SIZE)
+ #define IPCMNI			(1 << IPCMNI_SHIFT)
+ #define IPCMNI_EXTEND		(1 << IPCMNI_EXTEND_SHIFT)
+ 
+ #ifdef CONFIG_SYSVIPC_SYSCTL
+ extern int ipc_mni;
+ extern int ipc_mni_shift;
+ extern int ipc_min_cycle;
+ 
+ #define ipcmni_seq_shift()	ipc_mni_shift
+ #define IPCMNI_IDX_MASK		((1 << ipc_mni_shift) - 1)
+ 
+ #else /* CONFIG_SYSVIPC_SYSCTL */
+ 
+ #define ipc_mni			IPCMNI
+ #define ipc_min_cycle		((int)RADIX_TREE_MAP_SIZE)
+ #define ipcmni_seq_shift()	IPCMNI_SHIFT
+ #define IPCMNI_IDX_MASK		((1 << IPCMNI_SHIFT) - 1)
+ #endif /* CONFIG_SYSVIPC_SYSCTL */
+ 
+ void sem_init(void);
+ void msg_init(void);
+ void shm_init(void);
++>>>>>>> 99db46ea2927 (ipc: do cyclic id allocation for the ipc object.)
  
  struct ipc_namespace;
 -struct pid_namespace;
  
  #ifdef CONFIG_POSIX_MQUEUE
  extern void mq_clear_sbinfo(struct ipc_namespace *ns);
* Unmerged path ipc/ipc_sysctl.c
* Unmerged path ipc/util.c
* Unmerged path ipc/util.h
