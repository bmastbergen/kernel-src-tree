percpu: generalize bitmap (un)populated iterators

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Dennis Zhou (Facebook) <dennisszhou@gmail.com>
commit 91e914c5a4988d00a13c14297ab02b250611e00e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/91e914c5.failed

The area map allocator only used a bitmap for the backing page state.
The new bitmap allocator will use bitmaps to manage the allocation
region in addition to this.

This patch generalizes the bitmap iterators so they can be reused with
the bitmap allocator.

	Signed-off-by: Dennis Zhou <dennisszhou@gmail.com>
	Reviewed-by: Josef Bacik <jbacik@fb.com>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 91e914c5a4988d00a13c14297ab02b250611e00e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/percpu.c
diff --cc mm/percpu.c
index 3c1f6f694380,84cc2559d4aa..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -246,22 -244,25 +246,20 @@@ static int __maybe_unused pcpu_page_idx
  static unsigned long pcpu_chunk_addr(struct pcpu_chunk *chunk,
  				     unsigned int cpu, int page_idx)
  {
 -	return (unsigned long)chunk->base_addr +
 -	       pcpu_unit_page_offset(cpu, page_idx);
 +	return (unsigned long)chunk->base_addr + pcpu_unit_offsets[cpu] +
 +		(page_idx << PAGE_SHIFT);
  }
  
- static void __maybe_unused pcpu_next_unpop(struct pcpu_chunk *chunk,
- 					   int *rs, int *re, int end)
+ static void pcpu_next_unpop(unsigned long *bitmap, int *rs, int *re, int end)
  {
- 	*rs = find_next_zero_bit(chunk->populated, end, *rs);
- 	*re = find_next_bit(chunk->populated, end, *rs + 1);
+ 	*rs = find_next_zero_bit(bitmap, end, *rs);
+ 	*re = find_next_bit(bitmap, end, *rs + 1);
  }
  
- static void __maybe_unused pcpu_next_pop(struct pcpu_chunk *chunk,
- 					 int *rs, int *re, int end)
+ static void pcpu_next_pop(unsigned long *bitmap, int *rs, int *re, int end)
  {
- 	*rs = find_next_bit(chunk->populated, end, *rs);
- 	*re = find_next_zero_bit(chunk->populated, end, *rs + 1);
+ 	*rs = find_next_bit(bitmap, end, *rs);
+ 	*re = find_next_zero_bit(bitmap, end, *rs + 1);
  }
  
  /*
@@@ -1147,7 -1220,8 +1146,12 @@@ static void pcpu_balance_workfn(struct 
  	list_for_each_entry_safe(chunk, next, &to_free, list) {
  		int rs, re;
  
++<<<<<<< HEAD
 +		pcpu_for_each_pop_region(chunk, rs, re, 0, pcpu_unit_pages) {
++=======
+ 		pcpu_for_each_pop_region(chunk->populated, rs, re, 0,
+ 					 chunk->nr_pages) {
++>>>>>>> 91e914c5a498 (percpu: generalize bitmap (un)populated iterators)
  			pcpu_depopulate_chunk(chunk, rs, re);
  			spin_lock_irq(&pcpu_lock);
  			pcpu_chunk_depopulated(chunk, rs, re);
@@@ -1214,7 -1288,8 +1218,12 @@@ retry_pop
  			continue;
  
  		/* @chunk can't go away while pcpu_alloc_mutex is held */
++<<<<<<< HEAD
 +		pcpu_for_each_unpop_region(chunk, rs, re, 0, pcpu_unit_pages) {
++=======
+ 		pcpu_for_each_unpop_region(chunk->populated, rs, re, 0,
+ 					   chunk->nr_pages) {
++>>>>>>> 91e914c5a498 (percpu: generalize bitmap (un)populated iterators)
  			int nr = min(re - rs, nr_to_pop);
  
  			ret = pcpu_populate_chunk(chunk, rs, rs + nr);
* Unmerged path mm/percpu.c
