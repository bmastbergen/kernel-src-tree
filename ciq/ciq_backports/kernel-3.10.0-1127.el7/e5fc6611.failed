sched: Fix race in idle_balance()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Daniel Lezcano <daniel.lezcano@linaro.org>
commit e5fc66119ec97054eefc83f173a7ee9e133c3c3a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/e5fc6611.failed

The scheduler main function 'schedule()' checks if there are no more tasks
on the runqueue. Then it checks if a task should be pulled in the current
runqueue in idle_balance() assuming it will go to idle otherwise.

But idle_balance() releases the rq->lock in order to look up the sched
domains and takes the lock again right after. That opens a window where
another cpu may put a task in our runqueue, so we won't go to idle but
we have filled the idle_stamp, thinking we will.

This patch closes the window by checking if the runqueue has been modified
but without pulling a task after taking the lock again, so we won't go to idle
right after in the __schedule() function.

	Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
	Cc: alex.shi@linaro.org
	Signed-off-by: Peter Zijlstra <peterz@infradead.org>
Link: http://lkml.kernel.org/r/1389949444-14821-2-git-send-email-daniel.lezcano@linaro.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit e5fc66119ec97054eefc83f173a7ee9e133c3c3a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/fair.c
diff --cc kernel/sched/fair.c
index f3df0d8beb03,5ebc6817c036..000000000000
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@@ -6927,10 -6589,20 +6927,25 @@@ void idle_balance(int this_cpu, struct 
  
  	raw_spin_lock(&this_rq->lock);
  
++<<<<<<< HEAD
 +out:
 +	/* Move the next balance forward */
 +	if (time_after(this_rq->next_balance, next_balance))
++=======
+ 	/*
+ 	 * While browsing the domains, we released the rq lock.
+ 	 * A task could have be enqueued in the meantime
+ 	 */
+ 	if (this_rq->nr_running && !pulled_task)
+ 		return;
+ 
+ 	if (pulled_task || time_after(jiffies, this_rq->next_balance)) {
+ 		/*
+ 		 * We are going idle. next_balance may be set based on
+ 		 * a busy processor. So reset next_balance.
+ 		 */
++>>>>>>> e5fc66119ec9 (sched: Fix race in idle_balance())
  		this_rq->next_balance = next_balance;
 -	}
  
  	if (curr_cost > this_rq->max_idle_balance_cost)
  		this_rq->max_idle_balance_cost = curr_cost;
* Unmerged path kernel/sched/fair.c
