iomap: Clean up __generic_write_end calling

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Christoph Hellwig <hch@lst.de>
commit dbc582b6fb6ad6461085adfaae0106ae78721107
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/dbc582b6.failed

Move the call to __generic_write_end into iomap_write_end instead of
duplicating it in each of the three branches.  This requires open coding
the generic_write_end for the buffer_head case.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
	Reviewed-by: Jan Kara <jack@suse.cz>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
(cherry picked from commit dbc582b6fb6ad6461085adfaae0106ae78721107)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/iomap.c
diff --cc fs/iomap.c
index b368e069ba43,9f159c39fbdc..000000000000
--- a/fs/iomap.c
+++ b/fs/iomap.c
@@@ -160,9 -688,58 +160,61 @@@ iomap_write_begin(struct inode *inode, 
  	return status;
  }
  
++<<<<<<< HEAD
++=======
+ int
+ iomap_set_page_dirty(struct page *page)
+ {
+ 	struct address_space *mapping = page_mapping(page);
+ 	int newly_dirty;
+ 
+ 	if (unlikely(!mapping))
+ 		return !TestSetPageDirty(page);
+ 
+ 	/*
+ 	 * Lock out page->mem_cgroup migration to keep PageDirty
+ 	 * synchronized with per-memcg dirty page counters.
+ 	 */
+ 	lock_page_memcg(page);
+ 	newly_dirty = !TestSetPageDirty(page);
+ 	if (newly_dirty)
+ 		__set_page_dirty(page, mapping, 0);
+ 	unlock_page_memcg(page);
+ 
+ 	if (newly_dirty)
+ 		__mark_inode_dirty(mapping->host, I_DIRTY_PAGES);
+ 	return newly_dirty;
+ }
+ EXPORT_SYMBOL_GPL(iomap_set_page_dirty);
+ 
+ static int
+ __iomap_write_end(struct inode *inode, loff_t pos, unsigned len,
+ 		unsigned copied, struct page *page, struct iomap *iomap)
+ {
+ 	flush_dcache_page(page);
+ 
+ 	/*
+ 	 * The blocks that were entirely written will now be uptodate, so we
+ 	 * don't have to worry about a readpage reading them and overwriting a
+ 	 * partial write.  However if we have encountered a short write and only
+ 	 * partially written into a block, it will not be marked uptodate, so a
+ 	 * readpage might come in and destroy our partial write.
+ 	 *
+ 	 * Do the simplest thing, and just treat any short write to a non
+ 	 * uptodate page as a zero-length write, and force the caller to redo
+ 	 * the whole thing.
+ 	 */
+ 	if (unlikely(copied < len && !PageUptodate(page)))
+ 		return 0;
+ 	iomap_set_range_uptodate(page, offset_in_page(pos), len);
+ 	iomap_set_page_dirty(page);
+ 	return copied;
+ }
+ 
++>>>>>>> dbc582b6fb6a (iomap: Clean up __generic_write_end calling)
  static int
  iomap_write_end_inline(struct inode *inode, struct page *page,
 -		struct iomap *iomap, loff_t pos, unsigned copied)
 +		struct iomap *iomap, loff_t pos, unsigned len, unsigned copied)
  {
  	void *addr;
  
@@@ -174,8 -751,6 +226,11 @@@
  	kunmap_atomic(addr);
  
  	mark_inode_dirty(inode);
++<<<<<<< HEAD
 +	__generic_write_end(NULL, inode->i_mapping, pos, len, copied, page,
 +			NULL);
++=======
++>>>>>>> dbc582b6fb6a (iomap: Clean up __generic_write_end calling)
  	return copied;
  }
  
@@@ -186,13 -761,15 +241,23 @@@ iomap_write_end(struct inode *inode, lo
  	int ret;
  
  	if (iomap->type == IOMAP_INLINE) {
++<<<<<<< HEAD
 +		ret = iomap_write_end_inline(inode, page, iomap, pos, len,
 +				copied);
 +	} else {
 +		ret = generic_write_end(NULL, inode->i_mapping, pos, len,
 +				copied, page, NULL);
++=======
+ 		ret = iomap_write_end_inline(inode, page, iomap, pos, copied);
+ 	} else if (iomap->flags & IOMAP_F_BUFFER_HEAD) {
+ 		ret = block_write_end(NULL, inode->i_mapping, pos, len, copied,
+ 				page, NULL);
+ 	} else {
+ 		ret = __iomap_write_end(inode, pos, len, copied, page, iomap);
++>>>>>>> dbc582b6fb6a (iomap: Clean up __generic_write_end calling)
  	}
  
+ 	ret = __generic_write_end(inode, pos, ret, page);
  	if (iomap->page_done)
  		iomap->page_done(inode, pos, copied, page, iomap);
  
* Unmerged path fs/iomap.c
