percpu: combine percpu address checks

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Dennis Zhou (Facebook) <dennisszhou@gmail.com>
commit 560f2c23666853b31acc32c892d44f5b14d258de
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/560f2c23.failed

The percpu address checks for the reserved and dynamic region chunks are
now specific to each region. The address checking logic can be combined
taking advantage of the global references to the dynamic and static
region chunks.

	Signed-off-by: Dennis Zhou <dennisszhou@gmail.com>
	Reviewed-by: Josef Bacik <jbacik@fb.com>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 560f2c23666853b31acc32c892d44f5b14d258de)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/percpu.c
diff --cc mm/percpu.c
index 3c1f6f694380,5b1fcefdc386..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -190,19 -181,26 +190,42 @@@ static void pcpu_schedule_balance_work(
  		schedule_work(&pcpu_balance_work);
  }
  
++<<<<<<< HEAD
 +static bool pcpu_addr_in_first_chunk(void *addr)
 +{
 +	void *first_start = pcpu_first_chunk->base_addr;
 +
 +	return addr >= first_start && addr < first_start + pcpu_unit_size;
 +}
 +
 +static bool pcpu_addr_in_reserved_chunk(void *addr)
++=======
+ /**
+  * pcpu_addr_in_chunk - check if the address is served from this chunk
+  * @chunk: chunk of interest
+  * @addr: percpu address
+  *
+  * RETURNS:
+  * True if the address is served from this chunk.
+  */
+ static bool pcpu_addr_in_chunk(struct pcpu_chunk *chunk, void *addr)
++>>>>>>> 560f2c236668 (percpu: combine percpu address checks)
  {
 -	void *start_addr, *end_addr;
 +	void *first_start = pcpu_first_chunk->base_addr;
  
++<<<<<<< HEAD
 +	return addr >= first_start &&
 +		addr < first_start + pcpu_reserved_chunk_limit;
++=======
+ 	if (!chunk)
+ 		return false;
+ 
+ 	start_addr = chunk->base_addr + chunk->start_offset;
+ 	end_addr = chunk->base_addr + chunk->nr_pages * PAGE_SIZE -
+ 		   chunk->end_offset;
+ 
+ 	return addr >= start_addr && addr < end_addr;
++>>>>>>> 560f2c236668 (percpu: combine percpu address checks)
  }
  
  static int __pcpu_size_to_slot(int size)
@@@ -837,13 -899,13 +860,23 @@@ static int __init pcpu_verify_alloc_inf
   */
  static struct pcpu_chunk *pcpu_chunk_addr_search(void *addr)
  {
++<<<<<<< HEAD
 +	/* is it in the first chunk? */
 +	if (pcpu_addr_in_first_chunk(addr)) {
 +		/* is it in the reserved area? */
 +		if (pcpu_addr_in_reserved_chunk(addr))
 +			return pcpu_reserved_chunk;
 +		return pcpu_first_chunk;
 +	}
++=======
+ 	/* is it in the dynamic region (first chunk)? */
+ 	if (pcpu_addr_in_chunk(pcpu_first_chunk, addr))
+ 		return pcpu_first_chunk;
+ 
+ 	/* is it in the reserved region? */
+ 	if (pcpu_addr_in_chunk(pcpu_reserved_chunk, addr))
+ 		return pcpu_reserved_chunk;
++>>>>>>> 560f2c236668 (percpu: combine percpu address checks)
  
  	/*
  	 * The address is relative to unit0 which might be unused and
* Unmerged path mm/percpu.c
