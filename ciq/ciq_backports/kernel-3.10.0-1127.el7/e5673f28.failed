sched/fair: Remove double_lock_balance() from active_load_balance_cpu_stop()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Kirill Tkhai <ktkhai@parallels.com>
commit e5673f280501298dbb56efa46e333cf64ee5080a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/e5673f28.failed

Avoid double_rq_lock() and use the TASK_ON_RQ_MIGRATING state for
active_load_balance_cpu_stop(). The advantage is (obviously) not
holding two 'rq->lock's at the same time and thereby increasing
parallelism.

Further note that if there was no task to migrate we will not
have acquired the second rq->lock at all.

The important point to note is that because we acquire dst->lock
immediately after releasing src->lock the potential wait time of
task_rq_lock() callers on TASK_ON_RQ_MIGRATING is not longer
than it would have been in the double rq lock scenario.

	Signed-off-by: Kirill Tkhai <ktkhai@parallels.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Paul Turner <pjt@google.com>
	Cc: Oleg Nesterov <oleg@redhat.com>
	Cc: Steven Rostedt <rostedt@goodmis.org>
	Cc: Mike Galbraith <umgwanakikbuti@gmail.com>
	Cc: Kirill Tkhai <tkhai@yandex.ru>
	Cc: Tim Chen <tim.c.chen@linux.intel.com>
	Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
Link: http://lkml.kernel.org/r/1408528081.23412.92.camel@tkhai
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit e5673f280501298dbb56efa46e333cf64ee5080a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/fair.c
diff --cc kernel/sched/fair.c
index c68fec18dead,7e5cf051c144..000000000000
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@@ -5442,17 -5361,34 +5448,38 @@@ static struct task_struct *detach_one_t
  		if (!can_migrate_task(p, env))
  			continue;
  
++<<<<<<< HEAD
 +		move_task(p, env);
++=======
+ 		deactivate_task(env->src_rq, p, 0);
+ 		p->on_rq = TASK_ON_RQ_MIGRATING;
+ 		set_task_cpu(p, env->dst_cpu);
++>>>>>>> e5673f280501 (sched/fair: Remove double_lock_balance() from active_load_balance_cpu_stop())
  
  		/*
- 		 * Right now, this is only the second place move_task()
- 		 * is called, so we can safely collect move_task()
- 		 * stats here rather than inside move_task().
+ 		 * Right now, this is only the second place where
+ 		 * lb_gained[env->idle] is updated (other is move_tasks)
+ 		 * so we can safely collect stats here rather than
+ 		 * inside move_tasks().
  		 */
  		schedstat_inc(env->sd, lb_gained[env->idle]);
- 		return 1;
+ 		return p;
  	}
- 	return 0;
+ 	return NULL;
+ }
+ 
+ /*
+  * attach_one_task() -- attaches the task returned from detach_one_task() to
+  * its new rq.
+  */
+ static void attach_one_task(struct rq *rq, struct task_struct *p)
+ {
+ 	raw_spin_lock(&rq->lock);
+ 	BUG_ON(task_rq(p) != rq);
+ 	p->on_rq = TASK_ON_RQ_QUEUED;
+ 	activate_task(rq, p, 0);
+ 	check_preempt_curr(rq, p, 0);
+ 	raw_spin_unlock(&rq->lock);
  }
  
  static const unsigned int sched_nr_migrate_break = 32;
* Unmerged path kernel/sched/fair.c
