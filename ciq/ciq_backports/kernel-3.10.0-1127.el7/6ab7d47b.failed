percpu: convert spin_lock_irq to spin_lock_irqsave.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
Rebuild_CHGLOG: - [mm] percpu: convert spin_lock_irq to spin_lock_irqsave (Rafael Aquini) [1730471]
Rebuild_FUZZ: 99.01%
commit-author Dennis Zhou <dennis@kernel.org>
commit 6ab7d47bcbf0144a8cb81536c2cead4cde18acfe
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/6ab7d47b.failed

From Michael Cree:
  "Bisection lead to commit b38d08f3181c ("percpu: restructure
   locking") as being the cause of lockups at initial boot on
   the kernel built for generic Alpha.

   On a suggestion by Tejun Heo that:

   So, the only thing I can think of is that it's calling
   spin_unlock_irq() while irq handling isn't set up yet.
   Can you please try the followings?

   1. Convert all spin_[un]lock_irq() to
      spin_lock_irqsave/unlock_irqrestore()."

Fixes: b38d08f3181c ("percpu: restructure locking")
Reported-and-tested-by: Michael Cree <mcree@orcon.net.nz>
	Acked-by: Tejun Heo <tj@kernel.org>
	Signed-off-by: Dennis Zhou <dennis@kernel.org>
(cherry picked from commit 6ab7d47bcbf0144a8cb81536c2cead4cde18acfe)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/percpu-km.c
diff --cc mm/percpu-km.c
index 10e3d0b8a86d,0f643dc2dc65..000000000000
--- a/mm/percpu-km.c
+++ b/mm/percpu-km.c
@@@ -50,9 -50,10 +50,10 @@@ static struct pcpu_chunk *pcpu_create_c
  	const int nr_pages = pcpu_group_sizes[0] >> PAGE_SHIFT;
  	struct pcpu_chunk *chunk;
  	struct page *pages;
+ 	unsigned long flags;
  	int i;
  
 -	chunk = pcpu_alloc_chunk(gfp);
 +	chunk = pcpu_alloc_chunk();
  	if (!chunk)
  		return NULL;
  
@@@ -68,9 -69,12 +69,15 @@@
  	chunk->data = pages;
  	chunk->base_addr = page_address(pages) - pcpu_group_offsets[0];
  
++<<<<<<< HEAD
 +	spin_lock_irq(&pcpu_lock);
 +	pcpu_chunk_populated(chunk, 0, nr_pages);
 +	spin_unlock_irq(&pcpu_lock);
++=======
+ 	spin_lock_irqsave(&pcpu_lock, flags);
+ 	pcpu_chunk_populated(chunk, 0, nr_pages, false);
+ 	spin_unlock_irqrestore(&pcpu_lock, flags);
 -
 -	pcpu_stats_chunk_alloc();
 -	trace_percpu_create_chunk(chunk->base_addr);
++>>>>>>> 6ab7d47bcbf0 (percpu: convert spin_lock_irq to spin_lock_irqsave.)
  
  	return chunk;
  }
* Unmerged path mm/percpu-km.c
