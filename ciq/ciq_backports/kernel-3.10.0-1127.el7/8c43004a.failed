percpu: do not search past bitmap when allocating an area

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Dennis Zhou <dennis@kernel.org>
commit 8c43004af01635cc9fbb11031d070e5e0d327ef2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/8c43004a.failed

pcpu_find_block_fit() guarantees that a fit is found within
PCPU_BITMAP_BLOCK_BITS. Iteration is used to determine the first fit as
it compares against the block's contig_hint. This can lead to
incorrectly scanning past the end of the bitmap. The behavior was okay
given the check after for bit_off >= end and the correctness of the
hints from pcpu_find_block_fit().

This patch fixes this by bounding the end offset by the number of bits
in a chunk.

	Signed-off-by: Dennis Zhou <dennis@kernel.org>
	Reviewed-by: Peng Fan <peng.fan@nxp.com>
(cherry picked from commit 8c43004af01635cc9fbb11031d070e5e0d327ef2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/percpu.c
diff --cc mm/percpu.c
index 60a1f468f968,769b7583975b..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -677,55 -983,209 +677,67 @@@ static void pcpu_free_area(struct pcpu_
  
  	lockdep_assert_held(&pcpu_lock);
  
 -	oslot = pcpu_chunk_slot(chunk);
 -
 +	freeme |= 1;	/* we are searching for <given offset, in use> pair */
 +
++<<<<<<< HEAD
 +	i = 0;
 +	j = chunk->map_used;
 +	while (i != j) {
 +		unsigned k = (i + j) / 2;
 +		off = chunk->map[k];
 +		if (off < freeme)
 +			i = k + 1;
 +		else if (off > freeme)
 +			j = k;
 +		else
 +			i = j = k;
 +	}
 +	BUG_ON(off != freeme);
++=======
+ 	/*
+ 	 * Search to find a fit.
+ 	 */
+ 	end = min_t(int, start + alloc_bits + PCPU_BITMAP_BLOCK_BITS,
+ 		    pcpu_chunk_map_bits(chunk));
+ 	bit_off = bitmap_find_next_zero_area(chunk->alloc_map, end, start,
+ 					     alloc_bits, align_mask);
+ 	if (bit_off >= end)
+ 		return -1;
++>>>>>>> 8c43004af016 (percpu: do not search past bitmap when allocating an area)
  
 -	/* update alloc map */
 -	bitmap_set(chunk->alloc_map, bit_off, alloc_bits);
 -
 -	/* update boundary map */
 -	set_bit(bit_off, chunk->bound_map);
 -	bitmap_clear(chunk->bound_map, bit_off + 1, alloc_bits - 1);
 -	set_bit(bit_off + alloc_bits, chunk->bound_map);
 -
 -	chunk->free_bytes -= alloc_bits * PCPU_MIN_ALLOC_SIZE;
 -
 -	/* update first free bit */
 -	if (bit_off == chunk->first_bit)
 -		chunk->first_bit = find_next_zero_bit(
 -					chunk->alloc_map,
 -					pcpu_chunk_map_bits(chunk),
 -					bit_off + alloc_bits);
 -
 -	pcpu_block_update_hint_alloc(chunk, bit_off, alloc_bits);
 -
 -	pcpu_chunk_relocate(chunk, oslot);
 -
 -	return bit_off * PCPU_MIN_ALLOC_SIZE;
 -}
 -
 -/**
 - * pcpu_free_area - frees the corresponding offset
 - * @chunk: chunk of interest
 - * @off: addr offset into chunk
 - *
 - * This function determines the size of an allocation to free using
 - * the boundary bitmap and clears the allocation map.
 - */
 -static void pcpu_free_area(struct pcpu_chunk *chunk, int off)
 -{
 -	int bit_off, bits, end, oslot;
 -
 -	lockdep_assert_held(&pcpu_lock);
 -	pcpu_stats_area_dealloc(chunk);
 -
 -	oslot = pcpu_chunk_slot(chunk);
 +	if (i < chunk->first_free)
 +		chunk->first_free = i;
  
 -	bit_off = off / PCPU_MIN_ALLOC_SIZE;
 +	p = chunk->map + i;
 +	*p = off &= ~1;
 +	chunk->free_size += (p[1] & ~1) - off;
  
 -	/* find end index */
 -	end = find_next_bit(chunk->bound_map, pcpu_chunk_map_bits(chunk),
 -			    bit_off + 1);
 -	bits = end - bit_off;
 -	bitmap_clear(chunk->alloc_map, bit_off, bits);
 -
 -	/* update metadata */
 -	chunk->free_bytes += bits * PCPU_MIN_ALLOC_SIZE;
 -
 -	/* update first free bit */
 -	chunk->first_bit = min(chunk->first_bit, bit_off);
 -
 -	pcpu_block_update_hint_free(chunk, bit_off, bits);
 -
 -	pcpu_chunk_relocate(chunk, oslot);
 -}
 +	*occ_pages_p = pcpu_count_occupied_pages(chunk, i);
  
 -static void pcpu_init_md_blocks(struct pcpu_chunk *chunk)
 -{
 -	struct pcpu_block_md *md_block;
 -
 -	for (md_block = chunk->md_blocks;
 -	     md_block != chunk->md_blocks + pcpu_chunk_nr_blocks(chunk);
 -	     md_block++) {
 -		md_block->contig_hint = PCPU_BITMAP_BLOCK_BITS;
 -		md_block->left_free = PCPU_BITMAP_BLOCK_BITS;
 -		md_block->right_free = PCPU_BITMAP_BLOCK_BITS;
 -	}
 -}
 -
 -/**
 - * pcpu_alloc_first_chunk - creates chunks that serve the first chunk
 - * @tmp_addr: the start of the region served
 - * @map_size: size of the region served
 - *
 - * This is responsible for creating the chunks that serve the first chunk.  The
 - * base_addr is page aligned down of @tmp_addr while the region end is page
 - * aligned up.  Offsets are kept track of to determine the region served. All
 - * this is done to appease the bitmap allocator in avoiding partial blocks.
 - *
 - * RETURNS:
 - * Chunk serving the region at @tmp_addr of @map_size.
 - */
 -static struct pcpu_chunk * __init pcpu_alloc_first_chunk(unsigned long tmp_addr,
 -							 int map_size)
 -{
 -	struct pcpu_chunk *chunk;
 -	unsigned long aligned_addr, lcm_align;
 -	int start_offset, offset_bits, region_size, region_bits;
 -	size_t alloc_size;
 -
 -	/* region calculations */
 -	aligned_addr = tmp_addr & PAGE_MASK;
 -
 -	start_offset = tmp_addr - aligned_addr;
 -
 -	/*
 -	 * Align the end of the region with the LCM of PAGE_SIZE and
 -	 * PCPU_BITMAP_BLOCK_SIZE.  One of these constants is a multiple of
 -	 * the other.
 -	 */
 -	lcm_align = lcm(PAGE_SIZE, PCPU_BITMAP_BLOCK_SIZE);
 -	region_size = ALIGN(start_offset + map_size, lcm_align);
 -
 -	/* allocate chunk */
 -	alloc_size = sizeof(struct pcpu_chunk) +
 -		BITS_TO_LONGS(region_size >> PAGE_SHIFT);
 -	chunk = memblock_alloc(alloc_size, SMP_CACHE_BYTES);
 -	if (!chunk)
 -		panic("%s: Failed to allocate %zu bytes\n", __func__,
 -		      alloc_size);
 -
 -	INIT_LIST_HEAD(&chunk->list);
 -
 -	chunk->base_addr = (void *)aligned_addr;
 -	chunk->start_offset = start_offset;
 -	chunk->end_offset = region_size - chunk->start_offset - map_size;
 -
 -	chunk->nr_pages = region_size >> PAGE_SHIFT;
 -	region_bits = pcpu_chunk_map_bits(chunk);
 -
 -	alloc_size = BITS_TO_LONGS(region_bits) * sizeof(chunk->alloc_map[0]);
 -	chunk->alloc_map = memblock_alloc(alloc_size, SMP_CACHE_BYTES);
 -	if (!chunk->alloc_map)
 -		panic("%s: Failed to allocate %zu bytes\n", __func__,
 -		      alloc_size);
 -
 -	alloc_size =
 -		BITS_TO_LONGS(region_bits + 1) * sizeof(chunk->bound_map[0]);
 -	chunk->bound_map = memblock_alloc(alloc_size, SMP_CACHE_BYTES);
 -	if (!chunk->bound_map)
 -		panic("%s: Failed to allocate %zu bytes\n", __func__,
 -		      alloc_size);
 -
 -	alloc_size = pcpu_chunk_nr_blocks(chunk) * sizeof(chunk->md_blocks[0]);
 -	chunk->md_blocks = memblock_alloc(alloc_size, SMP_CACHE_BYTES);
 -	if (!chunk->md_blocks)
 -		panic("%s: Failed to allocate %zu bytes\n", __func__,
 -		      alloc_size);
 -
 -	pcpu_init_md_blocks(chunk);
 -
 -	/* manage populated page bitmap */
 -	chunk->immutable = true;
 -	bitmap_fill(chunk->populated, chunk->nr_pages);
 -	chunk->nr_populated = chunk->nr_pages;
 -	chunk->nr_empty_pop_pages =
 -		pcpu_cnt_pop_pages(chunk, start_offset / PCPU_MIN_ALLOC_SIZE,
 -				   map_size / PCPU_MIN_ALLOC_SIZE);
 -
 -	chunk->contig_bits = map_size / PCPU_MIN_ALLOC_SIZE;
 -	chunk->free_bytes = map_size;
 -
 -	if (chunk->start_offset) {
 -		/* hide the beginning of the bitmap */
 -		offset_bits = chunk->start_offset / PCPU_MIN_ALLOC_SIZE;
 -		bitmap_set(chunk->alloc_map, 0, offset_bits);
 -		set_bit(0, chunk->bound_map);
 -		set_bit(offset_bits, chunk->bound_map);
 -
 -		chunk->first_bit = offset_bits;
 -
 -		pcpu_block_update_hint_alloc(chunk, 0, offset_bits);
 +	/* merge with next? */
 +	if (!(p[1] & 1))
 +		to_free++;
 +	/* merge with previous? */
 +	if (i > 0 && !(p[-1] & 1)) {
 +		to_free++;
 +		i--;
 +		p--;
  	}
 -
 -	if (chunk->end_offset) {
 -		/* hide the end of the bitmap */
 -		offset_bits = chunk->end_offset / PCPU_MIN_ALLOC_SIZE;
 -		bitmap_set(chunk->alloc_map,
 -			   pcpu_chunk_map_bits(chunk) - offset_bits,
 -			   offset_bits);
 -		set_bit((start_offset + map_size) / PCPU_MIN_ALLOC_SIZE,
 -			chunk->bound_map);
 -		set_bit(region_bits, chunk->bound_map);
 -
 -		pcpu_block_update_hint_alloc(chunk, pcpu_chunk_map_bits(chunk)
 -					     - offset_bits, offset_bits);
 +	if (to_free) {
 +		chunk->map_used -= to_free;
 +		memmove(p + 1, p + 1 + to_free,
 +			(chunk->map_used - i) * sizeof(chunk->map[0]));
  	}
  
 -	return chunk;
 +	chunk->contig_hint = max(chunk->map[i + 1] - chunk->map[i] - 1, chunk->contig_hint);
 +	pcpu_chunk_relocate(chunk, oslot);
  }
  
 -static struct pcpu_chunk *pcpu_alloc_chunk(gfp_t gfp)
 +static struct pcpu_chunk *pcpu_alloc_chunk(void)
  {
  	struct pcpu_chunk *chunk;
 -	int region_bits;
  
 -	chunk = pcpu_mem_zalloc(pcpu_chunk_struct_size, gfp);
 +	chunk = pcpu_mem_zalloc(pcpu_chunk_struct_size);
  	if (!chunk)
  		return NULL;
  
* Unmerged path mm/percpu.c
