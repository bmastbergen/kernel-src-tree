cpu/speculation: Uninline and export CPU mitigations helpers

jira LE-1907
cve CVE-2018-12207
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Tyler Hicks <tyhicks@canonical.com>
commit 731dc9df975a5da21237a18c3384f811a7a41cc6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/731dc9df.failed

A kernel module may need to check the value of the "mitigations=" kernel
command line parameter as part of its setup when the module needs
to perform software mitigations for a CPU flaw.

Uninline and export the helper functions surrounding the cpu_mitigations
enum to allow for their usage from a module.

Lastly, privatize the enum and cpu_mitigations variable since the value of
cpu_mitigations can be checked with the exported helper functions.

	Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

(cherry picked from commit 731dc9df975a5da21237a18c3384f811a7a41cc6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/cpu.c
diff --cc kernel/cpu.c
index 597b346fd51e,e2cad3ee2ead..000000000000
--- a/kernel/cpu.c
+++ b/kernel/cpu.c
@@@ -996,84 -2289,102 +996,99 @@@ const DECLARE_BITMAP(cpu_all_bits, NR_C
  EXPORT_SYMBOL(cpu_all_bits);
  
  #ifdef CONFIG_INIT_ALL_POSSIBLE
 -struct cpumask __cpu_possible_mask __read_mostly
 -	= {CPU_BITS_ALL};
 +static DECLARE_BITMAP(cpu_possible_bits, CONFIG_NR_CPUS) __read_mostly
 +	= CPU_BITS_ALL;
  #else
 -struct cpumask __cpu_possible_mask __read_mostly;
 +static DECLARE_BITMAP(cpu_possible_bits, CONFIG_NR_CPUS) __read_mostly;
  #endif
 -EXPORT_SYMBOL(__cpu_possible_mask);
 +const struct cpumask *const cpu_possible_mask = to_cpumask(cpu_possible_bits);
 +EXPORT_SYMBOL(cpu_possible_mask);
  
 -struct cpumask __cpu_online_mask __read_mostly;
 -EXPORT_SYMBOL(__cpu_online_mask);
 +static DECLARE_BITMAP(cpu_online_bits, CONFIG_NR_CPUS) __read_mostly;
 +const struct cpumask *const cpu_online_mask = to_cpumask(cpu_online_bits);
 +EXPORT_SYMBOL(cpu_online_mask);
  
 -struct cpumask __cpu_present_mask __read_mostly;
 -EXPORT_SYMBOL(__cpu_present_mask);
 +static DECLARE_BITMAP(cpu_present_bits, CONFIG_NR_CPUS) __read_mostly;
 +const struct cpumask *const cpu_present_mask = to_cpumask(cpu_present_bits);
 +EXPORT_SYMBOL(cpu_present_mask);
  
 -struct cpumask __cpu_active_mask __read_mostly;
 -EXPORT_SYMBOL(__cpu_active_mask);
 +static DECLARE_BITMAP(cpu_active_bits, CONFIG_NR_CPUS) __read_mostly;
 +const struct cpumask *const cpu_active_mask = to_cpumask(cpu_active_bits);
 +EXPORT_SYMBOL(cpu_active_mask);
  
 -atomic_t __num_online_cpus __read_mostly;
 -EXPORT_SYMBOL(__num_online_cpus);
 +void set_cpu_possible(unsigned int cpu, bool possible)
 +{
 +	if (possible)
 +		cpumask_set_cpu(cpu, to_cpumask(cpu_possible_bits));
 +	else
 +		cpumask_clear_cpu(cpu, to_cpumask(cpu_possible_bits));
 +}
  
 -void init_cpu_present(const struct cpumask *src)
 +void set_cpu_present(unsigned int cpu, bool present)
  {
 -	cpumask_copy(&__cpu_present_mask, src);
 +	if (present)
 +		cpumask_set_cpu(cpu, to_cpumask(cpu_present_bits));
 +	else
 +		cpumask_clear_cpu(cpu, to_cpumask(cpu_present_bits));
  }
  
 -void init_cpu_possible(const struct cpumask *src)
 +void set_cpu_online(unsigned int cpu, bool online)
  {
 -	cpumask_copy(&__cpu_possible_mask, src);
 +	if (online)
 +		cpumask_set_cpu(cpu, to_cpumask(cpu_online_bits));
 +	else
 +		cpumask_clear_cpu(cpu, to_cpumask(cpu_online_bits));
  }
  
 -void init_cpu_online(const struct cpumask *src)
 +void set_cpu_active(unsigned int cpu, bool active)
  {
 -	cpumask_copy(&__cpu_online_mask, src);
 +	if (active)
 +		cpumask_set_cpu(cpu, to_cpumask(cpu_active_bits));
 +	else
 +		cpumask_clear_cpu(cpu, to_cpumask(cpu_active_bits));
  }
  
 -void set_cpu_online(unsigned int cpu, bool online)
 +void reset_cpu_possible_mask(void)
  {
 -	/*
 -	 * atomic_inc/dec() is required to handle the horrid abuse of this
 -	 * function by the reboot and kexec code which invoke it from
 -	 * IPI/NMI broadcasts when shutting down CPUs. Invocation from
 -	 * regular CPU hotplug is properly serialized.
 -	 *
 -	 * Note, that the fact that __num_online_cpus is of type atomic_t
 -	 * does not protect readers which are not serialized against
 -	 * concurrent hotplug operations.
 -	 */
 -	if (online) {
 -		if (!cpumask_test_and_set_cpu(cpu, &__cpu_online_mask))
 -			atomic_inc(&__num_online_cpus);
 -	} else {
 -		if (cpumask_test_and_clear_cpu(cpu, &__cpu_online_mask))
 -			atomic_dec(&__num_online_cpus);
 -	}
 +	bitmap_zero(cpu_possible_bits, NR_CPUS);
  }
  
 -/*
 - * Activate the first processor.
 - */
 -void __init boot_cpu_init(void)
++<<<<<<< HEAD
 +void init_cpu_present(const struct cpumask *src)
  {
 -	int cpu = smp_processor_id();
 +	cpumask_copy(to_cpumask(cpu_present_bits), src);
 +}
  
 -	/* Mark the boot cpu "present", "online" etc for SMP and UP case */
 -	set_cpu_online(cpu, true);
 -	set_cpu_active(cpu, true);
 -	set_cpu_present(cpu, true);
 -	set_cpu_possible(cpu, true);
 +void init_cpu_possible(const struct cpumask *src)
 +{
 +	cpumask_copy(to_cpumask(cpu_possible_bits), src);
 +}
  
 -#ifdef CONFIG_SMP
 -	__boot_cpu_id = cpu;
 -#endif
 +void init_cpu_online(const struct cpumask *src)
 +{
 +	cpumask_copy(to_cpumask(cpu_online_bits), src);
  }
  
 -/*
 - * Must be called _AFTER_ setting up the per_cpu areas
 - */
 -void __init boot_cpu_hotplug_init(void)
 +void __init boot_cpu_state_init(void)
  {
 -#ifdef CONFIG_SMP
 -	cpumask_set_cpu(smp_processor_id(), &cpus_booted_once_mask);
 -#endif
 -	this_cpu_write(cpuhp_state.state, CPUHP_ONLINE);
 +	this_cpu_write(booted_once, true);
  }
  
 +enum cpu_mitigations cpu_mitigations = CPU_MITIGATIONS_AUTO;
++=======
+ /*
+  * These are used for a global "mitigations=" cmdline option for toggling
+  * optional CPU mitigations.
+  */
+ enum cpu_mitigations {
+ 	CPU_MITIGATIONS_OFF,
+ 	CPU_MITIGATIONS_AUTO,
+ 	CPU_MITIGATIONS_AUTO_NOSMT,
+ };
+ 
+ static enum cpu_mitigations cpu_mitigations __ro_after_init =
+ 	CPU_MITIGATIONS_AUTO;
++>>>>>>> 731dc9df975a (cpu/speculation: Uninline and export CPU mitigations helpers)
  
  static int __init mitigations_parse_cmdline(char *arg)
  {
diff --git a/include/linux/cpu.h b/include/linux/cpu.h
index 6fecb3df2476..7a586d30fc51 100644
--- a/include/linux/cpu.h
+++ b/include/linux/cpu.h
@@ -325,28 +325,7 @@ bool cpu_smt_allowed(unsigned int cpu);
 static inline bool cpu_smt_allowed(unsigned int cpu) { return true; }
 #endif
 
-/*
- * These are used for a global "mitigations=" cmdline option for toggling
- * optional CPU mitigations.
- */
-enum cpu_mitigations {
-	CPU_MITIGATIONS_OFF,
-	CPU_MITIGATIONS_AUTO,
-	CPU_MITIGATIONS_AUTO_NOSMT,
-};
-
-extern enum cpu_mitigations cpu_mitigations;
-
-/* mitigations=off */
-static inline bool cpu_mitigations_off(void)
-{
-	return cpu_mitigations == CPU_MITIGATIONS_OFF;
-}
-
-/* mitigations=auto,nosmt */
-static inline bool cpu_mitigations_auto_nosmt(void)
-{
-	return cpu_mitigations == CPU_MITIGATIONS_AUTO_NOSMT;
-}
+extern bool cpu_mitigations_off(void);
+extern bool cpu_mitigations_auto_nosmt(void);
 
 #endif /* _LINUX_CPU_H_ */
* Unmerged path kernel/cpu.c
