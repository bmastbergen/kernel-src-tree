xfs: fall back to vmalloc when allocation log vector buffers

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Dave Chinner <dchinner@redhat.com>
commit cb0a8d23024e7bd234dea4d0fc5c4902a8dda766
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/cb0a8d23.failed

When using large directory blocks, we regularly see memory
allocations of >64k being made for the shadow log vector buffer.
When we are under memory pressure, kmalloc() may not be able to find
contiguous memory chunks large enough to satisfy these allocations
easily, and if memory is fragmented we can potentially stall here.

TO avoid this problem, switch the log vector buffer allocation to
use kmem_alloc_large(). This will allow failed allocations to fall
back to vmalloc and so remove the dependency on large contiguous
regions of memory being available. This should prevent slowdowns
and potential stalls when memory is low and/or fragmented.

Signed-Off-By: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
(cherry picked from commit cb0a8d23024e7bd234dea4d0fc5c4902a8dda766)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/kmem.c
diff --cc fs/xfs/kmem.c
index bb2beaef531a,7bace03dc9dc..000000000000
--- a/fs/xfs/kmem.c
+++ b/fs/xfs/kmem.c
@@@ -45,9 -46,9 +45,9 @@@ kmem_alloc(size_t size, xfs_km_flags_t 
  }
  
  void *
- kmem_zalloc_large(size_t size, xfs_km_flags_t flags)
+ kmem_alloc_large(size_t size, xfs_km_flags_t flags)
  {
 -	unsigned nofs_flag = 0;
 +	unsigned noio_flag = 0;
  	void	*ptr;
  	gfp_t	lflags;
  
@@@ -59,17 -60,17 +59,21 @@@
  	 * __vmalloc() will allocate data pages and auxillary structures (e.g.
  	 * pagetables) with GFP_KERNEL, yet we may be under GFP_NOFS context
  	 * here. Hence we need to tell memory reclaim that we are in such a
 -	 * context via PF_MEMALLOC_NOFS to prevent memory reclaim re-entering
 +	 * context via PF_MEMALLOC_NOIO to prevent memory reclaim re-entering
  	 * the filesystem here and potentially deadlocking.
  	 */
 -	if (flags & KM_NOFS)
 -		nofs_flag = memalloc_nofs_save();
 +	if ((current->flags & PF_FSTRANS) || (flags & KM_NOFS))
 +		noio_flag = memalloc_noio_save();
  
  	lflags = kmem_flags_convert(flags);
++<<<<<<< HEAD
 +	ptr = __vmalloc(size, lflags | __GFP_HIGHMEM | __GFP_ZERO, PAGE_KERNEL);
++=======
+ 	ptr = __vmalloc(size, lflags, PAGE_KERNEL);
++>>>>>>> cb0a8d23024e (xfs: fall back to vmalloc when allocation log vector buffers)
  
 -	if (flags & KM_NOFS)
 -		memalloc_nofs_restore(nofs_flag);
 +	if ((current->flags & PF_FSTRANS) || (flags & KM_NOFS))
 +		memalloc_noio_restore(noio_flag);
  
  	return ptr;
  }
* Unmerged path fs/xfs/kmem.c
diff --git a/fs/xfs/kmem.h b/fs/xfs/kmem.h
index 4244f3ad8aa8..7e990756ab14 100644
--- a/fs/xfs/kmem.h
+++ b/fs/xfs/kmem.h
@@ -61,7 +61,7 @@ kmem_flags_convert(xfs_km_flags_t flags)
 }
 
 extern void *kmem_alloc(size_t, xfs_km_flags_t);
-extern void *kmem_zalloc_large(size_t size, xfs_km_flags_t);
+extern void *kmem_alloc_large(size_t size, xfs_km_flags_t);
 extern void *kmem_realloc(const void *, size_t, xfs_km_flags_t);
 static inline void  kmem_free(const void *ptr)
 {
@@ -75,6 +75,12 @@ kmem_zalloc(size_t size, xfs_km_flags_t flags)
 	return kmem_alloc(size, flags | KM_ZERO);
 }
 
+static inline void *
+kmem_zalloc_large(size_t size, xfs_km_flags_t flags)
+{
+	return kmem_alloc_large(size, flags | KM_ZERO);
+}
+
 /*
  * Zone interfaces
  */
diff --git a/fs/xfs/xfs_log_cil.c b/fs/xfs/xfs_log_cil.c
index 51ad7b35d578..01055d98a294 100644
--- a/fs/xfs/xfs_log_cil.c
+++ b/fs/xfs/xfs_log_cil.c
@@ -199,7 +199,7 @@ xlog_cil_alloc_shadow_bufs(
 			 */
 			kmem_free(lip->li_lv_shadow);
 
-			lv = kmem_alloc(buf_size, KM_SLEEP|KM_NOFS);
+			lv = kmem_alloc_large(buf_size, KM_SLEEP | KM_NOFS);
 			memset(lv, 0, xlog_cil_iovec_space(niovecs));
 
 			lv->lv_item = lip;
