mm, compaction: pass gfp mask to compact_control

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author David Rientjes <rientjes@google.com>
commit 6d7ce55940b6ecd463ca044ad241f0122d913293
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/6d7ce559.failed

struct compact_control currently converts the gfp mask to a migratetype,
but we need the entire gfp mask in a follow-up patch.

Pass the entire gfp mask as part of struct compact_control.

	Signed-off-by: David Rientjes <rientjes@google.com>
	Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
	Reviewed-by: Zhang Yanfei <zhangyanfei@cn.fujitsu.com>
	Acked-by: Minchan Kim <minchan@kernel.org>
	Acked-by: Mel Gorman <mgorman@suse.de>
	Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
	Cc: Michal Nazarewicz <mina86@mina86.com>
	Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
	Cc: Christoph Lameter <cl@linux.com>
	Cc: Rik van Riel <riel@redhat.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 6d7ce55940b6ecd463ca044ad241f0122d913293)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/compaction.c
diff --cc mm/compaction.c
index 261d5ca9d561,15163b4b35ab..000000000000
--- a/mm/compaction.c
+++ b/mm/compaction.c
@@@ -895,24 -977,63 +895,24 @@@ static isolate_migrate_t isolate_migrat
  	/* Only scan within a pageblock boundary */
  	end_pfn = ALIGN(low_pfn + 1, pageblock_nr_pages);
  
 -	/*
 -	 * Iterate over whole pageblocks until we find the first suitable.
 -	 * Do not cross the free scanner.
 -	 */
 -	for (; end_pfn <= cc->free_pfn;
 -			low_pfn = end_pfn, end_pfn += pageblock_nr_pages) {
 -
 -		/*
 -		 * This can potentially iterate a massively long zone with
 -		 * many pageblocks unsuitable, so periodically check if we
 -		 * need to schedule, or even abort async compaction.
 -		 */
 -		if (!(low_pfn % (SWAP_CLUSTER_MAX * pageblock_nr_pages))
 -						&& compact_should_abort(cc))
 -			break;
 -
 -		page = pageblock_pfn_to_page(low_pfn, end_pfn, zone);
 -		if (!page)
 -			continue;
 -
 -		/* If isolation recently failed, do not retry */
 -		if (!isolation_suitable(cc, page))
 -			continue;
 -
 -		/*
 -		 * For async compaction, also only scan in MOVABLE blocks.
 -		 * Async compaction is optimistic to see if the minimum amount
 -		 * of work satisfies the allocation.
 -		 */
 -		if (cc->mode == MIGRATE_ASYNC &&
 -		    !migrate_async_suitable(get_pageblock_migratetype(page)))
 -			continue;
 -
 -		/* Perform the isolation */
 -		low_pfn = isolate_migratepages_block(cc, low_pfn, end_pfn,
 -								isolate_mode);
 -
 -		if (!low_pfn || cc->contended)
 -			return ISOLATE_ABORT;
 -
 -		/*
 -		 * Either we isolated something and proceed with migration. Or
 -		 * we failed and compact_zone should decide if we should
 -		 * continue or not.
 -		 */
 -		break;
 +	/* Do not cross the free scanner or scan within a memory hole */
 +	if (end_pfn > cc->free_pfn || !pfn_valid(low_pfn)) {
 +		cc->migrate_pfn = end_pfn;
 +		return ISOLATE_NONE;
  	}
  
 -	acct_isolated(zone, cc);
 -	/* Record where migration scanner will be restarted */
 +	/* Perform the isolation */
 +	low_pfn = isolate_migratepages_range(zone, cc, low_pfn, end_pfn, false);
 +	if (!low_pfn || cc->contended)
 +		return ISOLATE_ABORT;
 +
  	cc->migrate_pfn = low_pfn;
  
 -	return cc->nr_migratepages ? ISOLATE_SUCCESS : ISOLATE_NONE;
 +	return ISOLATE_SUCCESS;
  }
  
- static int compact_finished(struct zone *zone,
- 			    struct compact_control *cc)
+ static int compact_finished(struct zone *zone, struct compact_control *cc,
+ 			    const int migratetype)
  {
  	unsigned int order;
  	unsigned long watermark;
@@@ -1019,6 -1145,8 +1019,11 @@@ static int compact_zone(struct zone *zo
  	int ret;
  	unsigned long start_pfn = zone->zone_start_pfn;
  	unsigned long end_pfn = zone_end_pfn(zone);
++<<<<<<< HEAD
++=======
+ 	const int migratetype = gfpflags_to_migratetype(cc->gfp_mask);
+ 	const bool sync = cc->mode != MIGRATE_ASYNC;
++>>>>>>> 6d7ce55940b6 (mm, compaction: pass gfp mask to compact_control)
  
  	ret = compaction_suitable(zone, cc->order);
  	switch (ret) {
@@@ -1052,13 -1180,16 +1057,18 @@@
  	}
  	if (cc->migrate_pfn < start_pfn || cc->migrate_pfn > end_pfn) {
  		cc->migrate_pfn = start_pfn;
 -		zone->compact_cached_migrate_pfn[0] = cc->migrate_pfn;
 -		zone->compact_cached_migrate_pfn[1] = cc->migrate_pfn;
 +		zone->compact_cached_migrate_pfn = cc->migrate_pfn;
  	}
  
 -	trace_mm_compaction_begin(start_pfn, cc->migrate_pfn, cc->free_pfn, end_pfn);
 -
  	migrate_prep_local();
  
++<<<<<<< HEAD
 +	while ((ret = compact_finished(zone, cc)) == COMPACT_CONTINUE) {
 +		unsigned long nr_migrate, nr_remaining;
++=======
+ 	while ((ret = compact_finished(zone, cc, migratetype)) ==
+ 						COMPACT_CONTINUE) {
++>>>>>>> 6d7ce55940b6 (mm, compaction: pass gfp mask to compact_control)
  		int err;
  
  		switch (isolate_migratepages(zone, cc)) {
@@@ -1116,9 -1244,9 +1126,9 @@@ static unsigned long compact_zone_order
  		.nr_freepages = 0,
  		.nr_migratepages = 0,
  		.order = order,
- 		.migratetype = gfpflags_to_migratetype(gfp_mask),
+ 		.gfp_mask = gfp_mask,
  		.zone = zone,
 -		.mode = mode,
 +		.sync = sync,
  	};
  	INIT_LIST_HEAD(&cc.freepages);
  	INIT_LIST_HEAD(&cc.migratepages);
* Unmerged path mm/compaction.c
diff --git a/mm/internal.h b/mm/internal.h
index af10783b4dc0..8e3bc8c717ff 100644
--- a/mm/internal.h
+++ b/mm/internal.h
@@ -131,7 +131,7 @@ struct compact_control {
 	bool finished_update_migrate;
 
 	int order;			/* order a direct compactor needs */
-	int migratetype;		/* MOVABLE, RECLAIMABLE etc */
+	const gfp_t gfp_mask;		/* gfp mask of a direct compactor */
 	struct zone *zone;
 	bool contended;			/* True if a lock was contended, or
 					 * need_resched() true during async
