blk-mq: remove blk_mq_complete_request_sync

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Ming Lei <ming.lei@redhat.com>
commit a87ccce0b5a06ee546931859fa62e10f1bce54f9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/a87ccce0.failed

blk_mq_tagset_wait_completed_request() has been applied for waiting
for completed request's fn, so not necessary to use
blk_mq_complete_request_sync() any more.

	Cc: Max Gurtovoy <maxg@mellanox.com>
	Cc: Sagi Grimberg <sagi@grimberg.me>
	Cc: Keith Busch <keith.busch@intel.com>
	Cc: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit a87ccce0b5a06ee546931859fa62e10f1bce54f9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
#	drivers/nvme/host/core.c
#	include/linux/blk-mq.h
diff --cc block/blk-mq.c
index 20c0772929d4,6968de9d7402..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -607,18 -652,9 +607,21 @@@ void blk_mq_complete_request(struct req
  }
  EXPORT_SYMBOL(blk_mq_complete_request);
  
++<<<<<<< HEAD
 +void blk_mq_complete_request_sync(struct request *rq, int error)
 +{
 +	if (!blk_mark_rq_complete(rq)) {
 +		rq->errors = error;
 +		__blk_mq_complete_request(rq, true);
 +	}
 +}
 +EXPORT_SYMBOL_GPL(blk_mq_complete_request_sync);
 +
++=======
++>>>>>>> a87ccce0b5a0 (blk-mq: remove blk_mq_complete_request_sync)
  int blk_mq_request_started(struct request *rq)
  {
 -	return blk_mq_rq_state(rq) != MQ_RQ_IDLE;
 +	return test_bit(REQ_ATOM_STARTED, &rq->atomic_flags);
  }
  EXPORT_SYMBOL_GPL(blk_mq_request_started);
  
diff --cc drivers/nvme/host/core.c
index aa80e92e846f,4ba374633dc8..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -254,12 -288,13 +254,18 @@@ void nvme_cancel_request(struct reques
  	dev_dbg_ratelimited(((struct nvme_ctrl *) data)->device,
  				"Cancelling I/O %d", req->tag);
  
 -	/* don't abort one completed request */
 -	if (blk_mq_request_completed(req))
 -		return true;
 +	status = NVME_SC_ABORT_REQ;
 +	if (blk_queue_dying(req->q))
 +		status |= NVME_SC_DNR;
 +	nvme_req(req)->status = status;
 +	blk_mq_complete_request_sync(req, 0);
  
++<<<<<<< HEAD
++=======
+ 	nvme_req(req)->status = NVME_SC_ABORT_REQ;
+ 	blk_mq_complete_request(req);
+ 	return true;
++>>>>>>> a87ccce0b5a0 (blk-mq: remove blk_mq_complete_request_sync)
  }
  EXPORT_SYMBOL_GPL(nvme_cancel_request);
  
diff --cc include/linux/blk-mq.h
index a446b71af41d,1cdd2788cfa6..000000000000
--- a/include/linux/blk-mq.h
+++ b/include/linux/blk-mq.h
@@@ -328,17 -298,15 +328,23 @@@ struct blk_mq_hw_ctx *blk_mq_alloc_sing
  int blk_mq_request_started(struct request *rq);
  int blk_mq_request_completed(struct request *rq);
  void blk_mq_start_request(struct request *rq);
 -void blk_mq_end_request(struct request *rq, blk_status_t error);
 -void __blk_mq_end_request(struct request *rq, blk_status_t error);
 +void blk_mq_end_request(struct request *rq, int error);
 +void __blk_mq_end_request(struct request *rq, int error);
  
  void blk_mq_requeue_request(struct request *rq, bool kick_requeue_list);
 +void blk_mq_add_to_requeue_list(struct request *rq, bool at_head,
 +				bool kick_requeue_list);
  void blk_mq_kick_requeue_list(struct request_queue *q);
  void blk_mq_delay_kick_requeue_list(struct request_queue *q, unsigned long msecs);
++<<<<<<< HEAD
 +void blk_mq_complete_request(struct request *rq, int error);
 +void blk_mq_complete_request_sync(struct request *rq, int error);
 +
++=======
+ bool blk_mq_complete_request(struct request *rq);
+ bool blk_mq_bio_list_merge(struct request_queue *q, struct list_head *list,
+ 			   struct bio *bio, unsigned int nr_segs);
++>>>>>>> a87ccce0b5a0 (blk-mq: remove blk_mq_complete_request_sync)
  bool blk_mq_queue_stopped(struct request_queue *q);
  void blk_mq_stop_hw_queue(struct blk_mq_hw_ctx *hctx);
  void blk_mq_start_hw_queue(struct blk_mq_hw_ctx *hctx);
* Unmerged path block/blk-mq.c
* Unmerged path drivers/nvme/host/core.c
* Unmerged path include/linux/blk-mq.h
