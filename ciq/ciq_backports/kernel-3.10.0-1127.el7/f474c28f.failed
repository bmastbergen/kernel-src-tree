powerpc/watchpoint: Restore NV GPRs while returning from exception

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
Rebuild_CHGLOG: - [powerpc] watchpoint: Restore NV GPRs while returning from exception (Steve Best) [1729856]
Rebuild_FUZZ: 93.55%
commit-author Ravi Bangoria <ravi.bangoria@linux.ibm.com>
commit f474c28fbcbe42faca4eb415172c07d76adcb819
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/f474c28f.failed

powerpc hardware triggers watchpoint before executing the instruction.
To make trigger-after-execute behavior, kernel emulates the
instruction. If the instruction is 'load something into non-volatile
register', exception handler should restore emulated register state
while returning back, otherwise there will be register state
corruption. eg, adding a watchpoint on a list can corrput the list:

  # cat /proc/kallsyms | grep kthread_create_list
  c00000000121c8b8 d kthread_create_list

Add watchpoint on kthread_create_list->prev:

  # perf record -e mem:0xc00000000121c8c0

Run some workload such that new kthread gets invoked. eg, I just
logged out from console:

  list_add corruption. next->prev should be prev (c000000001214e00), \
	but was c00000000121c8b8. (next=c00000000121c8b8).
  WARNING: CPU: 59 PID: 309 at lib/list_debug.c:25 __list_add_valid+0xb4/0xc0
  CPU: 59 PID: 309 Comm: kworker/59:0 Kdump: loaded Not tainted 5.1.0-rc7+ #69
  ...
  NIP __list_add_valid+0xb4/0xc0
  LR __list_add_valid+0xb0/0xc0
  Call Trace:
  __list_add_valid+0xb0/0xc0 (unreliable)
  __kthread_create_on_node+0xe0/0x260
  kthread_create_on_node+0x34/0x50
  create_worker+0xe8/0x260
  worker_thread+0x444/0x560
  kthread+0x160/0x1a0
  ret_from_kernel_thread+0x5c/0x70

List corruption happened because it uses 'load into non-volatile
register' instruction:

Snippet from __kthread_create_on_node:

  c000000000136be8:     addis   r29,r2,-19
  c000000000136bec:     ld      r29,31424(r29)
        if (!__list_add_valid(new, prev, next))
  c000000000136bf0:     mr      r3,r30
  c000000000136bf4:     mr      r5,r28
  c000000000136bf8:     mr      r4,r29
  c000000000136bfc:     bl      c00000000059a2f8 <__list_add_valid+0x8>

Register state from WARN_ON():

  GPR00: c00000000059a3a0 c000007ff23afb50 c000000001344e00 0000000000000075
  GPR04: 0000000000000000 0000000000000000 0000001852af8bc1 0000000000000000
  GPR08: 0000000000000001 0000000000000007 0000000000000006 00000000000004aa
  GPR12: 0000000000000000 c000007ffffeb080 c000000000137038 c000005ff62aaa00
  GPR16: 0000000000000000 0000000000000000 c000007fffbe7600 c000007fffbe7370
  GPR20: c000007fffbe7320 c000007fffbe7300 c000000001373a00 0000000000000000
  GPR24: fffffffffffffef7 c00000000012e320 c000007ff23afcb0 c000000000cb8628
  GPR28: c00000000121c8b8 c000000001214e00 c000007fef5b17e8 c000007fef5b17c0

Watchpoint hit at 0xc000000000136bec.

  addis   r29,r2,-19
   => r29 = 0xc000000001344e00 + (-19 << 16)
   => r29 = 0xc000000001214e00

  ld      r29,31424(r29)
   => r29 = *(0xc000000001214e00 + 31424)
   => r29 = *(0xc00000000121c8c0)

0xc00000000121c8c0 is where we placed a watchpoint and thus this
instruction was emulated by emulate_step. But because handle_dabr_fault
did not restore emulated register state, r29 still contains stale
value in above register state.

Fixes: 5aae8a5370802 ("powerpc, hw_breakpoints: Implement hw_breakpoints for 64-bit server processors")
	Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
	Cc: stable@vger.kernel.org # 2.6.36+
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit f474c28fbcbe42faca4eb415172c07d76adcb819)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/kernel/exceptions-64s.S
diff --cc arch/powerpc/kernel/exceptions-64s.S
index 5e43ccff7efa,4d4fd2ad5b7d..000000000000
--- a/arch/powerpc/kernel/exceptions-64s.S
+++ b/arch/powerpc/kernel/exceptions-64s.S
@@@ -539,739 -340,732 +539,799 @@@ BEGIN_FTR_SECTIO
  	andc	r11,r11,r10		/* Turn off MSR_ME */
  	b	1b
  	b	.	/* prevent speculative execution */
 +END_FTR_SECTION_IFSET(CPU_FTR_HVMODE)
  
 -TRAMP_REAL_BEGIN(machine_check_pSeries)
 +machine_check_pSeries:
  	.globl machine_check_fwnmi
  machine_check_fwnmi:
 +	HMT_MEDIUM_PPR_DISCARD
  	SET_SCRATCH0(r13)		/* save r13 */
  	EXCEPTION_PROLOG_0(PACA_EXMC)
 -BEGIN_FTR_SECTION
 -	b	machine_check_common_early
 -END_FTR_SECTION_IFCLR(CPU_FTR_HVMODE)
  machine_check_pSeries_0:
 -	EXCEPTION_PROLOG_1(PACA_EXMC, KVMTEST_PR, 0x200)
 -	/*
 -	 * MSR_RI is not enabled, because PACA_EXMC is being used, so a
 -	 * nested machine check corrupts it. machine_check_common enables
 -	 * MSR_RI.
 -	 */
 -	EXCEPTION_PROLOG_2_NORI(machine_check_common, EXC_STD)
 +	EXCEPTION_PROLOG_1(PACA_EXMC, KVMTEST, 0x200)
 +	EXCEPTION_PROLOG_PSERIES_1(machine_check_common, EXC_STD)
 +	KVM_HANDLER_SKIP(PACA_EXMC, EXC_STD, 0x200)
 +
 +	/* moved from 0x300 */
 +data_access_pSeries_OOL:
 +	EXCEPTION_PROLOG_PSERIES_OOL(PACA_EXGEN, data_access_common, EXC_STD,
 +				     KVMTEST, 0x300)
 +data_access_check_stab:
 +	GET_PACA(r13)
 +	std	r9,PACA_EXSLB+EX_R9(r13)
 +	std	r10,PACA_EXSLB+EX_R10(r13)
 +	mfspr	r10,SPRN_DAR
 +	mfspr	r9,SPRN_DSISR
 +	srdi	r10,r10,60
 +	rlwimi	r10,r9,16,0x20
 +#ifdef CONFIG_KVM_BOOK3S_PR_POSSIBLE
 +	lbz	r9,HSTATE_IN_GUEST(r13)
 +	rlwimi	r10,r9,8,0x300
 +#endif
 +	mfcr	r9
 +	cmpwi	r10,0x2c
 +	beq	do_stab_bolted_pSeries
 +	mtcrf	0x80,r9
 +	ld	r9,PACA_EXSLB+EX_R9(r13)
 +	ld	r10,PACA_EXSLB+EX_R10(r13)
 +	b	data_access_not_stab
 +do_stab_bolted_pSeries:
 +	std	r11,PACA_EXSLB+EX_R11(r13)
 +	std	r12,PACA_EXSLB+EX_R12(r13)
 +	GET_SCRATCH0(r10)
 +	std	r10,PACA_EXSLB+EX_R13(r13)
 +	EXCEPTION_PROLOG_PSERIES_1(do_stab_bolted, EXC_STD)
 +
 +	KVM_HANDLER_SKIP(PACA_EXGEN, EXC_STD, 0x300)
 +	KVM_HANDLER_SKIP(PACA_EXSLB, EXC_STD, 0x380)
 +	KVM_HANDLER_PR(PACA_EXGEN, EXC_STD, 0x400)
 +	KVM_HANDLER_PR(PACA_EXSLB, EXC_STD, 0x480)
 +	KVM_HANDLER_PR(PACA_EXGEN, EXC_STD, 0x900)
 +	KVM_HANDLER(PACA_EXGEN, EXC_HV, 0x982)
  
 -TRAMP_KVM_SKIP(PACA_EXMC, 0x200)
 +#ifdef CONFIG_PPC_DENORMALISATION
 +denorm_assist:
 +BEGIN_FTR_SECTION
 +/*
 + * To denormalise we need to move a copy of the register to itself.
 + * For POWER6 do that here for all FP regs.
 + */
 +	mfmsr	r10
 +	ori	r10,r10,(MSR_FP|MSR_FE0|MSR_FE1)
 +	xori	r10,r10,(MSR_FE0|MSR_FE1)
 +	mtmsrd	r10
 +	sync
  
 -EXC_COMMON_BEGIN(machine_check_common)
 -	/*
 -	 * Machine check is different because we use a different
 -	 * save area: PACA_EXMC instead of PACA_EXGEN.
 -	 */
 -	mfspr	r10,SPRN_DAR
 -	std	r10,PACA_EXMC+EX_DAR(r13)
 -	mfspr	r10,SPRN_DSISR
 -	stw	r10,PACA_EXMC+EX_DSISR(r13)
 -	EXCEPTION_PROLOG_COMMON(0x200, PACA_EXMC)
 -	FINISH_NAP
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	ld	r3,PACA_EXMC+EX_DAR(r13)
 -	lwz	r4,PACA_EXMC+EX_DSISR(r13)
 -	/* Enable MSR_RI when finished with PACA_EXMC */
 -	li	r10,MSR_RI
 -	mtmsrd 	r10,1
 -	std	r3,_DAR(r1)
 -	std	r4,_DSISR(r1)
 -	bl	save_nvgprs
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	machine_check_exception
 -	b	ret_from_except
 +#define FMR2(n)  fmr (n), (n) ; fmr n+1, n+1
 +#define FMR4(n)  FMR2(n) ; FMR2(n+2)
 +#define FMR8(n)  FMR4(n) ; FMR4(n+4)
 +#define FMR16(n) FMR8(n) ; FMR8(n+8)
 +#define FMR32(n) FMR16(n) ; FMR16(n+16)
 +	FMR32(0)
  
 -#define MACHINE_CHECK_HANDLER_WINDUP			\
 -	/* Clear MSR_RI before setting SRR0 and SRR1. */\
 -	li	r0,MSR_RI;				\
 -	mfmsr	r9;		/* get MSR value */	\
 -	andc	r9,r9,r0;				\
 -	mtmsrd	r9,1;		/* Clear MSR_RI */	\
 -	/* Move original SRR0 and SRR1 into the respective regs */	\
 -	ld	r9,_MSR(r1);				\
 -	mtspr	SPRN_SRR1,r9;				\
 -	ld	r3,_NIP(r1);				\
 -	mtspr	SPRN_SRR0,r3;				\
 -	ld	r9,_CTR(r1);				\
 -	mtctr	r9;					\
 -	ld	r9,_XER(r1);				\
 -	mtxer	r9;					\
 -	ld	r9,_LINK(r1);				\
 -	mtlr	r9;					\
 -	REST_GPR(0, r1);				\
 -	REST_8GPRS(2, r1);				\
 -	REST_GPR(10, r1);				\
 -	ld	r11,_CCR(r1);				\
 -	mtcr	r11;					\
 -	/* Decrement paca->in_mce. */			\
 -	lhz	r12,PACA_IN_MCE(r13);			\
 -	subi	r12,r12,1;				\
 -	sth	r12,PACA_IN_MCE(r13);			\
 -	REST_GPR(11, r1);				\
 -	REST_2GPRS(12, r1);				\
 -	/* restore original r1. */			\
 -	ld	r1,GPR1(r1)
 -
 -#ifdef CONFIG_PPC_P7_NAP
 +FTR_SECTION_ELSE
  /*
 - * This is an idle wakeup. Low level machine check has already been
 - * done. Queue the event then call the idle code to do the wake up.
 + * To denormalise we need to move a copy of the register to itself.
 + * For POWER7 do that here for the first 32 VSX registers only.
   */
 -EXC_COMMON_BEGIN(machine_check_idle_common)
 -	bl	machine_check_queue_event
 -
 -	/*
 -	 * We have not used any non-volatile GPRs here, and as a rule
 -	 * most exception code including machine check does not.
 -	 * Therefore PACA_NAPSTATELOST does not need to be set. Idle
 -	 * wakeup will restore volatile registers.
 -	 *
 -	 * Load the original SRR1 into r3 for pnv_powersave_wakeup_mce.
 -	 *
 -	 * Then decrement MCE nesting after finishing with the stack.
 -	 */
 -	ld	r3,_MSR(r1)
 -	ld	r4,_LINK(r1)
 -
 -	lhz	r11,PACA_IN_MCE(r13)
 -	subi	r11,r11,1
 -	sth	r11,PACA_IN_MCE(r13)
 -
 -	mtlr	r4
 -	rlwinm	r10,r3,47-31,30,31
 -	cmpwi	cr1,r10,2
 -	bltlr	cr1	/* no state loss, return to idle caller */
 -	b	idle_return_gpr_loss
 -#endif
 -	/*
 -	 * Handle machine check early in real mode. We come here with
 -	 * ME=1, MMU (IR=0 and DR=0) off and using MC emergency stack.
 -	 */
 -EXC_COMMON_BEGIN(machine_check_handle_early)
 -	std	r0,GPR0(r1)	/* Save r0 */
 -	EXCEPTION_PROLOG_COMMON_3(0x200)
 -	bl	save_nvgprs
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	machine_check_early
 -	std	r3,RESULT(r1)	/* Save result */
 -	ld	r12,_MSR(r1)
 -BEGIN_FTR_SECTION
 -	b	4f
 -END_FTR_SECTION_IFCLR(CPU_FTR_HVMODE)
 +	mfmsr	r10
 +	oris	r10,r10,MSR_VSX@h
 +	mtmsrd	r10
 +	sync
  
 -#ifdef	CONFIG_PPC_P7_NAP
 -	/*
 -	 * Check if thread was in power saving mode. We come here when any
 -	 * of the following is true:
 -	 * a. thread wasn't in power saving mode
 -	 * b. thread was in power saving mode with no state loss,
 -	 *    supervisor state loss or hypervisor state loss.
 -	 *
 -	 * Go back to nap/sleep/winkle mode again if (b) is true.
 -	 */
 -	BEGIN_FTR_SECTION
 -	rlwinm.	r11,r12,47-31,30,31
 -	bne	machine_check_idle_common
 -	END_FTR_SECTION_IFSET(CPU_FTR_HVMODE | CPU_FTR_ARCH_206)
 -#endif
 +#define XVCPSGNDP2(n) XVCPSGNDP(n,n,n) ; XVCPSGNDP(n+1,n+1,n+1)
 +#define XVCPSGNDP4(n) XVCPSGNDP2(n) ; XVCPSGNDP2(n+2)
 +#define XVCPSGNDP8(n) XVCPSGNDP4(n) ; XVCPSGNDP4(n+4)
 +#define XVCPSGNDP16(n) XVCPSGNDP8(n) ; XVCPSGNDP8(n+8)
 +#define XVCPSGNDP32(n) XVCPSGNDP16(n) ; XVCPSGNDP16(n+16)
 +	XVCPSGNDP32(0)
  
 -	/*
 -	 * Check if we are coming from hypervisor userspace. If yes then we
 -	 * continue in host kernel in V mode to deliver the MC event.
 -	 */
 -	rldicl.	r11,r12,4,63		/* See if MC hit while in HV mode. */
 -	beq	5f
 -4:	andi.	r11,r12,MSR_PR		/* See if coming from user. */
 -	bne	9f			/* continue in V mode if we are. */
 +ALT_FTR_SECTION_END_IFCLR(CPU_FTR_ARCH_206)
  
 -5:
 -#ifdef CONFIG_KVM_BOOK3S_64_HANDLER
  BEGIN_FTR_SECTION
 -	/*
 -	 * We are coming from kernel context. Check if we are coming from
 -	 * guest. if yes, then we can continue. We will fall through
 -	 * do_kvm_200->kvmppc_interrupt to deliver the MC event to guest.
 -	 */
 -	lbz	r11,HSTATE_IN_GUEST(r13)
 -	cmpwi	r11,0			/* Check if coming from guest */
 -	bne	9f			/* continue if we are. */
 -END_FTR_SECTION_IFSET(CPU_FTR_HVMODE)
 -#endif
 -	/*
 -	 * At this point we are not sure about what context we come from.
 -	 * Queue up the MCE event and return from the interrupt.
 -	 * But before that, check if this is an un-recoverable exception.
 -	 * If yes, then stay on emergency stack and panic.
 -	 */
 -	andi.	r11,r12,MSR_RI
 -	bne	2f
 -1:	mfspr	r11,SPRN_SRR0
 -	LOAD_HANDLER(r10,unrecover_mce)
 -	mtspr	SPRN_SRR0,r10
 -	ld	r10,PACAKMSR(r13)
 -	/*
 -	 * We are going down. But there are chances that we might get hit by
 -	 * another MCE during panic path and we may run into unstable state
 -	 * with no way out. Hence, turn ME bit off while going down, so that
 -	 * when another MCE is hit during panic path, system will checkstop
 -	 * and hypervisor will get restarted cleanly by SP.
 -	 */
 -	li	r3,MSR_ME
 -	andc	r10,r10,r3		/* Turn off MSR_ME */
 -	mtspr	SPRN_SRR1,r10
 -	RFI_TO_KERNEL
 -	b	.
 -2:
 -	/*
 -	 * Check if we have successfully handled/recovered from error, if not
 -	 * then stay on emergency stack and panic.
 -	 */
 -	ld	r3,RESULT(r1)	/* Load result */
 -	cmpdi	r3,0		/* see if we handled MCE successfully */
 -
 -	beq	1b		/* if !handled then panic */
 +	b	denorm_done
 +END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
 +/*
 + * To denormalise we need to move a copy of the register to itself.
 + * For POWER8 we need to do that for all 64 VSX registers
 + */
 +	XVCPSGNDP32(32)
 +denorm_done:
 +	mtspr	SPRN_HSRR0,r11
 +	mtcrf	0x80,r9
 +	ld	r9,PACA_EXGEN+EX_R9(r13)
 +	RESTORE_PPR_PACA(PACA_EXGEN, r10)
  BEGIN_FTR_SECTION
 -	/*
 -	 * Return from MC interrupt.
 -	 * Queue up the MCE event so that we can log it later, while
 -	 * returning from kernel or opal call.
 -	 */
 -	bl	machine_check_queue_event
 -	MACHINE_CHECK_HANDLER_WINDUP
 -	RFI_TO_USER_OR_KERNEL
 -FTR_SECTION_ELSE
 -	/*
 -	 * pSeries: Return from MC interrupt. Before that stay on emergency
 -	 * stack and call machine_check_exception to log the MCE event.
 -	 */
 -	LOAD_HANDLER(r10,mce_return)
 -	mtspr	SPRN_SRR0,r10
 -	ld	r10,PACAKMSR(r13)
 -	mtspr	SPRN_SRR1,r10
 -	RFI_TO_KERNEL
 +	ld	r10,PACA_EXGEN+EX_CFAR(r13)
 +	mtspr	SPRN_CFAR,r10
 +END_FTR_SECTION_IFSET(CPU_FTR_CFAR)
 +	ld	r10,PACA_EXGEN+EX_R10(r13)
 +	ld	r11,PACA_EXGEN+EX_R11(r13)
 +	ld	r12,PACA_EXGEN+EX_R12(r13)
 +	ld	r13,PACA_EXGEN+EX_R13(r13)
 +	HRFI_TO_UNKNOWN
  	b	.
 -ALT_FTR_SECTION_END_IFSET(CPU_FTR_HVMODE)
 -9:
 -	/* Deliver the machine check to host kernel in V mode. */
 -	MACHINE_CHECK_HANDLER_WINDUP
 -	SET_SCRATCH0(r13)		/* save r13 */
 -	EXCEPTION_PROLOG_0(PACA_EXMC)
 -	b	machine_check_pSeries_0
 +#endif
  
 -EXC_COMMON_BEGIN(unrecover_mce)
 -	/* Invoke machine_check_exception to print MCE event and panic. */
 +	.align	7
 +	/* moved from 0xe00 */
 +	STD_EXCEPTION_HV_OOL(0xe02, h_data_storage)
 +	KVM_HANDLER_SKIP(PACA_EXGEN, EXC_HV, 0xe02)
 +	STD_EXCEPTION_HV_OOL(0xe22, h_instr_storage)
 +	KVM_HANDLER(PACA_EXGEN, EXC_HV, 0xe22)
 +	STD_EXCEPTION_HV_OOL(0xe42, emulation_assist)
 +	KVM_HANDLER(PACA_EXGEN, EXC_HV, 0xe42)
 +	MASKABLE_EXCEPTION_HV_OOL(0xe62, hmi_exception)
 +	KVM_HANDLER(PACA_EXGEN, EXC_HV, 0xe62)
 +
 +	.globl hmi_exception_early
 +hmi_exception_early:
 +	EXCEPTION_PROLOG_1(PACA_EXGEN, KVMTEST, 0xe62)
 +	mr	r10,r1			/* Save r1			*/
 +	ld	r1,PACAEMERGSP(r13)	/* Use emergency stack		*/
 +	subi	r1,r1,INT_FRAME_SIZE	/* alloc stack frame		*/
 +	std	r9,_CCR(r1)		/* save CR in stackframe	*/
 +	mfspr	r11,SPRN_HSRR0		/* Save HSRR0 */
 +	std	r11,_NIP(r1)		/* save HSRR0 in stackframe	*/
 +	mfspr	r12,SPRN_HSRR1		/* Save SRR1 */
 +	std	r12,_MSR(r1)		/* save SRR1 in stackframe	*/
 +	std	r10,0(r1)		/* make stack chain pointer	*/
 +	std	r0,GPR0(r1)		/* save r0 in stackframe	*/
 +	std	r10,GPR1(r1)		/* save r1 in stackframe	*/
 +	EXCEPTION_PROLOG_COMMON_2(PACA_EXGEN)
 +	EXCEPTION_PROLOG_COMMON_3(0xe60)
  	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	machine_check_exception
 +	bl	hmi_exception_realmode
 +	/* Windup the stack. */
 +	/* Move original HSRR0 and HSRR1 into the respective regs */
 +	ld	r9,_MSR(r1)
 +	mtspr	SPRN_HSRR1,r9
 +	ld	r3,_NIP(r1)
 +	mtspr	SPRN_HSRR0,r3
 +	ld	r9,_CTR(r1)
 +	mtctr	r9
 +	ld	r9,_XER(r1)
 +	mtxer	r9
 +	ld	r9,_LINK(r1)
 +	mtlr	r9
 +	REST_GPR(0, r1)
 +	REST_8GPRS(2, r1)
 +	REST_GPR(10, r1)
 +	ld	r11,_CCR(r1)
 +	mtcr	r11
 +	REST_GPR(11, r1)
 +	REST_2GPRS(12, r1)
 +	/* restore original r1. */
 +	ld	r1,GPR1(r1)
 +
  	/*
 -	 * We will not reach here. Even if we did, there is no way out. Call
 -	 * unrecoverable_exception and die.
 +	 * Go to virtual mode and pull the HMI event information from
 +	 * firmware.
  	 */
 -1:	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	unrecoverable_exception
 -	b	1b
 +	.globl hmi_exception_after_realmode
 +hmi_exception_after_realmode:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXGEN)
 +	b	hmi_exception_hv
 +
 +	MASKABLE_EXCEPTION_HV_OOL(0xe82, h_doorbell)
 +	KVM_HANDLER(PACA_EXGEN, EXC_HV, 0xe82)
 +
 +	/* moved from 0xf00 */
 +	STD_EXCEPTION_PSERIES_OOL(0xf00, performance_monitor)
 +	KVM_HANDLER_PR(PACA_EXGEN, EXC_STD, 0xf00)
 +	STD_EXCEPTION_PSERIES_OOL(0xf20, altivec_unavailable)
 +	KVM_HANDLER_PR(PACA_EXGEN, EXC_STD, 0xf20)
 +	STD_EXCEPTION_PSERIES_OOL(0xf40, vsx_unavailable)
 +	KVM_HANDLER_PR(PACA_EXGEN, EXC_STD, 0xf40)
 +	STD_EXCEPTION_PSERIES_OOL(0xf60, facility_unavailable)
 +	KVM_HANDLER_PR(PACA_EXGEN, EXC_STD, 0xf60)
 +	STD_EXCEPTION_HV_OOL(0xf82, facility_unavailable)
 +	KVM_HANDLER(PACA_EXGEN, EXC_HV, 0xf82)
  
 -EXC_COMMON_BEGIN(mce_return)
 -	/* Invoke machine_check_exception to print MCE event and return. */
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	machine_check_exception
 -	MACHINE_CHECK_HANDLER_WINDUP
 -	RFI_TO_KERNEL
 +/*
 + * An interrupt came in while soft-disabled. We set paca->irq_happened, then:
 + * - If it was a decrementer interrupt, we bump the dec to max and and return.
 + * - If it was a doorbell we return immediately since doorbells are edge
 + *   triggered and won't automatically refire.
 + * - If it was a HMI we return immediately since we handled it in realmode
 + *   and it won't refire.
 + * - else we hard disable and return.
 + * This is called with r10 containing the value to OR to the paca field.
 + */
 +#define MASKED_INTERRUPT(_H)				\
 +masked_##_H##interrupt:					\
 +	std	r11,PACA_EXGEN+EX_R11(r13);		\
 +	lbz	r11,PACAIRQHAPPENED(r13);		\
 +	or	r11,r11,r10;				\
 +	stb	r11,PACAIRQHAPPENED(r13);		\
 +	cmpwi	r10,PACA_IRQ_DEC;			\
 +	bne	1f;					\
 +	lis	r10,0x7fff;				\
 +	ori	r10,r10,0xffff;				\
 +	mtspr	SPRN_DEC,r10;				\
 +	b	2f;					\
 +1:	cmpwi	r10,PACA_IRQ_DBELL;			\
 +	beq	2f;					\
 +	cmpwi	r10,PACA_IRQ_HMI;			\
 +	beq	2f;					\
 +	mfspr	r10,SPRN_##_H##SRR1;			\
 +	rldicl	r10,r10,48,1; /* clear MSR_EE */	\
 +	rotldi	r10,r10,16;				\
 +	mtspr	SPRN_##_H##SRR1,r10;			\
 +2:	mtcrf	0x80,r9;				\
 +	ld	r9,PACA_EXGEN+EX_R9(r13);		\
 +	ld	r10,PACA_EXGEN+EX_R10(r13);		\
 +	ld	r11,PACA_EXGEN+EX_R11(r13);		\
 +	GET_SCRATCH0(r13);				\
 +	##_H##RFI_TO_KERNEL;				\
  	b	.
 +	
 +	MASKED_INTERRUPT()
 +	MASKED_INTERRUPT(H)
 +
 +	.globl stf_barrier_fallback
 +stf_barrier_fallback:
 +	ld	r13,PACA_AUX_PTR(r13)		/* r13 now = paca_aux pointer */
 +	std	r9,PACA_AUX_EXRFI+EX_R9(r13)
 +	std	r10,PACA_AUX_EXRFI+EX_R10(r13)
 +	sync
 +	ld	r9,PACA_AUX_EXRFI+EX_R9(r13)
 +	ld	r10,PACA_AUX_EXRFI+EX_R10(r13)
 +	ori	31,31,0
 +	.rept 14
 +	b	1f
 +1:
 +	.endr
 +	GET_PACA(r13)
 +	blr
 +
 +	.globl rfi_flush_fallback
 +rfi_flush_fallback:
 +	SET_SCRATCH0(r13);
 +	GET_PACA(r13);
 +	ld	r13,PACA_AUX_PTR(r13)		/* r13 now = paca_aux pointer */
 +	std	r9,PACA_AUX_EXRFI+EX_R9(r13)
 +	std	r10,PACA_AUX_EXRFI+EX_R10(r13)
 +	std	r11,PACA_AUX_EXRFI+EX_R11(r13)
 +	mfctr	r9
 +	ld	r10,PACA_AUX_RFI_FLUSH_FALLBACK_AREA(r13)
 +	ld	r11,PACA_AUX_L1D_FLUSH_SIZE(r13)
 +	srdi	r11,r11,(7 + 3) /* 128 byte lines, unrolled 8x */
 +	mtctr	r11
 +	DCBT_STOP_ALL_STREAM_IDS(r11) /* Stop prefetch streams */
  
 -EXC_REAL_BEGIN(data_access, 0x300, 0x80)
 -SET_SCRATCH0(r13)		/* save r13 */
 -EXCEPTION_PROLOG_0(PACA_EXGEN)
 -	b	tramp_real_data_access
 -EXC_REAL_END(data_access, 0x300, 0x80)
 +	/* order ld/st prior to dcbt stop all streams with flushing */
 +	hwsync
  
 -TRAMP_REAL_BEGIN(tramp_real_data_access)
 -EXCEPTION_PROLOG_1(PACA_EXGEN, KVMTEST_PR, 0x300)
  	/*
 -	 * DAR/DSISR must be read before setting MSR[RI], because
 -	 * a d-side MCE will clobber those registers so is not
 -	 * recoverable if they are live.
 +	 * The load adresses are at staggered offsets within cachelines,
 +	 * which suits some pipelines better (on others it should not
 +	 * hurt).
  	 */
 -	mfspr	r10,SPRN_DAR
 -	mfspr	r11,SPRN_DSISR
 -	std	r10,PACA_EXGEN+EX_DAR(r13)
 -	stw	r11,PACA_EXGEN+EX_DSISR(r13)
 -EXCEPTION_PROLOG_2(data_access_common, EXC_STD)
 +1:
 +	ld	r11,(0x80 + 8)*0(r10)
 +	ld	r11,(0x80 + 8)*1(r10)
 +	ld	r11,(0x80 + 8)*2(r10)
 +	ld	r11,(0x80 + 8)*3(r10)
 +	ld	r11,(0x80 + 8)*4(r10)
 +	ld	r11,(0x80 + 8)*5(r10)
 +	ld	r11,(0x80 + 8)*6(r10)
 +	ld	r11,(0x80 + 8)*7(r10)
 +	addi	r10,r10,0x80*8
 +	bdnz	1b
  
 -EXC_VIRT_BEGIN(data_access, 0x4300, 0x80)
 -SET_SCRATCH0(r13)		/* save r13 */
 -EXCEPTION_PROLOG_0(PACA_EXGEN)
 -EXCEPTION_PROLOG_1(PACA_EXGEN, NOTEST, 0x300)
 -	mfspr	r10,SPRN_DAR
 -	mfspr	r11,SPRN_DSISR
 -	std	r10,PACA_EXGEN+EX_DAR(r13)
 -	stw	r11,PACA_EXGEN+EX_DSISR(r13)
 -EXCEPTION_PROLOG_2_RELON(data_access_common, EXC_STD)
 -EXC_VIRT_END(data_access, 0x4300, 0x80)
 +	mtctr	r9
 +	ld	r9,PACA_AUX_EXRFI+EX_R9(r13)
 +	ld	r10,PACA_AUX_EXRFI+EX_R10(r13)
 +	ld	r11,PACA_AUX_EXRFI+EX_R11(r13)
 +	GET_SCRATCH0(r13);
 +	rfid
 +
 +	.globl hrfi_flush_fallback
 +hrfi_flush_fallback:
 +	SET_SCRATCH0(r13);
 +	GET_PACA(r13);
 +	ld	r13,PACA_AUX_PTR(r13)		/* r13 now = paca_aux pointer */
 +	std	r9,PACA_AUX_EXRFI+EX_R9(r13)
 +	std	r10,PACA_AUX_EXRFI+EX_R10(r13)
 +	std	r11,PACA_AUX_EXRFI+EX_R11(r13)
 +	mfctr	r9
 +	ld	r10,PACA_AUX_RFI_FLUSH_FALLBACK_AREA(r13)
 +	ld	r11,PACA_AUX_L1D_FLUSH_SIZE(r13)
 +	srdi	r11,r11,(7 + 3) /* 128 byte lines, unrolled 8x */
 +	mtctr	r11
 +	DCBT_STOP_ALL_STREAM_IDS(r11) /* Stop prefetch streams */
  
 -TRAMP_KVM_SKIP(PACA_EXGEN, 0x300)
 +	/* order ld/st prior to dcbt stop all streams with flushing */
 +	hwsync
  
 -EXC_COMMON_BEGIN(data_access_common)
  	/*
 -	 * Here r13 points to the paca, r9 contains the saved CR,
 -	 * SRR0 and SRR1 are saved in r11 and r12,
 -	 * r9 - r13 are saved in paca->exgen.
 -	 * EX_DAR and EX_DSISR have saved DAR/DSISR
 +	 * The load adresses are at staggered offsets within cachelines,
 +	 * which suits some pipelines better (on others it should not
 +	 * hurt.
  	 */
 -	EXCEPTION_PROLOG_COMMON(0x300, PACA_EXGEN)
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	ld	r12,_MSR(r1)
 -	ld	r3,PACA_EXGEN+EX_DAR(r13)
 -	lwz	r4,PACA_EXGEN+EX_DSISR(r13)
 -	li	r5,0x300
 -	std	r3,_DAR(r1)
 -	std	r4,_DSISR(r1)
 -BEGIN_MMU_FTR_SECTION
 -	b	do_hash_page		/* Try to handle as hpte fault */
 -MMU_FTR_SECTION_ELSE
 -	b	handle_page_fault
 -ALT_MMU_FTR_SECTION_END_IFCLR(MMU_FTR_TYPE_RADIX)
 -
 -
 -EXC_REAL_BEGIN(data_access_slb, 0x380, 0x80)
 -SET_SCRATCH0(r13)		/* save r13 */
 -EXCEPTION_PROLOG_0(PACA_EXSLB)
 -	b	tramp_real_data_access_slb
 -EXC_REAL_END(data_access_slb, 0x380, 0x80)
 +1:
 +	ld	r11,(0x80 + 8)*0(r10)
 +	ld	r11,(0x80 + 8)*1(r10)
 +	ld	r11,(0x80 + 8)*2(r10)
 +	ld	r11,(0x80 + 8)*3(r10)
 +	ld	r11,(0x80 + 8)*4(r10)
 +	ld	r11,(0x80 + 8)*5(r10)
 +	ld	r11,(0x80 + 8)*6(r10)
 +	ld	r11,(0x80 + 8)*7(r10)
 +	addi	r10,r10,0x80*8
 +	bdnz	1b
  
 -TRAMP_REAL_BEGIN(tramp_real_data_access_slb)
 -EXCEPTION_PROLOG_1(PACA_EXSLB, KVMTEST_PR, 0x380)
 -	mfspr	r10,SPRN_DAR
 -	std	r10,PACA_EXSLB+EX_DAR(r13)
 -EXCEPTION_PROLOG_2(data_access_slb_common, EXC_STD)
 +	mtctr	r9
 +	ld	r9,PACA_AUX_EXRFI+EX_R9(r13)
 +	ld	r10,PACA_AUX_EXRFI+EX_R10(r13)
 +	ld	r11,PACA_AUX_EXRFI+EX_R11(r13)
 +	GET_SCRATCH0(r13);
 +	hrfid
  
 -EXC_VIRT_BEGIN(data_access_slb, 0x4380, 0x80)
 -SET_SCRATCH0(r13)		/* save r13 */
 -EXCEPTION_PROLOG_0(PACA_EXSLB)
 -EXCEPTION_PROLOG_1(PACA_EXSLB, NOTEST, 0x380)
 -	mfspr	r10,SPRN_DAR
 -	std	r10,PACA_EXSLB+EX_DAR(r13)
 -EXCEPTION_PROLOG_2_RELON(data_access_slb_common, EXC_STD)
 -EXC_VIRT_END(data_access_slb, 0x4380, 0x80)
 +/*
 + * Called from arch_local_irq_enable when an interrupt needs
 + * to be resent. r3 contains 0x500, 0x900, 0xa00 or 0xe80 to indicate
 + * which kind of interrupt. MSR:EE is already off. We generate a
 + * stackframe like if a real interrupt had happened.
 + *
 + * Note: While MSR:EE is off, we need to make sure that _MSR
 + * in the generated frame has EE set to 1 or the exception
 + * handler will not properly re-enable them.
 + */
 +_GLOBAL(__replay_interrupt)
 +	/* We are going to jump to the exception common code which
 +	 * will retrieve various register values from the PACA which
 +	 * we don't give a damn about, so we don't bother storing them.
 +	 */
 +	mfmsr	r12
 +	mflr	r11
 +	mfcr	r9
 +	ori	r12,r12,MSR_EE
 +	cmpwi	r3,0x900
 +	beq	decrementer_common
 +	cmpwi	r3,0x500
 +	beq	hardware_interrupt_common
 +BEGIN_FTR_SECTION
 +	cmpwi	r3,0xe80
 +	beq	h_doorbell_common
 +	cmpwi	r3,0xe60
 +	beq	hmi_exception_common
 +FTR_SECTION_ELSE
 +	cmpwi	r3,0xa00
 +	beq	doorbell_super_common
 +ALT_FTR_SECTION_END_IFSET(CPU_FTR_HVMODE)
 +	blr
  
 -TRAMP_KVM_SKIP(PACA_EXSLB, 0x380)
 +#ifdef CONFIG_PPC_PSERIES
 +/*
 + * Vectors for the FWNMI option.  Share common code.
 + */
 +	.globl system_reset_fwnmi
 +      .align 7
 +system_reset_fwnmi:
 +	HMT_MEDIUM_PPR_DISCARD
 +	SET_SCRATCH0(r13)		/* save r13 */
 +	EXCEPTION_PROLOG_PSERIES(PACA_EXGEN, system_reset_common, EXC_STD,
 +				 NOTEST, 0x100)
  
 -EXC_COMMON_BEGIN(data_access_slb_common)
 -	EXCEPTION_PROLOG_COMMON(0x380, PACA_EXSLB)
 -	ld	r4,PACA_EXSLB+EX_DAR(r13)
 -	std	r4,_DAR(r1)
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -BEGIN_MMU_FTR_SECTION
 -	/* HPT case, do SLB fault */
 -	bl	do_slb_fault
 -	cmpdi	r3,0
 -	bne-	1f
 -	b	fast_exception_return
 -1:	/* Error case */
 -MMU_FTR_SECTION_ELSE
 -	/* Radix case, access is outside page table range */
 -	li	r3,-EFAULT
 -ALT_MMU_FTR_SECTION_END_IFCLR(MMU_FTR_TYPE_RADIX)
 -	std	r3,RESULT(r1)
 -	bl	save_nvgprs
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	ld	r4,_DAR(r1)
 -	ld	r5,RESULT(r1)
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	do_bad_slb_fault
 -	b	ret_from_except
 +#endif /* CONFIG_PPC_PSERIES */
  
 +#ifdef __DISABLED__
 +/*
 + * This is used for when the SLB miss handler has to go virtual,
 + * which doesn't happen for now anymore but will once we re-implement
 + * dynamic VSIDs for shared page tables
 + */
 +slb_miss_user_pseries:
 +	std	r10,PACA_EXGEN+EX_R10(r13)
 +	std	r11,PACA_EXGEN+EX_R11(r13)
 +	std	r12,PACA_EXGEN+EX_R12(r13)
 +	GET_SCRATCH0(r10)
 +	ld	r11,PACA_EXSLB+EX_R9(r13)
 +	ld	r12,PACA_EXSLB+EX_R3(r13)
 +	std	r10,PACA_EXGEN+EX_R13(r13)
 +	std	r11,PACA_EXGEN+EX_R9(r13)
 +	std	r12,PACA_EXGEN+EX_R3(r13)
 +	clrrdi	r12,r13,32
 +	mfmsr	r10
 +	mfspr	r11,SRR0			/* save SRR0 */
 +	ori	r12,r12,slb_miss_user_common@l	/* virt addr of handler */
 +	ori	r10,r10,MSR_IR|MSR_DR|MSR_RI
 +	mtspr	SRR0,r12
 +	mfspr	r12,SRR1			/* and SRR1 */
 +	mtspr	SRR1,r10
 +	rfid
 +	b	.				/* prevent spec. execution */
 +#endif /* __DISABLED__ */
  
 -EXC_REAL(instruction_access, 0x400, 0x80)
 -EXC_VIRT(instruction_access, 0x4400, 0x80, 0x400)
 -TRAMP_KVM(PACA_EXGEN, 0x400)
 +#ifdef CONFIG_KVM_BOOK3S_64_HANDLER
 +kvmppc_skip_interrupt:
 +	/*
 +	 * Here all GPRs are unchanged from when the interrupt happened
 +	 * except for r13, which is saved in SPRG_SCRATCH0.
 +	 */
 +	mfspr	r13, SPRN_SRR0
 +	addi	r13, r13, 4
 +	mtspr	SPRN_SRR0, r13
 +	GET_SCRATCH0(r13)
 +	RFI_TO_KERNEL
 +	b	.
  
 -EXC_COMMON_BEGIN(instruction_access_common)
 -	EXCEPTION_PROLOG_COMMON(0x400, PACA_EXGEN)
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	ld	r12,_MSR(r1)
 -	ld	r3,_NIP(r1)
 -	andis.	r4,r12,DSISR_SRR1_MATCH_64S@h
 -	li	r5,0x400
 -	std	r3,_DAR(r1)
 -	std	r4,_DSISR(r1)
 -BEGIN_MMU_FTR_SECTION
 -	b	do_hash_page		/* Try to handle as hpte fault */
 -MMU_FTR_SECTION_ELSE
 -	b	handle_page_fault
 -ALT_MMU_FTR_SECTION_END_IFCLR(MMU_FTR_TYPE_RADIX)
 +kvmppc_skip_Hinterrupt:
 +	/*
 +	 * Here all GPRs are unchanged from when the interrupt happened
 +	 * except for r13, which is saved in SPRG_SCRATCH0.
 +	 */
 +	mfspr	r13, SPRN_HSRR0
 +	addi	r13, r13, 4
 +	mtspr	SPRN_HSRR0, r13
 +	GET_SCRATCH0(r13)
 +	HRFI_TO_KERNEL
 +	b	.
 +#endif
  
 +/*
 + * Code from here down to __end_handlers is invoked from the
 + * exception prologs above.  Because the prologs assemble the
 + * addresses of these handlers using the LOAD_HANDLER macro,
 + * which uses an ori instruction, these handlers must be in
 + * the first 64k of the kernel image.
 + */
  
 -EXC_REAL_BEGIN(instruction_access_slb, 0x480, 0x80)
 -EXCEPTION_PROLOG(PACA_EXSLB, instruction_access_slb_common, EXC_STD, KVMTEST_PR, 0x480);
 -EXC_REAL_END(instruction_access_slb, 0x480, 0x80)
 +/*** Common interrupt handlers ***/
  
 -EXC_VIRT_BEGIN(instruction_access_slb, 0x4480, 0x80)
 -EXCEPTION_RELON_PROLOG(PACA_EXSLB, instruction_access_slb_common, EXC_STD, NOTEST, 0x480);
 -EXC_VIRT_END(instruction_access_slb, 0x4480, 0x80)
 +	STD_EXCEPTION_COMMON(0x100, system_reset, system_reset_exception)
  
 -TRAMP_KVM(PACA_EXSLB, 0x480)
 +	STD_EXCEPTION_COMMON_ASYNC(0x500, hardware_interrupt, do_IRQ)
 +	STD_EXCEPTION_COMMON_ASYNC(0x900, decrementer, timer_interrupt)
 +.globl decrementer_pSeries_OOL
 +decrementer_pSeries_OOL:
 +	_MASKABLE_EXCEPTION_PSERIES_OOL(0x900, decrementer, EXC_STD, SOFTEN_TEST_PR)
 +	STD_EXCEPTION_COMMON(0x980, hdecrementer, hdec_interrupt)
 +	STD_EXCEPTION_HV_OOL(0x982, hdecrementer)
 +#ifdef CONFIG_PPC_DOORBELL
 +	STD_EXCEPTION_COMMON_ASYNC(0xa00, doorbell_super, doorbell_exception)
 +#else
 +	STD_EXCEPTION_COMMON_ASYNC(0xa00, doorbell_super, unknown_exception)
 +#endif
 +	STD_EXCEPTION_COMMON(0xb00, trap_0b, unknown_exception)
 +	STD_EXCEPTION_COMMON(0xd00, single_step, single_step_exception)
 +	STD_EXCEPTION_COMMON(0xe00, trap_0e, unknown_exception)
 +	STD_EXCEPTION_COMMON(0xe40, emulation_assist, emulation_assist_interrupt)
 +	STD_EXCEPTION_COMMON_ASYNC(0xe60, hmi_exception, handle_hmi_exception)
 +#ifdef CONFIG_PPC_DOORBELL
 +	STD_EXCEPTION_COMMON_ASYNC(0xe80, h_doorbell, doorbell_exception)
 +#else
 +	STD_EXCEPTION_COMMON_ASYNC(0xe80, h_doorbell, unknown_exception)
 +#endif
 +	STD_EXCEPTION_COMMON_ASYNC(0xf00, performance_monitor, performance_monitor_exception)
 +	STD_EXCEPTION_COMMON(0x1300, instruction_breakpoint, instruction_breakpoint_exception)
 +	STD_EXCEPTION_COMMON(0x1502, denorm, unknown_exception)
 +#ifdef CONFIG_ALTIVEC
 +	STD_EXCEPTION_COMMON(0x1700, altivec_assist, altivec_assist_exception)
 +#else
 +	STD_EXCEPTION_COMMON(0x1700, altivec_assist, unknown_exception)
 +#endif
 +#ifdef CONFIG_CBE_RAS
 +	STD_EXCEPTION_COMMON(0x1200, cbe_system_error, cbe_system_error_exception)
 +	STD_EXCEPTION_COMMON(0x1600, cbe_maintenance, cbe_maintenance_exception)
 +	STD_EXCEPTION_COMMON(0x1800, cbe_thermal, cbe_thermal_exception)
 +#endif /* CONFIG_CBE_RAS */
  
 -EXC_COMMON_BEGIN(instruction_access_slb_common)
 -	EXCEPTION_PROLOG_COMMON(0x480, PACA_EXSLB)
 -	ld	r4,_NIP(r1)
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -BEGIN_MMU_FTR_SECTION
 -	/* HPT case, do SLB fault */
 -	bl	do_slb_fault
 -	cmpdi	r3,0
 -	bne-	1f
 -	b	fast_exception_return
 -1:	/* Error case */
 -MMU_FTR_SECTION_ELSE
 -	/* Radix case, access is outside page table range */
 -	li	r3,-EFAULT
 -ALT_MMU_FTR_SECTION_END_IFCLR(MMU_FTR_TYPE_RADIX)
 -	std	r3,RESULT(r1)
 -	bl	save_nvgprs
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	ld	r4,_NIP(r1)
 -	ld	r5,RESULT(r1)
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	do_bad_slb_fault
 -	b	ret_from_except
 +	/*
 +	 * Relocation-on interrupts: A subset of the interrupts can be delivered
 +	 * with IR=1/DR=1, if AIL==2 and MSR.HV won't be changed by delivering
 +	 * it.  Addresses are the same as the original interrupt addresses, but
 +	 * offset by 0xc000000000004000.
 +	 * It's impossible to receive interrupts below 0x300 via this mechanism.
 +	 * KVM: None of these traps are from the guest ; anything that escalated
 +	 * to HV=1 from HV=0 is delivered via real mode handlers.
 +	 */
  
 +	/*
 +	 * This uses the standard macro, since the original 0x300 vector
 +	 * only has extra guff for STAB-based processors -- which never
 +	 * come here.
 +	 */
 +	STD_RELON_EXCEPTION_PSERIES(0x4300, 0x300, data_access)
 +	. = 0x4380
 +	.globl data_access_slb_relon_pSeries
 +data_access_slb_relon_pSeries:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXSLB)
 +	EXCEPTION_PROLOG_1(PACA_EXSLB, NOTEST, 0x380)
 +	std	r3,PACA_EXSLB+EX_R3(r13)
 +	mfspr	r3,SPRN_DAR
 +	mfspr	r12,SPRN_SRR1
 +#ifndef CONFIG_RELOCATABLE
 +	b	slb_miss_realmode
 +#else
 +	/*
 +	 * We can't just use a direct branch to slb_miss_realmode
 +	 * because the distance from here to there depends on where
 +	 * the kernel ends up being put.
 +	 */
 +	mfctr	r11
 +	ld	r10,PACAKBASE(r13)
 +	LOAD_HANDLER(r10, slb_miss_realmode)
 +	mtctr	r10
 +	bctr
 +#endif
  
 -EXC_REAL_BEGIN(hardware_interrupt, 0x500, 0x100)
 -	.globl hardware_interrupt_hv;
 -hardware_interrupt_hv:
 -	BEGIN_FTR_SECTION
 -		MASKABLE_EXCEPTION_HV(0x500, hardware_interrupt_common, IRQS_DISABLED)
 -	FTR_SECTION_ELSE
 -		MASKABLE_EXCEPTION(0x500, hardware_interrupt_common, IRQS_DISABLED)
 -	ALT_FTR_SECTION_END_IFSET(CPU_FTR_HVMODE | CPU_FTR_ARCH_206)
 -EXC_REAL_END(hardware_interrupt, 0x500, 0x100)
 +	STD_RELON_EXCEPTION_PSERIES(0x4400, 0x400, instruction_access)
 +	. = 0x4480
 +	.globl instruction_access_slb_relon_pSeries
 +instruction_access_slb_relon_pSeries:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXSLB)
 +	EXCEPTION_PROLOG_1(PACA_EXSLB, NOTEST, 0x480)
 +	std	r3,PACA_EXSLB+EX_R3(r13)
 +	mfspr	r3,SPRN_SRR0		/* SRR0 is faulting address */
 +	mfspr	r12,SPRN_SRR1
 +#ifndef CONFIG_RELOCATABLE
 +	b	slb_miss_realmode
 +#else
 +	mfctr	r11
 +	ld	r10,PACAKBASE(r13)
 +	LOAD_HANDLER(r10, slb_miss_realmode)
 +	mtctr	r10
 +	bctr
 +#endif
  
 -EXC_VIRT_BEGIN(hardware_interrupt, 0x4500, 0x100)
 +	. = 0x4500
 +	.globl hardware_interrupt_relon_pSeries;
  	.globl hardware_interrupt_relon_hv;
 +hardware_interrupt_relon_pSeries:
  hardware_interrupt_relon_hv:
  	BEGIN_FTR_SECTION
 -		MASKABLE_RELON_EXCEPTION_HV(0x500, hardware_interrupt_common,
 -					    IRQS_DISABLED)
 +		_MASKABLE_RELON_EXCEPTION_PSERIES(0x502, hardware_interrupt, EXC_HV, SOFTEN_TEST_HV)
  	FTR_SECTION_ELSE
 -		__MASKABLE_RELON_EXCEPTION(0x500, hardware_interrupt_common,
 -					   EXC_STD, SOFTEN_TEST_PR, IRQS_DISABLED)
 +		_MASKABLE_RELON_EXCEPTION_PSERIES(0x500, hardware_interrupt, EXC_STD, SOFTEN_TEST_PR)
  	ALT_FTR_SECTION_END_IFSET(CPU_FTR_HVMODE)
 -EXC_VIRT_END(hardware_interrupt, 0x4500, 0x100)
 -
 -TRAMP_KVM(PACA_EXGEN, 0x500)
 -TRAMP_KVM_HV(PACA_EXGEN, 0x500)
 -EXC_COMMON_ASYNC(hardware_interrupt_common, 0x500, do_IRQ)
 -
 +	STD_RELON_EXCEPTION_PSERIES(0x4600, 0x600, alignment)
 +	STD_RELON_EXCEPTION_PSERIES(0x4700, 0x700, program_check)
 +	STD_RELON_EXCEPTION_PSERIES(0x4800, 0x800, fp_unavailable)
 +	MASKABLE_RELON_EXCEPTION_PSERIES(0x4900, 0x900, decrementer)
 +	STD_RELON_EXCEPTION_HV(0x4980, 0x982, hdecrementer)
 +	MASKABLE_RELON_EXCEPTION_PSERIES(0x4a00, 0xa00, doorbell_super)
 +	STD_RELON_EXCEPTION_PSERIES(0x4b00, 0xb00, trap_0b)
 +
 +	. = 0x4c00
 +	.globl system_call_relon_pSeries
 +system_call_relon_pSeries:
 +	HMT_MEDIUM
 +	mr	r12,r13
 +	GET_PACA(r13)
 +	INTERRUPT_TO_KERNEL
 +	mr	r13,r12
 +	SYSCALL_PSERIES_1
 +	SYSCALL_PSERIES_2_DIRECT
 +	SYSCALL_PSERIES_3
  
 -EXC_REAL_BEGIN(alignment, 0x600, 0x100)
 -SET_SCRATCH0(r13)		/* save r13 */
 -EXCEPTION_PROLOG_0(PACA_EXGEN)
 -EXCEPTION_PROLOG_1(PACA_EXGEN, KVMTEST_PR, 0x600)
 -	mfspr	r10,SPRN_DAR
 -	mfspr	r11,SPRN_DSISR
 -	std	r10,PACA_EXGEN+EX_DAR(r13)
 -	stw	r11,PACA_EXGEN+EX_DSISR(r13)
 -EXCEPTION_PROLOG_2(alignment_common, EXC_STD)
 -EXC_REAL_END(alignment, 0x600, 0x100)
 -
 -EXC_VIRT_BEGIN(alignment, 0x4600, 0x100)
 -SET_SCRATCH0(r13)		/* save r13 */
 -EXCEPTION_PROLOG_0(PACA_EXGEN)
 -EXCEPTION_PROLOG_1(PACA_EXGEN, NOTEST, 0x600)
 -	mfspr	r10,SPRN_DAR
 -	mfspr	r11,SPRN_DSISR
 -	std	r10,PACA_EXGEN+EX_DAR(r13)
 -	stw	r11,PACA_EXGEN+EX_DSISR(r13)
 -EXCEPTION_PROLOG_2_RELON(alignment_common, EXC_STD)
 -EXC_VIRT_END(alignment, 0x4600, 0x100)
 +	STD_RELON_EXCEPTION_PSERIES(0x4d00, 0xd00, single_step)
  
 -TRAMP_KVM(PACA_EXGEN, 0x600)
 -EXC_COMMON_BEGIN(alignment_common)
 -	EXCEPTION_PROLOG_COMMON(0x600, PACA_EXGEN)
 -	ld	r3,PACA_EXGEN+EX_DAR(r13)
 -	lwz	r4,PACA_EXGEN+EX_DSISR(r13)
 -	std	r3,_DAR(r1)
 -	std	r4,_DSISR(r1)
 -	bl	save_nvgprs
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	alignment_exception
 -	b	ret_from_except
 +	. = 0x4e00
 +	b	.	/* Can't happen, see v2.07 Book III-S section 6.5 */
  
 +	. = 0x4e20
 +	b	.	/* Can't happen, see v2.07 Book III-S section 6.5 */
  
 -EXC_REAL(program_check, 0x700, 0x100)
 -EXC_VIRT(program_check, 0x4700, 0x100, 0x700)
 -TRAMP_KVM(PACA_EXGEN, 0x700)
 -EXC_COMMON_BEGIN(program_check_common)
 -	/*
 -	 * It's possible to receive a TM Bad Thing type program check with
 -	 * userspace register values (in particular r1), but with SRR1 reporting
 -	 * that we came from the kernel. Normally that would confuse the bad
 -	 * stack logic, and we would report a bad kernel stack pointer. Instead
 -	 * we switch to the emergency stack if we're taking a TM Bad Thing from
 -	 * the kernel.
 -	 */
 -	li	r10,MSR_PR		/* Build a mask of MSR_PR ..	*/
 -	oris	r10,r10,0x200000@h	/* .. and SRR1_PROGTM		*/
 -	and	r10,r10,r12		/* Mask SRR1 with that.		*/
 -	srdi	r10,r10,8		/* Shift it so we can compare	*/
 -	cmpldi	r10,(0x200000 >> 8)	/* .. with an immediate.	*/
 -	bne 1f				/* If != go to normal path.	*/
 -
 -	/* SRR1 had PR=0 and SRR1_PROGTM=1, so use the emergency stack	*/
 -	andi.	r10,r12,MSR_PR;		/* Set CR0 correctly for label	*/
 -					/* 3 in EXCEPTION_PROLOG_COMMON	*/
 -	mr	r10,r1			/* Save r1			*/
 -	ld	r1,PACAEMERGSP(r13)	/* Use emergency stack		*/
 -	subi	r1,r1,INT_FRAME_SIZE	/* alloc stack frame		*/
 -	b 3f				/* Jump into the macro !!	*/
 -1:	EXCEPTION_PROLOG_COMMON(0x700, PACA_EXGEN)
 -	bl	save_nvgprs
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	program_check_exception
 -	b	ret_from_except
 +	. = 0x4e40
 +emulation_assist_relon_trampoline:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXGEN)
 +	b	emulation_assist_relon_hv
  
 +	. = 0x4e60
 +	b	.	/* Can't happen, see v2.07 Book III-S section 6.5 */
  
 -EXC_REAL(fp_unavailable, 0x800, 0x100)
 -EXC_VIRT(fp_unavailable, 0x4800, 0x100, 0x800)
 -TRAMP_KVM(PACA_EXGEN, 0x800)
 -EXC_COMMON_BEGIN(fp_unavailable_common)
 -	EXCEPTION_PROLOG_COMMON(0x800, PACA_EXGEN)
 -	bne	1f			/* if from user, just load it up */
 -	bl	save_nvgprs
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	kernel_fp_unavailable_exception
 -	BUG_OPCODE
 -1:
 -#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
 -BEGIN_FTR_SECTION
 -	/* Test if 2 TM state bits are zero.  If non-zero (ie. userspace was in
 -	 * transaction), go do TM stuff
 -	 */
 -	rldicl.	r0, r12, (64-MSR_TS_LG), (64-2)
 -	bne-	2f
 -END_FTR_SECTION_IFSET(CPU_FTR_TM)
 -#endif
 -	bl	load_up_fpu
 -	b	fast_exception_return
 -#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
 -2:	/* User process was in a transaction */
 -	bl	save_nvgprs
 -	RECONCILE_IRQ_STATE(r10, r11)
 -	addi	r3,r1,STACK_FRAME_OVERHEAD
 -	bl	fp_unavailable_tm
 -	b	ret_from_except
 -#endif
 +	. = 0x4e80
 +h_doorbell_relon_trampoline:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXGEN)
 +	b	h_doorbell_relon_hv
  
 +	. = 0x4f00
 +performance_monitor_relon_pseries_trampoline:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXGEN)
 +	b	performance_monitor_relon_pSeries
  
 -EXC_REAL_OOL_MASKABLE(decrementer, 0x900, 0x80, IRQS_DISABLED)
 -EXC_VIRT_MASKABLE(decrementer, 0x4900, 0x80, 0x900, IRQS_DISABLED)
 -TRAMP_KVM(PACA_EXGEN, 0x900)
 -EXC_COMMON_ASYNC(decrementer_common, 0x900, timer_interrupt)
 +	. = 0x4f20
 +altivec_unavailable_relon_pseries_trampoline:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXGEN)
 +	b	altivec_unavailable_relon_pSeries
  
 +	. = 0x4f40
 +vsx_unavailable_relon_pseries_trampoline:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXGEN)
 +	b	vsx_unavailable_relon_pSeries
  
 -EXC_REAL_HV(hdecrementer, 0x980, 0x80)
 -EXC_VIRT_HV(hdecrementer, 0x4980, 0x80, 0x980)
 -TRAMP_KVM_HV(PACA_EXGEN, 0x980)
 -EXC_COMMON(hdecrementer_common, 0x980, hdec_interrupt)
 +	. = 0x4f60
 +facility_unavailable_relon_trampoline:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXGEN)
 +	b	facility_unavailable_relon_pSeries
  
 +	. = 0x4f80
 +hv_facility_unavailable_relon_trampoline:
 +	SET_SCRATCH0(r13)
 +	EXCEPTION_PROLOG_0(PACA_EXGEN)
 +	b	hv_facility_unavailable_relon_hv
  
 -EXC_REAL_MASKABLE(doorbell_super, 0xa00, 0x100, IRQS_DISABLED)
 -EXC_VIRT_MASKABLE(doorbell_super, 0x4a00, 0x100, 0xa00, IRQS_DISABLED)
 -TRAMP_KVM(PACA_EXGEN, 0xa00)
 -#ifdef CONFIG_PPC_DOORBELL
 -EXC_COMMON_ASYNC(doorbell_super_common, 0xa00, doorbell_exception)
 -#else
 -EXC_COMMON_ASYNC(doorbell_super_common, 0xa00, unknown_exception)
 +	STD_RELON_EXCEPTION_PSERIES(0x5300, 0x1300, instruction_breakpoint)
 +#ifdef CONFIG_PPC_DENORMALISATION
 +	. = 0x5500
 +	b	denorm_exception_hv
  #endif
 +	STD_RELON_EXCEPTION_PSERIES(0x5700, 0x1700, altivec_assist)
  
 +	/* Other future vectors */
 +	.align	7
 +	.globl	__end_interrupts
 +__end_interrupts:
  
 -EXC_REAL(trap_0b, 0xb00, 0x100)
 -EXC_VIRT(trap_0b, 0x4b00, 0x100, 0xb00)
 -TRAMP_KVM(PACA_EXGEN, 0xb00)
 -EXC_COMMON(trap_0b_common, 0xb00, unknown_exception)
 -
 -/*
 - * system call / hypercall (0xc00, 0x4c00)
 - *
 - * The system call exception is invoked with "sc 0" and does not alter HV bit.
 - * There is support for kernel code to invoke system calls but there are no
 - * in-tree users.
 - *
 - * The hypercall is invoked with "sc 1" and sets HV=1.
 - *
 - * In HPT, sc 1 always goes to 0xc00 real mode. In RADIX, sc 1 can go to
 - * 0x4c00 virtual mode.
 - *
 - * Call convention:
 - *
 - * syscall register convention is in Documentation/powerpc/syscall64-abi.txt
 - *
 - * For hypercalls, the register convention is as follows:
 - * r0 volatile
 - * r1-2 nonvolatile
 - * r3 volatile parameter and return value for status
 - * r4-r10 volatile input and output value
 - * r11 volatile hypercall number and output value
 - * r12 volatile input and output value
 - * r13-r31 nonvolatile
 - * LR nonvolatile
 - * CTR volatile
 - * XER volatile
 - * CR0-1 CR5-7 volatile
 - * CR2-4 nonvolatile
 - * Other registers nonvolatile
 - *
 - * The intersection of volatile registers that don't contain possible
 - * inputs is: cr0, xer, ctr. We may use these as scratch regs upon entry
 - * without saving, though xer is not a good idea to use, as hardware may
 - * interpret some bits so it may be costly to change them.
 - */
 -#ifdef CONFIG_KVM_BOOK3S_64_HANDLER
 -	/*
 -	 * There is a little bit of juggling to get syscall and hcall
 -	 * working well. Save r13 in ctr to avoid using SPRG scratch
 -	 * register.
 -	 *
 -	 * Userspace syscalls have already saved the PPR, hcalls must save
 -	 * it before setting HMT_MEDIUM.
 +	.align	7
 +system_call_entry_direct:
 +#if defined(CONFIG_RELOCATABLE)
 +	/* The first level prologue may have used LR to get here, saving
 +	 * orig in r10.  To save hacking/ifdeffing common code, restore here.
  	 */
 -#define SYSCALL_KVMTEST							\
 -	mtctr	r13;							\
 -	GET_PACA(r13);							\
 -	std	r10,PACA_EXGEN+EX_R10(r13);				\
 -	INTERRUPT_TO_KERNEL;						\
 -	KVMTEST_PR(0xc00); /* uses r10, branch to do_kvm_0xc00_system_call */ \
 -	HMT_MEDIUM;							\
 -	mfctr	r9;
++<<<<<<< HEAD
 +	mtlr	r10
++=======
++        mr 	r4,r12
++	ld      r6,_DSISR(r1)
++	bl	__hash_page		/* build HPTE if possible */
++        cmpdi	r3,0			/* see if __hash_page succeeded */
+ 
 -#else
 -#define SYSCALL_KVMTEST							\
 -	HMT_MEDIUM;							\
 -	mr	r9,r13;							\
 -	GET_PACA(r13);							\
 -	INTERRUPT_TO_KERNEL;
 -#endif
 -	
 -#define LOAD_SYSCALL_HANDLER(reg)					\
 -	__LOAD_HANDLER(reg, system_call_common)
++	/* Success */
++	beq	fast_exc_return_irq	/* Return from exception on success */
+ 
 -/*
 - * After SYSCALL_KVMTEST, we reach here with PACA in r13, r13 in r9,
 - * and HMT_MEDIUM.
 - */
 -#define SYSCALL_REAL	 					\
 -	mfspr	r11,SPRN_SRR0 ;					\
 -	mfspr	r12,SPRN_SRR1 ;					\
 -	LOAD_SYSCALL_HANDLER(r10) ; 				\
 -	mtspr	SPRN_SRR0,r10 ; 				\
 -	ld	r10,PACAKMSR(r13) ;				\
 -	mtspr	SPRN_SRR1,r10 ; 				\
 -	RFI_TO_KERNEL ;						\
 -	b	. ;	/* prevent speculative execution */
++	/* Error */
++	blt-	13f
+ 
 -#ifdef CONFIG_PPC_FAST_ENDIAN_SWITCH
 -#define SYSCALL_FASTENDIAN_TEST					\
 -BEGIN_FTR_SECTION						\
 -	cmpdi	r0,0x1ebe ; 					\
 -	beq-	1f ;						\
 -END_FTR_SECTION_IFSET(CPU_FTR_REAL_LE)				\
++	/* Reload DSISR into r4 for the DABR check below */
++	ld      r4,_DSISR(r1)
++#endif /* CONFIG_PPC_BOOK3S_64 */
+ 
 -#define SYSCALL_FASTENDIAN					\
 -	/* Fast LE/BE switch system call */			\
 -1:	mfspr	r12,SPRN_SRR1 ;					\
 -	xori	r12,r12,MSR_LE ;				\
 -	mtspr	SPRN_SRR1,r12 ;					\
 -	mr	r13,r9 ;					\
 -	RFI_TO_USER ;	/* return to userspace */		\
 -	b	. ;	/* prevent speculative execution */
 -#else
 -#define SYSCALL_FASTENDIAN_TEST
 -#define SYSCALL_FASTENDIAN
 -#endif /* CONFIG_PPC_FAST_ENDIAN_SWITCH */
++/* Here we have a page fault that hash_page can't handle. */
++handle_page_fault:
++11:	andis.  r0,r4,DSISR_DABRMATCH@h
++	bne-    handle_dabr_fault
++	ld	r4,_DAR(r1)
++	ld	r5,_DSISR(r1)
++	addi	r3,r1,STACK_FRAME_OVERHEAD
++	bl	do_page_fault
++	cmpdi	r3,0
++	beq+	ret_from_except_lite
++	bl	save_nvgprs
++	mr	r5,r3
++	addi	r3,r1,STACK_FRAME_OVERHEAD
++	lwz	r4,_DAR(r1)
++	bl	bad_page_fault
++	b	ret_from_except
+ 
 -#if defined(CONFIG_RELOCATABLE)
++/* We have a data breakpoint exception - handle it */
++handle_dabr_fault:
++	bl	save_nvgprs
++	ld      r4,_DAR(r1)
++	ld      r5,_DSISR(r1)
++	addi    r3,r1,STACK_FRAME_OVERHEAD
++	bl      do_break
+ 	/*
 -	 * We can't branch directly so we do it via the CTR which
 -	 * is volatile across system calls.
++	 * do_break() may have changed the NV GPRS while handling a breakpoint.
++	 * If so, we need to restore them with their updated values. Don't use
++	 * ret_from_except_lite here.
+ 	 */
 -#define SYSCALL_VIRT						\
 -	LOAD_SYSCALL_HANDLER(r10) ;				\
 -	mtctr	r10 ;						\
 -	mfspr	r11,SPRN_SRR0 ;					\
 -	mfspr	r12,SPRN_SRR1 ;					\
 -	li	r10,MSR_RI ;					\
 -	mtmsrd 	r10,1 ;						\
 -	bctr ;
 -#else
 -	/* We can branch directly */
 -#define SYSCALL_VIRT						\
 -	mfspr	r11,SPRN_SRR0 ;					\
 -	mfspr	r12,SPRN_SRR1 ;					\
 -	li	r10,MSR_RI ;					\
 -	mtmsrd 	r10,1 ;			/* Set RI (EE=0) */	\
 -	b	system_call_common ;
 -#endif
 -
 -EXC_REAL_BEGIN(system_call, 0xc00, 0x100)
 -	SYSCALL_KVMTEST /* loads PACA into r13, and saves r13 to r9 */
 -	SYSCALL_FASTENDIAN_TEST
 -	SYSCALL_REAL
 -	SYSCALL_FASTENDIAN
 -EXC_REAL_END(system_call, 0xc00, 0x100)
++	b       ret_from_except
+ 
 -EXC_VIRT_BEGIN(system_call, 0x4c00, 0x100)
 -	SYSCALL_KVMTEST /* loads PACA into r13, and saves r13 to r9 */
 -	SYSCALL_FASTENDIAN_TEST
 -	SYSCALL_VIRT
 -	SYSCALL_FASTENDIAN
 -EXC_VIRT_END(system_call, 0x4c00, 0x100)
+ 
 -#ifdef CONFIG_KVM_BOOK3S_64_HANDLER
 -	/*
 -	 * This is a hcall, so register convention is as above, with these
 -	 * differences:
 -	 * r13 = PACA
 -	 * ctr = orig r13
 -	 * orig r10 saved in PACA
 -	 */
 -TRAMP_KVM_BEGIN(do_kvm_0xc00)
 -	 /*
 -	  * Save the PPR (on systems that support it) before changing to
 -	  * HMT_MEDIUM. That allows the KVM code to save that value into the
 -	  * guest state (it is the guest's PPR value).
 -	  */
 -	OPT_GET_SPR(r10, SPRN_PPR, CPU_FTR_HAS_PPR)
 -	HMT_MEDIUM
 -	OPT_SAVE_REG_TO_PACA(PACA_EXGEN+EX_PPR, r10, CPU_FTR_HAS_PPR)
 -	mfctr	r10
 -	SET_SCRATCH0(r10)
 -	std	r9,PACA_EXGEN+EX_R9(r13)
 -	mfcr	r9
 -	KVM_HANDLER(PACA_EXGEN, EXC_STD, 0xc00)
++#ifdef CONFIG_PPC_BOOK3S_64
++/* We have a page fault that hash_page could handle but HV refused
++ * the PTE insertion
++ */
++13:	bl	save_nvgprs
++	mr	r5,r3
++	addi	r3,r1,STACK_FRAME_OVERHEAD
++	ld	r4,_DAR(r1)
++	bl	low_hash_fault
++	b	ret_from_except
++>>>>>>> f474c28fbcbe (powerpc/watchpoint: Restore NV GPRs while returning from exception)
  #endif
 +system_call_entry:
 +	b	system_call_common
 +
 +ppc64_runlatch_on_trampoline:
 +	b	__ppc64_runlatch_on
  
 +/*
 + * Here we have detected that the kernel stack pointer is bad.
 + * R9 contains the saved CR, r13 points to the paca,
 + * r10 contains the (bad) kernel stack pointer,
 + * r11 and r12 contain the saved SRR0 and SRR1.
 + * We switch to using an emergency stack, save the registers there,
 + * and call kernel_bad_stack(), which panics.
 + */
 +bad_stack:
 +	ld	r1,PACAEMERGSP(r13)
 +	subi	r1,r1,64+INT_FRAME_SIZE
 +	std	r9,_CCR(r1)
 +	std	r10,GPR1(r1)
 +	std	r11,_NIP(r1)
 +	std	r12,_MSR(r1)
 +	mfspr	r11,SPRN_DAR
 +	mfspr	r12,SPRN_DSISR
 +	std	r11,_DAR(r1)
 +	std	r12,_DSISR(r1)
 +	mflr	r10
 +	mfctr	r11
 +	mfxer	r12
 +	std	r10,_LINK(r1)
 +	std	r11,_CTR(r1)
 +	std	r12,_XER(r1)
 +	SAVE_GPR(0,r1)
 +	SAVE_GPR(2,r1)
 +	ld	r10,EX_R3(r3)
 +	std	r10,GPR3(r1)
 +	SAVE_GPR(4,r1)
 +	SAVE_4GPRS(5,r1)
 +	ld	r9,EX_R9(r3)
 +	ld	r10,EX_R10(r3)
 +	SAVE_2GPRS(9,r1)
 +	ld	r9,EX_R11(r3)
 +	ld	r10,EX_R12(r3)
 +	ld	r11,EX_R13(r3)
 +	std	r9,GPR11(r1)
 +	std	r10,GPR12(r1)
 +	std	r11,GPR13(r1)
 +BEGIN_FTR_SECTION
 +	ld	r10,EX_CFAR(r3)
 +	std	r10,ORIG_GPR3(r1)
 +END_FTR_SECTION_IFSET(CPU_FTR_CFAR)
 +	SAVE_8GPRS(14,r1)
 +	SAVE_10GPRS(22,r1)
 +	lhz	r12,PACA_TRAP_SAVE(r13)
 +	std	r12,_TRAP(r1)
 +	addi	r11,r1,INT_FRAME_SIZE
 +	std	r11,0(r1)
 +	li	r12,0
 +	std	r12,0(r11)
 +	ld	r2,PACATOC(r13)
 +	ld	r11,exception_marker@toc(r2)
 +	std	r12,RESULT(r1)
 +	std	r11,STACK_FRAME_OVERHEAD-16(r1)
 +1:	addi	r3,r1,STACK_FRAME_OVERHEAD
 +	bl	kernel_bad_stack
 +	b	1b
  
 -EXC_REAL(single_step, 0xd00, 0x100)
 -EXC_VIRT(single_step, 0x4d00, 0x100, 0xd00)
 -TRAMP_KVM(PACA_EXGEN, 0xd00)
 -EXC_COMMON(single_step_common, 0xd00, single_step_exception)
 +/*
 + * Here r13 points to the paca, r9 contains the saved CR,
 + * SRR0 and SRR1 are saved in r11 and r12,
 + * r9 - r13 are saved in paca->exgen.
 + */
 +	.align	7
 +	.globl data_access_common
 +data_access_common:
 +	mfspr	r10,SPRN_DAR
 +	std	r10,PACA_EXGEN+EX_DAR(r13)
 +	mfspr	r10,SPRN_DSISR
 +	stw	r10,PACA_EXGEN+EX_DSISR(r13)
 +	EXCEPTION_PROLOG_COMMON(0x300, PACA_EXGEN)
 +	DISABLE_INTS
 +	ld	r12,_MSR(r1)
 +	ld	r3,PACA_EXGEN+EX_DAR(r13)
 +	lwz	r4,PACA_EXGEN+EX_DSISR(r13)
 +	li	r5,0x300
 +	b	do_hash_page		/* Try to handle as hpte fault */
  
 -EXC_REAL_OOL_HV(h_data_storage, 0xe00, 0x20)
 -EXC_VIRT_OOL_HV(h_data_storage, 0x4e00, 0x20, 0xe00)
 -TRAMP_KVM_HV_SKIP(PACA_EXGEN, 0xe00)
 -EXC_COMMON_BEGIN(h_data_storage_common)
 +	.align  7
 +	.globl  h_data_storage_common
 +h_data_storage_common:
  	mfspr   r10,SPRN_HDAR
  	std     r10,PACA_EXGEN+EX_DAR(r13)
  	mfspr   r10,SPRN_HDSISR
* Unmerged path arch/powerpc/kernel/exceptions-64s.S
