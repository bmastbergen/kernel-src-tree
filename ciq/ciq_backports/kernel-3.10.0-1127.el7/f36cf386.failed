x86/speculation/swapgs: Exclude ATOMs from speculation through SWAPGS

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Thomas Gleixner <tglx@linutronix.de>
commit f36cf386e3fec258a341d446915862eded3e13d8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/f36cf386.failed

Intel provided the following information:

 On all current Atom processors, instructions that use a segment register
 value (e.g. a load or store) will not speculatively execute before the
 last writer of that segment retires. Thus they will not use a
 speculatively written segment value.

That means on ATOMs there is no speculation through SWAPGS, so the SWAPGS
entry paths can be excluded from the extra LFENCE if PTI is disabled.

Create a separate bug flag for the through SWAPGS speculation and mark all
out-of-order ATOMs and AMD/HYGON CPUs as not affected. The in-order ATOMs
are excluded from the whole mitigation mess anyway.

	Reported-by: Andrew Cooper <andrew.cooper3@citrix.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Tyler Hicks <tyhicks@canonical.com>
	Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
(cherry picked from commit f36cf386e3fec258a341d446915862eded3e13d8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/kernel/cpu/common.c
diff --cc arch/x86/kernel/cpu/bugs.c
index 9ec6cfa4f503,6383f0db098c..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -216,9 -269,126 +216,104 @@@ static int __init mds_cmdline(char *str
  early_param("mds", mds_cmdline);
  
  #undef pr_fmt
++<<<<<<< HEAD
++=======
+ #define pr_fmt(fmt)     "Spectre V1 : " fmt
+ 
+ enum spectre_v1_mitigation {
+ 	SPECTRE_V1_MITIGATION_NONE,
+ 	SPECTRE_V1_MITIGATION_AUTO,
+ };
+ 
+ static enum spectre_v1_mitigation spectre_v1_mitigation __ro_after_init =
+ 	SPECTRE_V1_MITIGATION_AUTO;
+ 
+ static const char * const spectre_v1_strings[] = {
+ 	[SPECTRE_V1_MITIGATION_NONE] = "Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriers",
+ 	[SPECTRE_V1_MITIGATION_AUTO] = "Mitigation: usercopy/swapgs barriers and __user pointer sanitization",
+ };
+ 
+ /*
+  * Does SMAP provide full mitigation against speculative kernel access to
+  * userspace?
+  */
+ static bool smap_works_speculatively(void)
+ {
+ 	if (!boot_cpu_has(X86_FEATURE_SMAP))
+ 		return false;
+ 
+ 	/*
+ 	 * On CPUs which are vulnerable to Meltdown, SMAP does not
+ 	 * prevent speculative access to user data in the L1 cache.
+ 	 * Consider SMAP to be non-functional as a mitigation on these
+ 	 * CPUs.
+ 	 */
+ 	if (boot_cpu_has(X86_BUG_CPU_MELTDOWN))
+ 		return false;
+ 
+ 	return true;
+ }
+ 
+ static void __init spectre_v1_select_mitigation(void)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V1) || cpu_mitigations_off()) {
+ 		spectre_v1_mitigation = SPECTRE_V1_MITIGATION_NONE;
+ 		return;
+ 	}
+ 
+ 	if (spectre_v1_mitigation == SPECTRE_V1_MITIGATION_AUTO) {
+ 		/*
+ 		 * With Spectre v1, a user can speculatively control either
+ 		 * path of a conditional swapgs with a user-controlled GS
+ 		 * value.  The mitigation is to add lfences to both code paths.
+ 		 *
+ 		 * If FSGSBASE is enabled, the user can put a kernel address in
+ 		 * GS, in which case SMAP provides no protection.
+ 		 *
+ 		 * [ NOTE: Don't check for X86_FEATURE_FSGSBASE until the
+ 		 *	   FSGSBASE enablement patches have been merged. ]
+ 		 *
+ 		 * If FSGSBASE is disabled, the user can only put a user space
+ 		 * address in GS.  That makes an attack harder, but still
+ 		 * possible if there's no SMAP protection.
+ 		 */
+ 		if (!smap_works_speculatively()) {
+ 			/*
+ 			 * Mitigation can be provided from SWAPGS itself or
+ 			 * PTI as the CR3 write in the Meltdown mitigation
+ 			 * is serializing.
+ 			 *
+ 			 * If neither is there, mitigate with an LFENCE to
+ 			 * stop speculation through swapgs.
+ 			 */
+ 			if (boot_cpu_has_bug(X86_BUG_SWAPGS) &&
+ 			    !boot_cpu_has(X86_FEATURE_PTI))
+ 				setup_force_cpu_cap(X86_FEATURE_FENCE_SWAPGS_USER);
+ 
+ 			/*
+ 			 * Enable lfences in the kernel entry (non-swapgs)
+ 			 * paths, to prevent user entry from speculatively
+ 			 * skipping swapgs.
+ 			 */
+ 			setup_force_cpu_cap(X86_FEATURE_FENCE_SWAPGS_KERNEL);
+ 		}
+ 	}
+ 
+ 	pr_info("%s\n", spectre_v1_strings[spectre_v1_mitigation]);
+ }
+ 
+ static int __init nospectre_v1_cmdline(char *str)
+ {
+ 	spectre_v1_mitigation = SPECTRE_V1_MITIGATION_NONE;
+ 	return 0;
+ }
+ early_param("nospectre_v1", nospectre_v1_cmdline);
+ 
+ #undef pr_fmt
++>>>>>>> f36cf386e3fe (x86/speculation/swapgs: Exclude ATOMs from speculation through SWAPGS)
  #define pr_fmt(fmt)     "Spectre V2 : " fmt
  
 -static enum spectre_v2_mitigation spectre_v2_enabled __ro_after_init =
 -	SPECTRE_V2_NONE;
 -
 -static enum spectre_v2_user_mitigation spectre_v2_user __ro_after_init =
 -	SPECTRE_V2_USER_NONE;
 -
 -#ifdef CONFIG_RETPOLINE
 -static bool spectre_v2_bad_module;
 -
 -bool retpoline_module_ok(bool has_retpoline)
 -{
 -	if (spectre_v2_enabled == SPECTRE_V2_NONE || has_retpoline)
 -		return true;
 -
 -	pr_err("System may be vulnerable to spectre v2\n");
 -	spectre_v2_bad_module = true;
 -	return false;
 -}
 -
 -static inline const char *spectre_v2_module_string(void)
 -{
 -	return spectre_v2_bad_module ? " - vulnerable module loaded" : "";
 -}
 -#else
 -static inline const char *spectre_v2_module_string(void) { return ""; }
 -#endif
 +enum spectre_v2_mitigation spectre_v2_enabled = SPECTRE_V2_NONE;
  
  static inline bool match_option(const char *arg, int arglen, const char *opt)
  {
diff --cc arch/x86/kernel/cpu/common.c
index f0257a566938,300dcf00d287..000000000000
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@@ -936,20 -1006,29 +937,33 @@@ static const __initconst struct x86_cpu
  
  	VULNWL_INTEL(CORE_YONAH,		NO_SSB),
  
- 	VULNWL_INTEL(ATOM_AIRMONT_MID,		NO_L1TF | MSBDS_ONLY),
+ 	VULNWL_INTEL(ATOM_AIRMONT_MID,		NO_L1TF | MSBDS_ONLY | NO_SWAPGS),
  
- 	VULNWL_INTEL(ATOM_GOLDMONT,		NO_MDS | NO_L1TF),
- 	VULNWL_INTEL(ATOM_GOLDMONT_X,		NO_MDS | NO_L1TF),
- 	VULNWL_INTEL(ATOM_GOLDMONT_PLUS,	NO_MDS | NO_L1TF),
+ 	VULNWL_INTEL(ATOM_GOLDMONT,		NO_MDS | NO_L1TF | NO_SWAPGS),
+ 	VULNWL_INTEL(ATOM_GOLDMONT_X,		NO_MDS | NO_L1TF | NO_SWAPGS),
+ 	VULNWL_INTEL(ATOM_GOLDMONT_PLUS,	NO_MDS | NO_L1TF | NO_SWAPGS),
+ 
+ 	/*
+ 	 * Technically, swapgs isn't serializing on AMD (despite it previously
+ 	 * being documented as such in the APM).  But according to AMD, %gs is
+ 	 * updated non-speculatively, and the issuing of %gs-relative memory
+ 	 * operands will be blocked until the %gs update completes, which is
+ 	 * good enough for our purposes.
+ 	 */
  
  	/* AMD Family 0xf - 0x12 */
- 	VULNWL_AMD(0x0f,	NO_MELTDOWN | NO_SSB | NO_L1TF | NO_MDS),
- 	VULNWL_AMD(0x10,	NO_MELTDOWN | NO_SSB | NO_L1TF | NO_MDS),
- 	VULNWL_AMD(0x11,	NO_MELTDOWN | NO_SSB | NO_L1TF | NO_MDS),
- 	VULNWL_AMD(0x12,	NO_MELTDOWN | NO_SSB | NO_L1TF | NO_MDS),
+ 	VULNWL_AMD(0x0f,	NO_MELTDOWN | NO_SSB | NO_L1TF | NO_MDS | NO_SWAPGS),
+ 	VULNWL_AMD(0x10,	NO_MELTDOWN | NO_SSB | NO_L1TF | NO_MDS | NO_SWAPGS),
+ 	VULNWL_AMD(0x11,	NO_MELTDOWN | NO_SSB | NO_L1TF | NO_MDS | NO_SWAPGS),
+ 	VULNWL_AMD(0x12,	NO_MELTDOWN | NO_SSB | NO_L1TF | NO_MDS | NO_SWAPGS),
  
  	/* FAMILY_ANY must be last, otherwise 0x0f - 0x12 matches won't work */
++<<<<<<< HEAD
 +	VULNWL_AMD(X86_FAMILY_ANY,	NO_MELTDOWN | NO_L1TF | NO_MDS),
++=======
+ 	VULNWL_AMD(X86_FAMILY_ANY,	NO_MELTDOWN | NO_L1TF | NO_MDS | NO_SWAPGS),
+ 	VULNWL_HYGON(X86_FAMILY_ANY,	NO_MELTDOWN | NO_L1TF | NO_MDS | NO_SWAPGS),
++>>>>>>> f36cf386e3fe (x86/speculation/swapgs: Exclude ATOMs from speculation through SWAPGS)
  	{}
  };
  
diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.h
index dbaf1dd9cc7a..795be9ab5ade 100644
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@ -358,5 +358,6 @@
 #define X86_BUG_L1TF			X86_BUG(18) /* CPU is affected by L1 Terminal Fault */
 #define X86_BUG_MDS			X86_BUG(19) /* CPU is affected by Microarchitectural data sampling */
 #define X86_BUG_MSBDS_ONLY		X86_BUG(20) /* CPU is only affected by the  MSDBS variant of BUG_MDS */
+#define X86_BUG_SWAPGS			X86_BUG(21) /* CPU is affected by speculation through SWAPGS */
 
 #endif /* _ASM_X86_CPUFEATURES_H */
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/kernel/cpu/common.c
