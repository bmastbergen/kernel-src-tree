netfilter: conntrack: resched in nf_ct_iterate_cleanup

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Florian Westphal <fw@strlen.de>
commit d93c6258ee4255749c10012c50a31c08f4e9fb16
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/d93c6258.failed

Ulrich reports soft lockup with following (shortened) callchain:

NMI watchdog: BUG: soft lockup - CPU#1 stuck for 22s!
__netif_receive_skb_core+0x6e4/0x774
process_backlog+0x94/0x160
net_rx_action+0x88/0x178
call_do_softirq+0x24/0x3c
do_softirq+0x54/0x6c
__local_bh_enable_ip+0x7c/0xbc
nf_ct_iterate_cleanup+0x11c/0x22c [nf_conntrack]
masq_inet_event+0x20/0x30 [nf_nat_masquerade_ipv6]
atomic_notifier_call_chain+0x1c/0x2c
ipv6_del_addr+0x1bc/0x220 [ipv6]

Problem is that nf_ct_iterate_cleanup can run for a very long time
since it can be interrupted by softirq processing.
Moreover, atomic_notifier_call_chain runs with rcu readlock held.

So lets call cond_resched() in nf_ct_iterate_cleanup and defer
the call to a work queue for the atomic_notifier_call_chain case.

We also need another cond_resched in get_next_corpse, since we
have to deal with iter() always returning false, in that case
get_next_corpse will walk entire conntrack table.

	Reported-by: Ulrich Weber <uw@ocedo.com>
	Tested-by: Ulrich Weber <uw@ocedo.com>
	Signed-off-by: Florian Westphal <fw@strlen.de>
	Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
(cherry picked from commit d93c6258ee4255749c10012c50a31c08f4e9fb16)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv6/netfilter/nf_nat_masquerade_ipv6.c
diff --cc net/ipv6/netfilter/nf_nat_masquerade_ipv6.c
index e47dc94f678b,051b6a6bfff6..000000000000
--- a/net/ipv6/netfilter/nf_nat_masquerade_ipv6.c
+++ b/net/ipv6/netfilter/nf_nat_masquerade_ipv6.c
@@@ -78,50 -82,94 +82,119 @@@ static struct notifier_block masq_dev_n
  	.notifier_call	= masq_device_event,
  };
  
++<<<<<<< HEAD
 +static int masq_inet6_event(struct notifier_block *this,
 +			    unsigned long event, void *ptr)
++=======
+ struct masq_dev_work {
+ 	struct work_struct work;
+ 	struct net *net;
+ 	int ifindex;
+ };
+ 
+ static void iterate_cleanup_work(struct work_struct *work)
+ {
+ 	struct masq_dev_work *w;
+ 	long index;
+ 
+ 	w = container_of(work, struct masq_dev_work, work);
+ 
+ 	index = w->ifindex;
+ 	nf_ct_iterate_cleanup(w->net, device_cmp, (void *)index, 0, 0);
+ 
+ 	put_net(w->net);
+ 	kfree(w);
+ 	atomic_dec(&v6_worker_count);
+ 	module_put(THIS_MODULE);
+ }
+ 
+ /* ipv6 inet notifier is an atomic notifier, i.e. we cannot
+  * schedule.
+  *
+  * Unfortunately, nf_ct_iterate_cleanup can run for a long
+  * time if there are lots of conntracks and the system
+  * handles high softirq load, so it frequently calls cond_resched
+  * while iterating the conntrack table.
+  *
+  * So we defer nf_ct_iterate_cleanup walk to the system workqueue.
+  *
+  * As we can have 'a lot' of inet_events (depending on amount
+  * of ipv6 addresses being deleted), we also need to add an upper
+  * limit to the number of queued work items.
+  */
+ static int masq_inet_event(struct notifier_block *this,
+ 			   unsigned long event, void *ptr)
++>>>>>>> d93c6258ee42 (netfilter: conntrack: resched in nf_ct_iterate_cleanup)
  {
  	struct inet6_ifaddr *ifa = ptr;
- 	struct netdev_notifier_info info;
+ 	const struct net_device *dev;
+ 	struct masq_dev_work *w;
+ 	struct net *net;
+ 
+ 	if (event != NETDEV_DOWN ||
+ 	    atomic_read(&v6_worker_count) >= MAX_WORK_COUNT)
+ 		return NOTIFY_DONE;
+ 
+ 	dev = ifa->idev->dev;
+ 	net = maybe_get_net(dev_net(dev));
+ 	if (!net)
+ 		return NOTIFY_DONE;
  
- 	netdev_notifier_info_init(&info, ifa->idev->dev);
- 	return masq_device_event(this, event, &info);
+ 	if (!try_module_get(THIS_MODULE))
+ 		goto err_module;
+ 
+ 	w = kmalloc(sizeof(*w), GFP_ATOMIC);
+ 	if (w) {
+ 		atomic_inc(&v6_worker_count);
+ 
+ 		INIT_WORK(&w->work, iterate_cleanup_work);
+ 		w->ifindex = dev->ifindex;
+ 		w->net = net;
+ 		schedule_work(&w->work);
+ 
+ 		return NOTIFY_DONE;
+ 	}
+ 
+ 	module_put(THIS_MODULE);
+  err_module:
+ 	put_net(net);
+ 	return NOTIFY_DONE;
  }
  
 -static struct notifier_block masq_inet_notifier = {
 -	.notifier_call	= masq_inet_event,
 +static struct notifier_block masq_inet6_notifier = {
 +	.notifier_call	= masq_inet6_event,
  };
  
 -static atomic_t masquerade_notifier_refcount = ATOMIC_INIT(0);
 +static int masq_refcnt;
 +static DEFINE_MUTEX(masq_mutex);
  
 -void nf_nat_masquerade_ipv6_register_notifier(void)
 +int nf_nat_masquerade_ipv6_register_notifier(void)
  {
 +	int ret = 0;
 +
 +	mutex_lock(&masq_mutex);
  	/* check if the notifier is already set */
 -	if (atomic_inc_return(&masquerade_notifier_refcount) > 1)
 -		return;
 +	if (++masq_refcnt > 1)
 +		goto out_unlock;
 +
 +	ret = register_netdevice_notifier_rh(&masq_dev_notifier);
 +	if (ret)
 +		goto err_dec;
 +
 +	ret = register_inet6addr_notifier(&masq_inet6_notifier);
 +	if (ret)
 +		goto err_unregister;
  
 -	register_netdevice_notifier(&masq_dev_notifier);
 -	register_inet6addr_notifier(&masq_inet_notifier);
 +	mutex_unlock(&masq_mutex);
 +	return ret;
 +
 +err_unregister:
 +	unregister_netdevice_notifier(&masq_dev_notifier);
 +err_dec:
 +	masq_refcnt--;
 +out_unlock:
 +	mutex_unlock(&masq_mutex);
 +	return ret;
  }
  EXPORT_SYMBOL_GPL(nf_nat_masquerade_ipv6_register_notifier);
  
* Unmerged path net/ipv6/netfilter/nf_nat_masquerade_ipv6.c
diff --git a/net/netfilter/nf_conntrack_core.c b/net/netfilter/nf_conntrack_core.c
index 8ee995b605c1..e6ca29aff413 100644
--- a/net/netfilter/nf_conntrack_core.c
+++ b/net/netfilter/nf_conntrack_core.c
@@ -1532,6 +1532,7 @@ get_next_corpse(struct net *net, int (*iter)(struct nf_conn *i, void *data),
 		}
 		spin_unlock(lockp);
 		local_bh_enable();
+		cond_resched();
 	}
 
 	for_each_possible_cpu(cpu) {
@@ -1544,6 +1545,7 @@ get_next_corpse(struct net *net, int (*iter)(struct nf_conn *i, void *data),
 				set_bit(IPS_DYING_BIT, &ct->status);
 		}
 		spin_unlock_bh(&pcpu->lock);
+		cond_resched();
 	}
 	return NULL;
 found:
@@ -1560,6 +1562,8 @@ void nf_ct_iterate_cleanup(struct net *net,
 	struct nf_conn *ct;
 	unsigned int bucket = 0;
 
+	might_sleep();
+
 	while ((ct = get_next_corpse(net, iter, data, &bucket)) != NULL) {
 		/* Time to push up daises... */
 		if (del_timer(&ct->timeout))
@@ -1568,6 +1572,7 @@ void nf_ct_iterate_cleanup(struct net *net,
 		/* ... else the timer will get him soon. */
 
 		nf_ct_put(ct);
+		cond_resched();
 	}
 }
 EXPORT_SYMBOL_GPL(nf_ct_iterate_cleanup);
