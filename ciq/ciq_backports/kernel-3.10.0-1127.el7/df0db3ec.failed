iomap: Add a page_prepare callback

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Andreas Gruenbacher <agruenba@redhat.com>
commit df0db3ecdb8fc942e9d812558b8e15ecd3e050b1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/df0db3ec.failed

Move the page_done callback into a separate iomap_page_ops structure and
add a page_prepare calback to be called before the next page is written
to.  In gfs2, we'll want to start a transaction in page_prepare and end
it in page_done.  Other filesystems that implement data journaling will
require the same kind of mechanism.

	Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Jan Kara <jack@suse.cz>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
(cherry picked from commit df0db3ecdb8fc942e9d812558b8e15ecd3e050b1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/gfs2/bmap.c
#	fs/iomap.c
diff --cc fs/gfs2/bmap.c
index cbb60a8063dc,f6d1a3893f5a..000000000000
--- a/fs/gfs2/bmap.c
+++ b/fs/gfs2/bmap.c
@@@ -958,17 -965,23 +958,34 @@@ static void gfs2_write_unlock(struct in
  	gfs2_glock_dq_uninit(&ip->i_gh);
  }
  
++<<<<<<< HEAD
 +static void gfs2_iomap_journaled_page_done(struct inode *inode, loff_t pos,
 +					   unsigned copied, struct page *page,
 +					   struct iomap *iomap)
++=======
+ static void gfs2_iomap_page_done(struct inode *inode, loff_t pos,
+ 				 unsigned copied, struct page *page,
+ 				 struct iomap *iomap)
++>>>>>>> df0db3ecdb8f (iomap: Add a page_prepare callback)
  {
  	struct gfs2_inode *ip = GFS2_I(inode);
  
- 	gfs2_page_add_databufs(ip, page, offset_in_page(pos), copied);
+ 	if (page)
+ 		gfs2_page_add_databufs(ip, page, offset_in_page(pos), copied);
  }
  
++<<<<<<< HEAD
 +static int gfs2_iomap_begin_write(struct inode *inode, loff_t pos, loff_t length,
 +				  unsigned flags, struct iomap *iomap,
++=======
+ static const struct iomap_page_ops gfs2_iomap_page_ops = {
+ 	.page_done = gfs2_iomap_page_done,
+ };
+ 
+ static int gfs2_iomap_begin_write(struct inode *inode, loff_t pos,
+ 				  loff_t length, unsigned flags,
+ 				  struct iomap *iomap,
++>>>>>>> df0db3ecdb8f (iomap: Add a page_prepare callback)
  				  struct metapath *mp)
  {
  	struct gfs2_inode *ip = GFS2_I(inode);
diff --cc fs/iomap.c
index b368e069ba43,fbfe20b7f6f0..000000000000
--- a/fs/iomap.c
+++ b/fs/iomap.c
@@@ -145,18 -681,25 +154,32 @@@ iomap_write_begin(struct inode *inode, 
  
  	if (iomap->type == IOMAP_INLINE)
  		iomap_read_inline_data(inode, page, iomap);
 -	else if (iomap->flags & IOMAP_F_BUFFER_HEAD)
 -		status = __block_write_begin_int(page, pos, len, NULL, iomap);
  	else
++<<<<<<< HEAD
 +		status = __block_write_begin_int(page, pos, len, NULL, iomap);
 +
 +	if (unlikely(status)) {
 +		unlock_page(page);
 +		put_page(page);
 +		page = NULL;
++=======
+ 		status = __iomap_write_begin(inode, pos, len, page, iomap);
++>>>>>>> df0db3ecdb8f (iomap: Add a page_prepare callback)
  
- 		iomap_write_failed(inode, pos, len);
- 	}
+ 	if (unlikely(status))
+ 		goto out_unlock;
  
  	*pagep = page;
+ 	return 0;
+ 
+ out_unlock:
+ 	unlock_page(page);
+ 	put_page(page);
+ 	iomap_write_failed(inode, pos, len);
+ 
+ out_no_page:
+ 	if (page_ops && page_ops->page_done)
+ 		page_ops->page_done(inode, pos, 0, NULL, iomap);
  	return status;
  }
  
@@@ -186,15 -777,18 +210,22 @@@ iomap_write_end(struct inode *inode, lo
  	int ret;
  
  	if (iomap->type == IOMAP_INLINE) {
 -		ret = iomap_write_end_inline(inode, page, iomap, pos, copied);
 -	} else if (iomap->flags & IOMAP_F_BUFFER_HEAD) {
 -		ret = block_write_end(NULL, inode->i_mapping, pos, len, copied,
 -				page, NULL);
 +		ret = iomap_write_end_inline(inode, page, iomap, pos, len,
 +				copied);
  	} else {
 -		ret = __iomap_write_end(inode, pos, len, copied, page, iomap);
 +		ret = generic_write_end(NULL, inode->i_mapping, pos, len,
 +				copied, page, NULL);
  	}
  
++<<<<<<< HEAD
 +	if (iomap->page_done)
 +		iomap->page_done(inode, pos, copied, page, iomap);
++=======
+ 	__generic_write_end(inode, pos, ret, page);
+ 	if (page_ops && page_ops->page_done)
+ 		page_ops->page_done(inode, pos, copied, page, iomap);
+ 	put_page(page);
++>>>>>>> df0db3ecdb8f (iomap: Add a page_prepare callback)
  
  	if (ret < len)
  		iomap_write_failed(inode, pos, len);
* Unmerged path fs/gfs2/bmap.c
* Unmerged path fs/iomap.c
diff --git a/include/linux/iomap.h b/include/linux/iomap.h
index 10bfcd107955..b8468c2529e4 100644
--- a/include/linux/iomap.h
+++ b/include/linux/iomap.h
@@ -48,6 +48,8 @@ struct vm_fault;
  */
 #define IOMAP_NULL_ADDR -1ULL	/* addr is not valid */
 
+struct iomap_page_ops;
+
 struct iomap {
 	u64			addr; /* disk offset of mapping, bytes */
 	loff_t			offset;	/* file offset of mapping, bytes */
@@ -58,12 +60,22 @@ struct iomap {
 	struct dax_device	*dax_dev; /* dax_dev for dax operations */
 	void			*inline_data;
 	void			*private; /* filesystem private */
+	const struct iomap_page_ops *page_ops;
+};
 
-	/*
-	 * Called when finished processing a page in the mapping returned in
-	 * this iomap.  At least for now this is only supported in the buffered
-	 * write path.
-	 */
+/*
+ * When a filesystem sets page_ops in an iomap mapping it returns, page_prepare
+ * and page_done will be called for each page written to.  This only applies to
+ * buffered writes as unbuffered writes will not typically have pages
+ * associated with them.
+ *
+ * When page_prepare succeeds, page_done will always be called to do any
+ * cleanup work necessary.  In that page_done call, @page will be NULL if the
+ * associated page could not be obtained.
+ */
+struct iomap_page_ops {
+	int (*page_prepare)(struct inode *inode, loff_t pos, unsigned len,
+			struct iomap *iomap);
 	void (*page_done)(struct inode *inode, loff_t pos, unsigned copied,
 			struct page *page, struct iomap *iomap);
 };
