x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr'

jira LE-2015
cve CVE-2024-2201
Rebuild_History Non-Buildable kernel-5.14.0-427.42.1.el9_4
commit-author Ingo Molnar <mingo@kernel.org>
commit d0485730d2189ffe5d986d4e9e191f1e4d5ffd24
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-5.14.0-427.42.1.el9_4/d0485730.failed

So we are using the 'ia32_cap' value in a number of places,
which got its name from MSR_IA32_ARCH_CAPABILITIES MSR register.

But there's very little 'IA32' about it - this isn't 32-bit only
code, nor does it originate from there, it's just a historic
quirk that many Intel MSR names are prefixed with IA32_.

This is already clear from the helper method around the MSR:
x86_read_arch_cap_msr(), which doesn't have the IA32 prefix.

So rename 'ia32_cap' to 'x86_arch_cap_msr' to be consistent with
its role and with the naming of the helper function.

	Signed-off-by: Ingo Molnar <mingo@kernel.org>
	Cc: Josh Poimboeuf <jpoimboe@redhat.com>
	Cc: Nikolay Borisov <nik.borisov@suse.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Sean Christopherson <seanjc@google.com>
Link: https://lore.kernel.org/r/9592a18a814368e75f8f4b9d74d3883aa4fd1eaf.1712813475.git.jpoimboe@kernel.org
(cherry picked from commit d0485730d2189ffe5d986d4e9e191f1e4d5ffd24)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/apic/apic.c
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/kernel/cpu/common.c
diff --cc arch/x86/kernel/apic/apic.c
index 2dc0943c5bd4,c342c4aa9c68..000000000000
--- a/arch/x86/kernel/apic/apic.c
+++ b/arch/x86/kernel/apic/apic.c
@@@ -1752,6 -1685,19 +1752,22 @@@ enum 
  };
  static int x2apic_state;
  
++<<<<<<< HEAD
++=======
+ static bool x2apic_hw_locked(void)
+ {
+ 	u64 x86_arch_cap_msr;
+ 	u64 msr;
+ 
+ 	x86_arch_cap_msr = x86_read_arch_cap_msr();
+ 	if (x86_arch_cap_msr & ARCH_CAP_XAPIC_DISABLE) {
+ 		rdmsrl(MSR_IA32_XAPIC_DISABLE_STATUS, msr);
+ 		return (msr & LEGACY_XAPIC_DISABLED);
+ 	}
+ 	return false;
+ }
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  static void __x2apic_disable(void)
  {
  	u64 msr;
diff --cc arch/x86/kernel/cpu/bugs.c
index d1c0c8f6898b,1b0cfc136432..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -61,6 -61,8 +61,11 @@@ EXPORT_SYMBOL_GPL(x86_spec_ctrl_current
  u64 x86_pred_cmd __ro_after_init = PRED_CMD_IBPB;
  EXPORT_SYMBOL_GPL(x86_pred_cmd);
  
++<<<<<<< HEAD
++=======
+ static u64 __ro_after_init x86_arch_cap_msr;
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  static DEFINE_MUTEX(spec_ctrl_mutex);
  
  void (*x86_return_thunk)(void) __ro_after_init = __x86_return_thunk;
@@@ -144,6 -146,8 +149,11 @@@ void __init cpu_select_mitigations(void
  		x86_spec_ctrl_base &= ~SPEC_CTRL_MITIGATIONS_MASK;
  	}
  
++<<<<<<< HEAD
++=======
+ 	x86_arch_cap_msr = x86_read_arch_cap_msr();
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  	/* Select the proper CPU mitigations before patching alternatives: */
  	spectre_v1_select_mitigation();
  	spectre_v2_select_mitigation();
@@@ -341,9 -343,8 +351,14 @@@ static void __init taa_select_mitigatio
  	 * On MDS_NO=1 CPUs if ARCH_CAP_TSX_CTRL_MSR is not set, microcode
  	 * update is required.
  	 */
++<<<<<<< HEAD
 +	ia32_cap = x86_read_arch_cap_msr();
 +	if ( (ia32_cap & ARCH_CAP_MDS_NO) &&
 +	    !(ia32_cap & ARCH_CAP_TSX_CTRL_MSR))
++=======
+ 	if ( (x86_arch_cap_msr & ARCH_CAP_MDS_NO) &&
+ 	    !(x86_arch_cap_msr & ARCH_CAP_TSX_CTRL_MSR))
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  		taa_mitigation = TAA_MITIGATION_UCODE_NEEDED;
  
  	/*
@@@ -508,7 -505,7 +523,11 @@@ static void __init rfds_select_mitigati
  	if (rfds_mitigation == RFDS_MITIGATION_OFF)
  		return;
  
++<<<<<<< HEAD
 +	if (x86_read_arch_cap_msr() & ARCH_CAP_RFDS_CLEAR)
++=======
+ 	if (x86_arch_cap_msr & ARCH_CAP_RFDS_CLEAR)
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  		setup_force_cpu_cap(X86_FEATURE_CLEAR_CPU_BUF);
  	else
  		rfds_mitigation = RFDS_MITIGATION_UCODE_NEEDED;
@@@ -669,8 -664,7 +688,12 @@@ static void __init srbds_select_mitigat
  	 * are only exposed to SRBDS when TSX is enabled or when CPU is affected
  	 * by Processor MMIO Stale Data vulnerability.
  	 */
++<<<<<<< HEAD
 +	ia32_cap = x86_read_arch_cap_msr();
 +	if ((ia32_cap & ARCH_CAP_MDS_NO) && !boot_cpu_has(X86_FEATURE_RTM) &&
++=======
+ 	if ((x86_arch_cap_msr & ARCH_CAP_MDS_NO) && !boot_cpu_has(X86_FEATURE_RTM) &&
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  	    !boot_cpu_has_bug(X86_BUG_MMIO_STALE_DATA))
  		srbds_mitigation = SRBDS_MITIGATION_TSX_OFF;
  	else if (boot_cpu_has(X86_FEATURE_HYPERVISOR))
@@@ -813,7 -807,7 +836,11 @@@ static void __init gds_select_mitigatio
  	/* Will verify below that mitigation _can_ be disabled */
  
  	/* No microcode */
++<<<<<<< HEAD
 +	if (!(x86_read_arch_cap_msr() & ARCH_CAP_GDS_CTRL)) {
++=======
+ 	if (!(x86_arch_cap_msr & ARCH_CAP_GDS_CTRL)) {
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  		if (gds_mitigation == GDS_MITIGATION_FORCE) {
  			/*
  			 * This only needs to be done on the boot CPU so do it
@@@ -2814,6 -2801,23 +2841,26 @@@ static char *pbrsb_eibrs_state(void
  	}
  }
  
++<<<<<<< HEAD
++=======
+ static const char *spectre_bhi_state(void)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_BHI))
+ 		return "; BHI: Not affected";
+ 	else if  (boot_cpu_has(X86_FEATURE_CLEAR_BHB_HW))
+ 		return "; BHI: BHI_DIS_S";
+ 	else if  (boot_cpu_has(X86_FEATURE_CLEAR_BHB_LOOP))
+ 		return "; BHI: SW loop, KVM: SW loop";
+ 	else if (boot_cpu_has(X86_FEATURE_RETPOLINE) &&
+ 		 !(x86_arch_cap_msr & ARCH_CAP_RRSBA))
+ 		return "; BHI: Retpoline";
+ 	else if  (boot_cpu_has(X86_FEATURE_CLEAR_BHB_LOOP_ON_VMEXIT))
+ 		return "; BHI: Syscall hardening, KVM: SW loop";
+ 
+ 	return "; BHI: Vulnerable (Syscall hardening enabled)";
+ }
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  static ssize_t spectre_v2_show_state(char *buf)
  {
  	if (spectre_v2_enabled == SPECTRE_V2_LFENCE)
diff --cc arch/x86/kernel/cpu/common.c
index d70234c30213,605c26c009c8..000000000000
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@@ -1461,11 -1342,16 +1461,17 @@@ static void __init cpu_set_bug_bits(str
  	/*
  	 * AMD's AutoIBRS is equivalent to Intel's eIBRS - use the Intel feature
  	 * flag and protect from vendor-specific bugs via the whitelist.
 -	 *
 -	 * Don't use AutoIBRS when SNP is enabled because it degrades host
 -	 * userspace indirect branch performance.
  	 */
++<<<<<<< HEAD
 +	if ((ia32_cap & ARCH_CAP_IBRS_ALL) || cpu_has(c, X86_FEATURE_AUTOIBRS)) {
++=======
+ 	if ((x86_arch_cap_msr & ARCH_CAP_IBRS_ALL) ||
+ 	    (cpu_has(c, X86_FEATURE_AUTOIBRS) &&
+ 	     !cpu_feature_enabled(X86_FEATURE_SEV_SNP))) {
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  		setup_force_cpu_cap(X86_FEATURE_IBRS_ENHANCED);
  		if (!cpu_matches(cpu_vuln_whitelist, NO_EIBRS_PBRSB) &&
- 		    !(ia32_cap & ARCH_CAP_PBRSB_NO))
+ 		    !(x86_arch_cap_msr & ARCH_CAP_PBRSB_NO))
  			setup_force_cpu_bug(X86_BUG_EIBRS_PBRSB);
  	}
  
@@@ -1525,8 -1411,7 +1531,12 @@@
  	}
  
  	if (!cpu_has(c, X86_FEATURE_BTC_NO)) {
++<<<<<<< HEAD
 +		if (cpu_matches(cpu_vuln_blacklist, RETBLEED) ||
 +		   ((ia32_cap & ARCH_CAP_RSBA) && !cpu_in_retbleed_whitelist(c)))
++=======
+ 		if (cpu_matches(cpu_vuln_blacklist, RETBLEED) || (x86_arch_cap_msr & ARCH_CAP_RSBA))
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  			setup_force_cpu_bug(X86_BUG_RETBLEED);
  	}
  
* Unmerged path arch/x86/kernel/apic/apic.c
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/kernel/cpu/common.c
